======================================================
learning_rate: 0.1
weight_decay: 0.0001
momentum: 0.1
batch_size: 100
max_epoch: 500
disp_freq: 50
test_epoch: 5
plot_epoch: 100
network: Lin-784-20 Relu Lin-20-10 Relu
loss: Softmax
result dir: ./result/good_model
======================================================
09:39:07.144 Training @ 0 epoch...
09:39:09.422   Training iter 50, batch loss 2.2939, batch acc 0.1866
09:39:11.667   Training iter 100, batch loss 2.1447, batch acc 0.3172
09:39:13.874   Training iter 150, batch loss 1.7193, batch acc 0.4092
09:39:16.083   Training iter 200, batch loss 1.4729, batch acc 0.4866
09:39:18.307   Training iter 250, batch loss 1.3275, batch acc 0.5616
09:39:20.500   Training iter 300, batch loss 1.1698, batch acc 0.6042
09:39:22.740   Training iter 350, batch loss 1.0886, batch acc 0.6126
09:39:24.996   Training iter 400, batch loss 1.0871, batch acc 0.6072
09:39:27.271   Training iter 450, batch loss 1.0331, batch acc 0.6238
09:39:29.517   Training iter 500, batch loss 1.0199, batch acc 0.6188
09:39:31.754   Training iter 550, batch loss 0.9931, batch acc 0.6290
09:39:34.004   Training iter 600, batch loss 1.0344, batch acc 0.6140
09:39:34.006 Testing @ 0 epoch...
09:39:34.056     Testing, total mean loss 0.98960, total acc 0.62480
09:39:34.056 Plot @ 0 epoch...
09:39:34.056 Training @ 1 epoch...
09:39:36.315   Training iter 50, batch loss 1.0193, batch acc 0.6168
09:39:38.649   Training iter 100, batch loss 1.0058, batch acc 0.6254
09:39:40.911   Training iter 150, batch loss 0.9838, batch acc 0.6302
09:39:43.179   Training iter 200, batch loss 0.9802, batch acc 0.6282
09:39:45.450   Training iter 250, batch loss 1.0028, batch acc 0.6164
09:39:48.208   Training iter 300, batch loss 0.9611, batch acc 0.6352
09:39:50.593   Training iter 350, batch loss 0.9732, batch acc 0.6374
09:39:52.874   Training iter 400, batch loss 0.9880, batch acc 0.6250
09:39:55.196   Training iter 450, batch loss 0.9834, batch acc 0.6248
09:39:57.512   Training iter 500, batch loss 0.9548, batch acc 0.6364
09:39:59.793   Training iter 550, batch loss 0.9517, batch acc 0.6378
09:40:02.076   Training iter 600, batch loss 0.9487, batch acc 0.6380
09:40:02.078 Training @ 2 epoch...
09:40:04.345   Training iter 50, batch loss 0.9513, batch acc 0.6368
09:40:06.595   Training iter 100, batch loss 0.9758, batch acc 0.6312
09:40:08.829   Training iter 150, batch loss 0.9290, batch acc 0.6390
09:40:11.071   Training iter 200, batch loss 0.9403, batch acc 0.6548
09:40:13.330   Training iter 250, batch loss 0.8335, batch acc 0.7254
09:40:15.586   Training iter 300, batch loss 0.8338, batch acc 0.7142
09:40:17.815   Training iter 350, batch loss 0.7970, batch acc 0.7208
09:40:20.042   Training iter 400, batch loss 0.7798, batch acc 0.7262
09:40:22.272   Training iter 450, batch loss 0.7779, batch acc 0.7242
09:40:24.507   Training iter 500, batch loss 0.8050, batch acc 0.7160
09:40:26.787   Training iter 550, batch loss 0.7507, batch acc 0.7292
09:40:29.054   Training iter 600, batch loss 0.7643, batch acc 0.7272
09:40:29.056 Training @ 3 epoch...
09:40:31.328   Training iter 50, batch loss 0.7485, batch acc 0.7282
09:40:33.606   Training iter 100, batch loss 0.7365, batch acc 0.7330
09:40:35.900   Training iter 150, batch loss 0.7364, batch acc 0.7330
09:40:38.930   Training iter 200, batch loss 0.7651, batch acc 0.7238
09:40:41.243   Training iter 250, batch loss 0.7386, batch acc 0.7328
09:40:43.527   Training iter 300, batch loss 0.7306, batch acc 0.7330
09:40:45.812   Training iter 350, batch loss 0.7598, batch acc 0.7236
09:40:48.087   Training iter 400, batch loss 0.7201, batch acc 0.7364
09:40:50.344   Training iter 450, batch loss 0.7219, batch acc 0.7392
09:40:52.688   Training iter 500, batch loss 0.7285, batch acc 0.7322
09:40:54.938   Training iter 550, batch loss 0.7426, batch acc 0.7238
09:40:57.208   Training iter 600, batch loss 0.7180, batch acc 0.7326
09:40:57.210 Training @ 4 epoch...
09:40:59.470   Training iter 50, batch loss 0.7358, batch acc 0.7264
09:41:01.774   Training iter 100, batch loss 0.7019, batch acc 0.7418
09:41:04.078   Training iter 150, batch loss 0.7098, batch acc 0.7360
09:41:06.354   Training iter 200, batch loss 0.7028, batch acc 0.7370
09:41:08.612   Training iter 250, batch loss 0.7282, batch acc 0.7276
09:41:10.866   Training iter 300, batch loss 0.6986, batch acc 0.7424
09:41:13.124   Training iter 350, batch loss 0.7049, batch acc 0.7360
09:41:15.405   Training iter 400, batch loss 0.6923, batch acc 0.7436
09:41:17.752   Training iter 450, batch loss 0.7002, batch acc 0.7450
09:41:20.052   Training iter 500, batch loss 0.7162, batch acc 0.7334
09:41:22.281   Training iter 550, batch loss 0.7132, batch acc 0.7320
09:41:24.512   Training iter 600, batch loss 0.7367, batch acc 0.7346
09:41:24.513 Training @ 5 epoch...
09:41:26.754   Training iter 50, batch loss 0.6960, batch acc 0.7374
09:41:28.995   Training iter 100, batch loss 0.7001, batch acc 0.7386
09:41:31.241   Training iter 150, batch loss 0.7262, batch acc 0.7252
09:41:33.499   Training iter 200, batch loss 0.6920, batch acc 0.7380
09:41:35.799   Training iter 250, batch loss 0.6893, batch acc 0.7410
09:41:38.078   Training iter 300, batch loss 0.6882, batch acc 0.7408
09:41:40.336   Training iter 350, batch loss 0.6917, batch acc 0.7420
09:41:42.603   Training iter 400, batch loss 0.7264, batch acc 0.7296
09:41:44.868   Training iter 450, batch loss 0.6736, batch acc 0.7452
09:41:47.145   Training iter 500, batch loss 0.6696, batch acc 0.7476
09:41:49.416   Training iter 550, batch loss 0.6932, batch acc 0.7408
09:41:51.686   Training iter 600, batch loss 0.6700, batch acc 0.7530
09:41:51.688 Testing @ 5 epoch...
09:41:51.738     Testing, total mean loss 0.68062, total acc 0.74140
09:41:51.738 Training @ 6 epoch...
09:41:54.009   Training iter 50, batch loss 0.7070, batch acc 0.7372
09:41:56.272   Training iter 100, batch loss 0.6961, batch acc 0.7376
09:41:58.524   Training iter 150, batch loss 0.6695, batch acc 0.7484
09:42:00.763   Training iter 200, batch loss 0.6648, batch acc 0.7484
09:42:03.031   Training iter 250, batch loss 0.6304, batch acc 0.7784
09:42:05.311   Training iter 300, batch loss 0.4905, batch acc 0.8306
09:42:07.591   Training iter 350, batch loss 0.4826, batch acc 0.8338
09:42:09.834   Training iter 400, batch loss 0.5052, batch acc 0.8200
09:42:12.068   Training iter 450, batch loss 0.4762, batch acc 0.8290
09:42:14.282   Training iter 500, batch loss 0.4812, batch acc 0.8320
09:42:16.507   Training iter 550, batch loss 0.4854, batch acc 0.8272
09:42:18.734   Training iter 600, batch loss 0.4841, batch acc 0.8246
09:42:18.736 Training @ 7 epoch...
09:42:20.972   Training iter 50, batch loss 0.4598, batch acc 0.8316
09:42:23.200   Training iter 100, batch loss 0.4690, batch acc 0.8294
09:42:25.448   Training iter 150, batch loss 0.4584, batch acc 0.8334
09:42:27.704   Training iter 200, batch loss 0.4661, batch acc 0.8318
09:42:29.990   Training iter 250, batch loss 0.4841, batch acc 0.8284
09:42:32.237   Training iter 300, batch loss 0.4553, batch acc 0.8334
09:42:34.460   Training iter 350, batch loss 0.4703, batch acc 0.8306
09:42:36.696   Training iter 400, batch loss 0.4544, batch acc 0.8344
09:42:38.922   Training iter 450, batch loss 0.4478, batch acc 0.8366
09:42:41.131   Training iter 500, batch loss 0.4733, batch acc 0.8250
09:42:43.350   Training iter 550, batch loss 0.4549, batch acc 0.8354
09:42:45.551   Training iter 600, batch loss 0.4763, batch acc 0.8270
09:42:45.553 Training @ 8 epoch...
09:42:47.817   Training iter 50, batch loss 0.4444, batch acc 0.8328
09:42:50.047   Training iter 100, batch loss 0.4336, batch acc 0.8394
09:42:52.278   Training iter 150, batch loss 0.4495, batch acc 0.8364
09:42:54.527   Training iter 200, batch loss 0.4548, batch acc 0.8350
09:42:56.772   Training iter 250, batch loss 0.4604, batch acc 0.8346
09:42:58.991   Training iter 300, batch loss 0.4623, batch acc 0.8356
09:43:01.208   Training iter 350, batch loss 0.4390, batch acc 0.8362
09:43:03.475   Training iter 400, batch loss 0.4460, batch acc 0.8432
09:43:05.734   Training iter 450, batch loss 0.4326, batch acc 0.8380
09:43:07.997   Training iter 500, batch loss 0.4705, batch acc 0.8256
09:43:10.249   Training iter 550, batch loss 0.4551, batch acc 0.8300
09:43:12.499   Training iter 600, batch loss 0.4540, batch acc 0.8296
09:43:12.501 Training @ 9 epoch...
09:43:14.752   Training iter 50, batch loss 0.4719, batch acc 0.8280
09:43:16.965   Training iter 100, batch loss 0.4330, batch acc 0.8418
09:43:19.190   Training iter 150, batch loss 0.4380, batch acc 0.8372
09:43:21.396   Training iter 200, batch loss 0.4423, batch acc 0.8346
09:43:23.612   Training iter 250, batch loss 0.4789, batch acc 0.8258
09:43:25.863   Training iter 300, batch loss 0.4471, batch acc 0.8380
09:43:28.124   Training iter 350, batch loss 0.4223, batch acc 0.8442
09:43:30.393   Training iter 400, batch loss 0.4428, batch acc 0.8368
09:43:32.630   Training iter 450, batch loss 0.4155, batch acc 0.8464
09:43:34.854   Training iter 500, batch loss 0.4261, batch acc 0.8400
09:43:37.052   Training iter 550, batch loss 0.4299, batch acc 0.8398
09:43:39.279   Training iter 600, batch loss 0.4334, batch acc 0.8418
09:43:39.281 Training @ 10 epoch...
09:43:41.504   Training iter 50, batch loss 0.4595, batch acc 0.8346
09:43:43.724   Training iter 100, batch loss 0.4414, batch acc 0.8364
09:43:45.961   Training iter 150, batch loss 0.4509, batch acc 0.8336
09:43:48.222   Training iter 200, batch loss 0.4504, batch acc 0.8362
09:43:50.466   Training iter 250, batch loss 0.4356, batch acc 0.8348
09:43:52.715   Training iter 300, batch loss 0.4086, batch acc 0.8498
09:43:54.946   Training iter 350, batch loss 0.4225, batch acc 0.8410
09:43:57.190   Training iter 400, batch loss 0.4175, batch acc 0.8450
09:43:59.431   Training iter 450, batch loss 0.4438, batch acc 0.8350
09:44:01.685   Training iter 500, batch loss 0.4231, batch acc 0.8432
09:44:03.966   Training iter 550, batch loss 0.4036, batch acc 0.8510
09:44:06.253   Training iter 600, batch loss 0.4356, batch acc 0.8400
09:44:06.255 Testing @ 10 epoch...
09:44:06.306     Testing, total mean loss 0.44130, total acc 0.83470
09:44:06.306 Training @ 11 epoch...
09:44:08.590   Training iter 50, batch loss 0.4023, batch acc 0.8510
09:44:10.836   Training iter 100, batch loss 0.4353, batch acc 0.8382
09:44:13.085   Training iter 150, batch loss 0.4228, batch acc 0.8394
09:44:15.309   Training iter 200, batch loss 0.4162, batch acc 0.8476
09:44:17.537   Training iter 250, batch loss 0.4324, batch acc 0.8384
09:44:19.770   Training iter 300, batch loss 0.4607, batch acc 0.8296
09:44:21.981   Training iter 350, batch loss 0.4472, batch acc 0.8322
09:44:24.206   Training iter 400, batch loss 0.4248, batch acc 0.8394
09:44:26.598   Training iter 450, batch loss 0.4161, batch acc 0.8462
09:44:28.937   Training iter 500, batch loss 0.4187, batch acc 0.8464
09:44:31.276   Training iter 550, batch loss 0.4068, batch acc 0.8474
09:44:33.602   Training iter 600, batch loss 0.4245, batch acc 0.8428
09:44:33.603 Training @ 12 epoch...
09:44:35.968   Training iter 50, batch loss 0.4028, batch acc 0.8486
09:44:38.347   Training iter 100, batch loss 0.4051, batch acc 0.8470
09:44:40.657   Training iter 150, batch loss 0.4361, batch acc 0.8384
09:44:42.952   Training iter 200, batch loss 0.4151, batch acc 0.8454
09:44:45.266   Training iter 250, batch loss 0.4106, batch acc 0.8446
09:44:47.610   Training iter 300, batch loss 0.4351, batch acc 0.8370
09:44:49.938   Training iter 350, batch loss 0.4122, batch acc 0.8492
09:44:52.249   Training iter 400, batch loss 0.4079, batch acc 0.8478
09:44:54.567   Training iter 450, batch loss 0.4352, batch acc 0.8406
09:44:56.882   Training iter 500, batch loss 0.4314, batch acc 0.8398
09:44:59.195   Training iter 550, batch loss 0.4252, batch acc 0.8412
09:45:01.524   Training iter 600, batch loss 0.4215, batch acc 0.8410
09:45:01.526 Training @ 13 epoch...
09:45:03.918   Training iter 50, batch loss 0.4108, batch acc 0.8484
09:45:06.249   Training iter 100, batch loss 0.4270, batch acc 0.8396
09:45:08.598   Training iter 150, batch loss 0.4117, batch acc 0.8458
09:45:10.881   Training iter 200, batch loss 0.4183, batch acc 0.8434
09:45:13.155   Training iter 250, batch loss 0.4296, batch acc 0.8388
09:45:15.449   Training iter 300, batch loss 0.4191, batch acc 0.8440
09:45:17.827   Training iter 350, batch loss 0.4222, batch acc 0.8422
09:45:20.188   Training iter 400, batch loss 0.4067, batch acc 0.8512
09:45:22.560   Training iter 450, batch loss 0.4090, batch acc 0.8452
09:45:25.030   Training iter 500, batch loss 0.4092, batch acc 0.8464
09:45:27.575   Training iter 550, batch loss 0.4261, batch acc 0.8370
09:45:30.082   Training iter 600, batch loss 0.4030, batch acc 0.8488
09:45:30.084 Training @ 14 epoch...
09:45:32.587   Training iter 50, batch loss 0.4121, batch acc 0.8444
09:45:35.100   Training iter 100, batch loss 0.4077, batch acc 0.8450
09:45:37.628   Training iter 150, batch loss 0.3930, batch acc 0.8484
09:45:40.123   Training iter 200, batch loss 0.3835, batch acc 0.8584
09:45:42.612   Training iter 250, batch loss 0.4244, batch acc 0.8438
09:45:45.079   Training iter 300, batch loss 0.4142, batch acc 0.8458
09:45:47.569   Training iter 350, batch loss 0.3958, batch acc 0.8524
09:45:50.075   Training iter 400, batch loss 0.4174, batch acc 0.8424
09:45:52.583   Training iter 450, batch loss 0.4147, batch acc 0.8446
09:45:55.079   Training iter 500, batch loss 0.4308, batch acc 0.8384
09:45:57.537   Training iter 550, batch loss 0.4067, batch acc 0.8494
09:45:59.811   Training iter 600, batch loss 0.4336, batch acc 0.8352
09:45:59.812 Training @ 15 epoch...
09:46:02.139   Training iter 50, batch loss 0.4319, batch acc 0.8350
09:46:04.438   Training iter 100, batch loss 0.3910, batch acc 0.8524
09:46:06.759   Training iter 150, batch loss 0.3986, batch acc 0.8506
09:46:09.061   Training iter 200, batch loss 0.3903, batch acc 0.8510
09:46:11.359   Training iter 250, batch loss 0.4199, batch acc 0.8428
09:46:13.673   Training iter 300, batch loss 0.3879, batch acc 0.8546
09:46:15.981   Training iter 350, batch loss 0.3953, batch acc 0.8520
09:46:18.261   Training iter 400, batch loss 0.4145, batch acc 0.8394
09:46:20.516   Training iter 450, batch loss 0.4184, batch acc 0.8468
09:46:22.777   Training iter 500, batch loss 0.4049, batch acc 0.8408
09:46:25.039   Training iter 550, batch loss 0.4176, batch acc 0.8458
09:46:27.337   Training iter 600, batch loss 0.4072, batch acc 0.8468
09:46:27.339 Testing @ 15 epoch...
09:46:27.389     Testing, total mean loss 0.43684, total acc 0.83720
09:46:27.389 Training @ 16 epoch...
09:46:29.669   Training iter 50, batch loss 0.3938, batch acc 0.8512
09:46:31.942   Training iter 100, batch loss 0.4079, batch acc 0.8458
09:46:34.215   Training iter 150, batch loss 0.4196, batch acc 0.8414
09:46:36.543   Training iter 200, batch loss 0.4169, batch acc 0.8390
09:46:38.823   Training iter 250, batch loss 0.3948, batch acc 0.8512
09:46:41.101   Training iter 300, batch loss 0.4201, batch acc 0.8414
09:46:43.377   Training iter 350, batch loss 0.4101, batch acc 0.8484
09:46:45.665   Training iter 400, batch loss 0.3809, batch acc 0.8530
09:46:47.976   Training iter 450, batch loss 0.4005, batch acc 0.8476
09:46:50.248   Training iter 500, batch loss 0.3899, batch acc 0.8494
09:46:52.516   Training iter 550, batch loss 0.4042, batch acc 0.8478
09:46:54.792   Training iter 600, batch loss 0.3902, batch acc 0.8538
09:46:54.794 Training @ 17 epoch...
09:46:57.138   Training iter 50, batch loss 0.3622, batch acc 0.8612
09:46:59.464   Training iter 100, batch loss 0.3884, batch acc 0.8548
09:47:01.760   Training iter 150, batch loss 0.4032, batch acc 0.8510
09:47:04.087   Training iter 200, batch loss 0.4156, batch acc 0.8404
09:47:06.370   Training iter 250, batch loss 0.3906, batch acc 0.8522
09:47:08.649   Training iter 300, batch loss 0.3936, batch acc 0.8540
09:47:10.929   Training iter 350, batch loss 0.4093, batch acc 0.8456
09:47:13.253   Training iter 400, batch loss 0.4205, batch acc 0.8372
09:47:15.564   Training iter 450, batch loss 0.4133, batch acc 0.8430
09:47:17.872   Training iter 500, batch loss 0.3889, batch acc 0.8532
09:47:20.163   Training iter 550, batch loss 0.3981, batch acc 0.8512
09:47:22.429   Training iter 600, batch loss 0.4015, batch acc 0.8474
09:47:22.431 Training @ 18 epoch...
09:47:24.712   Training iter 50, batch loss 0.4161, batch acc 0.8464
09:47:27.013   Training iter 100, batch loss 0.3733, batch acc 0.8562
09:47:29.256   Training iter 150, batch loss 0.3948, batch acc 0.8480
09:47:31.538   Training iter 200, batch loss 0.3904, batch acc 0.8506
09:47:33.819   Training iter 250, batch loss 0.3893, batch acc 0.8568
09:47:36.104   Training iter 300, batch loss 0.3824, batch acc 0.8534
09:47:38.394   Training iter 350, batch loss 0.3858, batch acc 0.8514
09:47:40.674   Training iter 400, batch loss 0.4103, batch acc 0.8438
09:47:42.965   Training iter 450, batch loss 0.3937, batch acc 0.8536
09:47:45.272   Training iter 500, batch loss 0.4151, batch acc 0.8446
09:47:47.595   Training iter 550, batch loss 0.3719, batch acc 0.8576
09:47:49.860   Training iter 600, batch loss 0.4186, batch acc 0.8430
09:47:49.861 Training @ 19 epoch...
09:47:52.135   Training iter 50, batch loss 0.3732, batch acc 0.8574
09:47:54.400   Training iter 100, batch loss 0.3976, batch acc 0.8500
09:47:56.721   Training iter 150, batch loss 0.3981, batch acc 0.8486
09:47:59.014   Training iter 200, batch loss 0.3929, batch acc 0.8510
09:48:01.286   Training iter 250, batch loss 0.3697, batch acc 0.8558
09:48:03.620   Training iter 300, batch loss 0.3946, batch acc 0.8534
09:48:05.934   Training iter 350, batch loss 0.3910, batch acc 0.8496
09:48:08.216   Training iter 400, batch loss 0.3903, batch acc 0.8516
09:48:10.488   Training iter 450, batch loss 0.3850, batch acc 0.8530
09:48:12.747   Training iter 500, batch loss 0.3881, batch acc 0.8516
09:48:15.009   Training iter 550, batch loss 0.4018, batch acc 0.8456
09:48:17.279   Training iter 600, batch loss 0.4064, batch acc 0.8454
09:48:17.280 Training @ 20 epoch...
09:48:19.539   Training iter 50, batch loss 0.3658, batch acc 0.8578
09:48:21.798   Training iter 100, batch loss 0.3922, batch acc 0.8502
09:48:24.064   Training iter 150, batch loss 0.3747, batch acc 0.8574
09:48:26.383   Training iter 200, batch loss 0.3943, batch acc 0.8468
09:48:28.661   Training iter 250, batch loss 0.3975, batch acc 0.8484
09:48:30.991   Training iter 300, batch loss 0.3948, batch acc 0.8488
09:48:33.317   Training iter 350, batch loss 0.3820, batch acc 0.8570
09:48:35.577   Training iter 400, batch loss 0.4029, batch acc 0.8442
09:48:37.965   Training iter 450, batch loss 0.3860, batch acc 0.8520
09:48:40.430   Training iter 500, batch loss 0.3722, batch acc 0.8570
09:48:42.877   Training iter 550, batch loss 0.3987, batch acc 0.8472
09:48:45.302   Training iter 600, batch loss 0.4036, batch acc 0.8452
09:48:45.304 Testing @ 20 epoch...
09:48:45.361     Testing, total mean loss 0.41944, total acc 0.84150
09:48:45.361 Training @ 21 epoch...
09:48:47.860   Training iter 50, batch loss 0.3943, batch acc 0.8514
09:48:50.307   Training iter 100, batch loss 0.3910, batch acc 0.8508
09:48:52.748   Training iter 150, batch loss 0.4085, batch acc 0.8448
09:48:55.187   Training iter 200, batch loss 0.3755, batch acc 0.8606
09:48:57.662   Training iter 250, batch loss 0.3701, batch acc 0.8546
09:49:00.086   Training iter 300, batch loss 0.3816, batch acc 0.8580
09:49:02.371   Training iter 350, batch loss 0.3850, batch acc 0.8496
09:49:04.654   Training iter 400, batch loss 0.3734, batch acc 0.8566
09:49:06.937   Training iter 450, batch loss 0.3961, batch acc 0.8490
09:49:09.187   Training iter 500, batch loss 0.3997, batch acc 0.8460
09:49:11.444   Training iter 550, batch loss 0.3874, batch acc 0.8512
09:49:13.709   Training iter 600, batch loss 0.3628, batch acc 0.8584
09:49:13.710 Training @ 22 epoch...
09:49:15.976   Training iter 50, batch loss 0.3698, batch acc 0.8568
09:49:18.235   Training iter 100, batch loss 0.3794, batch acc 0.8572
09:49:20.509   Training iter 150, batch loss 0.3784, batch acc 0.8580
09:49:22.786   Training iter 200, batch loss 0.3865, batch acc 0.8504
09:49:25.059   Training iter 250, batch loss 0.3828, batch acc 0.8506
09:49:27.338   Training iter 300, batch loss 0.3977, batch acc 0.8502
09:49:29.607   Training iter 350, batch loss 0.3797, batch acc 0.8532
09:49:31.874   Training iter 400, batch loss 0.3909, batch acc 0.8538
09:49:34.140   Training iter 450, batch loss 0.3703, batch acc 0.8606
09:49:36.399   Training iter 500, batch loss 0.3767, batch acc 0.8564
09:49:38.668   Training iter 550, batch loss 0.4020, batch acc 0.8444
09:49:40.921   Training iter 600, batch loss 0.3925, batch acc 0.8468
09:49:40.923 Training @ 23 epoch...
09:49:43.182   Training iter 50, batch loss 0.3972, batch acc 0.8492
09:49:45.431   Training iter 100, batch loss 0.3705, batch acc 0.8576
09:49:47.665   Training iter 150, batch loss 0.4096, batch acc 0.8452
09:49:49.907   Training iter 200, batch loss 0.3777, batch acc 0.8554
09:49:52.144   Training iter 250, batch loss 0.3779, batch acc 0.8562
09:49:54.412   Training iter 300, batch loss 0.3925, batch acc 0.8508
09:49:56.668   Training iter 350, batch loss 0.3679, batch acc 0.8600
09:49:58.946   Training iter 400, batch loss 0.3690, batch acc 0.8592
09:50:01.224   Training iter 450, batch loss 0.3782, batch acc 0.8540
09:50:03.525   Training iter 500, batch loss 0.3829, batch acc 0.8520
09:50:05.847   Training iter 550, batch loss 0.3701, batch acc 0.8544
09:50:08.176   Training iter 600, batch loss 0.3857, batch acc 0.8516
09:50:08.178 Training @ 24 epoch...
09:50:10.468   Training iter 50, batch loss 0.3862, batch acc 0.8490
09:50:12.764   Training iter 100, batch loss 0.3806, batch acc 0.8540
09:50:15.050   Training iter 150, batch loss 0.3689, batch acc 0.8564
09:50:17.345   Training iter 200, batch loss 0.3840, batch acc 0.8528
09:50:19.696   Training iter 250, batch loss 0.3782, batch acc 0.8538
09:50:22.034   Training iter 300, batch loss 0.3815, batch acc 0.8532
09:50:24.351   Training iter 350, batch loss 0.3767, batch acc 0.8540
09:50:26.639   Training iter 400, batch loss 0.3777, batch acc 0.8546
09:50:28.920   Training iter 450, batch loss 0.3823, batch acc 0.8526
09:50:31.271   Training iter 500, batch loss 0.3752, batch acc 0.8538
09:50:33.633   Training iter 550, batch loss 0.3826, batch acc 0.8540
09:50:35.987   Training iter 600, batch loss 0.3716, batch acc 0.8604
09:50:35.989 Training @ 25 epoch...
09:50:38.340   Training iter 50, batch loss 0.3819, batch acc 0.8526
09:50:40.621   Training iter 100, batch loss 0.3756, batch acc 0.8588
09:50:42.896   Training iter 150, batch loss 0.3948, batch acc 0.8516
09:50:45.164   Training iter 200, batch loss 0.3573, batch acc 0.8624
09:50:47.496   Training iter 250, batch loss 0.3797, batch acc 0.8510
09:50:49.835   Training iter 300, batch loss 0.3577, batch acc 0.8592
09:50:52.194   Training iter 350, batch loss 0.3824, batch acc 0.8550
09:50:54.502   Training iter 400, batch loss 0.3862, batch acc 0.8528
09:50:56.811   Training iter 450, batch loss 0.3811, batch acc 0.8534
09:50:59.094   Training iter 500, batch loss 0.3711, batch acc 0.8558
09:51:01.366   Training iter 550, batch loss 0.3903, batch acc 0.8504
09:51:03.640   Training iter 600, batch loss 0.3719, batch acc 0.8572
09:51:03.642 Testing @ 25 epoch...
09:51:03.692     Testing, total mean loss 0.39859, total acc 0.84810
09:51:03.692 Training @ 26 epoch...
09:51:05.962   Training iter 50, batch loss 0.3595, batch acc 0.8608
09:51:08.236   Training iter 100, batch loss 0.3765, batch acc 0.8548
09:51:10.500   Training iter 150, batch loss 0.3840, batch acc 0.8520
09:51:12.784   Training iter 200, batch loss 0.3861, batch acc 0.8546
09:51:15.065   Training iter 250, batch loss 0.3856, batch acc 0.8526
09:51:17.355   Training iter 300, batch loss 0.3609, batch acc 0.8572
09:51:19.621   Training iter 350, batch loss 0.3562, batch acc 0.8618
09:51:21.878   Training iter 400, batch loss 0.3889, batch acc 0.8494
09:51:24.147   Training iter 450, batch loss 0.3694, batch acc 0.8588
09:51:26.432   Training iter 500, batch loss 0.3791, batch acc 0.8560
09:51:28.790   Training iter 550, batch loss 0.3801, batch acc 0.8548
09:51:31.114   Training iter 600, batch loss 0.3703, batch acc 0.8580
09:51:31.116 Training @ 27 epoch...
09:51:33.440   Training iter 50, batch loss 0.3660, batch acc 0.8600
09:51:35.719   Training iter 100, batch loss 0.3634, batch acc 0.8600
09:51:38.033   Training iter 150, batch loss 0.3955, batch acc 0.8454
09:51:40.363   Training iter 200, batch loss 0.3652, batch acc 0.8560
09:51:42.622   Training iter 250, batch loss 0.3981, batch acc 0.8456
09:51:44.894   Training iter 300, batch loss 0.3733, batch acc 0.8542
09:51:47.176   Training iter 350, batch loss 0.3626, batch acc 0.8600
09:51:49.458   Training iter 400, batch loss 0.3793, batch acc 0.8560
09:51:51.737   Training iter 450, batch loss 0.3746, batch acc 0.8584
09:51:54.055   Training iter 500, batch loss 0.3612, batch acc 0.8602
09:51:56.383   Training iter 550, batch loss 0.3645, batch acc 0.8576
09:51:58.675   Training iter 600, batch loss 0.3822, batch acc 0.8578
09:51:58.676 Training @ 28 epoch...
09:52:00.957   Training iter 50, batch loss 0.3761, batch acc 0.8550
09:52:03.287   Training iter 100, batch loss 0.3982, batch acc 0.8472
09:52:05.619   Training iter 150, batch loss 0.3802, batch acc 0.8532
09:52:07.922   Training iter 200, batch loss 0.3722, batch acc 0.8564
09:52:10.554   Training iter 250, batch loss 0.3705, batch acc 0.8548
09:52:13.085   Training iter 300, batch loss 0.3472, batch acc 0.8652
09:52:15.341   Training iter 350, batch loss 0.3490, batch acc 0.8666
09:52:17.625   Training iter 400, batch loss 0.3603, batch acc 0.8610
09:52:19.899   Training iter 450, batch loss 0.3790, batch acc 0.8546
09:52:22.167   Training iter 500, batch loss 0.4034, batch acc 0.8456
09:52:24.415   Training iter 550, batch loss 0.3783, batch acc 0.8532
09:52:26.667   Training iter 600, batch loss 0.3543, batch acc 0.8636
09:52:26.669 Training @ 29 epoch...
09:52:28.934   Training iter 50, batch loss 0.3643, batch acc 0.8610
09:52:31.216   Training iter 100, batch loss 0.3583, batch acc 0.8576
09:52:33.491   Training iter 150, batch loss 0.3682, batch acc 0.8572
09:52:35.754   Training iter 200, batch loss 0.3627, batch acc 0.8616
09:52:38.004   Training iter 250, batch loss 0.3660, batch acc 0.8608
09:52:40.241   Training iter 300, batch loss 0.3817, batch acc 0.8514
09:52:42.502   Training iter 350, batch loss 0.3481, batch acc 0.8668
09:52:44.760   Training iter 400, batch loss 0.3733, batch acc 0.8554
09:52:47.024   Training iter 450, batch loss 0.3959, batch acc 0.8456
09:52:49.289   Training iter 500, batch loss 0.3684, batch acc 0.8582
09:52:51.563   Training iter 550, batch loss 0.3645, batch acc 0.8580
09:52:53.837   Training iter 600, batch loss 0.3930, batch acc 0.8474
09:52:53.838 Training @ 30 epoch...
09:52:56.109   Training iter 50, batch loss 0.3549, batch acc 0.8610
09:52:58.376   Training iter 100, batch loss 0.3686, batch acc 0.8584
09:53:00.637   Training iter 150, batch loss 0.3477, batch acc 0.8656
09:53:02.932   Training iter 200, batch loss 0.3790, batch acc 0.8520
09:53:05.217   Training iter 250, batch loss 0.3602, batch acc 0.8622
09:53:07.483   Training iter 300, batch loss 0.3702, batch acc 0.8570
09:53:09.759   Training iter 350, batch loss 0.3733, batch acc 0.8562
09:53:12.014   Training iter 400, batch loss 0.3756, batch acc 0.8576
09:53:14.270   Training iter 450, batch loss 0.3957, batch acc 0.8456
09:53:16.537   Training iter 500, batch loss 0.3825, batch acc 0.8514
09:53:18.804   Training iter 550, batch loss 0.3620, batch acc 0.8610
09:53:21.079   Training iter 600, batch loss 0.3624, batch acc 0.8612
09:53:21.081 Testing @ 30 epoch...
09:53:21.131     Testing, total mean loss 0.38918, total acc 0.85100
09:53:21.131 Training @ 31 epoch...
09:53:23.401   Training iter 50, batch loss 0.3585, batch acc 0.8608
09:53:25.659   Training iter 100, batch loss 0.3545, batch acc 0.8634
09:53:27.939   Training iter 150, batch loss 0.3780, batch acc 0.8524
09:53:30.227   Training iter 200, batch loss 0.3785, batch acc 0.8564
09:53:32.488   Training iter 250, batch loss 0.3695, batch acc 0.8570
09:53:34.746   Training iter 300, batch loss 0.3765, batch acc 0.8540
09:53:37.010   Training iter 350, batch loss 0.3680, batch acc 0.8566
09:53:39.296   Training iter 400, batch loss 0.3867, batch acc 0.8518
09:53:41.578   Training iter 450, batch loss 0.3629, batch acc 0.8590
09:53:43.849   Training iter 500, batch loss 0.3606, batch acc 0.8592
09:53:46.117   Training iter 550, batch loss 0.3657, batch acc 0.8558
09:53:48.379   Training iter 600, batch loss 0.3659, batch acc 0.8590
09:53:48.380 Training @ 32 epoch...
09:53:50.635   Training iter 50, batch loss 0.3593, batch acc 0.8610
09:53:52.897   Training iter 100, batch loss 0.3825, batch acc 0.8528
09:53:55.178   Training iter 150, batch loss 0.3676, batch acc 0.8568
09:53:57.456   Training iter 200, batch loss 0.3663, batch acc 0.8542
09:53:59.724   Training iter 250, batch loss 0.3785, batch acc 0.8502
09:54:01.998   Training iter 300, batch loss 0.3741, batch acc 0.8578
09:54:04.291   Training iter 350, batch loss 0.3640, batch acc 0.8574
09:54:06.579   Training iter 400, batch loss 0.3588, batch acc 0.8582
09:54:08.882   Training iter 450, batch loss 0.3730, batch acc 0.8544
09:54:11.190   Training iter 500, batch loss 0.3487, batch acc 0.8646
09:54:13.495   Training iter 550, batch loss 0.3685, batch acc 0.8562
09:54:15.816   Training iter 600, batch loss 0.3624, batch acc 0.8614
09:54:15.817 Training @ 33 epoch...
09:54:18.142   Training iter 50, batch loss 0.3658, batch acc 0.8578
09:54:20.413   Training iter 100, batch loss 0.3649, batch acc 0.8552
09:54:22.692   Training iter 150, batch loss 0.3688, batch acc 0.8566
09:54:25.042   Training iter 200, batch loss 0.3787, batch acc 0.8602
09:54:27.349   Training iter 250, batch loss 0.3626, batch acc 0.8550
09:54:29.668   Training iter 300, batch loss 0.3505, batch acc 0.8654
09:54:31.965   Training iter 350, batch loss 0.3637, batch acc 0.8602
09:54:34.254   Training iter 400, batch loss 0.3893, batch acc 0.8472
09:54:36.527   Training iter 450, batch loss 0.3671, batch acc 0.8568
09:54:38.811   Training iter 500, batch loss 0.3909, batch acc 0.8510
09:54:41.093   Training iter 550, batch loss 0.3522, batch acc 0.8618
09:54:43.391   Training iter 600, batch loss 0.3361, batch acc 0.8692
09:54:43.393 Training @ 34 epoch...
09:54:45.695   Training iter 50, batch loss 0.3419, batch acc 0.8656
09:54:47.984   Training iter 100, batch loss 0.3950, batch acc 0.8466
09:54:50.277   Training iter 150, batch loss 0.3623, batch acc 0.8588
09:54:52.641   Training iter 200, batch loss 0.3786, batch acc 0.8530
09:54:55.010   Training iter 250, batch loss 0.3620, batch acc 0.8588
09:54:57.319   Training iter 300, batch loss 0.3540, batch acc 0.8642
09:54:59.615   Training iter 350, batch loss 0.3819, batch acc 0.8552
09:55:01.982   Training iter 400, batch loss 0.3598, batch acc 0.8622
09:55:04.279   Training iter 450, batch loss 0.3727, batch acc 0.8536
09:55:06.582   Training iter 500, batch loss 0.3487, batch acc 0.8668
09:55:08.876   Training iter 550, batch loss 0.3483, batch acc 0.8634
09:55:11.208   Training iter 600, batch loss 0.3581, batch acc 0.8610
09:55:11.210 Training @ 35 epoch...
09:55:13.556   Training iter 50, batch loss 0.3638, batch acc 0.8558
09:55:15.888   Training iter 100, batch loss 0.3602, batch acc 0.8596
09:55:18.215   Training iter 150, batch loss 0.3440, batch acc 0.8688
09:55:20.533   Training iter 200, batch loss 0.3742, batch acc 0.8584
09:55:22.842   Training iter 250, batch loss 0.3760, batch acc 0.8526
09:55:25.162   Training iter 300, batch loss 0.3628, batch acc 0.8586
09:55:27.495   Training iter 350, batch loss 0.3548, batch acc 0.8598
09:55:29.924   Training iter 400, batch loss 0.3383, batch acc 0.8710
09:55:32.431   Training iter 450, batch loss 0.3674, batch acc 0.8562
09:55:34.907   Training iter 500, batch loss 0.3855, batch acc 0.8502
09:55:37.215   Training iter 550, batch loss 0.3729, batch acc 0.8544
09:55:39.516   Training iter 600, batch loss 0.3627, batch acc 0.8566
09:55:39.518 Testing @ 35 epoch...
09:55:39.570     Testing, total mean loss 0.40043, total acc 0.84610
09:55:39.570 Training @ 36 epoch...
09:55:41.868   Training iter 50, batch loss 0.3591, batch acc 0.8586
09:55:44.158   Training iter 100, batch loss 0.3418, batch acc 0.8674
09:55:46.462   Training iter 150, batch loss 0.3686, batch acc 0.8564
09:55:48.769   Training iter 200, batch loss 0.3629, batch acc 0.8598
09:55:51.066   Training iter 250, batch loss 0.3723, batch acc 0.8562
09:55:53.339   Training iter 300, batch loss 0.3637, batch acc 0.8630
09:55:55.615   Training iter 350, batch loss 0.3804, batch acc 0.8514
09:55:57.905   Training iter 400, batch loss 0.3611, batch acc 0.8590
09:56:00.213   Training iter 450, batch loss 0.3618, batch acc 0.8578
09:56:02.538   Training iter 500, batch loss 0.3470, batch acc 0.8620
09:56:04.862   Training iter 550, batch loss 0.3492, batch acc 0.8636
09:56:07.178   Training iter 600, batch loss 0.3830, batch acc 0.8536
09:56:07.180 Training @ 37 epoch...
09:56:09.473   Training iter 50, batch loss 0.3542, batch acc 0.8608
09:56:11.765   Training iter 100, batch loss 0.3632, batch acc 0.8572
09:56:14.058   Training iter 150, batch loss 0.3563, batch acc 0.8628
09:56:16.356   Training iter 200, batch loss 0.3574, batch acc 0.8630
09:56:18.657   Training iter 250, batch loss 0.3568, batch acc 0.8584
09:56:20.957   Training iter 300, batch loss 0.3687, batch acc 0.8558
09:56:23.257   Training iter 350, batch loss 0.3529, batch acc 0.8612
09:56:25.595   Training iter 400, batch loss 0.3572, batch acc 0.8608
09:56:27.913   Training iter 450, batch loss 0.3637, batch acc 0.8566
09:56:30.228   Training iter 500, batch loss 0.3607, batch acc 0.8568
09:56:32.533   Training iter 550, batch loss 0.3755, batch acc 0.8528
09:56:34.842   Training iter 600, batch loss 0.3700, batch acc 0.8586
09:56:34.844 Training @ 38 epoch...
09:56:37.172   Training iter 50, batch loss 0.3599, batch acc 0.8606
09:56:39.527   Training iter 100, batch loss 0.3558, batch acc 0.8642
09:56:41.892   Training iter 150, batch loss 0.3598, batch acc 0.8604
09:56:44.217   Training iter 200, batch loss 0.3546, batch acc 0.8620
09:56:46.501   Training iter 250, batch loss 0.3745, batch acc 0.8574
09:56:48.872   Training iter 300, batch loss 0.3554, batch acc 0.8602
09:56:51.277   Training iter 350, batch loss 0.3956, batch acc 0.8466
09:56:53.643   Training iter 400, batch loss 0.3546, batch acc 0.8632
09:56:55.945   Training iter 450, batch loss 0.3569, batch acc 0.8592
09:56:58.265   Training iter 500, batch loss 0.3480, batch acc 0.8642
09:57:00.547   Training iter 550, batch loss 0.3621, batch acc 0.8586
09:57:02.852   Training iter 600, batch loss 0.3462, batch acc 0.8652
09:57:02.854 Training @ 39 epoch...
09:57:05.146   Training iter 50, batch loss 0.3554, batch acc 0.8612
09:57:07.445   Training iter 100, batch loss 0.3649, batch acc 0.8582
09:57:09.743   Training iter 150, batch loss 0.3630, batch acc 0.8590
09:57:12.043   Training iter 200, batch loss 0.3368, batch acc 0.8662
09:57:14.320   Training iter 250, batch loss 0.3884, batch acc 0.8494
09:57:16.618   Training iter 300, batch loss 0.3909, batch acc 0.8486
09:57:18.903   Training iter 350, batch loss 0.3563, batch acc 0.8608
09:57:21.187   Training iter 400, batch loss 0.3642, batch acc 0.8548
09:57:23.508   Training iter 450, batch loss 0.3567, batch acc 0.8632
09:57:25.839   Training iter 500, batch loss 0.3609, batch acc 0.8608
09:57:28.848   Training iter 550, batch loss 0.3254, batch acc 0.8714
09:57:31.181   Training iter 600, batch loss 0.3512, batch acc 0.8640
09:57:31.183 Training @ 40 epoch...
09:57:33.489   Training iter 50, batch loss 0.3558, batch acc 0.8608
09:57:35.810   Training iter 100, batch loss 0.3580, batch acc 0.8618
09:57:38.119   Training iter 150, batch loss 0.3490, batch acc 0.8636
09:57:40.417   Training iter 200, batch loss 0.3458, batch acc 0.8676
09:57:42.707   Training iter 250, batch loss 0.3741, batch acc 0.8536
09:57:44.992   Training iter 300, batch loss 0.3280, batch acc 0.8758
09:57:47.329   Training iter 350, batch loss 0.3513, batch acc 0.8602
09:57:49.646   Training iter 400, batch loss 0.3891, batch acc 0.8480
09:57:51.940   Training iter 450, batch loss 0.3503, batch acc 0.8622
09:57:54.215   Training iter 500, batch loss 0.3663, batch acc 0.8542
09:57:56.525   Training iter 550, batch loss 0.3825, batch acc 0.8504
09:57:58.858   Training iter 600, batch loss 0.3560, batch acc 0.8596
09:57:58.860 Testing @ 40 epoch...
09:57:58.913     Testing, total mean loss 0.39298, total acc 0.84940
09:57:58.913 Training @ 41 epoch...
09:58:01.294   Training iter 50, batch loss 0.3550, batch acc 0.8608
09:58:03.651   Training iter 100, batch loss 0.3621, batch acc 0.8594
09:58:05.950   Training iter 150, batch loss 0.3432, batch acc 0.8648
09:58:08.282   Training iter 200, batch loss 0.3827, batch acc 0.8506
09:58:10.566   Training iter 250, batch loss 0.3541, batch acc 0.8608
09:58:12.877   Training iter 300, batch loss 0.3627, batch acc 0.8596
09:58:15.189   Training iter 350, batch loss 0.3539, batch acc 0.8592
09:58:17.518   Training iter 400, batch loss 0.3757, batch acc 0.8550
09:58:19.825   Training iter 450, batch loss 0.3683, batch acc 0.8556
09:58:22.195   Training iter 500, batch loss 0.3303, batch acc 0.8700
09:58:24.521   Training iter 550, batch loss 0.3525, batch acc 0.8610
09:58:26.823   Training iter 600, batch loss 0.3472, batch acc 0.8652
09:58:26.825 Training @ 42 epoch...
09:58:29.156   Training iter 50, batch loss 0.3671, batch acc 0.8550
09:58:31.512   Training iter 100, batch loss 0.3354, batch acc 0.8682
09:58:33.852   Training iter 150, batch loss 0.3383, batch acc 0.8686
09:58:36.152   Training iter 200, batch loss 0.3431, batch acc 0.8638
09:58:38.486   Training iter 250, batch loss 0.3413, batch acc 0.8648
09:58:40.782   Training iter 300, batch loss 0.3645, batch acc 0.8568
09:58:43.066   Training iter 350, batch loss 0.3608, batch acc 0.8596
09:58:45.364   Training iter 400, batch loss 0.3595, batch acc 0.8618
09:58:47.660   Training iter 450, batch loss 0.3653, batch acc 0.8580
09:58:49.949   Training iter 500, batch loss 0.3679, batch acc 0.8560
09:58:52.242   Training iter 550, batch loss 0.3748, batch acc 0.8550
09:58:54.533   Training iter 600, batch loss 0.3510, batch acc 0.8594
09:58:54.534 Training @ 43 epoch...
09:58:56.821   Training iter 50, batch loss 0.3502, batch acc 0.8630
09:58:59.142   Training iter 100, batch loss 0.3565, batch acc 0.8576
09:59:01.454   Training iter 150, batch loss 0.3408, batch acc 0.8650
09:59:03.761   Training iter 200, batch loss 0.3408, batch acc 0.8682
09:59:06.113   Training iter 250, batch loss 0.3608, batch acc 0.8592
09:59:08.455   Training iter 300, batch loss 0.3610, batch acc 0.8586
09:59:10.791   Training iter 350, batch loss 0.3420, batch acc 0.8648
09:59:13.111   Training iter 400, batch loss 0.3566, batch acc 0.8596
09:59:15.535   Training iter 450, batch loss 0.3570, batch acc 0.8616
09:59:18.011   Training iter 500, batch loss 0.3576, batch acc 0.8620
09:59:20.376   Training iter 550, batch loss 0.3793, batch acc 0.8526
09:59:22.688   Training iter 600, batch loss 0.3673, batch acc 0.8584
09:59:22.690 Training @ 44 epoch...
09:59:24.975   Training iter 50, batch loss 0.3558, batch acc 0.8640
09:59:27.278   Training iter 100, batch loss 0.3294, batch acc 0.8670
09:59:29.563   Training iter 150, batch loss 0.3696, batch acc 0.8532
09:59:31.857   Training iter 200, batch loss 0.3657, batch acc 0.8548
09:59:34.166   Training iter 250, batch loss 0.3430, batch acc 0.8668
09:59:36.500   Training iter 300, batch loss 0.3633, batch acc 0.8570
09:59:38.834   Training iter 350, batch loss 0.3422, batch acc 0.8660
09:59:41.126   Training iter 400, batch loss 0.3699, batch acc 0.8552
09:59:43.427   Training iter 450, batch loss 0.3538, batch acc 0.8642
09:59:45.752   Training iter 500, batch loss 0.3530, batch acc 0.8620
09:59:48.046   Training iter 550, batch loss 0.3512, batch acc 0.8618
09:59:50.339   Training iter 600, batch loss 0.3715, batch acc 0.8564
09:59:50.340 Training @ 45 epoch...
09:59:52.643   Training iter 50, batch loss 0.3689, batch acc 0.8542
09:59:54.936   Training iter 100, batch loss 0.3495, batch acc 0.8630
09:59:57.213   Training iter 150, batch loss 0.3581, batch acc 0.8604
09:59:59.564   Training iter 200, batch loss 0.3340, batch acc 0.8716
10:00:02.098   Training iter 250, batch loss 0.3830, batch acc 0.8490
10:00:04.443   Training iter 300, batch loss 0.3386, batch acc 0.8670
10:00:06.761   Training iter 350, batch loss 0.3550, batch acc 0.8606
10:00:09.065   Training iter 400, batch loss 0.3570, batch acc 0.8594
10:00:11.354   Training iter 450, batch loss 0.3421, batch acc 0.8682
10:00:13.715   Training iter 500, batch loss 0.3585, batch acc 0.8598
10:00:15.959   Training iter 550, batch loss 0.3529, batch acc 0.8632
10:00:18.392   Training iter 600, batch loss 0.3703, batch acc 0.8558
10:00:18.393 Testing @ 45 epoch...
10:00:18.448     Testing, total mean loss 0.39082, total acc 0.85070
10:00:18.448 Training @ 46 epoch...
10:00:20.795   Training iter 50, batch loss 0.3551, batch acc 0.8638
10:00:23.106   Training iter 100, batch loss 0.3502, batch acc 0.8628
10:00:25.423   Training iter 150, batch loss 0.3700, batch acc 0.8548
10:00:27.775   Training iter 200, batch loss 0.3448, batch acc 0.8644
10:00:30.078   Training iter 250, batch loss 0.3577, batch acc 0.8606
10:00:32.376   Training iter 300, batch loss 0.3518, batch acc 0.8616
10:00:34.737   Training iter 350, batch loss 0.3713, batch acc 0.8534
10:00:37.124   Training iter 400, batch loss 0.3331, batch acc 0.8704
10:00:39.549   Training iter 450, batch loss 0.3839, batch acc 0.8480
10:00:41.868   Training iter 500, batch loss 0.3486, batch acc 0.8606
10:00:44.180   Training iter 550, batch loss 0.3531, batch acc 0.8610
10:00:46.478   Training iter 600, batch loss 0.3370, batch acc 0.8662
10:00:46.480 Training @ 47 epoch...
10:00:48.773   Training iter 50, batch loss 0.3715, batch acc 0.8532
10:00:51.069   Training iter 100, batch loss 0.3629, batch acc 0.8560
10:00:53.373   Training iter 150, batch loss 0.3473, batch acc 0.8622
10:00:55.688   Training iter 200, batch loss 0.3368, batch acc 0.8682
10:00:58.026   Training iter 250, batch loss 0.3485, batch acc 0.8616
10:01:00.316   Training iter 300, batch loss 0.3554, batch acc 0.8656
10:01:02.724   Training iter 350, batch loss 0.3260, batch acc 0.8726
10:01:05.102   Training iter 400, batch loss 0.3518, batch acc 0.8588
10:01:07.469   Training iter 450, batch loss 0.3568, batch acc 0.8624
10:01:09.833   Training iter 500, batch loss 0.3820, batch acc 0.8508
10:01:12.186   Training iter 550, batch loss 0.3600, batch acc 0.8604
10:01:14.502   Training iter 600, batch loss 0.3490, batch acc 0.8596
10:01:14.504 Training @ 48 epoch...
10:01:16.810   Training iter 50, batch loss 0.3540, batch acc 0.8616
10:01:19.111   Training iter 100, batch loss 0.3472, batch acc 0.8632
10:01:21.409   Training iter 150, batch loss 0.3621, batch acc 0.8578
10:01:23.778   Training iter 200, batch loss 0.3496, batch acc 0.8618
10:01:26.154   Training iter 250, batch loss 0.3616, batch acc 0.8612
10:01:28.491   Training iter 300, batch loss 0.3606, batch acc 0.8540
10:01:30.792   Training iter 350, batch loss 0.3410, batch acc 0.8672
10:01:33.115   Training iter 400, batch loss 0.3737, batch acc 0.8518
10:01:35.409   Training iter 450, batch loss 0.3666, batch acc 0.8602
10:01:37.744   Training iter 500, batch loss 0.3478, batch acc 0.8646
10:01:40.051   Training iter 550, batch loss 0.3320, batch acc 0.8684
10:01:42.347   Training iter 600, batch loss 0.3435, batch acc 0.8628
10:01:42.349 Training @ 49 epoch...
10:01:44.660   Training iter 50, batch loss 0.3624, batch acc 0.8572
10:01:46.964   Training iter 100, batch loss 0.3318, batch acc 0.8692
10:01:49.254   Training iter 150, batch loss 0.3530, batch acc 0.8624
10:01:51.552   Training iter 200, batch loss 0.3571, batch acc 0.8608
10:01:53.898   Training iter 250, batch loss 0.3607, batch acc 0.8596
10:01:56.239   Training iter 300, batch loss 0.3459, batch acc 0.8636
10:01:58.570   Training iter 350, batch loss 0.3551, batch acc 0.8590
10:02:00.904   Training iter 400, batch loss 0.3326, batch acc 0.8730
10:02:03.248   Training iter 450, batch loss 0.3632, batch acc 0.8568
10:02:05.599   Training iter 500, batch loss 0.3520, batch acc 0.8626
10:02:07.949   Training iter 550, batch loss 0.3482, batch acc 0.8658
10:02:10.401   Training iter 600, batch loss 0.3583, batch acc 0.8606
10:02:10.404 Training @ 50 epoch...
10:02:12.744   Training iter 50, batch loss 0.3513, batch acc 0.8620
10:02:15.078   Training iter 100, batch loss 0.3544, batch acc 0.8608
10:02:17.431   Training iter 150, batch loss 0.3540, batch acc 0.8596
10:02:19.815   Training iter 200, batch loss 0.3479, batch acc 0.8610
10:02:22.183   Training iter 250, batch loss 0.3343, batch acc 0.8648
10:02:24.560   Training iter 300, batch loss 0.3533, batch acc 0.8620
10:02:26.908   Training iter 350, batch loss 0.3371, batch acc 0.8686
10:02:29.262   Training iter 400, batch loss 0.3468, batch acc 0.8642
10:02:31.587   Training iter 450, batch loss 0.3541, batch acc 0.8620
10:02:33.921   Training iter 500, batch loss 0.3570, batch acc 0.8586
10:02:36.272   Training iter 550, batch loss 0.3485, batch acc 0.8624
10:02:38.593   Training iter 600, batch loss 0.3720, batch acc 0.8532
10:02:38.595 Testing @ 50 epoch...
10:02:38.647     Testing, total mean loss 0.38580, total acc 0.85150
10:02:38.647 Training @ 51 epoch...
10:02:40.952   Training iter 50, batch loss 0.3854, batch acc 0.8540
10:02:43.264   Training iter 100, batch loss 0.3472, batch acc 0.8628
10:02:45.572   Training iter 150, batch loss 0.3553, batch acc 0.8586
10:02:47.921   Training iter 200, batch loss 0.3179, batch acc 0.8744
10:02:50.284   Training iter 250, batch loss 0.3371, batch acc 0.8696
10:02:52.646   Training iter 300, batch loss 0.3340, batch acc 0.8670
10:02:54.966   Training iter 350, batch loss 0.3593, batch acc 0.8578
10:02:57.343   Training iter 400, batch loss 0.3587, batch acc 0.8594
10:02:59.639   Training iter 450, batch loss 0.3517, batch acc 0.8624
10:03:01.941   Training iter 500, batch loss 0.3623, batch acc 0.8588
10:03:04.252   Training iter 550, batch loss 0.3617, batch acc 0.8586
10:03:06.578   Training iter 600, batch loss 0.3375, batch acc 0.8664
10:03:06.579 Training @ 52 epoch...
10:03:08.924   Training iter 50, batch loss 0.3415, batch acc 0.8668
10:03:11.238   Training iter 100, batch loss 0.3543, batch acc 0.8602
10:03:13.590   Training iter 150, batch loss 0.3420, batch acc 0.8652
10:03:15.952   Training iter 200, batch loss 0.3680, batch acc 0.8538
10:03:18.284   Training iter 250, batch loss 0.3609, batch acc 0.8552
10:03:20.600   Training iter 300, batch loss 0.3565, batch acc 0.8584
10:03:22.923   Training iter 350, batch loss 0.3413, batch acc 0.8644
10:03:25.586   Training iter 400, batch loss 0.3653, batch acc 0.8562
10:03:28.054   Training iter 450, batch loss 0.3598, batch acc 0.8610
10:03:30.764   Training iter 500, batch loss 0.3347, batch acc 0.8678
10:03:33.057   Training iter 550, batch loss 0.3492, batch acc 0.8648
10:03:35.338   Training iter 600, batch loss 0.3359, batch acc 0.8692
10:03:35.340 Training @ 53 epoch...
10:03:37.645   Training iter 50, batch loss 0.3553, batch acc 0.8578
10:03:40.003   Training iter 100, batch loss 0.3233, batch acc 0.8728
10:03:42.358   Training iter 150, batch loss 0.3588, batch acc 0.8584
10:03:44.687   Training iter 200, batch loss 0.3612, batch acc 0.8590
10:03:46.962   Training iter 250, batch loss 0.3570, batch acc 0.8590
10:03:49.313   Training iter 300, batch loss 0.3591, batch acc 0.8602
10:03:51.680   Training iter 350, batch loss 0.3552, batch acc 0.8612
10:03:54.041   Training iter 400, batch loss 0.3495, batch acc 0.8640
10:03:56.348   Training iter 450, batch loss 0.3377, batch acc 0.8666
10:03:58.644   Training iter 500, batch loss 0.3443, batch acc 0.8626
10:04:00.923   Training iter 550, batch loss 0.3210, batch acc 0.8760
10:04:03.245   Training iter 600, batch loss 0.3755, batch acc 0.8530
10:04:03.247 Training @ 54 epoch...
10:04:05.534   Training iter 50, batch loss 0.3426, batch acc 0.8650
10:04:07.855   Training iter 100, batch loss 0.3569, batch acc 0.8574
10:04:10.231   Training iter 150, batch loss 0.3357, batch acc 0.8642
10:04:12.601   Training iter 200, batch loss 0.3483, batch acc 0.8636
10:04:14.931   Training iter 250, batch loss 0.3485, batch acc 0.8640
10:04:17.205   Training iter 300, batch loss 0.3484, batch acc 0.8620
10:04:19.474   Training iter 350, batch loss 0.3634, batch acc 0.8588
10:04:21.753   Training iter 400, batch loss 0.3516, batch acc 0.8646
10:04:24.056   Training iter 450, batch loss 0.3389, batch acc 0.8678
10:04:26.365   Training iter 500, batch loss 0.3444, batch acc 0.8630
10:04:28.681   Training iter 550, batch loss 0.3662, batch acc 0.8540
10:04:31.002   Training iter 600, batch loss 0.3530, batch acc 0.8616
10:04:31.003 Training @ 55 epoch...
10:04:33.330   Training iter 50, batch loss 0.3535, batch acc 0.8614
10:04:35.609   Training iter 100, batch loss 0.3469, batch acc 0.8634
10:04:37.898   Training iter 150, batch loss 0.3492, batch acc 0.8626
10:04:40.204   Training iter 200, batch loss 0.3285, batch acc 0.8706
10:04:42.517   Training iter 250, batch loss 0.3540, batch acc 0.8618
10:04:44.820   Training iter 300, batch loss 0.3595, batch acc 0.8560
10:04:47.112   Training iter 350, batch loss 0.3337, batch acc 0.8694
10:04:49.414   Training iter 400, batch loss 0.3601, batch acc 0.8578
10:04:51.701   Training iter 450, batch loss 0.3648, batch acc 0.8546
10:04:53.994   Training iter 500, batch loss 0.3390, batch acc 0.8676
10:04:56.332   Training iter 550, batch loss 0.3516, batch acc 0.8668
10:04:58.669   Training iter 600, batch loss 0.3399, batch acc 0.8622
10:04:58.671 Testing @ 55 epoch...
10:04:58.722     Testing, total mean loss 0.40171, total acc 0.84840
10:04:58.722 Training @ 56 epoch...
10:05:01.027   Training iter 50, batch loss 0.3604, batch acc 0.8580
10:05:03.363   Training iter 100, batch loss 0.3681, batch acc 0.8542
10:05:05.651   Training iter 150, batch loss 0.3311, batch acc 0.8726
10:05:07.942   Training iter 200, batch loss 0.3405, batch acc 0.8648
10:05:10.245   Training iter 250, batch loss 0.3398, batch acc 0.8672
10:05:12.549   Training iter 300, batch loss 0.3477, batch acc 0.8622
10:05:14.864   Training iter 350, batch loss 0.3764, batch acc 0.8564
10:05:17.175   Training iter 400, batch loss 0.3299, batch acc 0.8724
10:05:19.623   Training iter 450, batch loss 0.3486, batch acc 0.8630
10:05:21.912   Training iter 500, batch loss 0.3330, batch acc 0.8662
10:05:24.194   Training iter 550, batch loss 0.3446, batch acc 0.8626
10:05:26.518   Training iter 600, batch loss 0.3653, batch acc 0.8558
10:05:26.520 Training @ 57 epoch...
10:05:29.442   Training iter 50, batch loss 0.3512, batch acc 0.8614
10:05:31.753   Training iter 100, batch loss 0.3482, batch acc 0.8614
10:05:34.044   Training iter 150, batch loss 0.3347, batch acc 0.8680
10:05:36.328   Training iter 200, batch loss 0.3340, batch acc 0.8684
10:05:38.604   Training iter 250, batch loss 0.3617, batch acc 0.8562
10:05:40.875   Training iter 300, batch loss 0.3527, batch acc 0.8622
10:05:43.164   Training iter 350, batch loss 0.3580, batch acc 0.8572
10:05:45.450   Training iter 400, batch loss 0.3616, batch acc 0.8582
10:05:47.747   Training iter 450, batch loss 0.3521, batch acc 0.8628
10:05:50.029   Training iter 500, batch loss 0.3230, batch acc 0.8746
10:05:52.310   Training iter 550, batch loss 0.3480, batch acc 0.8628
10:05:54.606   Training iter 600, batch loss 0.3445, batch acc 0.8604
10:05:54.607 Training @ 58 epoch...
10:05:56.887   Training iter 50, batch loss 0.3227, batch acc 0.8706
10:05:59.169   Training iter 100, batch loss 0.3448, batch acc 0.8642
10:06:01.461   Training iter 150, batch loss 0.3455, batch acc 0.8630
10:06:03.782   Training iter 200, batch loss 0.3326, batch acc 0.8702
10:06:06.090   Training iter 250, batch loss 0.3485, batch acc 0.8626
10:06:08.395   Training iter 300, batch loss 0.3317, batch acc 0.8644
10:06:10.680   Training iter 350, batch loss 0.3554, batch acc 0.8590
10:06:12.977   Training iter 400, batch loss 0.3410, batch acc 0.8658
10:06:15.277   Training iter 450, batch loss 0.3622, batch acc 0.8600
10:06:17.589   Training iter 500, batch loss 0.3773, batch acc 0.8500
10:06:19.900   Training iter 550, batch loss 0.3444, batch acc 0.8632
10:06:22.192   Training iter 600, batch loss 0.3695, batch acc 0.8570
10:06:22.193 Training @ 59 epoch...
10:06:24.485   Training iter 50, batch loss 0.3423, batch acc 0.8642
10:06:26.793   Training iter 100, batch loss 0.3438, batch acc 0.8674
10:06:29.098   Training iter 150, batch loss 0.3661, batch acc 0.8542
10:06:31.405   Training iter 200, batch loss 0.3395, batch acc 0.8690
10:06:33.709   Training iter 250, batch loss 0.3486, batch acc 0.8632
10:06:36.012   Training iter 300, batch loss 0.3602, batch acc 0.8568
10:06:38.291   Training iter 350, batch loss 0.3608, batch acc 0.8578
10:06:40.565   Training iter 400, batch loss 0.3523, batch acc 0.8600
10:06:42.841   Training iter 450, batch loss 0.3157, batch acc 0.8748
10:06:45.106   Training iter 500, batch loss 0.3392, batch acc 0.8632
10:06:47.389   Training iter 550, batch loss 0.3390, batch acc 0.8670
10:06:49.682   Training iter 600, batch loss 0.3580, batch acc 0.8586
10:06:49.683 Training @ 60 epoch...
10:06:51.976   Training iter 50, batch loss 0.3331, batch acc 0.8700
10:06:54.257   Training iter 100, batch loss 0.3357, batch acc 0.8678
10:06:56.541   Training iter 150, batch loss 0.3594, batch acc 0.8566
10:06:58.819   Training iter 200, batch loss 0.3662, batch acc 0.8542
10:07:01.082   Training iter 250, batch loss 0.3192, batch acc 0.8734
10:07:03.362   Training iter 300, batch loss 0.3579, batch acc 0.8620
10:07:05.634   Training iter 350, batch loss 0.3394, batch acc 0.8648
10:07:07.931   Training iter 400, batch loss 0.3344, batch acc 0.8680
10:07:10.197   Training iter 450, batch loss 0.3726, batch acc 0.8516
10:07:12.456   Training iter 500, batch loss 0.3402, batch acc 0.8670
10:07:14.735   Training iter 550, batch loss 0.3573, batch acc 0.8578
10:07:17.020   Training iter 600, batch loss 0.3327, batch acc 0.8682
10:07:17.022 Testing @ 60 epoch...
10:07:17.074     Testing, total mean loss 0.39203, total acc 0.85210
10:07:17.074 Training @ 61 epoch...
10:07:19.368   Training iter 50, batch loss 0.3442, batch acc 0.8636
10:07:21.650   Training iter 100, batch loss 0.3222, batch acc 0.8744
10:07:23.935   Training iter 150, batch loss 0.3509, batch acc 0.8600
10:07:26.239   Training iter 200, batch loss 0.3506, batch acc 0.8582
10:07:28.545   Training iter 250, batch loss 0.3299, batch acc 0.8688
10:07:30.846   Training iter 300, batch loss 0.3346, batch acc 0.8668
10:07:33.139   Training iter 350, batch loss 0.3497, batch acc 0.8642
10:07:35.419   Training iter 400, batch loss 0.3427, batch acc 0.8650
10:07:37.709   Training iter 450, batch loss 0.3615, batch acc 0.8584
10:07:39.991   Training iter 500, batch loss 0.3575, batch acc 0.8568
10:07:42.271   Training iter 550, batch loss 0.3445, batch acc 0.8640
10:07:44.566   Training iter 600, batch loss 0.3590, batch acc 0.8600
10:07:44.567 Training @ 62 epoch...
10:07:46.873   Training iter 50, batch loss 0.3404, batch acc 0.8648
10:07:49.166   Training iter 100, batch loss 0.3533, batch acc 0.8596
10:07:51.464   Training iter 150, batch loss 0.3395, batch acc 0.8650
10:07:53.764   Training iter 200, batch loss 0.3691, batch acc 0.8546
10:07:56.064   Training iter 250, batch loss 0.3382, batch acc 0.8680
10:07:58.361   Training iter 300, batch loss 0.3352, batch acc 0.8686
10:08:00.652   Training iter 350, batch loss 0.3385, batch acc 0.8656
10:08:02.970   Training iter 400, batch loss 0.3683, batch acc 0.8530
10:08:05.274   Training iter 450, batch loss 0.3478, batch acc 0.8652
10:08:07.577   Training iter 500, batch loss 0.3477, batch acc 0.8606
10:08:09.859   Training iter 550, batch loss 0.3358, batch acc 0.8680
10:08:12.153   Training iter 600, batch loss 0.3402, batch acc 0.8642
10:08:12.155 Training @ 63 epoch...
10:08:14.433   Training iter 50, batch loss 0.3326, batch acc 0.8724
10:08:16.702   Training iter 100, batch loss 0.3194, batch acc 0.8702
10:08:18.995   Training iter 150, batch loss 0.3443, batch acc 0.8650
10:08:21.286   Training iter 200, batch loss 0.3669, batch acc 0.8530
10:08:23.592   Training iter 250, batch loss 0.3572, batch acc 0.8564
10:08:25.884   Training iter 300, batch loss 0.3403, batch acc 0.8668
10:08:28.179   Training iter 350, batch loss 0.3279, batch acc 0.8686
10:08:30.470   Training iter 400, batch loss 0.3500, batch acc 0.8606
10:08:32.765   Training iter 450, batch loss 0.3702, batch acc 0.8548
10:08:35.055   Training iter 500, batch loss 0.3607, batch acc 0.8604
10:08:37.866   Training iter 550, batch loss 0.3332, batch acc 0.8686
10:08:40.161   Training iter 600, batch loss 0.3417, batch acc 0.8658
10:08:40.163 Training @ 64 epoch...
10:08:42.463   Training iter 50, batch loss 0.3398, batch acc 0.8670
10:08:44.758   Training iter 100, batch loss 0.3724, batch acc 0.8556
10:08:47.049   Training iter 150, batch loss 0.3391, batch acc 0.8658
10:08:49.336   Training iter 200, batch loss 0.3464, batch acc 0.8632
10:08:51.614   Training iter 250, batch loss 0.3411, batch acc 0.8646
10:08:53.898   Training iter 300, batch loss 0.3105, batch acc 0.8760
10:08:56.193   Training iter 350, batch loss 0.3410, batch acc 0.8634
10:08:58.496   Training iter 400, batch loss 0.3488, batch acc 0.8608
10:09:00.819   Training iter 450, batch loss 0.3590, batch acc 0.8574
10:09:03.151   Training iter 500, batch loss 0.3224, batch acc 0.8714
10:09:05.447   Training iter 550, batch loss 0.3501, batch acc 0.8642
10:09:07.742   Training iter 600, batch loss 0.3706, batch acc 0.8524
10:09:07.744 Training @ 65 epoch...
10:09:10.043   Training iter 50, batch loss 0.3263, batch acc 0.8682
10:09:12.329   Training iter 100, batch loss 0.3431, batch acc 0.8626
10:09:14.618   Training iter 150, batch loss 0.3561, batch acc 0.8598
10:09:16.917   Training iter 200, batch loss 0.3322, batch acc 0.8674
10:09:19.211   Training iter 250, batch loss 0.3548, batch acc 0.8600
10:09:21.496   Training iter 300, batch loss 0.3399, batch acc 0.8656
10:09:23.774   Training iter 350, batch loss 0.3207, batch acc 0.8708
10:09:26.058   Training iter 400, batch loss 0.3555, batch acc 0.8580
10:09:28.344   Training iter 450, batch loss 0.3367, batch acc 0.8664
10:09:30.698   Training iter 500, batch loss 0.3406, batch acc 0.8690
10:09:32.990   Training iter 550, batch loss 0.3634, batch acc 0.8592
10:09:35.278   Training iter 600, batch loss 0.3528, batch acc 0.8588
10:09:35.280 Testing @ 65 epoch...
10:09:35.331     Testing, total mean loss 0.39521, total acc 0.85190
10:09:35.331 Training @ 66 epoch...
10:09:37.626   Training iter 50, batch loss 0.3620, batch acc 0.8594
10:09:39.912   Training iter 100, batch loss 0.3414, batch acc 0.8646
10:09:42.197   Training iter 150, batch loss 0.3511, batch acc 0.8606
10:09:44.472   Training iter 200, batch loss 0.3555, batch acc 0.8586
10:09:46.779   Training iter 250, batch loss 0.3217, batch acc 0.8710
10:09:49.097   Training iter 300, batch loss 0.3449, batch acc 0.8634
10:09:51.392   Training iter 350, batch loss 0.3332, batch acc 0.8686
10:09:53.681   Training iter 400, batch loss 0.3384, batch acc 0.8668
10:09:55.966   Training iter 450, batch loss 0.3475, batch acc 0.8620
10:09:58.278   Training iter 500, batch loss 0.3573, batch acc 0.8592
10:10:00.585   Training iter 550, batch loss 0.3351, batch acc 0.8678
10:10:02.915   Training iter 600, batch loss 0.3379, batch acc 0.8644
10:10:02.917 Training @ 67 epoch...
10:10:05.229   Training iter 50, batch loss 0.3705, batch acc 0.8546
10:10:07.568   Training iter 100, batch loss 0.3446, batch acc 0.8630
10:10:09.899   Training iter 150, batch loss 0.3259, batch acc 0.8718
10:10:12.216   Training iter 200, batch loss 0.3465, batch acc 0.8596
10:10:14.539   Training iter 250, batch loss 0.3340, batch acc 0.8674
10:10:16.865   Training iter 300, batch loss 0.3398, batch acc 0.8646
10:10:19.209   Training iter 350, batch loss 0.3504, batch acc 0.8622
10:10:21.533   Training iter 400, batch loss 0.3213, batch acc 0.8724
10:10:23.859   Training iter 450, batch loss 0.3537, batch acc 0.8586
10:10:26.184   Training iter 500, batch loss 0.3374, batch acc 0.8676
10:10:28.510   Training iter 550, batch loss 0.3340, batch acc 0.8708
10:10:30.842   Training iter 600, batch loss 0.3576, batch acc 0.8612
10:10:30.843 Training @ 68 epoch...
10:10:33.194   Training iter 50, batch loss 0.3465, batch acc 0.8638
10:10:35.602   Training iter 100, batch loss 0.3546, batch acc 0.8566
10:10:37.915   Training iter 150, batch loss 0.3488, batch acc 0.8630
10:10:40.210   Training iter 200, batch loss 0.3205, batch acc 0.8712
10:10:42.478   Training iter 250, batch loss 0.3455, batch acc 0.8644
10:10:44.750   Training iter 300, batch loss 0.3634, batch acc 0.8540
10:10:47.022   Training iter 350, batch loss 0.3400, batch acc 0.8622
10:10:49.298   Training iter 400, batch loss 0.3071, batch acc 0.8770
10:10:51.594   Training iter 450, batch loss 0.3551, batch acc 0.8610
10:10:53.892   Training iter 500, batch loss 0.3466, batch acc 0.8618
10:10:56.218   Training iter 550, batch loss 0.3440, batch acc 0.8644
10:10:58.580   Training iter 600, batch loss 0.3437, batch acc 0.8650
10:10:58.582 Training @ 69 epoch...
10:11:00.980   Training iter 50, batch loss 0.3186, batch acc 0.8718
10:11:03.401   Training iter 100, batch loss 0.3398, batch acc 0.8672
10:11:05.794   Training iter 150, batch loss 0.3277, batch acc 0.8720
10:11:08.191   Training iter 200, batch loss 0.3260, batch acc 0.8716
10:11:10.513   Training iter 250, batch loss 0.3426, batch acc 0.8638
10:11:12.825   Training iter 300, batch loss 0.3654, batch acc 0.8526
10:11:15.130   Training iter 350, batch loss 0.3494, batch acc 0.8642
10:11:17.439   Training iter 400, batch loss 0.3414, batch acc 0.8646
10:11:19.821   Training iter 450, batch loss 0.3417, batch acc 0.8668
10:11:22.186   Training iter 500, batch loss 0.3589, batch acc 0.8578
10:11:24.511   Training iter 550, batch loss 0.3561, batch acc 0.8588
10:11:26.835   Training iter 600, batch loss 0.3495, batch acc 0.8618
10:11:26.837 Training @ 70 epoch...
10:11:29.280   Training iter 50, batch loss 0.3424, batch acc 0.8662
10:11:31.624   Training iter 100, batch loss 0.3272, batch acc 0.8728
10:11:33.941   Training iter 150, batch loss 0.3468, batch acc 0.8602
10:11:36.225   Training iter 200, batch loss 0.3463, batch acc 0.8614
10:11:38.524   Training iter 250, batch loss 0.3407, batch acc 0.8638
10:11:40.826   Training iter 300, batch loss 0.3456, batch acc 0.8630
10:11:43.350   Training iter 350, batch loss 0.3285, batch acc 0.8688
10:11:45.906   Training iter 400, batch loss 0.3542, batch acc 0.8592
10:11:48.439   Training iter 450, batch loss 0.3550, batch acc 0.8584
10:11:50.842   Training iter 500, batch loss 0.3458, batch acc 0.8610
10:11:53.286   Training iter 550, batch loss 0.3246, batch acc 0.8696
10:11:55.667   Training iter 600, batch loss 0.3441, batch acc 0.8688
10:11:55.669 Testing @ 70 epoch...
10:11:55.725     Testing, total mean loss 0.39700, total acc 0.84860
10:11:55.725 Training @ 71 epoch...
10:11:58.104   Training iter 50, batch loss 0.3269, batch acc 0.8696
10:12:00.425   Training iter 100, batch loss 0.3358, batch acc 0.8680
10:12:02.748   Training iter 150, batch loss 0.3292, batch acc 0.8702
10:12:05.068   Training iter 200, batch loss 0.3514, batch acc 0.8608
10:12:07.386   Training iter 250, batch loss 0.3457, batch acc 0.8612
10:12:09.682   Training iter 300, batch loss 0.3237, batch acc 0.8710
10:12:12.020   Training iter 350, batch loss 0.3597, batch acc 0.8540
10:12:14.339   Training iter 400, batch loss 0.3362, batch acc 0.8662
10:12:16.654   Training iter 450, batch loss 0.3480, batch acc 0.8610
10:12:18.943   Training iter 500, batch loss 0.3527, batch acc 0.8610
10:12:21.247   Training iter 550, batch loss 0.3386, batch acc 0.8654
10:12:23.560   Training iter 600, batch loss 0.3494, batch acc 0.8636
10:12:23.562 Training @ 72 epoch...
10:12:25.885   Training iter 50, batch loss 0.3397, batch acc 0.8672
10:12:28.223   Training iter 100, batch loss 0.3394, batch acc 0.8638
10:12:30.544   Training iter 150, batch loss 0.3412, batch acc 0.8598
10:12:32.867   Training iter 200, batch loss 0.3362, batch acc 0.8674
10:12:35.174   Training iter 250, batch loss 0.3296, batch acc 0.8684
10:12:37.485   Training iter 300, batch loss 0.3554, batch acc 0.8612
10:12:39.781   Training iter 350, batch loss 0.3406, batch acc 0.8662
10:12:42.068   Training iter 400, batch loss 0.3398, batch acc 0.8656
10:12:44.370   Training iter 450, batch loss 0.3501, batch acc 0.8590
10:12:46.672   Training iter 500, batch loss 0.3540, batch acc 0.8604
10:12:48.950   Training iter 550, batch loss 0.3326, batch acc 0.8686
10:12:51.234   Training iter 600, batch loss 0.3431, batch acc 0.8624
10:12:51.235 Training @ 73 epoch...
10:12:53.509   Training iter 50, batch loss 0.3406, batch acc 0.8668
10:12:55.794   Training iter 100, batch loss 0.3322, batch acc 0.8694
10:12:58.078   Training iter 150, batch loss 0.3386, batch acc 0.8626
10:13:00.358   Training iter 200, batch loss 0.3246, batch acc 0.8714
10:13:02.660   Training iter 250, batch loss 0.3268, batch acc 0.8670
10:13:04.916   Training iter 300, batch loss 0.3612, batch acc 0.8584
10:13:07.123   Training iter 350, batch loss 0.3645, batch acc 0.8578
10:13:09.385   Training iter 400, batch loss 0.3514, batch acc 0.8616
10:13:11.649   Training iter 450, batch loss 0.3489, batch acc 0.8628
10:13:13.869   Training iter 500, batch loss 0.3460, batch acc 0.8600
10:13:16.069   Training iter 550, batch loss 0.3273, batch acc 0.8664
10:13:18.317   Training iter 600, batch loss 0.3384, batch acc 0.8666
10:13:18.318 Training @ 74 epoch...
10:13:20.598   Training iter 50, batch loss 0.3496, batch acc 0.8600
10:13:22.826   Training iter 100, batch loss 0.3361, batch acc 0.8664
10:13:25.056   Training iter 150, batch loss 0.3584, batch acc 0.8596
10:13:27.301   Training iter 200, batch loss 0.3276, batch acc 0.8698
10:13:29.541   Training iter 250, batch loss 0.3514, batch acc 0.8644
10:13:31.770   Training iter 300, batch loss 0.3381, batch acc 0.8662
10:13:34.018   Training iter 350, batch loss 0.3449, batch acc 0.8634
10:13:36.504   Training iter 400, batch loss 0.3135, batch acc 0.8730
10:13:38.937   Training iter 450, batch loss 0.3370, batch acc 0.8658
10:13:41.237   Training iter 500, batch loss 0.3401, batch acc 0.8662
10:13:43.534   Training iter 550, batch loss 0.3370, batch acc 0.8658
10:13:45.894   Training iter 600, batch loss 0.3514, batch acc 0.8566
10:13:45.895 Training @ 75 epoch...
10:13:48.279   Training iter 50, batch loss 0.3271, batch acc 0.8710
10:13:50.608   Training iter 100, batch loss 0.3430, batch acc 0.8618
10:13:52.912   Training iter 150, batch loss 0.3320, batch acc 0.8686
10:13:55.280   Training iter 200, batch loss 0.3216, batch acc 0.8708
10:13:57.655   Training iter 250, batch loss 0.3454, batch acc 0.8628
10:14:00.031   Training iter 300, batch loss 0.3444, batch acc 0.8644
10:14:02.393   Training iter 350, batch loss 0.3292, batch acc 0.8690
10:14:04.722   Training iter 400, batch loss 0.3382, batch acc 0.8668
10:14:07.137   Training iter 450, batch loss 0.3380, batch acc 0.8632
10:14:09.445   Training iter 500, batch loss 0.3485, batch acc 0.8632
10:14:11.738   Training iter 550, batch loss 0.3606, batch acc 0.8566
10:14:14.028   Training iter 600, batch loss 0.3494, batch acc 0.8620
10:14:14.030 Testing @ 75 epoch...
10:14:14.085     Testing, total mean loss 0.39239, total acc 0.85190
10:14:14.085 Training @ 76 epoch...
10:14:16.397   Training iter 50, batch loss 0.3246, batch acc 0.8724
10:14:18.700   Training iter 100, batch loss 0.3210, batch acc 0.8692
10:14:21.012   Training iter 150, batch loss 0.3410, batch acc 0.8656
10:14:23.320   Training iter 200, batch loss 0.3565, batch acc 0.8582
10:14:25.622   Training iter 250, batch loss 0.3312, batch acc 0.8674
10:14:27.911   Training iter 300, batch loss 0.3319, batch acc 0.8690
10:14:30.221   Training iter 350, batch loss 0.3241, batch acc 0.8696
10:14:32.530   Training iter 400, batch loss 0.3520, batch acc 0.8594
10:14:34.843   Training iter 450, batch loss 0.3529, batch acc 0.8600
10:14:37.259   Training iter 500, batch loss 0.3615, batch acc 0.8580
10:14:39.653   Training iter 550, batch loss 0.3489, batch acc 0.8582
10:14:42.052   Training iter 600, batch loss 0.3360, batch acc 0.8656
10:14:42.053 Training @ 77 epoch...
10:14:44.452   Training iter 50, batch loss 0.3328, batch acc 0.8670
10:14:46.811   Training iter 100, batch loss 0.3302, batch acc 0.8684
10:14:49.167   Training iter 150, batch loss 0.3590, batch acc 0.8560
10:14:51.537   Training iter 200, batch loss 0.3487, batch acc 0.8614
10:14:53.890   Training iter 250, batch loss 0.3475, batch acc 0.8632
10:14:56.207   Training iter 300, batch loss 0.3269, batch acc 0.8696
10:14:58.514   Training iter 350, batch loss 0.3461, batch acc 0.8624
10:15:00.817   Training iter 400, batch loss 0.3152, batch acc 0.8764
10:15:03.155   Training iter 450, batch loss 0.3427, batch acc 0.8644
10:15:05.466   Training iter 500, batch loss 0.3380, batch acc 0.8670
10:15:07.795   Training iter 550, batch loss 0.3426, batch acc 0.8630
10:15:10.141   Training iter 600, batch loss 0.3539, batch acc 0.8626
10:15:10.142 Training @ 78 epoch...
10:15:12.464   Training iter 50, batch loss 0.3426, batch acc 0.8634
10:15:14.821   Training iter 100, batch loss 0.3502, batch acc 0.8636
10:15:17.164   Training iter 150, batch loss 0.3188, batch acc 0.8708
10:15:19.500   Training iter 200, batch loss 0.3202, batch acc 0.8702
10:15:21.828   Training iter 250, batch loss 0.3513, batch acc 0.8622
10:15:24.115   Training iter 300, batch loss 0.3579, batch acc 0.8620
10:15:26.479   Training iter 350, batch loss 0.3156, batch acc 0.8710
10:15:28.929   Training iter 400, batch loss 0.3390, batch acc 0.8630
10:15:31.313   Training iter 450, batch loss 0.3518, batch acc 0.8606
10:15:33.675   Training iter 500, batch loss 0.3442, batch acc 0.8632
10:15:35.972   Training iter 550, batch loss 0.3412, batch acc 0.8634
10:15:38.339   Training iter 600, batch loss 0.3342, batch acc 0.8656
10:15:38.341 Training @ 79 epoch...
10:15:40.726   Training iter 50, batch loss 0.3531, batch acc 0.8600
10:15:43.056   Training iter 100, batch loss 0.3389, batch acc 0.8638
10:15:45.430   Training iter 150, batch loss 0.3481, batch acc 0.8596
10:15:47.766   Training iter 200, batch loss 0.3119, batch acc 0.8778
10:15:50.102   Training iter 250, batch loss 0.3276, batch acc 0.8730
10:15:52.581   Training iter 300, batch loss 0.3325, batch acc 0.8668
10:15:54.919   Training iter 350, batch loss 0.3315, batch acc 0.8676
10:15:57.206   Training iter 400, batch loss 0.3247, batch acc 0.8708
10:15:59.501   Training iter 450, batch loss 0.3466, batch acc 0.8606
10:16:01.742   Training iter 500, batch loss 0.3498, batch acc 0.8576
10:16:03.987   Training iter 550, batch loss 0.3451, batch acc 0.8622
10:16:06.224   Training iter 600, batch loss 0.3559, batch acc 0.8626
10:16:06.226 Training @ 80 epoch...
10:16:08.494   Training iter 50, batch loss 0.3341, batch acc 0.8680
10:16:10.739   Training iter 100, batch loss 0.3416, batch acc 0.8644
10:16:13.023   Training iter 150, batch loss 0.3351, batch acc 0.8666
10:16:15.260   Training iter 200, batch loss 0.3226, batch acc 0.8700
10:16:17.502   Training iter 250, batch loss 0.3303, batch acc 0.8668
10:16:19.746   Training iter 300, batch loss 0.3428, batch acc 0.8602
10:16:21.983   Training iter 350, batch loss 0.3506, batch acc 0.8578
10:16:24.227   Training iter 400, batch loss 0.3470, batch acc 0.8644
10:16:26.474   Training iter 450, batch loss 0.3377, batch acc 0.8658
10:16:28.734   Training iter 500, batch loss 0.3416, batch acc 0.8668
10:16:30.980   Training iter 550, batch loss 0.3224, batch acc 0.8714
10:16:33.229   Training iter 600, batch loss 0.3559, batch acc 0.8622
10:16:33.230 Testing @ 80 epoch...
10:16:33.280     Testing, total mean loss 0.38442, total acc 0.85410
10:16:33.280 Training @ 81 epoch...
10:16:35.524   Training iter 50, batch loss 0.3424, batch acc 0.8654
10:16:37.758   Training iter 100, batch loss 0.3439, batch acc 0.8628
10:16:40.001   Training iter 150, batch loss 0.3230, batch acc 0.8744
10:16:42.245   Training iter 200, batch loss 0.3226, batch acc 0.8732
10:16:44.485   Training iter 250, batch loss 0.3392, batch acc 0.8642
10:16:46.757   Training iter 300, batch loss 0.3321, batch acc 0.8650
10:16:49.075   Training iter 350, batch loss 0.3336, batch acc 0.8682
10:16:51.384   Training iter 400, batch loss 0.3286, batch acc 0.8684
10:16:53.626   Training iter 450, batch loss 0.3469, batch acc 0.8630
10:16:55.949   Training iter 500, batch loss 0.3432, batch acc 0.8648
10:16:58.252   Training iter 550, batch loss 0.3564, batch acc 0.8582
10:17:00.541   Training iter 600, batch loss 0.3500, batch acc 0.8616
10:17:00.542 Training @ 82 epoch...
10:17:02.837   Training iter 50, batch loss 0.3132, batch acc 0.8740
10:17:05.090   Training iter 100, batch loss 0.3374, batch acc 0.8670
10:17:07.350   Training iter 150, batch loss 0.3531, batch acc 0.8592
10:17:09.595   Training iter 200, batch loss 0.3451, batch acc 0.8630
10:17:11.838   Training iter 250, batch loss 0.3340, batch acc 0.8676
10:17:14.133   Training iter 300, batch loss 0.3409, batch acc 0.8634
10:17:16.486   Training iter 350, batch loss 0.3508, batch acc 0.8612
10:17:18.890   Training iter 400, batch loss 0.3473, batch acc 0.8614
10:17:21.229   Training iter 450, batch loss 0.3313, batch acc 0.8678
10:17:23.592   Training iter 500, batch loss 0.3447, batch acc 0.8646
10:17:25.944   Training iter 550, batch loss 0.3352, batch acc 0.8672
10:17:28.405   Training iter 600, batch loss 0.3368, batch acc 0.8648
10:17:28.407 Training @ 83 epoch...
10:17:30.663   Training iter 50, batch loss 0.3403, batch acc 0.8670
10:17:32.913   Training iter 100, batch loss 0.3212, batch acc 0.8720
10:17:35.168   Training iter 150, batch loss 0.3468, batch acc 0.8598
10:17:37.437   Training iter 200, batch loss 0.3311, batch acc 0.8672
10:17:39.699   Training iter 250, batch loss 0.3506, batch acc 0.8594
10:17:41.957   Training iter 300, batch loss 0.3340, batch acc 0.8668
10:17:44.277   Training iter 350, batch loss 0.3436, batch acc 0.8638
10:17:46.705   Training iter 400, batch loss 0.3316, batch acc 0.8680
10:17:49.163   Training iter 450, batch loss 0.3364, batch acc 0.8642
10:17:51.577   Training iter 500, batch loss 0.3437, batch acc 0.8622
10:17:53.839   Training iter 550, batch loss 0.3312, batch acc 0.8680
10:17:56.101   Training iter 600, batch loss 0.3387, batch acc 0.8636
10:17:56.103 Training @ 84 epoch...
10:17:58.347   Training iter 50, batch loss 0.3390, batch acc 0.8642
10:18:00.573   Training iter 100, batch loss 0.3556, batch acc 0.8584
10:18:02.819   Training iter 150, batch loss 0.3339, batch acc 0.8688
10:18:05.067   Training iter 200, batch loss 0.3538, batch acc 0.8642
10:18:07.315   Training iter 250, batch loss 0.3279, batch acc 0.8688
10:18:09.570   Training iter 300, batch loss 0.3256, batch acc 0.8688
10:18:11.813   Training iter 350, batch loss 0.3291, batch acc 0.8714
10:18:14.064   Training iter 400, batch loss 0.3347, batch acc 0.8666
10:18:16.291   Training iter 450, batch loss 0.3375, batch acc 0.8682
10:18:18.533   Training iter 500, batch loss 0.3417, batch acc 0.8642
10:18:20.771   Training iter 550, batch loss 0.3370, batch acc 0.8640
10:18:23.016   Training iter 600, batch loss 0.3405, batch acc 0.8626
10:18:23.017 Training @ 85 epoch...
10:18:25.274   Training iter 50, batch loss 0.3246, batch acc 0.8702
10:18:27.530   Training iter 100, batch loss 0.3366, batch acc 0.8638
10:18:29.779   Training iter 150, batch loss 0.3219, batch acc 0.8734
10:18:32.022   Training iter 200, batch loss 0.3566, batch acc 0.8588
10:18:34.264   Training iter 250, batch loss 0.3648, batch acc 0.8560
10:18:36.514   Training iter 300, batch loss 0.3368, batch acc 0.8672
10:18:38.754   Training iter 350, batch loss 0.3223, batch acc 0.8722
10:18:40.998   Training iter 400, batch loss 0.3465, batch acc 0.8626
10:18:43.257   Training iter 450, batch loss 0.3357, batch acc 0.8664
10:18:45.505   Training iter 500, batch loss 0.3430, batch acc 0.8642
10:18:47.739   Training iter 550, batch loss 0.3277, batch acc 0.8692
10:18:49.971   Training iter 600, batch loss 0.3261, batch acc 0.8706
10:18:49.972 Testing @ 85 epoch...
10:18:50.023     Testing, total mean loss 0.39007, total acc 0.85360
10:18:50.023 Training @ 86 epoch...
10:18:52.262   Training iter 50, batch loss 0.3189, batch acc 0.8722
10:18:54.486   Training iter 100, batch loss 0.3284, batch acc 0.8678
10:18:56.705   Training iter 150, batch loss 0.3136, batch acc 0.8754
10:18:58.932   Training iter 200, batch loss 0.3527, batch acc 0.8608
10:19:01.162   Training iter 250, batch loss 0.3473, batch acc 0.8632
10:19:03.420   Training iter 300, batch loss 0.3405, batch acc 0.8654
10:19:05.673   Training iter 350, batch loss 0.3416, batch acc 0.8630
10:19:07.922   Training iter 400, batch loss 0.3334, batch acc 0.8656
10:19:10.168   Training iter 450, batch loss 0.3341, batch acc 0.8694
10:19:12.421   Training iter 500, batch loss 0.3462, batch acc 0.8588
10:19:14.681   Training iter 550, batch loss 0.3627, batch acc 0.8598
10:19:16.937   Training iter 600, batch loss 0.3248, batch acc 0.8706
10:19:16.939 Training @ 87 epoch...
10:19:19.190   Training iter 50, batch loss 0.3252, batch acc 0.8698
10:19:21.430   Training iter 100, batch loss 0.3362, batch acc 0.8640
10:19:23.670   Training iter 150, batch loss 0.3487, batch acc 0.8636
10:19:25.917   Training iter 200, batch loss 0.3474, batch acc 0.8606
10:19:28.303   Training iter 250, batch loss 0.3488, batch acc 0.8638
10:19:30.583   Training iter 300, batch loss 0.3393, batch acc 0.8642
10:19:33.009   Training iter 350, batch loss 0.3154, batch acc 0.8778
10:19:35.431   Training iter 400, batch loss 0.3441, batch acc 0.8644
10:19:37.750   Training iter 450, batch loss 0.3160, batch acc 0.8724
10:19:39.977   Training iter 500, batch loss 0.3417, batch acc 0.8628
10:19:42.200   Training iter 550, batch loss 0.3445, batch acc 0.8622
10:19:44.425   Training iter 600, batch loss 0.3351, batch acc 0.8662
10:19:44.427 Training @ 88 epoch...
10:19:46.670   Training iter 50, batch loss 0.3396, batch acc 0.8628
10:19:48.940   Training iter 100, batch loss 0.3300, batch acc 0.8688
10:19:51.171   Training iter 150, batch loss 0.3476, batch acc 0.8608
10:19:53.404   Training iter 200, batch loss 0.3263, batch acc 0.8718
10:19:55.635   Training iter 250, batch loss 0.3413, batch acc 0.8646
10:19:57.871   Training iter 300, batch loss 0.3259, batch acc 0.8686
10:20:00.122   Training iter 350, batch loss 0.3497, batch acc 0.8582
10:20:02.388   Training iter 400, batch loss 0.3484, batch acc 0.8618
10:20:04.650   Training iter 450, batch loss 0.3537, batch acc 0.8592
10:20:06.910   Training iter 500, batch loss 0.3409, batch acc 0.8638
10:20:09.162   Training iter 550, batch loss 0.3295, batch acc 0.8684
10:20:11.399   Training iter 600, batch loss 0.3126, batch acc 0.8766
10:20:11.400 Training @ 89 epoch...
10:20:13.643   Training iter 50, batch loss 0.3403, batch acc 0.8648
10:20:15.880   Training iter 100, batch loss 0.3254, batch acc 0.8692
10:20:18.125   Training iter 150, batch loss 0.3368, batch acc 0.8642
10:20:20.364   Training iter 200, batch loss 0.3361, batch acc 0.8660
10:20:22.596   Training iter 250, batch loss 0.3414, batch acc 0.8636
10:20:24.819   Training iter 300, batch loss 0.3220, batch acc 0.8746
10:20:27.064   Training iter 350, batch loss 0.3297, batch acc 0.8694
10:20:29.310   Training iter 400, batch loss 0.3303, batch acc 0.8680
10:20:31.555   Training iter 450, batch loss 0.3514, batch acc 0.8594
10:20:33.800   Training iter 500, batch loss 0.3470, batch acc 0.8634
10:20:36.050   Training iter 550, batch loss 0.3470, batch acc 0.8616
10:20:38.297   Training iter 600, batch loss 0.3186, batch acc 0.8740
10:20:38.298 Training @ 90 epoch...
10:20:40.543   Training iter 50, batch loss 0.3377, batch acc 0.8608
10:20:42.800   Training iter 100, batch loss 0.3205, batch acc 0.8732
10:20:45.060   Training iter 150, batch loss 0.3238, batch acc 0.8700
10:20:47.391   Training iter 200, batch loss 0.3516, batch acc 0.8604
10:20:49.705   Training iter 250, batch loss 0.3452, batch acc 0.8610
10:20:52.013   Training iter 300, batch loss 0.3316, batch acc 0.8722
10:20:54.297   Training iter 350, batch loss 0.3480, batch acc 0.8600
10:20:56.578   Training iter 400, batch loss 0.3345, batch acc 0.8674
10:20:58.906   Training iter 450, batch loss 0.3282, batch acc 0.8670
10:21:01.160   Training iter 500, batch loss 0.3323, batch acc 0.8664
10:21:03.417   Training iter 550, batch loss 0.3595, batch acc 0.8590
10:21:05.670   Training iter 600, batch loss 0.3228, batch acc 0.8718
10:21:05.672 Testing @ 90 epoch...
10:21:05.722     Testing, total mean loss 0.39481, total acc 0.85050
10:21:05.722 Training @ 91 epoch...
10:21:07.998   Training iter 50, batch loss 0.3413, batch acc 0.8606
10:21:10.256   Training iter 100, batch loss 0.3519, batch acc 0.8590
10:21:12.499   Training iter 150, batch loss 0.3206, batch acc 0.8716
10:21:14.741   Training iter 200, batch loss 0.3268, batch acc 0.8716
10:21:16.983   Training iter 250, batch loss 0.3302, batch acc 0.8668
10:21:19.228   Training iter 300, batch loss 0.3264, batch acc 0.8698
10:21:21.478   Training iter 350, batch loss 0.3463, batch acc 0.8602
10:21:23.737   Training iter 400, batch loss 0.3534, batch acc 0.8558
10:21:25.995   Training iter 450, batch loss 0.3491, batch acc 0.8622
10:21:28.233   Training iter 500, batch loss 0.3242, batch acc 0.8700
10:21:30.478   Training iter 550, batch loss 0.3301, batch acc 0.8696
10:21:32.756   Training iter 600, batch loss 0.3274, batch acc 0.8716
10:21:32.758 Training @ 92 epoch...
10:21:35.078   Training iter 50, batch loss 0.3172, batch acc 0.8704
10:21:37.396   Training iter 100, batch loss 0.3375, batch acc 0.8670
10:21:39.643   Training iter 150, batch loss 0.3225, batch acc 0.8692
10:21:41.896   Training iter 200, batch loss 0.3208, batch acc 0.8712
10:21:44.165   Training iter 250, batch loss 0.3510, batch acc 0.8622
10:21:46.448   Training iter 300, batch loss 0.3302, batch acc 0.8688
10:21:48.703   Training iter 350, batch loss 0.3257, batch acc 0.8704
10:21:50.954   Training iter 400, batch loss 0.3462, batch acc 0.8612
10:21:53.191   Training iter 450, batch loss 0.3260, batch acc 0.8694
10:21:55.457   Training iter 500, batch loss 0.3339, batch acc 0.8668
10:21:57.733   Training iter 550, batch loss 0.3592, batch acc 0.8552
10:22:00.039   Training iter 600, batch loss 0.3639, batch acc 0.8556
10:22:00.041 Training @ 93 epoch...
10:22:02.364   Training iter 50, batch loss 0.3488, batch acc 0.8594
10:22:04.634   Training iter 100, batch loss 0.3177, batch acc 0.8746
10:22:06.912   Training iter 150, batch loss 0.3257, batch acc 0.8674
10:22:09.258   Training iter 200, batch loss 0.3373, batch acc 0.8646
10:22:11.554   Training iter 250, batch loss 0.3443, batch acc 0.8640
10:22:13.826   Training iter 300, batch loss 0.3508, batch acc 0.8604
10:22:16.148   Training iter 350, batch loss 0.3496, batch acc 0.8608
10:22:18.399   Training iter 400, batch loss 0.3256, batch acc 0.8684
10:22:20.635   Training iter 450, batch loss 0.3494, batch acc 0.8614
10:22:22.875   Training iter 500, batch loss 0.3079, batch acc 0.8772
10:22:25.116   Training iter 550, batch loss 0.3373, batch acc 0.8640
10:22:27.379   Training iter 600, batch loss 0.3235, batch acc 0.8728
10:22:27.381 Training @ 94 epoch...
10:22:29.650   Training iter 50, batch loss 0.3222, batch acc 0.8700
10:22:31.914   Training iter 100, batch loss 0.3369, batch acc 0.8664
10:22:34.159   Training iter 150, batch loss 0.3249, batch acc 0.8680
10:22:36.415   Training iter 200, batch loss 0.3188, batch acc 0.8710
10:22:38.663   Training iter 250, batch loss 0.3356, batch acc 0.8660
10:22:40.902   Training iter 300, batch loss 0.3439, batch acc 0.8632
10:22:43.159   Training iter 350, batch loss 0.3337, batch acc 0.8652
10:22:45.413   Training iter 400, batch loss 0.3504, batch acc 0.8618
10:22:47.665   Training iter 450, batch loss 0.3409, batch acc 0.8634
10:22:49.884   Training iter 500, batch loss 0.3518, batch acc 0.8618
10:22:52.111   Training iter 550, batch loss 0.3343, batch acc 0.8642
10:22:54.343   Training iter 600, batch loss 0.3321, batch acc 0.8686
10:22:54.345 Training @ 95 epoch...
10:22:56.590   Training iter 50, batch loss 0.3188, batch acc 0.8726
10:22:58.859   Training iter 100, batch loss 0.3488, batch acc 0.8646
10:23:01.117   Training iter 150, batch loss 0.3356, batch acc 0.8674
10:23:03.383   Training iter 200, batch loss 0.3396, batch acc 0.8658
10:23:05.617   Training iter 250, batch loss 0.3423, batch acc 0.8632
10:23:07.857   Training iter 300, batch loss 0.3186, batch acc 0.8700
10:23:10.086   Training iter 350, batch loss 0.3457, batch acc 0.8628
10:23:12.319   Training iter 400, batch loss 0.3412, batch acc 0.8660
10:23:14.566   Training iter 450, batch loss 0.3153, batch acc 0.8738
10:23:16.821   Training iter 500, batch loss 0.3579, batch acc 0.8584
10:23:19.072   Training iter 550, batch loss 0.3249, batch acc 0.8718
10:23:21.319   Training iter 600, batch loss 0.3353, batch acc 0.8662
10:23:21.321 Testing @ 95 epoch...
10:23:21.370     Testing, total mean loss 0.39303, total acc 0.85230
10:23:21.370 Training @ 96 epoch...
10:23:23.608   Training iter 50, batch loss 0.3224, batch acc 0.8698
10:23:25.845   Training iter 100, batch loss 0.3218, batch acc 0.8718
10:23:28.093   Training iter 150, batch loss 0.3364, batch acc 0.8664
10:23:30.341   Training iter 200, batch loss 0.3599, batch acc 0.8546
10:23:32.602   Training iter 250, batch loss 0.3577, batch acc 0.8572
10:23:34.859   Training iter 300, batch loss 0.3289, batch acc 0.8678
10:23:37.117   Training iter 350, batch loss 0.3437, batch acc 0.8682
10:23:39.365   Training iter 400, batch loss 0.3419, batch acc 0.8624
10:23:41.611   Training iter 450, batch loss 0.3319, batch acc 0.8690
10:23:43.840   Training iter 500, batch loss 0.3305, batch acc 0.8688
10:23:46.068   Training iter 550, batch loss 0.3304, batch acc 0.8664
10:23:48.317   Training iter 600, batch loss 0.3164, batch acc 0.8710
10:23:48.319 Training @ 97 epoch...
10:23:50.570   Training iter 50, batch loss 0.3297, batch acc 0.8684
10:23:52.820   Training iter 100, batch loss 0.3356, batch acc 0.8666
10:23:55.062   Training iter 150, batch loss 0.3402, batch acc 0.8624
10:23:57.337   Training iter 200, batch loss 0.3413, batch acc 0.8634
10:23:59.648   Training iter 250, batch loss 0.3463, batch acc 0.8632
10:24:01.968   Training iter 300, batch loss 0.3295, batch acc 0.8670
10:24:04.274   Training iter 350, batch loss 0.3350, batch acc 0.8664
10:24:06.686   Training iter 400, batch loss 0.3384, batch acc 0.8654
10:24:09.119   Training iter 450, batch loss 0.3271, batch acc 0.8704
10:24:11.399   Training iter 500, batch loss 0.3142, batch acc 0.8752
10:24:13.666   Training iter 550, batch loss 0.3499, batch acc 0.8606
10:24:15.908   Training iter 600, batch loss 0.3323, batch acc 0.8670
10:24:15.910 Training @ 98 epoch...
10:24:18.158   Training iter 50, batch loss 0.3362, batch acc 0.8682
10:24:20.420   Training iter 100, batch loss 0.3364, batch acc 0.8638
10:24:22.690   Training iter 150, batch loss 0.3282, batch acc 0.8680
10:24:24.970   Training iter 200, batch loss 0.3134, batch acc 0.8754
10:24:27.238   Training iter 250, batch loss 0.3241, batch acc 0.8730
10:24:29.500   Training iter 300, batch loss 0.3387, batch acc 0.8652
10:24:31.760   Training iter 350, batch loss 0.3442, batch acc 0.8648
10:24:34.020   Training iter 400, batch loss 0.3424, batch acc 0.8636
10:24:36.307   Training iter 450, batch loss 0.3468, batch acc 0.8604
10:24:38.628   Training iter 500, batch loss 0.3308, batch acc 0.8658
10:24:41.050   Training iter 550, batch loss 0.3440, batch acc 0.8610
10:24:43.320   Training iter 600, batch loss 0.3322, batch acc 0.8676
10:24:43.321 Training @ 99 epoch...
10:24:45.587   Training iter 50, batch loss 0.3163, batch acc 0.8724
10:24:47.851   Training iter 100, batch loss 0.3241, batch acc 0.8718
10:24:50.114   Training iter 150, batch loss 0.3277, batch acc 0.8672
10:24:52.379   Training iter 200, batch loss 0.3249, batch acc 0.8688
10:24:54.638   Training iter 250, batch loss 0.3435, batch acc 0.8620
10:24:56.904   Training iter 300, batch loss 0.3322, batch acc 0.8666
10:24:59.166   Training iter 350, batch loss 0.3385, batch acc 0.8666
10:25:01.420   Training iter 400, batch loss 0.3417, batch acc 0.8626
10:25:03.708   Training iter 450, batch loss 0.3295, batch acc 0.8692
10:25:05.968   Training iter 500, batch loss 0.3374, batch acc 0.8672
10:25:08.241   Training iter 550, batch loss 0.3478, batch acc 0.8630
10:25:10.502   Training iter 600, batch loss 0.3420, batch acc 0.8636
10:25:10.504 Training @ 100 epoch...
10:25:12.769   Training iter 50, batch loss 0.3335, batch acc 0.8662
10:25:15.001   Training iter 100, batch loss 0.3535, batch acc 0.8614
10:25:17.243   Training iter 150, batch loss 0.3226, batch acc 0.8716
10:25:19.483   Training iter 200, batch loss 0.3359, batch acc 0.8656
10:25:21.729   Training iter 250, batch loss 0.3553, batch acc 0.8602
10:25:23.984   Training iter 300, batch loss 0.3374, batch acc 0.8638
10:25:26.266   Training iter 350, batch loss 0.3262, batch acc 0.8692
10:25:28.554   Training iter 400, batch loss 0.3172, batch acc 0.8730
10:25:30.836   Training iter 450, batch loss 0.3303, batch acc 0.8682
10:25:33.097   Training iter 500, batch loss 0.3257, batch acc 0.8706
10:25:35.352   Training iter 550, batch loss 0.3457, batch acc 0.8604
10:25:37.650   Training iter 600, batch loss 0.3223, batch acc 0.8702
10:25:37.652 Testing @ 100 epoch...
10:25:37.706     Testing, total mean loss 0.39165, total acc 0.85110
10:25:37.706 Plot @ 100 epoch...
10:25:37.706 Training @ 101 epoch...
10:25:40.060   Training iter 50, batch loss 0.3361, batch acc 0.8628
10:25:42.419   Training iter 100, batch loss 0.3328, batch acc 0.8660
10:25:44.689   Training iter 150, batch loss 0.3248, batch acc 0.8712
10:25:46.940   Training iter 200, batch loss 0.3398, batch acc 0.8628
10:25:49.255   Training iter 250, batch loss 0.3155, batch acc 0.8746
10:25:51.599   Training iter 300, batch loss 0.3331, batch acc 0.8658
10:25:53.935   Training iter 350, batch loss 0.3381, batch acc 0.8676
10:25:56.269   Training iter 400, batch loss 0.3411, batch acc 0.8646
10:25:58.551   Training iter 450, batch loss 0.3451, batch acc 0.8576
10:26:00.832   Training iter 500, batch loss 0.3314, batch acc 0.8700
10:26:03.149   Training iter 550, batch loss 0.3298, batch acc 0.8724
10:26:05.447   Training iter 600, batch loss 0.3301, batch acc 0.8662
10:26:05.448 Training @ 102 epoch...
10:26:07.765   Training iter 50, batch loss 0.3262, batch acc 0.8688
10:26:10.063   Training iter 100, batch loss 0.3217, batch acc 0.8694
10:26:12.369   Training iter 150, batch loss 0.3343, batch acc 0.8668
10:26:14.639   Training iter 200, batch loss 0.3392, batch acc 0.8648
10:26:16.914   Training iter 250, batch loss 0.3443, batch acc 0.8622
10:26:19.297   Training iter 300, batch loss 0.3403, batch acc 0.8634
10:26:21.709   Training iter 350, batch loss 0.3227, batch acc 0.8726
10:26:24.070   Training iter 400, batch loss 0.3444, batch acc 0.8604
10:26:26.419   Training iter 450, batch loss 0.3454, batch acc 0.8614
10:26:28.781   Training iter 500, batch loss 0.3301, batch acc 0.8670
10:26:31.110   Training iter 550, batch loss 0.3168, batch acc 0.8752
10:26:33.493   Training iter 600, batch loss 0.3344, batch acc 0.8658
10:26:33.495 Training @ 103 epoch...
10:26:35.816   Training iter 50, batch loss 0.3063, batch acc 0.8750
10:26:38.129   Training iter 100, batch loss 0.3107, batch acc 0.8736
10:26:40.425   Training iter 150, batch loss 0.3381, batch acc 0.8646
10:26:42.728   Training iter 200, batch loss 0.3254, batch acc 0.8690
10:26:45.046   Training iter 250, batch loss 0.3392, batch acc 0.8672
10:26:47.378   Training iter 300, batch loss 0.3332, batch acc 0.8682
10:26:50.249   Training iter 350, batch loss 0.3270, batch acc 0.8696
10:26:52.554   Training iter 400, batch loss 0.3569, batch acc 0.8594
10:26:54.890   Training iter 450, batch loss 0.3517, batch acc 0.8588
10:26:57.277   Training iter 500, batch loss 0.3619, batch acc 0.8538
10:26:59.583   Training iter 550, batch loss 0.3441, batch acc 0.8654
10:27:01.867   Training iter 600, batch loss 0.3140, batch acc 0.8764
10:27:01.869 Training @ 104 epoch...
10:27:04.179   Training iter 50, batch loss 0.3181, batch acc 0.8748
10:27:06.486   Training iter 100, batch loss 0.3294, batch acc 0.8680
10:27:08.777   Training iter 150, batch loss 0.3104, batch acc 0.8744
10:27:11.137   Training iter 200, batch loss 0.3242, batch acc 0.8716
10:27:13.577   Training iter 250, batch loss 0.3314, batch acc 0.8648
10:27:15.979   Training iter 300, batch loss 0.3211, batch acc 0.8714
10:27:18.243   Training iter 350, batch loss 0.3414, batch acc 0.8634
10:27:20.494   Training iter 400, batch loss 0.3409, batch acc 0.8642
10:27:22.743   Training iter 450, batch loss 0.3364, batch acc 0.8648
10:27:24.983   Training iter 500, batch loss 0.3415, batch acc 0.8644
10:27:27.239   Training iter 550, batch loss 0.3409, batch acc 0.8612
10:27:29.526   Training iter 600, batch loss 0.3426, batch acc 0.8620
10:27:29.528 Training @ 105 epoch...
10:27:31.805   Training iter 50, batch loss 0.3256, batch acc 0.8692
10:27:34.088   Training iter 100, batch loss 0.3365, batch acc 0.8636
10:27:36.377   Training iter 150, batch loss 0.3314, batch acc 0.8674
10:27:38.653   Training iter 200, batch loss 0.3480, batch acc 0.8600
10:27:40.922   Training iter 250, batch loss 0.3311, batch acc 0.8640
10:27:43.184   Training iter 300, batch loss 0.3317, batch acc 0.8688
10:27:45.441   Training iter 350, batch loss 0.3339, batch acc 0.8686
10:27:47.714   Training iter 400, batch loss 0.3140, batch acc 0.8760
10:27:49.980   Training iter 450, batch loss 0.3471, batch acc 0.8602
10:27:52.234   Training iter 500, batch loss 0.3272, batch acc 0.8682
10:27:54.487   Training iter 550, batch loss 0.3507, batch acc 0.8610
10:27:56.744   Training iter 600, batch loss 0.3270, batch acc 0.8664
10:27:56.745 Testing @ 105 epoch...
10:27:56.796     Testing, total mean loss 0.38979, total acc 0.85260
10:27:56.796 Training @ 106 epoch...
10:27:59.055   Training iter 50, batch loss 0.3049, batch acc 0.8782
10:28:01.299   Training iter 100, batch loss 0.3287, batch acc 0.8668
10:28:03.567   Training iter 150, batch loss 0.3403, batch acc 0.8634
10:28:05.834   Training iter 200, batch loss 0.3341, batch acc 0.8652
10:28:08.116   Training iter 250, batch loss 0.3370, batch acc 0.8642
10:28:10.407   Training iter 300, batch loss 0.3389, batch acc 0.8662
10:28:12.771   Training iter 350, batch loss 0.3219, batch acc 0.8708
10:28:15.163   Training iter 400, batch loss 0.3422, batch acc 0.8632
10:28:17.440   Training iter 450, batch loss 0.3342, batch acc 0.8682
10:28:19.729   Training iter 500, batch loss 0.3275, batch acc 0.8698
10:28:22.027   Training iter 550, batch loss 0.3427, batch acc 0.8632
10:28:24.363   Training iter 600, batch loss 0.3359, batch acc 0.8676
10:28:24.365 Training @ 107 epoch...
10:28:26.746   Training iter 50, batch loss 0.3399, batch acc 0.8638
10:28:29.127   Training iter 100, batch loss 0.3385, batch acc 0.8626
10:28:31.437   Training iter 150, batch loss 0.3174, batch acc 0.8710
10:28:33.755   Training iter 200, batch loss 0.3308, batch acc 0.8696
10:28:36.069   Training iter 250, batch loss 0.3171, batch acc 0.8750
10:28:38.370   Training iter 300, batch loss 0.3328, batch acc 0.8658
10:28:40.654   Training iter 350, batch loss 0.3250, batch acc 0.8692
10:28:42.944   Training iter 400, batch loss 0.3418, batch acc 0.8630
10:28:45.203   Training iter 450, batch loss 0.3289, batch acc 0.8694
10:28:47.450   Training iter 500, batch loss 0.3407, batch acc 0.8650
10:28:49.716   Training iter 550, batch loss 0.3455, batch acc 0.8596
10:28:52.054   Training iter 600, batch loss 0.3276, batch acc 0.8696
10:28:52.057 Training @ 108 epoch...
10:28:54.387   Training iter 50, batch loss 0.3272, batch acc 0.8696
10:28:56.941   Training iter 100, batch loss 0.3040, batch acc 0.8788
10:28:59.321   Training iter 150, batch loss 0.3388, batch acc 0.8634
10:29:01.691   Training iter 200, batch loss 0.3446, batch acc 0.8612
10:29:04.007   Training iter 250, batch loss 0.3277, batch acc 0.8696
10:29:06.312   Training iter 300, batch loss 0.3431, batch acc 0.8622
10:29:08.642   Training iter 350, batch loss 0.3356, batch acc 0.8670
10:29:10.961   Training iter 400, batch loss 0.3362, batch acc 0.8658
10:29:13.283   Training iter 450, batch loss 0.3352, batch acc 0.8662
10:29:15.674   Training iter 500, batch loss 0.3191, batch acc 0.8706
10:29:18.040   Training iter 550, batch loss 0.3319, batch acc 0.8680
10:29:20.355   Training iter 600, batch loss 0.3495, batch acc 0.8588
10:29:20.357 Training @ 109 epoch...
10:29:22.608   Training iter 50, batch loss 0.3214, batch acc 0.8718
10:29:24.862   Training iter 100, batch loss 0.3503, batch acc 0.8600
10:29:27.154   Training iter 150, batch loss 0.3300, batch acc 0.8676
10:29:29.437   Training iter 200, batch loss 0.3186, batch acc 0.8712
10:29:31.742   Training iter 250, batch loss 0.3409, batch acc 0.8620
10:29:33.997   Training iter 300, batch loss 0.3248, batch acc 0.8694
10:29:36.278   Training iter 350, batch loss 0.3236, batch acc 0.8720
10:29:38.531   Training iter 400, batch loss 0.3299, batch acc 0.8648
10:29:40.791   Training iter 450, batch loss 0.3379, batch acc 0.8648
10:29:43.062   Training iter 500, batch loss 0.3398, batch acc 0.8626
10:29:45.348   Training iter 550, batch loss 0.3421, batch acc 0.8634
10:29:47.605   Training iter 600, batch loss 0.3241, batch acc 0.8726
10:29:47.607 Training @ 110 epoch...
10:29:49.902   Training iter 50, batch loss 0.3271, batch acc 0.8672
10:29:52.196   Training iter 100, batch loss 0.3279, batch acc 0.8676
10:29:54.495   Training iter 150, batch loss 0.3118, batch acc 0.8748
10:29:56.919   Training iter 200, batch loss 0.3265, batch acc 0.8676
10:29:59.222   Training iter 250, batch loss 0.3416, batch acc 0.8626
10:30:01.512   Training iter 300, batch loss 0.3389, batch acc 0.8660
10:30:03.850   Training iter 350, batch loss 0.3365, batch acc 0.8662
10:30:06.200   Training iter 400, batch loss 0.3362, batch acc 0.8630
10:30:08.766   Training iter 450, batch loss 0.3405, batch acc 0.8662
10:30:11.590   Training iter 500, batch loss 0.3272, batch acc 0.8696
10:30:14.227   Training iter 550, batch loss 0.3306, batch acc 0.8696
10:30:16.673   Training iter 600, batch loss 0.3397, batch acc 0.8656
10:30:16.675 Testing @ 110 epoch...
10:30:16.731     Testing, total mean loss 0.38723, total acc 0.85330
10:30:16.731 Training @ 111 epoch...
10:30:19.146   Training iter 50, batch loss 0.3381, batch acc 0.8642
10:30:21.470   Training iter 100, batch loss 0.3169, batch acc 0.8736
10:30:23.806   Training iter 150, batch loss 0.2975, batch acc 0.8796
10:30:26.188   Training iter 200, batch loss 0.3258, batch acc 0.8688
10:30:28.476   Training iter 250, batch loss 0.3586, batch acc 0.8540
10:30:30.818   Training iter 300, batch loss 0.3405, batch acc 0.8640
10:30:33.087   Training iter 350, batch loss 0.3410, batch acc 0.8640
10:30:35.359   Training iter 400, batch loss 0.3421, batch acc 0.8626
10:30:37.630   Training iter 450, batch loss 0.3231, batch acc 0.8732
10:30:39.939   Training iter 500, batch loss 0.3467, batch acc 0.8590
10:30:42.213   Training iter 550, batch loss 0.3232, batch acc 0.8700
10:30:44.554   Training iter 600, batch loss 0.3246, batch acc 0.8712
10:30:44.555 Training @ 112 epoch...
10:30:46.818   Training iter 50, batch loss 0.3352, batch acc 0.8648
10:30:49.089   Training iter 100, batch loss 0.3154, batch acc 0.8704
10:30:51.367   Training iter 150, batch loss 0.3374, batch acc 0.8682
10:30:53.637   Training iter 200, batch loss 0.3250, batch acc 0.8692
10:30:55.903   Training iter 250, batch loss 0.3270, batch acc 0.8680
10:30:58.203   Training iter 300, batch loss 0.3390, batch acc 0.8668
10:31:00.533   Training iter 350, batch loss 0.3325, batch acc 0.8648
10:31:02.844   Training iter 400, batch loss 0.3401, batch acc 0.8616
10:31:05.183   Training iter 450, batch loss 0.3240, batch acc 0.8700
10:31:07.471   Training iter 500, batch loss 0.3196, batch acc 0.8726
10:31:09.744   Training iter 550, batch loss 0.3426, batch acc 0.8652
10:31:12.010   Training iter 600, batch loss 0.3409, batch acc 0.8648
10:31:12.012 Training @ 113 epoch...
10:31:14.287   Training iter 50, batch loss 0.3353, batch acc 0.8672
10:31:16.560   Training iter 100, batch loss 0.3206, batch acc 0.8698
10:31:18.839   Training iter 150, batch loss 0.3369, batch acc 0.8682
10:31:21.121   Training iter 200, batch loss 0.3416, batch acc 0.8634
10:31:23.399   Training iter 250, batch loss 0.3301, batch acc 0.8658
10:31:25.726   Training iter 300, batch loss 0.3314, batch acc 0.8672
10:31:28.008   Training iter 350, batch loss 0.3305, batch acc 0.8672
10:31:30.345   Training iter 400, batch loss 0.3468, batch acc 0.8586
10:31:32.746   Training iter 450, batch loss 0.3170, batch acc 0.8718
10:31:35.115   Training iter 500, batch loss 0.3261, batch acc 0.8700
10:31:37.458   Training iter 550, batch loss 0.3241, batch acc 0.8718
10:31:39.916   Training iter 600, batch loss 0.3330, batch acc 0.8626
10:31:39.918 Training @ 114 epoch...
10:31:42.204   Training iter 50, batch loss 0.3261, batch acc 0.8706
10:31:44.462   Training iter 100, batch loss 0.3382, batch acc 0.8626
10:31:46.732   Training iter 150, batch loss 0.3236, batch acc 0.8668
10:31:48.997   Training iter 200, batch loss 0.3242, batch acc 0.8688
10:31:51.266   Training iter 250, batch loss 0.3237, batch acc 0.8708
10:31:53.536   Training iter 300, batch loss 0.3261, batch acc 0.8680
10:31:55.809   Training iter 350, batch loss 0.3351, batch acc 0.8672
10:31:58.103   Training iter 400, batch loss 0.3280, batch acc 0.8712
10:32:00.384   Training iter 450, batch loss 0.3289, batch acc 0.8714
10:32:02.667   Training iter 500, batch loss 0.3557, batch acc 0.8590
10:32:04.938   Training iter 550, batch loss 0.3240, batch acc 0.8708
10:32:07.281   Training iter 600, batch loss 0.3347, batch acc 0.8672
10:32:07.282 Training @ 115 epoch...
10:32:09.558   Training iter 50, batch loss 0.3131, batch acc 0.8726
10:32:11.825   Training iter 100, batch loss 0.3249, batch acc 0.8710
10:32:14.095   Training iter 150, batch loss 0.3358, batch acc 0.8630
10:32:16.355   Training iter 200, batch loss 0.3383, batch acc 0.8652
10:32:18.610   Training iter 250, batch loss 0.3268, batch acc 0.8684
10:32:20.866   Training iter 300, batch loss 0.3342, batch acc 0.8640
10:32:23.130   Training iter 350, batch loss 0.3313, batch acc 0.8688
10:32:25.401   Training iter 400, batch loss 0.3398, batch acc 0.8612
10:32:27.675   Training iter 450, batch loss 0.3320, batch acc 0.8682
10:32:29.958   Training iter 500, batch loss 0.3438, batch acc 0.8634
10:32:32.221   Training iter 550, batch loss 0.3178, batch acc 0.8730
10:32:34.480   Training iter 600, batch loss 0.3355, batch acc 0.8646
10:32:34.481 Testing @ 115 epoch...
10:32:34.531     Testing, total mean loss 0.39269, total acc 0.85220
10:32:34.531 Training @ 116 epoch...
10:32:36.806   Training iter 50, batch loss 0.3454, batch acc 0.8620
10:32:39.073   Training iter 100, batch loss 0.3245, batch acc 0.8702
10:32:41.351   Training iter 150, batch loss 0.3312, batch acc 0.8646
10:32:43.624   Training iter 200, batch loss 0.3247, batch acc 0.8692
10:32:45.891   Training iter 250, batch loss 0.3097, batch acc 0.8766
10:32:48.160   Training iter 300, batch loss 0.3341, batch acc 0.8650
10:32:50.420   Training iter 350, batch loss 0.3174, batch acc 0.8724
10:32:52.681   Training iter 400, batch loss 0.3327, batch acc 0.8650
10:32:54.944   Training iter 450, batch loss 0.3338, batch acc 0.8660
10:32:57.201   Training iter 500, batch loss 0.3342, batch acc 0.8670
10:32:59.474   Training iter 550, batch loss 0.3395, batch acc 0.8672
10:33:01.756   Training iter 600, batch loss 0.3329, batch acc 0.8666
10:33:01.758 Training @ 117 epoch...
10:33:04.026   Training iter 50, batch loss 0.3340, batch acc 0.8670
10:33:06.294   Training iter 100, batch loss 0.3169, batch acc 0.8730
10:33:08.564   Training iter 150, batch loss 0.3184, batch acc 0.8714
10:33:10.816   Training iter 200, batch loss 0.3308, batch acc 0.8684
10:33:13.082   Training iter 250, batch loss 0.3230, batch acc 0.8690
10:33:15.342   Training iter 300, batch loss 0.3084, batch acc 0.8762
10:33:17.612   Training iter 350, batch loss 0.3356, batch acc 0.8662
10:33:19.868   Training iter 400, batch loss 0.3473, batch acc 0.8586
10:33:22.113   Training iter 450, batch loss 0.3327, batch acc 0.8666
10:33:24.364   Training iter 500, batch loss 0.3389, batch acc 0.8652
10:33:26.610   Training iter 550, batch loss 0.3397, batch acc 0.8640
10:33:28.867   Training iter 600, batch loss 0.3344, batch acc 0.8672
10:33:28.869 Training @ 118 epoch...
10:33:31.146   Training iter 50, batch loss 0.3268, batch acc 0.8666
10:33:33.414   Training iter 100, batch loss 0.3315, batch acc 0.8650
10:33:35.676   Training iter 150, batch loss 0.3389, batch acc 0.8656
10:33:38.026   Training iter 200, batch loss 0.3239, batch acc 0.8686
10:33:40.310   Training iter 250, batch loss 0.3269, batch acc 0.8666
10:33:42.585   Training iter 300, batch loss 0.3300, batch acc 0.8704
10:33:44.853   Training iter 350, batch loss 0.3335, batch acc 0.8652
10:33:47.122   Training iter 400, batch loss 0.3263, batch acc 0.8672
10:33:49.386   Training iter 450, batch loss 0.3079, batch acc 0.8764
10:33:51.647   Training iter 500, batch loss 0.3280, batch acc 0.8736
10:33:53.952   Training iter 550, batch loss 0.3618, batch acc 0.8548
10:33:56.283   Training iter 600, batch loss 0.3339, batch acc 0.8680
10:33:56.285 Training @ 119 epoch...
10:33:59.114   Training iter 50, batch loss 0.3451, batch acc 0.8604
10:34:01.553   Training iter 100, batch loss 0.3253, batch acc 0.8676
10:34:03.904   Training iter 150, batch loss 0.3455, batch acc 0.8596
10:34:06.186   Training iter 200, batch loss 0.3075, batch acc 0.8742
10:34:08.471   Training iter 250, batch loss 0.3211, batch acc 0.8688
10:34:10.727   Training iter 300, batch loss 0.3358, batch acc 0.8666
10:34:12.986   Training iter 350, batch loss 0.3216, batch acc 0.8726
10:34:15.241   Training iter 400, batch loss 0.3317, batch acc 0.8662
10:34:17.495   Training iter 450, batch loss 0.3325, batch acc 0.8656
10:34:19.751   Training iter 500, batch loss 0.3396, batch acc 0.8664
10:34:22.017   Training iter 550, batch loss 0.3162, batch acc 0.8746
10:34:24.282   Training iter 600, batch loss 0.3482, batch acc 0.8628
10:34:24.284 Training @ 120 epoch...
10:34:26.555   Training iter 50, batch loss 0.3124, batch acc 0.8768
10:34:28.806   Training iter 100, batch loss 0.3230, batch acc 0.8686
10:34:31.055   Training iter 150, batch loss 0.3224, batch acc 0.8684
10:34:33.290   Training iter 200, batch loss 0.3401, batch acc 0.8630
10:34:35.566   Training iter 250, batch loss 0.3414, batch acc 0.8642
10:34:37.856   Training iter 300, batch loss 0.3451, batch acc 0.8614
10:34:40.179   Training iter 350, batch loss 0.3088, batch acc 0.8772
10:34:42.477   Training iter 400, batch loss 0.3225, batch acc 0.8700
10:34:44.749   Training iter 450, batch loss 0.3249, batch acc 0.8708
10:34:47.017   Training iter 500, batch loss 0.3451, batch acc 0.8624
10:34:49.300   Training iter 550, batch loss 0.3439, batch acc 0.8648
10:34:51.601   Training iter 600, batch loss 0.3440, batch acc 0.8612
10:34:51.603 Testing @ 120 epoch...
10:34:51.656     Testing, total mean loss 0.39659, total acc 0.85090
10:34:51.657 Training @ 121 epoch...
10:34:53.982   Training iter 50, batch loss 0.3206, batch acc 0.8722
10:34:56.336   Training iter 100, batch loss 0.3439, batch acc 0.8616
10:34:58.627   Training iter 150, batch loss 0.3275, batch acc 0.8676
10:35:00.900   Training iter 200, batch loss 0.3179, batch acc 0.8736
10:35:03.182   Training iter 250, batch loss 0.3444, batch acc 0.8622
10:35:05.460   Training iter 300, batch loss 0.3297, batch acc 0.8682
10:35:07.759   Training iter 350, batch loss 0.3315, batch acc 0.8676
10:35:10.051   Training iter 400, batch loss 0.3213, batch acc 0.8708
10:35:12.340   Training iter 450, batch loss 0.3366, batch acc 0.8640
10:35:14.622   Training iter 500, batch loss 0.3274, batch acc 0.8680
10:35:16.901   Training iter 550, batch loss 0.3174, batch acc 0.8718
10:35:19.180   Training iter 600, batch loss 0.3523, batch acc 0.8582
10:35:19.182 Training @ 122 epoch...
10:35:21.467   Training iter 50, batch loss 0.3298, batch acc 0.8688
10:35:23.744   Training iter 100, batch loss 0.3319, batch acc 0.8658
10:35:26.031   Training iter 150, batch loss 0.3332, batch acc 0.8676
10:35:28.322   Training iter 200, batch loss 0.3279, batch acc 0.8686
10:35:30.687   Training iter 250, batch loss 0.3292, batch acc 0.8662
10:35:32.970   Training iter 300, batch loss 0.3393, batch acc 0.8620
10:35:35.344   Training iter 350, batch loss 0.3586, batch acc 0.8594
10:35:37.764   Training iter 400, batch loss 0.3423, batch acc 0.8614
10:35:40.155   Training iter 450, batch loss 0.3231, batch acc 0.8704
10:35:42.429   Training iter 500, batch loss 0.3142, batch acc 0.8734
10:35:44.697   Training iter 550, batch loss 0.3105, batch acc 0.8726
10:35:46.960   Training iter 600, batch loss 0.3233, batch acc 0.8698
10:35:46.962 Training @ 123 epoch...
10:35:49.220   Training iter 50, batch loss 0.3243, batch acc 0.8682
10:35:51.470   Training iter 100, batch loss 0.3333, batch acc 0.8662
10:35:53.713   Training iter 150, batch loss 0.3230, batch acc 0.8700
10:35:55.957   Training iter 200, batch loss 0.3507, batch acc 0.8598
10:35:58.217   Training iter 250, batch loss 0.3299, batch acc 0.8660
10:36:00.483   Training iter 300, batch loss 0.3377, batch acc 0.8656
10:36:02.762   Training iter 350, batch loss 0.3248, batch acc 0.8658
10:36:05.293   Training iter 400, batch loss 0.3267, batch acc 0.8684
10:36:07.583   Training iter 450, batch loss 0.3220, batch acc 0.8710
10:36:09.902   Training iter 500, batch loss 0.3305, batch acc 0.8668
10:36:12.206   Training iter 550, batch loss 0.3153, batch acc 0.8740
10:36:14.485   Training iter 600, batch loss 0.3444, batch acc 0.8640
10:36:14.486 Training @ 124 epoch...
10:36:16.748   Training iter 50, batch loss 0.3403, batch acc 0.8622
10:36:18.989   Training iter 100, batch loss 0.3174, batch acc 0.8698
10:36:21.246   Training iter 150, batch loss 0.3213, batch acc 0.8724
10:36:23.535   Training iter 200, batch loss 0.3314, batch acc 0.8682
10:36:25.807   Training iter 250, batch loss 0.3134, batch acc 0.8700
10:36:28.165   Training iter 300, batch loss 0.3555, batch acc 0.8576
10:36:30.547   Training iter 350, batch loss 0.3344, batch acc 0.8666
10:36:32.857   Training iter 400, batch loss 0.3423, batch acc 0.8620
10:36:35.103   Training iter 450, batch loss 0.3364, batch acc 0.8686
10:36:37.349   Training iter 500, batch loss 0.3109, batch acc 0.8758
10:36:39.600   Training iter 550, batch loss 0.3287, batch acc 0.8710
10:36:41.886   Training iter 600, batch loss 0.3237, batch acc 0.8708
10:36:41.888 Training @ 125 epoch...
10:36:44.161   Training iter 50, batch loss 0.3145, batch acc 0.8724
10:36:46.432   Training iter 100, batch loss 0.3131, batch acc 0.8764
10:36:48.690   Training iter 150, batch loss 0.3305, batch acc 0.8686
10:36:50.938   Training iter 200, batch loss 0.3230, batch acc 0.8698
10:36:53.177   Training iter 250, batch loss 0.3319, batch acc 0.8640
10:36:55.414   Training iter 300, batch loss 0.3486, batch acc 0.8592
10:36:57.653   Training iter 350, batch loss 0.3393, batch acc 0.8640
10:36:59.948   Training iter 400, batch loss 0.3305, batch acc 0.8658
10:37:02.232   Training iter 450, batch loss 0.3359, batch acc 0.8642
10:37:04.478   Training iter 500, batch loss 0.3336, batch acc 0.8662
10:37:06.736   Training iter 550, batch loss 0.3323, batch acc 0.8666
10:37:08.992   Training iter 600, batch loss 0.3231, batch acc 0.8736
10:37:08.993 Testing @ 125 epoch...
10:37:09.045     Testing, total mean loss 0.38746, total acc 0.85320
10:37:09.045 Training @ 126 epoch...
10:37:11.295   Training iter 50, batch loss 0.3398, batch acc 0.8636
10:37:13.543   Training iter 100, batch loss 0.3085, batch acc 0.8748
10:37:15.803   Training iter 150, batch loss 0.3377, batch acc 0.8668
10:37:18.069   Training iter 200, batch loss 0.3446, batch acc 0.8606
10:37:20.324   Training iter 250, batch loss 0.3218, batch acc 0.8740
10:37:22.564   Training iter 300, batch loss 0.3246, batch acc 0.8698
10:37:24.882   Training iter 350, batch loss 0.3268, batch acc 0.8660
10:37:27.136   Training iter 400, batch loss 0.3199, batch acc 0.8708
10:37:29.474   Training iter 450, batch loss 0.3219, batch acc 0.8694
10:37:31.735   Training iter 500, batch loss 0.3209, batch acc 0.8724
10:37:33.986   Training iter 550, batch loss 0.3263, batch acc 0.8688
10:37:36.237   Training iter 600, batch loss 0.3458, batch acc 0.8628
10:37:36.239 Training @ 127 epoch...
10:37:38.490   Training iter 50, batch loss 0.3287, batch acc 0.8674
10:37:40.732   Training iter 100, batch loss 0.3358, batch acc 0.8652
10:37:42.980   Training iter 150, batch loss 0.3456, batch acc 0.8608
10:37:45.258   Training iter 200, batch loss 0.3288, batch acc 0.8668
10:37:47.541   Training iter 250, batch loss 0.3382, batch acc 0.8644
10:37:49.856   Training iter 300, batch loss 0.3373, batch acc 0.8642
10:37:52.171   Training iter 350, batch loss 0.3074, batch acc 0.8742
10:37:54.454   Training iter 400, batch loss 0.3171, batch acc 0.8714
10:37:56.773   Training iter 450, batch loss 0.3208, batch acc 0.8702
10:37:59.046   Training iter 500, batch loss 0.3315, batch acc 0.8680
10:38:01.333   Training iter 550, batch loss 0.3352, batch acc 0.8646
10:38:03.656   Training iter 600, batch loss 0.3255, batch acc 0.8714
10:38:03.658 Training @ 128 epoch...
10:38:05.948   Training iter 50, batch loss 0.3397, batch acc 0.8612
10:38:08.278   Training iter 100, batch loss 0.3221, batch acc 0.8700
10:38:10.540   Training iter 150, batch loss 0.3278, batch acc 0.8666
10:38:12.819   Training iter 200, batch loss 0.3153, batch acc 0.8726
10:38:15.096   Training iter 250, batch loss 0.3361, batch acc 0.8642
10:38:17.348   Training iter 300, batch loss 0.3170, batch acc 0.8728
10:38:19.614   Training iter 350, batch loss 0.3392, batch acc 0.8650
10:38:21.894   Training iter 400, batch loss 0.3237, batch acc 0.8706
10:38:24.225   Training iter 450, batch loss 0.3264, batch acc 0.8700
10:38:26.522   Training iter 500, batch loss 0.3342, batch acc 0.8680
10:38:28.844   Training iter 550, batch loss 0.3319, batch acc 0.8650
10:38:31.121   Training iter 600, batch loss 0.3339, batch acc 0.8672
10:38:31.122 Training @ 129 epoch...
10:38:33.405   Training iter 50, batch loss 0.3186, batch acc 0.8722
10:38:35.707   Training iter 100, batch loss 0.3428, batch acc 0.8602
10:38:37.988   Training iter 150, batch loss 0.3356, batch acc 0.8652
10:38:40.306   Training iter 200, batch loss 0.3248, batch acc 0.8700
10:38:42.671   Training iter 250, batch loss 0.3175, batch acc 0.8732
10:38:44.901   Training iter 300, batch loss 0.3309, batch acc 0.8674
10:38:47.147   Training iter 350, batch loss 0.2986, batch acc 0.8798
10:38:49.372   Training iter 400, batch loss 0.3467, batch acc 0.8586
10:38:51.619   Training iter 450, batch loss 0.3454, batch acc 0.8600
10:38:53.921   Training iter 500, batch loss 0.3419, batch acc 0.8616
10:38:56.285   Training iter 550, batch loss 0.3402, batch acc 0.8648
10:38:58.610   Training iter 600, batch loss 0.3090, batch acc 0.8784
10:38:58.612 Training @ 130 epoch...
10:39:00.909   Training iter 50, batch loss 0.3352, batch acc 0.8670
10:39:03.215   Training iter 100, batch loss 0.3273, batch acc 0.8682
10:39:05.542   Training iter 150, batch loss 0.3361, batch acc 0.8646
10:39:07.811   Training iter 200, batch loss 0.3211, batch acc 0.8694
10:39:10.082   Training iter 250, batch loss 0.3350, batch acc 0.8646
10:39:12.373   Training iter 300, batch loss 0.3369, batch acc 0.8646
10:39:14.637   Training iter 350, batch loss 0.3136, batch acc 0.8722
10:39:16.900   Training iter 400, batch loss 0.3254, batch acc 0.8678
10:39:19.162   Training iter 450, batch loss 0.3430, batch acc 0.8606
10:39:21.419   Training iter 500, batch loss 0.3045, batch acc 0.8758
10:39:23.669   Training iter 550, batch loss 0.3242, batch acc 0.8708
10:39:25.924   Training iter 600, batch loss 0.3394, batch acc 0.8680
10:39:25.926 Testing @ 130 epoch...
10:39:25.976     Testing, total mean loss 0.42026, total acc 0.84380
10:39:25.976 Training @ 131 epoch...
10:39:28.259   Training iter 50, batch loss 0.3194, batch acc 0.8736
10:39:30.537   Training iter 100, batch loss 0.3167, batch acc 0.8718
10:39:32.811   Training iter 150, batch loss 0.3212, batch acc 0.8718
10:39:35.058   Training iter 200, batch loss 0.3320, batch acc 0.8676
10:39:37.385   Training iter 250, batch loss 0.3253, batch acc 0.8708
10:39:39.709   Training iter 300, batch loss 0.3239, batch acc 0.8694
10:39:42.048   Training iter 350, batch loss 0.3567, batch acc 0.8554
10:39:44.336   Training iter 400, batch loss 0.3374, batch acc 0.8622
10:39:46.600   Training iter 450, batch loss 0.3473, batch acc 0.8600
10:39:48.845   Training iter 500, batch loss 0.3197, batch acc 0.8728
10:39:51.103   Training iter 550, batch loss 0.3252, batch acc 0.8680
10:39:53.391   Training iter 600, batch loss 0.3169, batch acc 0.8732
10:39:53.393 Training @ 132 epoch...
10:39:55.736   Training iter 50, batch loss 0.3126, batch acc 0.8750
10:39:57.989   Training iter 100, batch loss 0.3355, batch acc 0.8636
10:40:00.247   Training iter 150, batch loss 0.3016, batch acc 0.8790
10:40:02.517   Training iter 200, batch loss 0.3411, batch acc 0.8634
10:40:04.763   Training iter 250, batch loss 0.3482, batch acc 0.8586
10:40:07.080   Training iter 300, batch loss 0.3314, batch acc 0.8648
10:40:09.371   Training iter 350, batch loss 0.3269, batch acc 0.8662
10:40:11.607   Training iter 400, batch loss 0.3327, batch acc 0.8650
10:40:13.925   Training iter 450, batch loss 0.3233, batch acc 0.8704
10:40:16.257   Training iter 500, batch loss 0.3162, batch acc 0.8726
10:40:18.562   Training iter 550, batch loss 0.3265, batch acc 0.8672
10:40:20.840   Training iter 600, batch loss 0.3472, batch acc 0.8628
10:40:20.842 Training @ 133 epoch...
10:40:23.110   Training iter 50, batch loss 0.3230, batch acc 0.8700
10:40:25.401   Training iter 100, batch loss 0.3286, batch acc 0.8666
10:40:27.687   Training iter 150, batch loss 0.3132, batch acc 0.8736
10:40:29.949   Training iter 200, batch loss 0.3370, batch acc 0.8644
10:40:32.207   Training iter 250, batch loss 0.3271, batch acc 0.8704
10:40:34.467   Training iter 300, batch loss 0.3227, batch acc 0.8714
10:40:36.758   Training iter 350, batch loss 0.3334, batch acc 0.8678
10:40:39.075   Training iter 400, batch loss 0.3217, batch acc 0.8698
10:40:41.345   Training iter 450, batch loss 0.3543, batch acc 0.8578
10:40:43.591   Training iter 500, batch loss 0.3225, batch acc 0.8688
10:40:45.834   Training iter 550, batch loss 0.3381, batch acc 0.8636
10:40:48.077   Training iter 600, batch loss 0.3131, batch acc 0.8764
10:40:48.078 Training @ 134 epoch...
10:40:50.326   Training iter 50, batch loss 0.3045, batch acc 0.8802
10:40:52.597   Training iter 100, batch loss 0.3346, batch acc 0.8650
10:40:54.867   Training iter 150, batch loss 0.3187, batch acc 0.8730
10:40:57.161   Training iter 200, batch loss 0.3587, batch acc 0.8558
10:40:59.457   Training iter 250, batch loss 0.3056, batch acc 0.8750
10:41:01.742   Training iter 300, batch loss 0.3200, batch acc 0.8718
10:41:04.033   Training iter 350, batch loss 0.3261, batch acc 0.8666
10:41:06.318   Training iter 400, batch loss 0.3227, batch acc 0.8680
10:41:08.562   Training iter 450, batch loss 0.3215, batch acc 0.8680
10:41:10.801   Training iter 500, batch loss 0.3385, batch acc 0.8630
10:41:13.049   Training iter 550, batch loss 0.3648, batch acc 0.8554
10:41:15.311   Training iter 600, batch loss 0.3167, batch acc 0.8736
10:41:15.312 Training @ 135 epoch...
10:41:17.582   Training iter 50, batch loss 0.3038, batch acc 0.8778
10:41:19.866   Training iter 100, batch loss 0.3247, batch acc 0.8668
10:41:22.157   Training iter 150, batch loss 0.3275, batch acc 0.8694
10:41:24.478   Training iter 200, batch loss 0.3450, batch acc 0.8616
10:41:26.780   Training iter 250, batch loss 0.3254, batch acc 0.8720
10:41:29.009   Training iter 300, batch loss 0.3385, batch acc 0.8654
10:41:31.235   Training iter 350, batch loss 0.3027, batch acc 0.8774
10:41:33.471   Training iter 400, batch loss 0.3334, batch acc 0.8672
10:41:35.723   Training iter 450, batch loss 0.3204, batch acc 0.8702
10:41:37.968   Training iter 500, batch loss 0.3313, batch acc 0.8636
10:41:40.194   Training iter 550, batch loss 0.3429, batch acc 0.8626
10:41:42.421   Training iter 600, batch loss 0.3184, batch acc 0.8700
10:41:42.422 Testing @ 135 epoch...
10:41:42.472     Testing, total mean loss 0.38678, total acc 0.85270
10:41:42.472 Training @ 136 epoch...
10:41:44.756   Training iter 50, batch loss 0.3082, batch acc 0.8746
10:41:46.998   Training iter 100, batch loss 0.3257, batch acc 0.8686
10:41:49.235   Training iter 150, batch loss 0.3218, batch acc 0.8722
10:41:51.482   Training iter 200, batch loss 0.3275, batch acc 0.8656
10:41:53.758   Training iter 250, batch loss 0.3258, batch acc 0.8666
10:41:56.079   Training iter 300, batch loss 0.3338, batch acc 0.8660
10:41:58.405   Training iter 350, batch loss 0.3166, batch acc 0.8736
10:42:00.733   Training iter 400, batch loss 0.3258, batch acc 0.8690
10:42:03.071   Training iter 450, batch loss 0.3361, batch acc 0.8632
10:42:05.337   Training iter 500, batch loss 0.3374, batch acc 0.8660
10:42:07.611   Training iter 550, batch loss 0.3187, batch acc 0.8710
10:42:09.876   Training iter 600, batch loss 0.3469, batch acc 0.8604
10:42:09.878 Training @ 137 epoch...
10:42:12.142   Training iter 50, batch loss 0.3261, batch acc 0.8700
10:42:14.390   Training iter 100, batch loss 0.3062, batch acc 0.8762
10:42:16.637   Training iter 150, batch loss 0.3113, batch acc 0.8732
10:42:18.882   Training iter 200, batch loss 0.3236, batch acc 0.8700
10:42:21.164   Training iter 250, batch loss 0.3210, batch acc 0.8710
10:42:23.450   Training iter 300, batch loss 0.3354, batch acc 0.8654
10:42:25.764   Training iter 350, batch loss 0.3386, batch acc 0.8640
10:42:28.084   Training iter 400, batch loss 0.3169, batch acc 0.8732
10:42:30.382   Training iter 450, batch loss 0.3271, batch acc 0.8668
10:42:32.683   Training iter 500, batch loss 0.3402, batch acc 0.8618
10:42:34.953   Training iter 550, batch loss 0.3220, batch acc 0.8740
10:42:37.195   Training iter 600, batch loss 0.3551, batch acc 0.8568
10:42:37.197 Training @ 138 epoch...
10:42:39.450   Training iter 50, batch loss 0.3155, batch acc 0.8724
10:42:41.720   Training iter 100, batch loss 0.3472, batch acc 0.8586
10:42:44.035   Training iter 150, batch loss 0.3389, batch acc 0.8644
10:42:46.364   Training iter 200, batch loss 0.3263, batch acc 0.8710
10:42:48.605   Training iter 250, batch loss 0.3377, batch acc 0.8622
10:42:50.846   Training iter 300, batch loss 0.3015, batch acc 0.8778
10:42:53.089   Training iter 350, batch loss 0.3265, batch acc 0.8716
10:42:55.345   Training iter 400, batch loss 0.2974, batch acc 0.8814
10:42:57.603   Training iter 450, batch loss 0.3633, batch acc 0.8530
10:42:59.888   Training iter 500, batch loss 0.3234, batch acc 0.8692
10:43:02.149   Training iter 550, batch loss 0.3189, batch acc 0.8730
10:43:04.400   Training iter 600, batch loss 0.3323, batch acc 0.8660
10:43:04.402 Training @ 139 epoch...
10:43:06.655   Training iter 50, batch loss 0.3204, batch acc 0.8710
10:43:08.883   Training iter 100, batch loss 0.3081, batch acc 0.8762
10:43:11.120   Training iter 150, batch loss 0.3149, batch acc 0.8740
10:43:13.362   Training iter 200, batch loss 0.3255, batch acc 0.8714
10:43:15.602   Training iter 250, batch loss 0.3383, batch acc 0.8630
10:43:17.841   Training iter 300, batch loss 0.3150, batch acc 0.8720
10:43:20.081   Training iter 350, batch loss 0.3396, batch acc 0.8628
10:43:22.312   Training iter 400, batch loss 0.3223, batch acc 0.8710
10:43:24.546   Training iter 450, batch loss 0.3178, batch acc 0.8726
10:43:26.793   Training iter 500, batch loss 0.3307, batch acc 0.8658
10:43:29.059   Training iter 550, batch loss 0.3395, batch acc 0.8628
10:43:31.321   Training iter 600, batch loss 0.3477, batch acc 0.8604
10:43:31.322 Training @ 140 epoch...
10:43:33.582   Training iter 50, batch loss 0.3273, batch acc 0.8714
10:43:35.833   Training iter 100, batch loss 0.3316, batch acc 0.8670
10:43:38.088   Training iter 150, batch loss 0.3229, batch acc 0.8696
10:43:40.339   Training iter 200, batch loss 0.3272, batch acc 0.8672
10:43:42.591   Training iter 250, batch loss 0.3227, batch acc 0.8700
10:43:44.849   Training iter 300, batch loss 0.3310, batch acc 0.8686
10:43:47.106   Training iter 350, batch loss 0.3260, batch acc 0.8716
10:43:49.357   Training iter 400, batch loss 0.3175, batch acc 0.8692
10:43:51.609   Training iter 450, batch loss 0.3375, batch acc 0.8668
10:43:53.866   Training iter 500, batch loss 0.3146, batch acc 0.8728
10:43:56.114   Training iter 550, batch loss 0.3316, batch acc 0.8678
10:43:58.377   Training iter 600, batch loss 0.3318, batch acc 0.8698
10:43:58.379 Testing @ 140 epoch...
10:43:58.429     Testing, total mean loss 0.40051, total acc 0.85030
10:43:58.429 Training @ 141 epoch...
10:44:00.705   Training iter 50, batch loss 0.3228, batch acc 0.8686
10:44:02.975   Training iter 100, batch loss 0.3115, batch acc 0.8762
10:44:05.241   Training iter 150, batch loss 0.3185, batch acc 0.8710
10:44:07.486   Training iter 200, batch loss 0.3302, batch acc 0.8658
10:44:09.713   Training iter 250, batch loss 0.3274, batch acc 0.8692
10:44:11.939   Training iter 300, batch loss 0.3364, batch acc 0.8638
10:44:14.180   Training iter 350, batch loss 0.3213, batch acc 0.8682
10:44:16.418   Training iter 400, batch loss 0.3308, batch acc 0.8666
10:44:18.661   Training iter 450, batch loss 0.3339, batch acc 0.8654
10:44:20.930   Training iter 500, batch loss 0.3295, batch acc 0.8700
10:44:23.168   Training iter 550, batch loss 0.3397, batch acc 0.8626
10:44:25.424   Training iter 600, batch loss 0.3272, batch acc 0.8684
10:44:25.426 Training @ 142 epoch...
10:44:27.710   Training iter 50, batch loss 0.3322, batch acc 0.8674
10:44:29.963   Training iter 100, batch loss 0.3149, batch acc 0.8724
10:44:32.219   Training iter 150, batch loss 0.3341, batch acc 0.8658
10:44:34.477   Training iter 200, batch loss 0.3250, batch acc 0.8690
10:44:36.739   Training iter 250, batch loss 0.3282, batch acc 0.8680
10:44:38.977   Training iter 300, batch loss 0.3323, batch acc 0.8636
10:44:41.220   Training iter 350, batch loss 0.3325, batch acc 0.8656
10:44:43.458   Training iter 400, batch loss 0.3249, batch acc 0.8708
10:44:45.693   Training iter 450, batch loss 0.3399, batch acc 0.8636
10:44:47.928   Training iter 500, batch loss 0.3158, batch acc 0.8742
10:44:50.187   Training iter 550, batch loss 0.3288, batch acc 0.8692
10:44:52.453   Training iter 600, batch loss 0.3179, batch acc 0.8714
10:44:52.455 Training @ 143 epoch...
10:44:54.747   Training iter 50, batch loss 0.3215, batch acc 0.8724
10:44:57.109   Training iter 100, batch loss 0.3266, batch acc 0.8674
10:44:59.487   Training iter 150, batch loss 0.3489, batch acc 0.8596
10:45:01.895   Training iter 200, batch loss 0.3318, batch acc 0.8646
10:45:04.200   Training iter 250, batch loss 0.3269, batch acc 0.8682
10:45:06.496   Training iter 300, batch loss 0.3215, batch acc 0.8710
10:45:08.793   Training iter 350, batch loss 0.3233, batch acc 0.8696
10:45:11.124   Training iter 400, batch loss 0.3011, batch acc 0.8764
10:45:13.445   Training iter 450, batch loss 0.3405, batch acc 0.8634
10:45:15.722   Training iter 500, batch loss 0.3251, batch acc 0.8692
10:45:17.989   Training iter 550, batch loss 0.3162, batch acc 0.8736
10:45:20.264   Training iter 600, batch loss 0.3305, batch acc 0.8684
10:45:20.266 Training @ 144 epoch...
10:45:22.558   Training iter 50, batch loss 0.3372, batch acc 0.8622
10:45:24.846   Training iter 100, batch loss 0.3256, batch acc 0.8668
10:45:27.113   Training iter 150, batch loss 0.3211, batch acc 0.8696
10:45:29.390   Training iter 200, batch loss 0.3349, batch acc 0.8650
10:45:31.727   Training iter 250, batch loss 0.3170, batch acc 0.8728
10:45:33.984   Training iter 300, batch loss 0.3392, batch acc 0.8610
10:45:36.236   Training iter 350, batch loss 0.3276, batch acc 0.8700
10:45:38.516   Training iter 400, batch loss 0.3116, batch acc 0.8726
10:45:40.857   Training iter 450, batch loss 0.3332, batch acc 0.8664
10:45:43.130   Training iter 500, batch loss 0.3261, batch acc 0.8674
10:45:45.443   Training iter 550, batch loss 0.3259, batch acc 0.8708
10:45:47.715   Training iter 600, batch loss 0.3143, batch acc 0.8730
10:45:47.717 Training @ 145 epoch...
10:45:49.986   Training iter 50, batch loss 0.3194, batch acc 0.8714
10:45:52.285   Training iter 100, batch loss 0.3256, batch acc 0.8706
10:45:54.629   Training iter 150, batch loss 0.3232, batch acc 0.8704
10:45:56.951   Training iter 200, batch loss 0.3487, batch acc 0.8606
10:45:59.298   Training iter 250, batch loss 0.3236, batch acc 0.8698
10:46:01.634   Training iter 300, batch loss 0.3252, batch acc 0.8702
10:46:03.906   Training iter 350, batch loss 0.3301, batch acc 0.8668
10:46:06.175   Training iter 400, batch loss 0.3278, batch acc 0.8696
10:46:08.458   Training iter 450, batch loss 0.3251, batch acc 0.8678
10:46:10.735   Training iter 500, batch loss 0.3080, batch acc 0.8782
10:46:13.008   Training iter 550, batch loss 0.3422, batch acc 0.8616
10:46:15.282   Training iter 600, batch loss 0.3261, batch acc 0.8658
10:46:15.283 Testing @ 145 epoch...
10:46:15.334     Testing, total mean loss 0.40027, total acc 0.84980
10:46:15.334 Training @ 146 epoch...
10:46:17.603   Training iter 50, batch loss 0.3391, batch acc 0.8610
10:46:19.867   Training iter 100, batch loss 0.3129, batch acc 0.8732
10:46:22.190   Training iter 150, batch loss 0.3167, batch acc 0.8714
10:46:24.490   Training iter 200, batch loss 0.2953, batch acc 0.8812
10:46:26.741   Training iter 250, batch loss 0.3372, batch acc 0.8632
10:46:28.993   Training iter 300, batch loss 0.3488, batch acc 0.8564
10:46:31.283   Training iter 350, batch loss 0.3239, batch acc 0.8702
10:46:33.559   Training iter 400, batch loss 0.3280, batch acc 0.8692
10:46:35.830   Training iter 450, batch loss 0.3647, batch acc 0.8534
10:46:38.089   Training iter 500, batch loss 0.3234, batch acc 0.8700
10:46:40.349   Training iter 550, batch loss 0.3195, batch acc 0.8708
10:46:42.623   Training iter 600, batch loss 0.3031, batch acc 0.8806
10:46:42.625 Training @ 147 epoch...
10:46:44.914   Training iter 50, batch loss 0.3520, batch acc 0.8610
10:46:47.198   Training iter 100, batch loss 0.3388, batch acc 0.8614
10:46:49.438   Training iter 150, batch loss 0.3097, batch acc 0.8746
10:46:51.680   Training iter 200, batch loss 0.3211, batch acc 0.8680
10:46:53.980   Training iter 250, batch loss 0.3394, batch acc 0.8640
10:46:56.209   Training iter 300, batch loss 0.3325, batch acc 0.8646
10:46:58.467   Training iter 350, batch loss 0.3180, batch acc 0.8736
10:47:00.753   Training iter 400, batch loss 0.3341, batch acc 0.8662
10:47:03.067   Training iter 450, batch loss 0.3221, batch acc 0.8726
10:47:05.329   Training iter 500, batch loss 0.3035, batch acc 0.8760
10:47:07.650   Training iter 550, batch loss 0.3171, batch acc 0.8720
10:47:09.974   Training iter 600, batch loss 0.3289, batch acc 0.8670
10:47:09.976 Training @ 148 epoch...
10:47:12.315   Training iter 50, batch loss 0.3297, batch acc 0.8674
10:47:14.685   Training iter 100, batch loss 0.3273, batch acc 0.8694
10:47:17.031   Training iter 150, batch loss 0.3260, batch acc 0.8686
10:47:19.386   Training iter 200, batch loss 0.3241, batch acc 0.8688
10:47:21.693   Training iter 250, batch loss 0.3350, batch acc 0.8644
10:47:23.946   Training iter 300, batch loss 0.3355, batch acc 0.8674
10:47:26.212   Training iter 350, batch loss 0.3092, batch acc 0.8750
10:47:28.474   Training iter 400, batch loss 0.3291, batch acc 0.8660
10:47:30.788   Training iter 450, batch loss 0.3025, batch acc 0.8762
10:47:33.123   Training iter 500, batch loss 0.3370, batch acc 0.8652
10:47:35.443   Training iter 550, batch loss 0.3353, batch acc 0.8638
10:47:37.739   Training iter 600, batch loss 0.3261, batch acc 0.8682
10:47:37.741 Training @ 149 epoch...
10:47:39.987   Training iter 50, batch loss 0.3259, batch acc 0.8676
10:47:42.233   Training iter 100, batch loss 0.3336, batch acc 0.8650
10:47:44.476   Training iter 150, batch loss 0.3288, batch acc 0.8684
10:47:46.732   Training iter 200, batch loss 0.3459, batch acc 0.8628
10:47:48.986   Training iter 250, batch loss 0.3263, batch acc 0.8680
10:47:51.250   Training iter 300, batch loss 0.3293, batch acc 0.8666
10:47:53.508   Training iter 350, batch loss 0.3016, batch acc 0.8792
10:47:55.761   Training iter 400, batch loss 0.3285, batch acc 0.8674
10:47:58.018   Training iter 450, batch loss 0.3361, batch acc 0.8622
10:48:00.268   Training iter 500, batch loss 0.3298, batch acc 0.8674
10:48:02.534   Training iter 550, batch loss 0.3216, batch acc 0.8722
10:48:04.811   Training iter 600, batch loss 0.3006, batch acc 0.8804
10:48:04.813 Training @ 150 epoch...
10:48:07.089   Training iter 50, batch loss 0.3018, batch acc 0.8798
10:48:09.346   Training iter 100, batch loss 0.3221, batch acc 0.8684
10:48:11.584   Training iter 150, batch loss 0.3135, batch acc 0.8744
10:48:13.825   Training iter 200, batch loss 0.3267, batch acc 0.8698
10:48:16.056   Training iter 250, batch loss 0.3164, batch acc 0.8712
10:48:18.294   Training iter 300, batch loss 0.3340, batch acc 0.8638
10:48:20.557   Training iter 350, batch loss 0.3470, batch acc 0.8598
10:48:22.824   Training iter 400, batch loss 0.3188, batch acc 0.8740
10:48:25.095   Training iter 450, batch loss 0.3382, batch acc 0.8652
10:48:27.348   Training iter 500, batch loss 0.3319, batch acc 0.8674
10:48:29.621   Training iter 550, batch loss 0.3445, batch acc 0.8614
10:48:31.863   Training iter 600, batch loss 0.3174, batch acc 0.8724
10:48:31.865 Testing @ 150 epoch...
10:48:31.915     Testing, total mean loss 0.39625, total acc 0.85030
10:48:31.915 Training @ 151 epoch...
10:48:34.153   Training iter 50, batch loss 0.3432, batch acc 0.8634
10:48:36.417   Training iter 100, batch loss 0.3147, batch acc 0.8738
10:48:38.686   Training iter 150, batch loss 0.3084, batch acc 0.8764
10:48:40.956   Training iter 200, batch loss 0.3293, batch acc 0.8680
10:48:43.211   Training iter 250, batch loss 0.3202, batch acc 0.8698
10:48:45.460   Training iter 300, batch loss 0.3097, batch acc 0.8712
10:48:47.714   Training iter 350, batch loss 0.3495, batch acc 0.8572
10:48:49.963   Training iter 400, batch loss 0.3351, batch acc 0.8664
10:48:52.219   Training iter 450, batch loss 0.3403, batch acc 0.8602
10:48:54.486   Training iter 500, batch loss 0.3164, batch acc 0.8720
10:48:56.753   Training iter 550, batch loss 0.3176, batch acc 0.8742
10:48:59.007   Training iter 600, batch loss 0.3310, batch acc 0.8664
10:48:59.009 Training @ 152 epoch...
10:49:01.254   Training iter 50, batch loss 0.3028, batch acc 0.8772
10:49:03.519   Training iter 100, batch loss 0.3261, batch acc 0.8704
10:49:05.768   Training iter 150, batch loss 0.3298, batch acc 0.8684
10:49:08.021   Training iter 200, batch loss 0.3324, batch acc 0.8652
10:49:10.272   Training iter 250, batch loss 0.3256, batch acc 0.8680
10:49:12.517   Training iter 300, batch loss 0.3222, batch acc 0.8712
10:49:14.760   Training iter 350, batch loss 0.3210, batch acc 0.8716
10:49:17.005   Training iter 400, batch loss 0.3245, batch acc 0.8698
10:49:19.248   Training iter 450, batch loss 0.3177, batch acc 0.8710
10:49:21.493   Training iter 500, batch loss 0.3413, batch acc 0.8626
10:49:23.741   Training iter 550, batch loss 0.3334, batch acc 0.8628
10:49:25.985   Training iter 600, batch loss 0.3280, batch acc 0.8684
10:49:25.987 Training @ 153 epoch...
10:49:28.257   Training iter 50, batch loss 0.3309, batch acc 0.8668
10:49:30.522   Training iter 100, batch loss 0.3260, batch acc 0.8668
10:49:32.761   Training iter 150, batch loss 0.3424, batch acc 0.8634
10:49:34.985   Training iter 200, batch loss 0.3236, batch acc 0.8700
10:49:37.217   Training iter 250, batch loss 0.3324, batch acc 0.8660
10:49:39.451   Training iter 300, batch loss 0.3183, batch acc 0.8698
10:49:41.706   Training iter 350, batch loss 0.2804, batch acc 0.8834
10:49:43.968   Training iter 400, batch loss 0.3225, batch acc 0.8686
10:49:46.220   Training iter 450, batch loss 0.3304, batch acc 0.8690
10:49:48.454   Training iter 500, batch loss 0.3338, batch acc 0.8674
10:49:50.694   Training iter 550, batch loss 0.3386, batch acc 0.8656
10:49:52.924   Training iter 600, batch loss 0.3124, batch acc 0.8758
10:49:52.926 Training @ 154 epoch...
10:49:55.153   Training iter 50, batch loss 0.3322, batch acc 0.8630
10:49:57.397   Training iter 100, batch loss 0.3018, batch acc 0.8776
10:49:59.643   Training iter 150, batch loss 0.3339, batch acc 0.8638
10:50:01.916   Training iter 200, batch loss 0.3132, batch acc 0.8728
10:50:04.178   Training iter 250, batch loss 0.3240, batch acc 0.8710
10:50:06.450   Training iter 300, batch loss 0.3062, batch acc 0.8754
10:50:08.770   Training iter 350, batch loss 0.3349, batch acc 0.8658
10:50:11.032   Training iter 400, batch loss 0.3286, batch acc 0.8680
10:50:13.305   Training iter 450, batch loss 0.3356, batch acc 0.8640
10:50:15.582   Training iter 500, batch loss 0.3293, batch acc 0.8700
10:50:17.855   Training iter 550, batch loss 0.3374, batch acc 0.8634
10:50:20.118   Training iter 600, batch loss 0.3274, batch acc 0.8706
10:50:20.120 Training @ 155 epoch...
10:50:22.409   Training iter 50, batch loss 0.3262, batch acc 0.8686
10:50:24.657   Training iter 100, batch loss 0.3115, batch acc 0.8740
10:50:26.910   Training iter 150, batch loss 0.3280, batch acc 0.8670
10:50:29.190   Training iter 200, batch loss 0.3211, batch acc 0.8716
10:50:31.475   Training iter 250, batch loss 0.3267, batch acc 0.8694
10:50:33.799   Training iter 300, batch loss 0.3332, batch acc 0.8676
10:50:36.097   Training iter 350, batch loss 0.3248, batch acc 0.8680
10:50:38.378   Training iter 400, batch loss 0.2982, batch acc 0.8800
10:50:40.648   Training iter 450, batch loss 0.3327, batch acc 0.8654
10:50:42.911   Training iter 500, batch loss 0.3417, batch acc 0.8630
10:50:45.182   Training iter 550, batch loss 0.3291, batch acc 0.8696
10:50:47.460   Training iter 600, batch loss 0.3144, batch acc 0.8718
10:50:47.462 Testing @ 155 epoch...
10:50:47.513     Testing, total mean loss 0.39220, total acc 0.85180
10:50:47.513 Training @ 156 epoch...
10:50:49.787   Training iter 50, batch loss 0.3086, batch acc 0.8756
10:50:52.033   Training iter 100, batch loss 0.3339, batch acc 0.8670
10:50:54.276   Training iter 150, batch loss 0.3021, batch acc 0.8786
10:50:56.522   Training iter 200, batch loss 0.3420, batch acc 0.8636
10:50:58.804   Training iter 250, batch loss 0.3095, batch acc 0.8732
10:51:01.092   Training iter 300, batch loss 0.3327, batch acc 0.8660
10:51:03.357   Training iter 350, batch loss 0.3345, batch acc 0.8658
10:51:05.615   Training iter 400, batch loss 0.3372, batch acc 0.8636
10:51:07.875   Training iter 450, batch loss 0.3236, batch acc 0.8718
10:51:10.125   Training iter 500, batch loss 0.3242, batch acc 0.8700
10:51:12.377   Training iter 550, batch loss 0.3142, batch acc 0.8730
10:51:14.626   Training iter 600, batch loss 0.3360, batch acc 0.8648
10:51:14.628 Training @ 157 epoch...
10:51:16.886   Training iter 50, batch loss 0.3284, batch acc 0.8688
10:51:19.191   Training iter 100, batch loss 0.3315, batch acc 0.8648
10:51:21.521   Training iter 150, batch loss 0.3130, batch acc 0.8738
10:51:23.847   Training iter 200, batch loss 0.3339, batch acc 0.8646
10:51:26.268   Training iter 250, batch loss 0.3271, batch acc 0.8668
10:51:29.170   Training iter 300, batch loss 0.3299, batch acc 0.8668
10:51:31.661   Training iter 350, batch loss 0.3337, batch acc 0.8664
10:51:33.916   Training iter 400, batch loss 0.3208, batch acc 0.8700
10:51:36.180   Training iter 450, batch loss 0.3181, batch acc 0.8720
10:51:38.435   Training iter 500, batch loss 0.3172, batch acc 0.8722
10:51:40.699   Training iter 550, batch loss 0.3301, batch acc 0.8668
10:51:42.953   Training iter 600, batch loss 0.3103, batch acc 0.8736
10:51:42.955 Training @ 158 epoch...
10:51:45.183   Training iter 50, batch loss 0.2951, batch acc 0.8814
10:51:47.409   Training iter 100, batch loss 0.3253, batch acc 0.8684
10:51:49.641   Training iter 150, batch loss 0.3236, batch acc 0.8716
10:51:51.860   Training iter 200, batch loss 0.3156, batch acc 0.8724
10:51:54.077   Training iter 250, batch loss 0.3376, batch acc 0.8648
10:51:56.299   Training iter 300, batch loss 0.3251, batch acc 0.8678
10:51:58.524   Training iter 350, batch loss 0.3213, batch acc 0.8708
10:52:00.791   Training iter 400, batch loss 0.3229, batch acc 0.8708
10:52:03.060   Training iter 450, batch loss 0.3346, batch acc 0.8650
10:52:05.321   Training iter 500, batch loss 0.3365, batch acc 0.8632
10:52:07.596   Training iter 550, batch loss 0.3411, batch acc 0.8618
10:52:09.864   Training iter 600, batch loss 0.3180, batch acc 0.8716
10:52:09.865 Training @ 159 epoch...
10:52:12.124   Training iter 50, batch loss 0.3126, batch acc 0.8762
10:52:14.366   Training iter 100, batch loss 0.3241, batch acc 0.8708
10:52:16.604   Training iter 150, batch loss 0.3268, batch acc 0.8688
10:52:18.838   Training iter 200, batch loss 0.3192, batch acc 0.8704
10:52:21.086   Training iter 250, batch loss 0.3262, batch acc 0.8694
10:52:23.336   Training iter 300, batch loss 0.3258, batch acc 0.8704
10:52:25.585   Training iter 350, batch loss 0.3245, batch acc 0.8686
10:52:27.843   Training iter 400, batch loss 0.3154, batch acc 0.8698
10:52:30.116   Training iter 450, batch loss 0.3301, batch acc 0.8678
10:52:32.359   Training iter 500, batch loss 0.3372, batch acc 0.8632
10:52:34.600   Training iter 550, batch loss 0.3284, batch acc 0.8676
10:52:36.899   Training iter 600, batch loss 0.3251, batch acc 0.8688
10:52:36.900 Training @ 160 epoch...
10:52:39.180   Training iter 50, batch loss 0.3223, batch acc 0.8688
10:52:41.460   Training iter 100, batch loss 0.3418, batch acc 0.8604
10:52:43.692   Training iter 150, batch loss 0.3010, batch acc 0.8776
10:52:45.908   Training iter 200, batch loss 0.3304, batch acc 0.8672
10:52:48.142   Training iter 250, batch loss 0.3349, batch acc 0.8662
10:52:50.377   Training iter 300, batch loss 0.3120, batch acc 0.8736
10:52:52.643   Training iter 350, batch loss 0.3125, batch acc 0.8752
10:52:54.881   Training iter 400, batch loss 0.3181, batch acc 0.8700
10:52:57.124   Training iter 450, batch loss 0.3244, batch acc 0.8718
10:52:59.374   Training iter 500, batch loss 0.3381, batch acc 0.8614
10:53:01.637   Training iter 550, batch loss 0.3242, batch acc 0.8692
10:53:03.892   Training iter 600, batch loss 0.3196, batch acc 0.8706
10:53:03.894 Testing @ 160 epoch...
10:53:03.944     Testing, total mean loss 0.39699, total acc 0.85190
10:53:03.944 Training @ 161 epoch...
10:53:06.184   Training iter 50, batch loss 0.3283, batch acc 0.8670
10:53:08.413   Training iter 100, batch loss 0.3104, batch acc 0.8752
10:53:10.638   Training iter 150, batch loss 0.3350, batch acc 0.8648
10:53:12.887   Training iter 200, batch loss 0.3221, batch acc 0.8694
10:53:15.203   Training iter 250, batch loss 0.3235, batch acc 0.8678
10:53:17.512   Training iter 300, batch loss 0.2899, batch acc 0.8812
10:53:19.789   Training iter 350, batch loss 0.3209, batch acc 0.8712
10:53:22.037   Training iter 400, batch loss 0.3292, batch acc 0.8706
10:53:24.291   Training iter 450, batch loss 0.3155, batch acc 0.8734
10:53:26.540   Training iter 500, batch loss 0.3342, batch acc 0.8650
10:53:28.829   Training iter 550, batch loss 0.3285, batch acc 0.8666
10:53:31.152   Training iter 600, batch loss 0.3579, batch acc 0.8594
10:53:31.154 Training @ 162 epoch...
10:53:33.453   Training iter 50, batch loss 0.3229, batch acc 0.8690
10:53:35.726   Training iter 100, batch loss 0.3162, batch acc 0.8724
10:53:37.990   Training iter 150, batch loss 0.3224, batch acc 0.8694
10:53:40.253   Training iter 200, batch loss 0.3279, batch acc 0.8666
10:53:42.534   Training iter 250, batch loss 0.3330, batch acc 0.8638
10:53:44.812   Training iter 300, batch loss 0.3193, batch acc 0.8734
10:53:47.097   Training iter 350, batch loss 0.3389, batch acc 0.8638
10:53:49.374   Training iter 400, batch loss 0.3234, batch acc 0.8676
10:53:51.644   Training iter 450, batch loss 0.3309, batch acc 0.8678
10:53:53.882   Training iter 500, batch loss 0.3260, batch acc 0.8680
10:53:56.147   Training iter 550, batch loss 0.3219, batch acc 0.8704
10:53:58.470   Training iter 600, batch loss 0.3195, batch acc 0.8710
10:53:58.472 Training @ 163 epoch...
10:54:00.804   Training iter 50, batch loss 0.3074, batch acc 0.8742
10:54:03.139   Training iter 100, batch loss 0.3097, batch acc 0.8766
10:54:05.453   Training iter 150, batch loss 0.3231, batch acc 0.8692
10:54:07.776   Training iter 200, batch loss 0.3317, batch acc 0.8678
10:54:10.033   Training iter 250, batch loss 0.3122, batch acc 0.8748
10:54:12.277   Training iter 300, batch loss 0.3338, batch acc 0.8654
10:54:14.530   Training iter 350, batch loss 0.3131, batch acc 0.8746
10:54:16.793   Training iter 400, batch loss 0.3371, batch acc 0.8642
10:54:19.050   Training iter 450, batch loss 0.3397, batch acc 0.8618
10:54:21.311   Training iter 500, batch loss 0.3285, batch acc 0.8652
10:54:23.556   Training iter 550, batch loss 0.3326, batch acc 0.8648
10:54:25.806   Training iter 600, batch loss 0.3389, batch acc 0.8608
10:54:25.808 Training @ 164 epoch...
10:54:28.067   Training iter 50, batch loss 0.3273, batch acc 0.8688
10:54:30.312   Training iter 100, batch loss 0.3182, batch acc 0.8714
10:54:32.556   Training iter 150, batch loss 0.3198, batch acc 0.8734
10:54:34.811   Training iter 200, batch loss 0.3355, batch acc 0.8648
10:54:37.110   Training iter 250, batch loss 0.3126, batch acc 0.8724
10:54:39.417   Training iter 300, batch loss 0.3225, batch acc 0.8680
10:54:41.778   Training iter 350, batch loss 0.3362, batch acc 0.8628
10:54:44.122   Training iter 400, batch loss 0.3249, batch acc 0.8688
10:54:46.388   Training iter 450, batch loss 0.3226, batch acc 0.8696
10:54:48.676   Training iter 500, batch loss 0.3265, batch acc 0.8676
10:54:51.014   Training iter 550, batch loss 0.3213, batch acc 0.8674
10:54:53.314   Training iter 600, batch loss 0.3291, batch acc 0.8704
10:54:53.316 Training @ 165 epoch...
10:54:55.625   Training iter 50, batch loss 0.3056, batch acc 0.8738
10:54:57.929   Training iter 100, batch loss 0.3363, batch acc 0.8632
10:55:00.220   Training iter 150, batch loss 0.3208, batch acc 0.8724
10:55:02.735   Training iter 200, batch loss 0.3359, batch acc 0.8664
10:55:05.072   Training iter 250, batch loss 0.3168, batch acc 0.8740
10:55:07.320   Training iter 300, batch loss 0.3454, batch acc 0.8610
10:55:09.569   Training iter 350, batch loss 0.3321, batch acc 0.8650
10:55:11.819   Training iter 400, batch loss 0.3193, batch acc 0.8726
10:55:14.075   Training iter 450, batch loss 0.3190, batch acc 0.8690
10:55:16.502   Training iter 500, batch loss 0.3103, batch acc 0.8748
10:55:18.853   Training iter 550, batch loss 0.3209, batch acc 0.8698
10:55:21.249   Training iter 600, batch loss 0.3281, batch acc 0.8676
10:55:21.251 Testing @ 165 epoch...
10:55:21.301     Testing, total mean loss 0.39909, total acc 0.85090
10:55:21.301 Training @ 166 epoch...
10:55:23.587   Training iter 50, batch loss 0.3243, batch acc 0.8684
10:55:25.859   Training iter 100, batch loss 0.3103, batch acc 0.8730
10:55:28.172   Training iter 150, batch loss 0.3074, batch acc 0.8776
10:55:30.419   Training iter 200, batch loss 0.3204, batch acc 0.8698
10:55:32.658   Training iter 250, batch loss 0.3380, batch acc 0.8634
10:55:34.898   Training iter 300, batch loss 0.3537, batch acc 0.8558
10:55:37.173   Training iter 350, batch loss 0.3160, batch acc 0.8730
10:55:39.493   Training iter 400, batch loss 0.3217, batch acc 0.8738
10:55:41.772   Training iter 450, batch loss 0.3152, batch acc 0.8718
10:55:44.052   Training iter 500, batch loss 0.3439, batch acc 0.8636
10:55:46.402   Training iter 550, batch loss 0.3177, batch acc 0.8712
10:55:48.742   Training iter 600, batch loss 0.3132, batch acc 0.8732
10:55:48.744 Training @ 167 epoch...
10:55:51.088   Training iter 50, batch loss 0.3088, batch acc 0.8754
10:55:53.454   Training iter 100, batch loss 0.3299, batch acc 0.8660
10:55:55.810   Training iter 150, batch loss 0.3285, batch acc 0.8694
10:55:58.459   Training iter 200, batch loss 0.3246, batch acc 0.8698
10:56:01.014   Training iter 250, batch loss 0.3299, batch acc 0.8642
10:56:03.336   Training iter 300, batch loss 0.3228, batch acc 0.8700
10:56:05.626   Training iter 350, batch loss 0.3243, batch acc 0.8690
10:56:07.875   Training iter 400, batch loss 0.3045, batch acc 0.8782
10:56:10.128   Training iter 450, batch loss 0.3375, batch acc 0.8630
10:56:12.371   Training iter 500, batch loss 0.3195, batch acc 0.8728
10:56:14.666   Training iter 550, batch loss 0.3273, batch acc 0.8666
10:56:17.020   Training iter 600, batch loss 0.3327, batch acc 0.8668
10:56:17.022 Training @ 168 epoch...
10:56:19.342   Training iter 50, batch loss 0.3169, batch acc 0.8702
10:56:21.630   Training iter 100, batch loss 0.3138, batch acc 0.8730
10:56:23.923   Training iter 150, batch loss 0.3150, batch acc 0.8744
10:56:26.222   Training iter 200, batch loss 0.3292, batch acc 0.8656
10:56:28.540   Training iter 250, batch loss 0.3164, batch acc 0.8706
10:56:30.909   Training iter 300, batch loss 0.3120, batch acc 0.8756
10:56:33.293   Training iter 350, batch loss 0.3257, batch acc 0.8698
10:56:35.665   Training iter 400, batch loss 0.3210, batch acc 0.8686
10:56:37.981   Training iter 450, batch loss 0.3309, batch acc 0.8638
10:56:40.270   Training iter 500, batch loss 0.3371, batch acc 0.8660
10:56:42.559   Training iter 550, batch loss 0.3403, batch acc 0.8626
10:56:44.852   Training iter 600, batch loss 0.3346, batch acc 0.8650
10:56:44.854 Training @ 169 epoch...
10:56:47.150   Training iter 50, batch loss 0.2860, batch acc 0.8850
10:56:49.434   Training iter 100, batch loss 0.3040, batch acc 0.8778
10:56:51.729   Training iter 150, batch loss 0.3317, batch acc 0.8668
10:56:54.035   Training iter 200, batch loss 0.3204, batch acc 0.8714
10:56:56.339   Training iter 250, batch loss 0.3209, batch acc 0.8684
10:56:58.650   Training iter 300, batch loss 0.3320, batch acc 0.8684
10:57:00.997   Training iter 350, batch loss 0.3299, batch acc 0.8672
10:57:03.342   Training iter 400, batch loss 0.3349, batch acc 0.8650
10:57:05.706   Training iter 450, batch loss 0.3293, batch acc 0.8660
10:57:08.013   Training iter 500, batch loss 0.3384, batch acc 0.8630
10:57:10.301   Training iter 550, batch loss 0.3340, batch acc 0.8646
10:57:12.663   Training iter 600, batch loss 0.3191, batch acc 0.8716
10:57:12.665 Training @ 170 epoch...
10:57:15.232   Training iter 50, batch loss 0.3187, batch acc 0.8730
10:57:17.611   Training iter 100, batch loss 0.3192, batch acc 0.8734
10:57:20.058   Training iter 150, batch loss 0.3115, batch acc 0.8740
10:57:22.454   Training iter 200, batch loss 0.3308, batch acc 0.8646
10:57:24.787   Training iter 250, batch loss 0.3266, batch acc 0.8688
10:57:27.253   Training iter 300, batch loss 0.3331, batch acc 0.8662
10:57:29.598   Training iter 350, batch loss 0.3180, batch acc 0.8716
10:57:32.100   Training iter 400, batch loss 0.3321, batch acc 0.8644
10:57:34.459   Training iter 450, batch loss 0.3115, batch acc 0.8736
10:57:36.735   Training iter 500, batch loss 0.3232, batch acc 0.8700
10:57:39.025   Training iter 550, batch loss 0.3334, batch acc 0.8670
10:57:41.337   Training iter 600, batch loss 0.3284, batch acc 0.8666
10:57:41.339 Testing @ 170 epoch...
10:57:41.390     Testing, total mean loss 0.40263, total acc 0.84950
10:57:41.390 Training @ 171 epoch...
10:57:43.684   Training iter 50, batch loss 0.3316, batch acc 0.8644
10:57:45.976   Training iter 100, batch loss 0.3272, batch acc 0.8678
10:57:48.279   Training iter 150, batch loss 0.3172, batch acc 0.8712
10:57:50.574   Training iter 200, batch loss 0.3124, batch acc 0.8744
10:57:52.865   Training iter 250, batch loss 0.3148, batch acc 0.8714
10:57:55.158   Training iter 300, batch loss 0.3110, batch acc 0.8720
10:57:57.439   Training iter 350, batch loss 0.3206, batch acc 0.8692
10:57:59.699   Training iter 400, batch loss 0.3377, batch acc 0.8636
10:58:01.986   Training iter 450, batch loss 0.3142, batch acc 0.8750
10:58:04.336   Training iter 500, batch loss 0.3360, batch acc 0.8672
10:58:06.824   Training iter 550, batch loss 0.3314, batch acc 0.8660
10:58:09.119   Training iter 600, batch loss 0.3327, batch acc 0.8636
10:58:09.121 Training @ 172 epoch...
10:58:11.403   Training iter 50, batch loss 0.2981, batch acc 0.8802
10:58:13.688   Training iter 100, batch loss 0.3171, batch acc 0.8706
10:58:15.975   Training iter 150, batch loss 0.3281, batch acc 0.8698
10:58:18.265   Training iter 200, batch loss 0.3277, batch acc 0.8662
10:58:20.563   Training iter 250, batch loss 0.3194, batch acc 0.8704
10:58:22.863   Training iter 300, batch loss 0.3125, batch acc 0.8756
10:58:25.203   Training iter 350, batch loss 0.3243, batch acc 0.8680
10:58:27.505   Training iter 400, batch loss 0.3173, batch acc 0.8706
10:58:29.807   Training iter 450, batch loss 0.3436, batch acc 0.8612
10:58:32.152   Training iter 500, batch loss 0.3313, batch acc 0.8650
10:58:34.452   Training iter 550, batch loss 0.3396, batch acc 0.8658
10:58:36.770   Training iter 600, batch loss 0.3097, batch acc 0.8762
10:58:36.772 Training @ 173 epoch...
10:58:39.094   Training iter 50, batch loss 0.3261, batch acc 0.8682
10:58:41.414   Training iter 100, batch loss 0.3091, batch acc 0.8750
10:58:43.726   Training iter 150, batch loss 0.3411, batch acc 0.8626
10:58:46.027   Training iter 200, batch loss 0.3118, batch acc 0.8714
10:58:48.317   Training iter 250, batch loss 0.3336, batch acc 0.8666
10:58:50.621   Training iter 300, batch loss 0.3146, batch acc 0.8730
10:58:52.990   Training iter 350, batch loss 0.3070, batch acc 0.8764
10:58:55.335   Training iter 400, batch loss 0.3336, batch acc 0.8650
10:58:57.690   Training iter 450, batch loss 0.3235, batch acc 0.8716
10:59:00.038   Training iter 500, batch loss 0.3228, batch acc 0.8676
10:59:02.371   Training iter 550, batch loss 0.3191, batch acc 0.8708
10:59:04.688   Training iter 600, batch loss 0.3330, batch acc 0.8686
10:59:04.690 Training @ 174 epoch...
10:59:07.018   Training iter 50, batch loss 0.3082, batch acc 0.8752
10:59:09.344   Training iter 100, batch loss 0.2966, batch acc 0.8788
10:59:11.657   Training iter 150, batch loss 0.3358, batch acc 0.8640
10:59:13.964   Training iter 200, batch loss 0.3410, batch acc 0.8618
10:59:16.257   Training iter 250, batch loss 0.3255, batch acc 0.8680
10:59:18.554   Training iter 300, batch loss 0.3224, batch acc 0.8714
10:59:20.853   Training iter 350, batch loss 0.3229, batch acc 0.8712
10:59:23.158   Training iter 400, batch loss 0.3304, batch acc 0.8658
10:59:25.467   Training iter 450, batch loss 0.3192, batch acc 0.8714
10:59:27.777   Training iter 500, batch loss 0.3190, batch acc 0.8718
10:59:30.111   Training iter 550, batch loss 0.3198, batch acc 0.8724
10:59:32.419   Training iter 600, batch loss 0.3403, batch acc 0.8622
10:59:32.421 Training @ 175 epoch...
10:59:34.801   Training iter 50, batch loss 0.3020, batch acc 0.8804
10:59:37.194   Training iter 100, batch loss 0.3289, batch acc 0.8672
10:59:39.545   Training iter 150, batch loss 0.3276, batch acc 0.8652
10:59:41.867   Training iter 200, batch loss 0.3392, batch acc 0.8638
10:59:44.188   Training iter 250, batch loss 0.3006, batch acc 0.8768
10:59:46.487   Training iter 300, batch loss 0.3261, batch acc 0.8696
10:59:48.798   Training iter 350, batch loss 0.3246, batch acc 0.8692
10:59:51.186   Training iter 400, batch loss 0.3344, batch acc 0.8642
10:59:53.414   Training iter 450, batch loss 0.3150, batch acc 0.8722
10:59:55.646   Training iter 500, batch loss 0.3272, batch acc 0.8702
10:59:57.914   Training iter 550, batch loss 0.3224, batch acc 0.8704
11:00:00.235   Training iter 600, batch loss 0.3264, batch acc 0.8682
11:00:00.237 Testing @ 175 epoch...
11:00:00.290     Testing, total mean loss 0.39309, total acc 0.85250
11:00:00.290 Training @ 176 epoch...
11:00:02.681   Training iter 50, batch loss 0.3329, batch acc 0.8654
11:00:05.031   Training iter 100, batch loss 0.3153, batch acc 0.8732
11:00:07.331   Training iter 150, batch loss 0.3144, batch acc 0.8718
11:00:09.600   Training iter 200, batch loss 0.3332, batch acc 0.8682
11:00:11.854   Training iter 250, batch loss 0.3347, batch acc 0.8678
11:00:14.117   Training iter 300, batch loss 0.3318, batch acc 0.8664
11:00:16.381   Training iter 350, batch loss 0.3202, batch acc 0.8692
11:00:18.638   Training iter 400, batch loss 0.3221, batch acc 0.8696
11:00:20.880   Training iter 450, batch loss 0.3370, batch acc 0.8664
11:00:23.128   Training iter 500, batch loss 0.3104, batch acc 0.8726
11:00:25.373   Training iter 550, batch loss 0.3248, batch acc 0.8694
11:00:27.626   Training iter 600, batch loss 0.3043, batch acc 0.8766
11:00:27.628 Training @ 177 epoch...
11:00:29.994   Training iter 50, batch loss 0.3090, batch acc 0.8730
11:00:32.323   Training iter 100, batch loss 0.3001, batch acc 0.8786
11:00:34.630   Training iter 150, batch loss 0.3410, batch acc 0.8628
11:00:36.974   Training iter 200, batch loss 0.3381, batch acc 0.8638
11:00:39.266   Training iter 250, batch loss 0.3178, batch acc 0.8736
11:00:41.643   Training iter 300, batch loss 0.3320, batch acc 0.8684
11:00:43.901   Training iter 350, batch loss 0.3213, batch acc 0.8688
11:00:46.131   Training iter 400, batch loss 0.3081, batch acc 0.8762
11:00:48.392   Training iter 450, batch loss 0.3337, batch acc 0.8640
11:00:50.642   Training iter 500, batch loss 0.3106, batch acc 0.8738
11:00:52.885   Training iter 550, batch loss 0.3421, batch acc 0.8620
11:00:55.147   Training iter 600, batch loss 0.3170, batch acc 0.8702
11:00:55.149 Training @ 178 epoch...
11:00:57.386   Training iter 50, batch loss 0.3046, batch acc 0.8778
11:00:59.614   Training iter 100, batch loss 0.3383, batch acc 0.8612
11:01:01.864   Training iter 150, batch loss 0.3476, batch acc 0.8566
11:01:04.133   Training iter 200, batch loss 0.3103, batch acc 0.8752
11:01:06.399   Training iter 250, batch loss 0.3208, batch acc 0.8700
11:01:08.678   Training iter 300, batch loss 0.3080, batch acc 0.8752
11:01:10.924   Training iter 350, batch loss 0.3028, batch acc 0.8804
11:01:13.179   Training iter 400, batch loss 0.3178, batch acc 0.8740
11:01:15.420   Training iter 450, batch loss 0.3415, batch acc 0.8630
11:01:17.671   Training iter 500, batch loss 0.3293, batch acc 0.8668
11:01:19.933   Training iter 550, batch loss 0.3287, batch acc 0.8676
11:01:22.213   Training iter 600, batch loss 0.3255, batch acc 0.8670
11:01:22.215 Training @ 179 epoch...
11:01:24.487   Training iter 50, batch loss 0.3052, batch acc 0.8760
11:01:26.746   Training iter 100, batch loss 0.3472, batch acc 0.8590
11:01:28.998   Training iter 150, batch loss 0.3289, batch acc 0.8680
11:01:31.277   Training iter 200, batch loss 0.3172, batch acc 0.8720
11:01:33.521   Training iter 250, batch loss 0.3126, batch acc 0.8720
11:01:35.764   Training iter 300, batch loss 0.3212, batch acc 0.8708
11:01:38.015   Training iter 350, batch loss 0.3444, batch acc 0.8600
11:01:40.263   Training iter 400, batch loss 0.3195, batch acc 0.8706
11:01:42.556   Training iter 450, batch loss 0.3467, batch acc 0.8604
11:01:44.869   Training iter 500, batch loss 0.3119, batch acc 0.8742
11:01:47.188   Training iter 550, batch loss 0.3156, batch acc 0.8712
11:01:49.481   Training iter 600, batch loss 0.3184, batch acc 0.8692
11:01:49.483 Training @ 180 epoch...
11:01:51.774   Training iter 50, batch loss 0.3206, batch acc 0.8696
11:01:54.076   Training iter 100, batch loss 0.3232, batch acc 0.8674
11:01:56.413   Training iter 150, batch loss 0.3207, batch acc 0.8676
11:01:58.672   Training iter 200, batch loss 0.3308, batch acc 0.8682
11:02:00.932   Training iter 250, batch loss 0.3052, batch acc 0.8762
11:02:03.218   Training iter 300, batch loss 0.3117, batch acc 0.8734
11:02:05.567   Training iter 350, batch loss 0.3242, batch acc 0.8696
11:02:07.850   Training iter 400, batch loss 0.3197, batch acc 0.8710
11:02:10.105   Training iter 450, batch loss 0.3244, batch acc 0.8682
11:02:12.381   Training iter 500, batch loss 0.3351, batch acc 0.8636
11:02:14.667   Training iter 550, batch loss 0.3271, batch acc 0.8684
11:02:16.948   Training iter 600, batch loss 0.3276, batch acc 0.8662
11:02:16.949 Testing @ 180 epoch...
11:02:17.001     Testing, total mean loss 0.40075, total acc 0.84920
11:02:17.001 Training @ 181 epoch...
11:02:19.277   Training iter 50, batch loss 0.3216, batch acc 0.8706
11:02:21.564   Training iter 100, batch loss 0.3068, batch acc 0.8764
11:02:23.858   Training iter 150, batch loss 0.3306, batch acc 0.8666
11:02:26.146   Training iter 200, batch loss 0.3130, batch acc 0.8734
11:02:28.426   Training iter 250, batch loss 0.3218, batch acc 0.8718
11:02:30.696   Training iter 300, batch loss 0.3088, batch acc 0.8740
11:02:32.973   Training iter 350, batch loss 0.3250, batch acc 0.8682
11:02:35.248   Training iter 400, batch loss 0.3388, batch acc 0.8632
11:02:37.523   Training iter 450, batch loss 0.3146, batch acc 0.8734
11:02:39.808   Training iter 500, batch loss 0.3218, batch acc 0.8688
11:02:42.103   Training iter 550, batch loss 0.3274, batch acc 0.8686
11:02:44.376   Training iter 600, batch loss 0.3357, batch acc 0.8642
11:02:44.378 Training @ 182 epoch...
11:02:46.638   Training iter 50, batch loss 0.3072, batch acc 0.8768
11:02:48.908   Training iter 100, batch loss 0.3275, batch acc 0.8664
11:02:51.153   Training iter 150, batch loss 0.3276, batch acc 0.8664
11:02:53.397   Training iter 200, batch loss 0.3241, batch acc 0.8688
11:02:55.656   Training iter 250, batch loss 0.3204, batch acc 0.8684
11:02:57.953   Training iter 300, batch loss 0.3154, batch acc 0.8714
11:03:00.215   Training iter 350, batch loss 0.3295, batch acc 0.8664
11:03:02.548   Training iter 400, batch loss 0.3138, batch acc 0.8756
11:03:04.861   Training iter 450, batch loss 0.3214, batch acc 0.8690
11:03:07.120   Training iter 500, batch loss 0.3126, batch acc 0.8734
11:03:09.370   Training iter 550, batch loss 0.3329, batch acc 0.8652
11:03:11.620   Training iter 600, batch loss 0.3348, batch acc 0.8676
11:03:11.622 Training @ 183 epoch...
11:03:13.877   Training iter 50, batch loss 0.3088, batch acc 0.8738
11:03:16.132   Training iter 100, batch loss 0.3151, batch acc 0.8700
11:03:18.377   Training iter 150, batch loss 0.3331, batch acc 0.8662
11:03:20.613   Training iter 200, batch loss 0.3179, batch acc 0.8722
11:03:22.843   Training iter 250, batch loss 0.3131, batch acc 0.8734
11:03:25.084   Training iter 300, batch loss 0.3199, batch acc 0.8724
11:03:27.333   Training iter 350, batch loss 0.3280, batch acc 0.8678
11:03:29.579   Training iter 400, batch loss 0.3298, batch acc 0.8698
11:03:31.821   Training iter 450, batch loss 0.3163, batch acc 0.8734
11:03:34.065   Training iter 500, batch loss 0.3186, batch acc 0.8722
11:03:36.306   Training iter 550, batch loss 0.3158, batch acc 0.8704
11:03:38.549   Training iter 600, batch loss 0.3466, batch acc 0.8592
11:03:38.550 Training @ 184 epoch...
11:03:40.798   Training iter 50, batch loss 0.3247, batch acc 0.8712
11:03:43.058   Training iter 100, batch loss 0.3256, batch acc 0.8724
11:03:45.314   Training iter 150, batch loss 0.3167, batch acc 0.8716
11:03:47.574   Training iter 200, batch loss 0.3209, batch acc 0.8696
11:03:49.801   Training iter 250, batch loss 0.3218, batch acc 0.8724
11:03:52.033   Training iter 300, batch loss 0.3396, batch acc 0.8610
11:03:54.272   Training iter 350, batch loss 0.3287, batch acc 0.8640
11:03:56.517   Training iter 400, batch loss 0.3112, batch acc 0.8716
11:03:58.762   Training iter 450, batch loss 0.3161, batch acc 0.8704
11:04:01.016   Training iter 500, batch loss 0.3366, batch acc 0.8632
11:04:03.301   Training iter 550, batch loss 0.3229, batch acc 0.8680
11:04:05.564   Training iter 600, batch loss 0.3098, batch acc 0.8744
11:04:05.566 Training @ 185 epoch...
11:04:07.834   Training iter 50, batch loss 0.3182, batch acc 0.8718
11:04:10.126   Training iter 100, batch loss 0.3162, batch acc 0.8710
11:04:12.378   Training iter 150, batch loss 0.3348, batch acc 0.8642
11:04:14.640   Training iter 200, batch loss 0.3223, batch acc 0.8692
11:04:16.916   Training iter 250, batch loss 0.3158, batch acc 0.8718
11:04:19.189   Training iter 300, batch loss 0.3179, batch acc 0.8710
11:04:21.447   Training iter 350, batch loss 0.3243, batch acc 0.8694
11:04:23.690   Training iter 400, batch loss 0.3234, batch acc 0.8670
11:04:25.969   Training iter 450, batch loss 0.3093, batch acc 0.8762
11:04:28.291   Training iter 500, batch loss 0.3346, batch acc 0.8632
11:04:30.560   Training iter 550, batch loss 0.3107, batch acc 0.8738
11:04:32.826   Training iter 600, batch loss 0.3231, batch acc 0.8680
11:04:32.827 Testing @ 185 epoch...
11:04:32.877     Testing, total mean loss 0.40183, total acc 0.85000
11:04:32.877 Training @ 186 epoch...
11:04:35.150   Training iter 50, batch loss 0.3294, batch acc 0.8656
11:04:37.400   Training iter 100, batch loss 0.3283, batch acc 0.8660
11:04:39.646   Training iter 150, batch loss 0.3235, batch acc 0.8710
11:04:41.886   Training iter 200, batch loss 0.3229, batch acc 0.8676
11:04:44.124   Training iter 250, batch loss 0.3154, batch acc 0.8722
11:04:46.354   Training iter 300, batch loss 0.3291, batch acc 0.8652
11:04:48.588   Training iter 350, batch loss 0.3194, batch acc 0.8696
11:04:50.827   Training iter 400, batch loss 0.3247, batch acc 0.8714
11:04:53.061   Training iter 450, batch loss 0.3210, batch acc 0.8708
11:04:55.288   Training iter 500, batch loss 0.3096, batch acc 0.8756
11:04:57.526   Training iter 550, batch loss 0.3294, batch acc 0.8674
11:04:59.816   Training iter 600, batch loss 0.3125, batch acc 0.8756
11:04:59.818 Training @ 187 epoch...
11:05:02.107   Training iter 50, batch loss 0.3154, batch acc 0.8720
11:05:04.388   Training iter 100, batch loss 0.3276, batch acc 0.8664
11:05:06.649   Training iter 150, batch loss 0.3117, batch acc 0.8732
11:05:08.904   Training iter 200, batch loss 0.3177, batch acc 0.8710
11:05:11.171   Training iter 250, batch loss 0.3265, batch acc 0.8708
11:05:13.497   Training iter 300, batch loss 0.3292, batch acc 0.8660
11:05:15.782   Training iter 350, batch loss 0.3308, batch acc 0.8652
11:05:18.037   Training iter 400, batch loss 0.3226, batch acc 0.8674
11:05:20.294   Training iter 450, batch loss 0.3386, batch acc 0.8638
11:05:22.585   Training iter 500, batch loss 0.3041, batch acc 0.8766
11:05:24.848   Training iter 550, batch loss 0.3177, batch acc 0.8708
11:05:27.098   Training iter 600, batch loss 0.3141, batch acc 0.8750
11:05:27.099 Training @ 188 epoch...
11:05:29.352   Training iter 50, batch loss 0.3098, batch acc 0.8772
11:05:31.620   Training iter 100, batch loss 0.3397, batch acc 0.8602
11:05:33.906   Training iter 150, batch loss 0.3100, batch acc 0.8750
11:05:36.153   Training iter 200, batch loss 0.3085, batch acc 0.8750
11:05:38.400   Training iter 250, batch loss 0.3115, batch acc 0.8754
11:05:40.642   Training iter 300, batch loss 0.3039, batch acc 0.8756
11:05:42.880   Training iter 350, batch loss 0.3268, batch acc 0.8666
11:05:45.127   Training iter 400, batch loss 0.3302, batch acc 0.8690
11:05:47.376   Training iter 450, batch loss 0.3293, batch acc 0.8654
11:05:49.626   Training iter 500, batch loss 0.3306, batch acc 0.8630
11:05:51.889   Training iter 550, batch loss 0.3231, batch acc 0.8706
11:05:54.168   Training iter 600, batch loss 0.3438, batch acc 0.8608
11:05:54.170 Training @ 189 epoch...
11:05:56.450   Training iter 50, batch loss 0.3223, batch acc 0.8704
11:05:58.711   Training iter 100, batch loss 0.3289, batch acc 0.8654
11:06:00.961   Training iter 150, batch loss 0.3276, batch acc 0.8682
11:06:03.251   Training iter 200, batch loss 0.3094, batch acc 0.8782
11:06:05.510   Training iter 250, batch loss 0.3175, batch acc 0.8698
11:06:07.765   Training iter 300, batch loss 0.3187, batch acc 0.8696
11:06:10.008   Training iter 350, batch loss 0.3199, batch acc 0.8712
11:06:12.307   Training iter 400, batch loss 0.3310, batch acc 0.8662
11:06:14.565   Training iter 450, batch loss 0.3184, batch acc 0.8708
11:06:16.829   Training iter 500, batch loss 0.3177, batch acc 0.8694
11:06:19.079   Training iter 550, batch loss 0.3271, batch acc 0.8664
11:06:21.340   Training iter 600, batch loss 0.3259, batch acc 0.8682
11:06:21.341 Training @ 190 epoch...
11:06:23.631   Training iter 50, batch loss 0.3215, batch acc 0.8710
11:06:25.941   Training iter 100, batch loss 0.3238, batch acc 0.8692
11:06:28.339   Training iter 150, batch loss 0.3147, batch acc 0.8724
11:06:30.682   Training iter 200, batch loss 0.3181, batch acc 0.8712
11:06:33.128   Training iter 250, batch loss 0.3230, batch acc 0.8680
11:06:35.513   Training iter 300, batch loss 0.3224, batch acc 0.8682
11:06:37.795   Training iter 350, batch loss 0.3305, batch acc 0.8668
11:06:40.075   Training iter 400, batch loss 0.3185, batch acc 0.8712
11:06:42.765   Training iter 450, batch loss 0.3195, batch acc 0.8718
11:06:45.171   Training iter 500, batch loss 0.3196, batch acc 0.8704
11:06:47.509   Training iter 550, batch loss 0.3159, batch acc 0.8714
11:06:49.804   Training iter 600, batch loss 0.3229, batch acc 0.8718
11:06:49.806 Testing @ 190 epoch...
11:06:49.859     Testing, total mean loss 0.39428, total acc 0.85160
11:06:49.859 Training @ 191 epoch...
11:06:52.156   Training iter 50, batch loss 0.3170, batch acc 0.8704
11:06:54.442   Training iter 100, batch loss 0.3101, batch acc 0.8752
11:06:56.740   Training iter 150, batch loss 0.3376, batch acc 0.8674
11:06:59.049   Training iter 200, batch loss 0.3306, batch acc 0.8670
11:07:01.400   Training iter 250, batch loss 0.3194, batch acc 0.8706
11:07:03.744   Training iter 300, batch loss 0.3314, batch acc 0.8670
11:07:06.087   Training iter 350, batch loss 0.3281, batch acc 0.8682
11:07:08.636   Training iter 400, batch loss 0.3177, batch acc 0.8692
11:07:10.998   Training iter 450, batch loss 0.3158, batch acc 0.8734
11:07:13.305   Training iter 500, batch loss 0.3333, batch acc 0.8664
11:07:15.607   Training iter 550, batch loss 0.3036, batch acc 0.8754
11:07:17.957   Training iter 600, batch loss 0.3194, batch acc 0.8680
11:07:17.959 Training @ 192 epoch...
11:07:20.252   Training iter 50, batch loss 0.3210, batch acc 0.8698
11:07:22.513   Training iter 100, batch loss 0.3135, batch acc 0.8716
11:07:24.783   Training iter 150, batch loss 0.3076, batch acc 0.8740
11:07:27.087   Training iter 200, batch loss 0.3136, batch acc 0.8726
11:07:29.384   Training iter 250, batch loss 0.3222, batch acc 0.8700
11:07:31.715   Training iter 300, batch loss 0.3132, batch acc 0.8730
11:07:33.994   Training iter 350, batch loss 0.3394, batch acc 0.8614
11:07:36.283   Training iter 400, batch loss 0.3267, batch acc 0.8670
11:07:38.572   Training iter 450, batch loss 0.3219, batch acc 0.8686
11:07:40.887   Training iter 500, batch loss 0.3290, batch acc 0.8688
11:07:43.379   Training iter 550, batch loss 0.3204, batch acc 0.8716
11:07:45.735   Training iter 600, batch loss 0.3215, batch acc 0.8684
11:07:45.737 Training @ 193 epoch...
11:07:48.139   Training iter 50, batch loss 0.3037, batch acc 0.8756
11:07:50.504   Training iter 100, batch loss 0.3162, batch acc 0.8728
11:07:52.815   Training iter 150, batch loss 0.3377, batch acc 0.8644
11:07:55.146   Training iter 200, batch loss 0.3107, batch acc 0.8752
11:07:57.482   Training iter 250, batch loss 0.3207, batch acc 0.8728
11:07:59.820   Training iter 300, batch loss 0.3185, batch acc 0.8714
11:08:02.551   Training iter 350, batch loss 0.3081, batch acc 0.8736
11:08:04.964   Training iter 400, batch loss 0.3142, batch acc 0.8722
11:08:07.331   Training iter 450, batch loss 0.3439, batch acc 0.8616
11:08:09.845   Training iter 500, batch loss 0.3302, batch acc 0.8648
11:08:12.366   Training iter 550, batch loss 0.3080, batch acc 0.8756
11:08:14.840   Training iter 600, batch loss 0.3380, batch acc 0.8612
11:08:14.842 Training @ 194 epoch...
11:08:17.161   Training iter 50, batch loss 0.3270, batch acc 0.8684
11:08:19.489   Training iter 100, batch loss 0.3434, batch acc 0.8622
11:08:21.856   Training iter 150, batch loss 0.2910, batch acc 0.8802
11:08:24.248   Training iter 200, batch loss 0.3071, batch acc 0.8754
11:08:26.566   Training iter 250, batch loss 0.3016, batch acc 0.8784
11:08:28.886   Training iter 300, batch loss 0.3196, batch acc 0.8690
11:08:31.195   Training iter 350, batch loss 0.3255, batch acc 0.8682
11:08:33.524   Training iter 400, batch loss 0.3306, batch acc 0.8662
11:08:35.843   Training iter 450, batch loss 0.3240, batch acc 0.8692
11:08:38.669   Training iter 500, batch loss 0.3304, batch acc 0.8654
11:08:40.987   Training iter 550, batch loss 0.3345, batch acc 0.8660
11:08:43.317   Training iter 600, batch loss 0.3255, batch acc 0.8676
11:08:43.319 Training @ 195 epoch...
11:08:45.628   Training iter 50, batch loss 0.3021, batch acc 0.8770
11:08:47.956   Training iter 100, batch loss 0.3157, batch acc 0.8718
11:08:50.322   Training iter 150, batch loss 0.3259, batch acc 0.8694
11:08:52.741   Training iter 200, batch loss 0.3080, batch acc 0.8730
11:08:55.128   Training iter 250, batch loss 0.3410, batch acc 0.8640
11:08:57.495   Training iter 300, batch loss 0.3108, batch acc 0.8752
11:08:59.842   Training iter 350, batch loss 0.3310, batch acc 0.8650
11:09:02.162   Training iter 400, batch loss 0.3276, batch acc 0.8680
11:09:04.469   Training iter 450, batch loss 0.3371, batch acc 0.8658
11:09:06.779   Training iter 500, batch loss 0.3304, batch acc 0.8672
11:09:09.083   Training iter 550, batch loss 0.3222, batch acc 0.8696
11:09:11.386   Training iter 600, batch loss 0.3019, batch acc 0.8772
11:09:11.388 Testing @ 195 epoch...
11:09:11.442     Testing, total mean loss 0.39770, total acc 0.85250
11:09:11.442 Training @ 196 epoch...
11:09:13.729   Training iter 50, batch loss 0.3215, batch acc 0.8726
11:09:16.019   Training iter 100, batch loss 0.3049, batch acc 0.8768
11:09:18.311   Training iter 150, batch loss 0.3376, batch acc 0.8622
11:09:20.594   Training iter 200, batch loss 0.3090, batch acc 0.8746
11:09:22.903   Training iter 250, batch loss 0.3269, batch acc 0.8664
11:09:25.214   Training iter 300, batch loss 0.3309, batch acc 0.8646
11:09:27.532   Training iter 350, batch loss 0.3037, batch acc 0.8784
11:09:29.832   Training iter 400, batch loss 0.3163, batch acc 0.8726
11:09:32.125   Training iter 450, batch loss 0.3411, batch acc 0.8634
11:09:34.473   Training iter 500, batch loss 0.3108, batch acc 0.8740
11:09:36.764   Training iter 550, batch loss 0.3183, batch acc 0.8726
11:09:39.074   Training iter 600, batch loss 0.3361, batch acc 0.8638
11:09:39.076 Training @ 197 epoch...
11:09:41.435   Training iter 50, batch loss 0.3316, batch acc 0.8672
11:09:43.799   Training iter 100, batch loss 0.3409, batch acc 0.8590
11:09:46.156   Training iter 150, batch loss 0.3088, batch acc 0.8758
11:09:48.525   Training iter 200, batch loss 0.3081, batch acc 0.8750
11:09:50.884   Training iter 250, batch loss 0.3274, batch acc 0.8664
11:09:53.221   Training iter 300, batch loss 0.3281, batch acc 0.8678
11:09:55.541   Training iter 350, batch loss 0.2934, batch acc 0.8802
11:09:57.860   Training iter 400, batch loss 0.3220, batch acc 0.8678
11:10:00.174   Training iter 450, batch loss 0.3282, batch acc 0.8658
11:10:02.499   Training iter 500, batch loss 0.3175, batch acc 0.8712
11:10:04.819   Training iter 550, batch loss 0.3300, batch acc 0.8658
11:10:07.127   Training iter 600, batch loss 0.3074, batch acc 0.8758
11:10:07.129 Training @ 198 epoch...
11:10:09.444   Training iter 50, batch loss 0.3286, batch acc 0.8690
11:10:11.740   Training iter 100, batch loss 0.3139, batch acc 0.8724
11:10:14.031   Training iter 150, batch loss 0.2930, batch acc 0.8818
11:10:16.329   Training iter 200, batch loss 0.3235, batch acc 0.8666
11:10:18.653   Training iter 250, batch loss 0.3163, batch acc 0.8724
11:10:20.925   Training iter 300, batch loss 0.3113, batch acc 0.8728
11:10:23.197   Training iter 350, batch loss 0.3347, batch acc 0.8642
11:10:25.496   Training iter 400, batch loss 0.3236, batch acc 0.8688
11:10:27.882   Training iter 450, batch loss 0.3199, batch acc 0.8716
11:10:30.303   Training iter 500, batch loss 0.3270, batch acc 0.8676
11:10:32.826   Training iter 550, batch loss 0.3250, batch acc 0.8666
11:10:35.197   Training iter 600, batch loss 0.3314, batch acc 0.8650
11:10:35.199 Training @ 199 epoch...
11:10:37.526   Training iter 50, batch loss 0.3143, batch acc 0.8732
11:10:39.853   Training iter 100, batch loss 0.2959, batch acc 0.8794
11:10:42.162   Training iter 150, batch loss 0.3248, batch acc 0.8684
11:10:44.497   Training iter 200, batch loss 0.3168, batch acc 0.8722
11:10:46.798   Training iter 250, batch loss 0.3397, batch acc 0.8654
11:10:49.091   Training iter 300, batch loss 0.3377, batch acc 0.8616
11:10:51.424   Training iter 350, batch loss 0.3082, batch acc 0.8744
11:10:53.793   Training iter 400, batch loss 0.3122, batch acc 0.8756
11:10:56.128   Training iter 450, batch loss 0.3265, batch acc 0.8664
11:10:58.439   Training iter 500, batch loss 0.3317, batch acc 0.8674
11:11:00.903   Training iter 550, batch loss 0.3151, batch acc 0.8716
11:11:03.436   Training iter 600, batch loss 0.3220, batch acc 0.8712
11:11:03.438 Training @ 200 epoch...
11:11:05.954   Training iter 50, batch loss 0.2932, batch acc 0.8812
11:11:08.482   Training iter 100, batch loss 0.3160, batch acc 0.8740
11:11:10.971   Training iter 150, batch loss 0.3197, batch acc 0.8694
11:11:13.457   Training iter 200, batch loss 0.3166, batch acc 0.8732
11:11:15.963   Training iter 250, batch loss 0.3245, batch acc 0.8660
11:11:18.483   Training iter 300, batch loss 0.3449, batch acc 0.8590
11:11:20.991   Training iter 350, batch loss 0.2902, batch acc 0.8816
11:11:23.475   Training iter 400, batch loss 0.3141, batch acc 0.8722
11:11:25.961   Training iter 450, batch loss 0.3312, batch acc 0.8660
11:11:28.482   Training iter 500, batch loss 0.3342, batch acc 0.8630
11:11:30.988   Training iter 550, batch loss 0.3344, batch acc 0.8644
11:11:33.456   Training iter 600, batch loss 0.3211, batch acc 0.8706
11:11:33.458 Testing @ 200 epoch...
11:11:33.511     Testing, total mean loss 0.40237, total acc 0.85040
11:11:33.511 Plot @ 200 epoch...
11:11:33.511 Training @ 201 epoch...
11:11:35.827   Training iter 50, batch loss 0.3252, batch acc 0.8680
11:11:38.134   Training iter 100, batch loss 0.3240, batch acc 0.8700
11:11:40.453   Training iter 150, batch loss 0.3204, batch acc 0.8702
11:11:42.743   Training iter 200, batch loss 0.3228, batch acc 0.8668
11:11:45.024   Training iter 250, batch loss 0.3178, batch acc 0.8710
11:11:47.301   Training iter 300, batch loss 0.3332, batch acc 0.8664
11:11:49.581   Training iter 350, batch loss 0.3154, batch acc 0.8740
11:11:51.863   Training iter 400, batch loss 0.3179, batch acc 0.8716
11:11:54.160   Training iter 450, batch loss 0.3157, batch acc 0.8740
11:11:56.452   Training iter 500, batch loss 0.3281, batch acc 0.8656
11:11:58.751   Training iter 550, batch loss 0.3004, batch acc 0.8782
11:12:01.050   Training iter 600, batch loss 0.3241, batch acc 0.8668
11:12:01.052 Training @ 202 epoch...
11:12:03.363   Training iter 50, batch loss 0.3079, batch acc 0.8744
11:12:05.662   Training iter 100, batch loss 0.3367, batch acc 0.8630
11:12:08.119   Training iter 150, batch loss 0.3176, batch acc 0.8712
11:12:10.621   Training iter 200, batch loss 0.3063, batch acc 0.8746
11:12:13.104   Training iter 250, batch loss 0.3322, batch acc 0.8660
11:12:15.606   Training iter 300, batch loss 0.3280, batch acc 0.8658
11:12:18.108   Training iter 350, batch loss 0.3181, batch acc 0.8718
11:12:20.608   Training iter 400, batch loss 0.2943, batch acc 0.8816
11:12:23.035   Training iter 450, batch loss 0.3289, batch acc 0.8644
11:12:25.336   Training iter 500, batch loss 0.3289, batch acc 0.8676
11:12:27.636   Training iter 550, batch loss 0.3192, batch acc 0.8714
11:12:29.923   Training iter 600, batch loss 0.3229, batch acc 0.8690
11:12:29.925 Training @ 203 epoch...
11:12:32.208   Training iter 50, batch loss 0.3044, batch acc 0.8768
11:12:34.480   Training iter 100, batch loss 0.3142, batch acc 0.8744
11:12:36.801   Training iter 150, batch loss 0.2979, batch acc 0.8792
11:12:39.113   Training iter 200, batch loss 0.3200, batch acc 0.8712
11:12:41.422   Training iter 250, batch loss 0.3307, batch acc 0.8640
11:12:43.712   Training iter 300, batch loss 0.3229, batch acc 0.8704
11:12:45.993   Training iter 350, batch loss 0.3222, batch acc 0.8698
11:12:48.287   Training iter 400, batch loss 0.3242, batch acc 0.8692
11:12:50.584   Training iter 450, batch loss 0.3252, batch acc 0.8694
11:12:52.887   Training iter 500, batch loss 0.3309, batch acc 0.8674
11:12:55.190   Training iter 550, batch loss 0.3250, batch acc 0.8672
11:12:57.484   Training iter 600, batch loss 0.3205, batch acc 0.8718
11:12:57.485 Training @ 204 epoch...
11:12:59.779   Training iter 50, batch loss 0.3248, batch acc 0.8702
11:13:02.086   Training iter 100, batch loss 0.3136, batch acc 0.8732
11:13:04.398   Training iter 150, batch loss 0.3292, batch acc 0.8682
11:13:06.698   Training iter 200, batch loss 0.3034, batch acc 0.8768
11:13:09.012   Training iter 250, batch loss 0.3373, batch acc 0.8634
11:13:11.326   Training iter 300, batch loss 0.3385, batch acc 0.8622
11:13:13.628   Training iter 350, batch loss 0.3157, batch acc 0.8732
11:13:15.940   Training iter 400, batch loss 0.3208, batch acc 0.8718
11:13:18.255   Training iter 450, batch loss 0.3186, batch acc 0.8712
11:13:20.549   Training iter 500, batch loss 0.3108, batch acc 0.8764
11:13:22.843   Training iter 550, batch loss 0.3186, batch acc 0.8694
11:13:25.137   Training iter 600, batch loss 0.3158, batch acc 0.8710
11:13:25.138 Training @ 205 epoch...
11:13:27.455   Training iter 50, batch loss 0.3279, batch acc 0.8664
11:13:29.766   Training iter 100, batch loss 0.3282, batch acc 0.8678
11:13:32.080   Training iter 150, batch loss 0.2960, batch acc 0.8814
11:13:34.371   Training iter 200, batch loss 0.3015, batch acc 0.8786
11:13:36.648   Training iter 250, batch loss 0.3354, batch acc 0.8652
11:13:38.921   Training iter 300, batch loss 0.3234, batch acc 0.8678
11:13:41.241   Training iter 350, batch loss 0.3264, batch acc 0.8684
11:13:43.571   Training iter 400, batch loss 0.3194, batch acc 0.8708
11:13:45.899   Training iter 450, batch loss 0.3217, batch acc 0.8676
11:13:48.213   Training iter 500, batch loss 0.3116, batch acc 0.8730
11:13:50.485   Training iter 550, batch loss 0.3219, batch acc 0.8682
11:13:52.771   Training iter 600, batch loss 0.3292, batch acc 0.8652
11:13:52.773 Testing @ 205 epoch...
11:13:52.826     Testing, total mean loss 0.39716, total acc 0.85130
11:13:52.827 Training @ 206 epoch...
11:13:55.124   Training iter 50, batch loss 0.3334, batch acc 0.8634
11:13:57.412   Training iter 100, batch loss 0.3233, batch acc 0.8694
11:13:59.694   Training iter 150, batch loss 0.3166, batch acc 0.8720
11:14:02.014   Training iter 200, batch loss 0.3206, batch acc 0.8692
11:14:04.403   Training iter 250, batch loss 0.3146, batch acc 0.8728
11:14:06.796   Training iter 300, batch loss 0.3082, batch acc 0.8740
11:14:09.150   Training iter 350, batch loss 0.3219, batch acc 0.8686
11:14:11.958   Training iter 400, batch loss 0.3141, batch acc 0.8728
11:14:14.320   Training iter 450, batch loss 0.3136, batch acc 0.8726
11:14:16.683   Training iter 500, batch loss 0.3201, batch acc 0.8698
11:14:19.045   Training iter 550, batch loss 0.3383, batch acc 0.8612
11:14:21.375   Training iter 600, batch loss 0.3060, batch acc 0.8760
11:14:21.377 Training @ 207 epoch...
11:14:23.674   Training iter 50, batch loss 0.3074, batch acc 0.8772
11:14:25.973   Training iter 100, batch loss 0.3297, batch acc 0.8666
11:14:28.338   Training iter 150, batch loss 0.3124, batch acc 0.8714
11:14:30.689   Training iter 200, batch loss 0.3062, batch acc 0.8740
11:14:33.045   Training iter 250, batch loss 0.3030, batch acc 0.8794
11:14:35.359   Training iter 300, batch loss 0.3289, batch acc 0.8658
11:14:37.663   Training iter 350, batch loss 0.3236, batch acc 0.8692
11:14:39.952   Training iter 400, batch loss 0.3503, batch acc 0.8574
11:14:42.249   Training iter 450, batch loss 0.3061, batch acc 0.8764
11:14:44.547   Training iter 500, batch loss 0.3244, batch acc 0.8676
11:14:46.853   Training iter 550, batch loss 0.3336, batch acc 0.8698
11:14:49.167   Training iter 600, batch loss 0.3208, batch acc 0.8720
11:14:49.169 Training @ 208 epoch...
11:14:51.483   Training iter 50, batch loss 0.3116, batch acc 0.8748
11:14:53.791   Training iter 100, batch loss 0.3083, batch acc 0.8754
11:14:56.158   Training iter 150, batch loss 0.3168, batch acc 0.8678
11:14:58.454   Training iter 200, batch loss 0.3264, batch acc 0.8668
11:15:00.754   Training iter 250, batch loss 0.3371, batch acc 0.8630
11:15:03.087   Training iter 300, batch loss 0.3195, batch acc 0.8710
11:15:05.404   Training iter 350, batch loss 0.3436, batch acc 0.8626
11:15:07.706   Training iter 400, batch loss 0.3173, batch acc 0.8704
11:15:09.999   Training iter 450, batch loss 0.3123, batch acc 0.8718
11:15:12.296   Training iter 500, batch loss 0.3231, batch acc 0.8700
11:15:14.606   Training iter 550, batch loss 0.3201, batch acc 0.8710
11:15:16.946   Training iter 600, batch loss 0.3124, batch acc 0.8752
11:15:16.948 Training @ 209 epoch...
11:15:19.283   Training iter 50, batch loss 0.3065, batch acc 0.8738
11:15:21.638   Training iter 100, batch loss 0.3194, batch acc 0.8704
11:15:23.932   Training iter 150, batch loss 0.3010, batch acc 0.8772
11:15:26.233   Training iter 200, batch loss 0.3201, batch acc 0.8682
11:15:28.603   Training iter 250, batch loss 0.3336, batch acc 0.8646
11:15:30.903   Training iter 300, batch loss 0.3213, batch acc 0.8692
11:15:33.199   Training iter 350, batch loss 0.3315, batch acc 0.8662
11:15:35.494   Training iter 400, batch loss 0.3405, batch acc 0.8614
11:15:37.797   Training iter 450, batch loss 0.3056, batch acc 0.8786
11:15:40.094   Training iter 500, batch loss 0.3170, batch acc 0.8720
11:15:42.439   Training iter 550, batch loss 0.3137, batch acc 0.8742
11:15:44.779   Training iter 600, batch loss 0.3211, batch acc 0.8700
11:15:44.780 Training @ 210 epoch...
11:15:47.139   Training iter 50, batch loss 0.3067, batch acc 0.8740
11:15:49.464   Training iter 100, batch loss 0.3134, batch acc 0.8752
11:15:51.802   Training iter 150, batch loss 0.3346, batch acc 0.8650
11:15:54.167   Training iter 200, batch loss 0.3222, batch acc 0.8684
11:15:56.539   Training iter 250, batch loss 0.3091, batch acc 0.8752
11:15:58.838   Training iter 300, batch loss 0.3135, batch acc 0.8722
11:16:01.205   Training iter 350, batch loss 0.3150, batch acc 0.8702
11:16:03.564   Training iter 400, batch loss 0.3239, batch acc 0.8696
11:16:05.918   Training iter 450, batch loss 0.3259, batch acc 0.8690
11:16:08.239   Training iter 500, batch loss 0.3104, batch acc 0.8738
11:16:10.560   Training iter 550, batch loss 0.3274, batch acc 0.8676
11:16:12.872   Training iter 600, batch loss 0.3377, batch acc 0.8622
11:16:12.873 Testing @ 210 epoch...
11:16:12.927     Testing, total mean loss 0.39679, total acc 0.85040
11:16:12.927 Training @ 211 epoch...
11:16:15.245   Training iter 50, batch loss 0.3279, batch acc 0.8676
11:16:17.588   Training iter 100, batch loss 0.3155, batch acc 0.8722
11:16:19.898   Training iter 150, batch loss 0.3065, batch acc 0.8762
11:16:22.194   Training iter 200, batch loss 0.3396, batch acc 0.8612
11:16:24.521   Training iter 250, batch loss 0.3352, batch acc 0.8644
11:16:26.841   Training iter 300, batch loss 0.3081, batch acc 0.8750
11:16:29.171   Training iter 350, batch loss 0.3097, batch acc 0.8740
11:16:31.488   Training iter 400, batch loss 0.3116, batch acc 0.8750
11:16:33.833   Training iter 450, batch loss 0.3231, batch acc 0.8694
11:16:36.223   Training iter 500, batch loss 0.3155, batch acc 0.8716
11:16:38.563   Training iter 550, batch loss 0.3173, batch acc 0.8710
11:16:40.857   Training iter 600, batch loss 0.3283, batch acc 0.8682
11:16:40.858 Training @ 212 epoch...
11:16:43.161   Training iter 50, batch loss 0.3325, batch acc 0.8674
11:16:45.462   Training iter 100, batch loss 0.3236, batch acc 0.8686
11:16:47.767   Training iter 150, batch loss 0.3106, batch acc 0.8744
11:16:50.067   Training iter 200, batch loss 0.3058, batch acc 0.8766
11:16:52.366   Training iter 250, batch loss 0.3501, batch acc 0.8572
11:16:54.688   Training iter 300, batch loss 0.3342, batch acc 0.8648
11:16:57.085   Training iter 350, batch loss 0.3121, batch acc 0.8738
11:16:59.401   Training iter 400, batch loss 0.3125, batch acc 0.8740
11:17:01.716   Training iter 450, batch loss 0.3175, batch acc 0.8728
11:17:04.028   Training iter 500, batch loss 0.3198, batch acc 0.8700
11:17:06.371   Training iter 550, batch loss 0.3172, batch acc 0.8690
11:17:08.713   Training iter 600, batch loss 0.3145, batch acc 0.8720
11:17:08.714 Training @ 213 epoch...
11:17:11.052   Training iter 50, batch loss 0.3289, batch acc 0.8674
11:17:13.355   Training iter 100, batch loss 0.3091, batch acc 0.8740
11:17:15.702   Training iter 150, batch loss 0.3075, batch acc 0.8746
11:17:18.061   Training iter 200, batch loss 0.3197, batch acc 0.8690
11:17:20.341   Training iter 250, batch loss 0.3465, batch acc 0.8576
11:17:22.615   Training iter 300, batch loss 0.3201, batch acc 0.8696
11:17:24.896   Training iter 350, batch loss 0.3210, batch acc 0.8700
11:17:27.193   Training iter 400, batch loss 0.3180, batch acc 0.8710
11:17:29.495   Training iter 450, batch loss 0.3091, batch acc 0.8742
11:17:31.830   Training iter 500, batch loss 0.3038, batch acc 0.8778
11:17:34.135   Training iter 550, batch loss 0.3285, batch acc 0.8656
11:17:36.465   Training iter 600, batch loss 0.3151, batch acc 0.8734
11:17:36.466 Training @ 214 epoch...
11:17:38.776   Training iter 50, batch loss 0.3093, batch acc 0.8738
11:17:41.074   Training iter 100, batch loss 0.3075, batch acc 0.8762
11:17:43.432   Training iter 150, batch loss 0.3146, batch acc 0.8714
11:17:45.815   Training iter 200, batch loss 0.3235, batch acc 0.8692
11:17:48.157   Training iter 250, batch loss 0.3234, batch acc 0.8700
11:17:50.521   Training iter 300, batch loss 0.3273, batch acc 0.8656
11:17:52.828   Training iter 350, batch loss 0.3151, batch acc 0.8756
11:17:55.130   Training iter 400, batch loss 0.3351, batch acc 0.8632
11:17:57.511   Training iter 450, batch loss 0.3349, batch acc 0.8618
11:17:59.954   Training iter 500, batch loss 0.3227, batch acc 0.8658
11:18:02.260   Training iter 550, batch loss 0.3155, batch acc 0.8746
11:18:04.550   Training iter 600, batch loss 0.3136, batch acc 0.8724
11:18:04.552 Training @ 215 epoch...
11:18:06.843   Training iter 50, batch loss 0.3054, batch acc 0.8770
11:18:09.154   Training iter 100, batch loss 0.3242, batch acc 0.8704
11:18:11.439   Training iter 150, batch loss 0.3272, batch acc 0.8708
11:18:13.723   Training iter 200, batch loss 0.3184, batch acc 0.8718
11:18:16.008   Training iter 250, batch loss 0.3144, batch acc 0.8734
11:18:18.310   Training iter 300, batch loss 0.3160, batch acc 0.8698
11:18:20.611   Training iter 350, batch loss 0.3334, batch acc 0.8640
11:18:22.918   Training iter 400, batch loss 0.3192, batch acc 0.8678
11:18:25.217   Training iter 450, batch loss 0.3342, batch acc 0.8644
11:18:27.518   Training iter 500, batch loss 0.3158, batch acc 0.8722
11:18:29.821   Training iter 550, batch loss 0.3122, batch acc 0.8714
11:18:32.175   Training iter 600, batch loss 0.3106, batch acc 0.8728
11:18:32.177 Testing @ 215 epoch...
11:18:32.235     Testing, total mean loss 0.40370, total acc 0.84920
11:18:32.235 Training @ 216 epoch...
11:18:34.615   Training iter 50, batch loss 0.3324, batch acc 0.8638
11:18:36.937   Training iter 100, batch loss 0.3076, batch acc 0.8746
11:18:39.249   Training iter 150, batch loss 0.3105, batch acc 0.8738
11:18:41.548   Training iter 200, batch loss 0.3143, batch acc 0.8744
11:18:43.883   Training iter 250, batch loss 0.3284, batch acc 0.8662
11:18:46.334   Training iter 300, batch loss 0.3294, batch acc 0.8662
11:18:48.801   Training iter 350, batch loss 0.3202, batch acc 0.8710
11:18:51.246   Training iter 400, batch loss 0.3017, batch acc 0.8768
11:18:53.618   Training iter 450, batch loss 0.3109, batch acc 0.8706
11:18:55.907   Training iter 500, batch loss 0.3462, batch acc 0.8620
11:18:58.206   Training iter 550, batch loss 0.3183, batch acc 0.8702
11:19:00.499   Training iter 600, batch loss 0.3145, batch acc 0.8734
11:19:00.501 Training @ 217 epoch...
11:19:03.350   Training iter 50, batch loss 0.2985, batch acc 0.8802
11:19:06.354   Training iter 100, batch loss 0.3331, batch acc 0.8664
11:19:08.934   Training iter 150, batch loss 0.3105, batch acc 0.8732
11:19:11.226   Training iter 200, batch loss 0.3283, batch acc 0.8660
11:19:13.522   Training iter 250, batch loss 0.3049, batch acc 0.8760
11:19:15.813   Training iter 300, batch loss 0.3234, batch acc 0.8676
11:19:18.112   Training iter 350, batch loss 0.3262, batch acc 0.8694
11:19:20.394   Training iter 400, batch loss 0.3131, batch acc 0.8746
11:19:22.671   Training iter 450, batch loss 0.3295, batch acc 0.8694
11:19:24.964   Training iter 500, batch loss 0.3185, batch acc 0.8686
11:19:27.273   Training iter 550, batch loss 0.3199, batch acc 0.8708
11:19:29.571   Training iter 600, batch loss 0.3268, batch acc 0.8670
11:19:29.572 Training @ 218 epoch...
11:19:31.868   Training iter 50, batch loss 0.3163, batch acc 0.8722
11:19:34.156   Training iter 100, batch loss 0.3243, batch acc 0.8662
11:19:36.458   Training iter 150, batch loss 0.3080, batch acc 0.8764
11:19:38.766   Training iter 200, batch loss 0.3115, batch acc 0.8750
11:19:41.087   Training iter 250, batch loss 0.3389, batch acc 0.8608
11:19:43.397   Training iter 300, batch loss 0.3174, batch acc 0.8726
11:19:45.683   Training iter 350, batch loss 0.3333, batch acc 0.8652
11:19:47.965   Training iter 400, batch loss 0.2961, batch acc 0.8812
11:19:50.238   Training iter 450, batch loss 0.3071, batch acc 0.8738
11:19:52.533   Training iter 500, batch loss 0.3304, batch acc 0.8662
11:19:54.829   Training iter 550, batch loss 0.3421, batch acc 0.8626
11:19:57.135   Training iter 600, batch loss 0.3075, batch acc 0.8728
11:19:57.136 Training @ 219 epoch...
11:19:59.450   Training iter 50, batch loss 0.3067, batch acc 0.8772
11:20:01.763   Training iter 100, batch loss 0.3165, batch acc 0.8692
11:20:04.144   Training iter 150, batch loss 0.3095, batch acc 0.8760
11:20:06.551   Training iter 200, batch loss 0.3104, batch acc 0.8736
11:20:08.916   Training iter 250, batch loss 0.3049, batch acc 0.8758
11:20:11.256   Training iter 300, batch loss 0.3348, batch acc 0.8634
11:20:13.633   Training iter 350, batch loss 0.3210, batch acc 0.8706
11:20:16.037   Training iter 400, batch loss 0.3469, batch acc 0.8594
11:20:18.388   Training iter 450, batch loss 0.3206, batch acc 0.8684
11:20:20.759   Training iter 500, batch loss 0.3164, batch acc 0.8726
11:20:23.136   Training iter 550, batch loss 0.3181, batch acc 0.8706
11:20:25.490   Training iter 600, batch loss 0.3314, batch acc 0.8664
11:20:25.492 Training @ 220 epoch...
11:20:27.823   Training iter 50, batch loss 0.3126, batch acc 0.8718
11:20:30.166   Training iter 100, batch loss 0.3170, batch acc 0.8730
11:20:32.466   Training iter 150, batch loss 0.3144, batch acc 0.8734
11:20:34.759   Training iter 200, batch loss 0.3365, batch acc 0.8602
11:20:37.067   Training iter 250, batch loss 0.3093, batch acc 0.8750
11:20:39.373   Training iter 300, batch loss 0.3351, batch acc 0.8638
11:20:41.682   Training iter 350, batch loss 0.3187, batch acc 0.8720
11:20:44.004   Training iter 400, batch loss 0.3109, batch acc 0.8724
11:20:46.366   Training iter 450, batch loss 0.3227, batch acc 0.8692
11:20:48.691   Training iter 500, batch loss 0.3202, batch acc 0.8664
11:20:51.007   Training iter 550, batch loss 0.3295, batch acc 0.8680
11:20:53.323   Training iter 600, batch loss 0.3129, batch acc 0.8734
11:20:53.325 Testing @ 220 epoch...
11:20:53.379     Testing, total mean loss 0.39276, total acc 0.85330
11:20:53.379 Training @ 221 epoch...
11:20:55.707   Training iter 50, batch loss 0.3087, batch acc 0.8734
11:20:58.029   Training iter 100, batch loss 0.3159, batch acc 0.8706
11:21:00.315   Training iter 150, batch loss 0.3240, batch acc 0.8708
11:21:02.631   Training iter 200, batch loss 0.3267, batch acc 0.8650
11:21:04.907   Training iter 250, batch loss 0.3047, batch acc 0.8762
11:21:07.203   Training iter 300, batch loss 0.3328, batch acc 0.8672
11:21:09.546   Training iter 350, batch loss 0.3202, batch acc 0.8710
11:21:11.919   Training iter 400, batch loss 0.3154, batch acc 0.8704
11:21:14.317   Training iter 450, batch loss 0.3358, batch acc 0.8634
11:21:16.678   Training iter 500, batch loss 0.3161, batch acc 0.8716
11:21:19.021   Training iter 550, batch loss 0.3287, batch acc 0.8688
11:21:21.336   Training iter 600, batch loss 0.3072, batch acc 0.8742
11:21:21.337 Training @ 222 epoch...
11:21:23.632   Training iter 50, batch loss 0.3208, batch acc 0.8706
11:21:25.948   Training iter 100, batch loss 0.3220, batch acc 0.8690
11:21:28.236   Training iter 150, batch loss 0.3127, batch acc 0.8720
11:21:30.514   Training iter 200, batch loss 0.3028, batch acc 0.8756
11:21:32.806   Training iter 250, batch loss 0.3028, batch acc 0.8770
11:21:35.102   Training iter 300, batch loss 0.3182, batch acc 0.8690
11:21:37.388   Training iter 350, batch loss 0.3188, batch acc 0.8676
11:21:39.667   Training iter 400, batch loss 0.3182, batch acc 0.8714
11:21:42.022   Training iter 450, batch loss 0.3213, batch acc 0.8696
11:21:44.332   Training iter 500, batch loss 0.3248, batch acc 0.8702
11:21:46.654   Training iter 550, batch loss 0.3351, batch acc 0.8644
11:21:49.013   Training iter 600, batch loss 0.3189, batch acc 0.8726
11:21:49.014 Training @ 223 epoch...
11:21:51.375   Training iter 50, batch loss 0.3205, batch acc 0.8690
11:21:53.722   Training iter 100, batch loss 0.3113, batch acc 0.8732
11:21:56.022   Training iter 150, batch loss 0.3110, batch acc 0.8742
11:21:58.309   Training iter 200, batch loss 0.3336, batch acc 0.8640
11:22:00.594   Training iter 250, batch loss 0.3358, batch acc 0.8660
11:22:02.945   Training iter 300, batch loss 0.3049, batch acc 0.8748
11:22:05.312   Training iter 350, batch loss 0.3426, batch acc 0.8600
11:22:07.651   Training iter 400, batch loss 0.3051, batch acc 0.8760
11:22:09.944   Training iter 450, batch loss 0.3269, batch acc 0.8670
11:22:12.272   Training iter 500, batch loss 0.3152, batch acc 0.8744
11:22:14.627   Training iter 550, batch loss 0.3145, batch acc 0.8726
11:22:16.985   Training iter 600, batch loss 0.3145, batch acc 0.8720
11:22:16.987 Training @ 224 epoch...
11:22:19.313   Training iter 50, batch loss 0.3130, batch acc 0.8738
11:22:21.739   Training iter 100, batch loss 0.3059, batch acc 0.8768
11:22:24.034   Training iter 150, batch loss 0.3235, batch acc 0.8702
11:22:26.389   Training iter 200, batch loss 0.3080, batch acc 0.8744
11:22:28.682   Training iter 250, batch loss 0.3032, batch acc 0.8768
11:22:30.976   Training iter 300, batch loss 0.3278, batch acc 0.8678
11:22:33.266   Training iter 350, batch loss 0.3137, batch acc 0.8708
11:22:35.566   Training iter 400, batch loss 0.3256, batch acc 0.8680
11:22:37.873   Training iter 450, batch loss 0.3334, batch acc 0.8658
11:22:40.165   Training iter 500, batch loss 0.3323, batch acc 0.8648
11:22:42.460   Training iter 550, batch loss 0.3212, batch acc 0.8682
11:22:44.783   Training iter 600, batch loss 0.3247, batch acc 0.8682
11:22:44.785 Training @ 225 epoch...
11:22:47.144   Training iter 50, batch loss 0.3045, batch acc 0.8758
11:22:49.610   Training iter 100, batch loss 0.3100, batch acc 0.8744
11:22:52.606   Training iter 150, batch loss 0.3258, batch acc 0.8672
11:22:55.048   Training iter 200, batch loss 0.3266, batch acc 0.8690
11:22:57.328   Training iter 250, batch loss 0.3184, batch acc 0.8714
11:22:59.619   Training iter 300, batch loss 0.3215, batch acc 0.8708
11:23:01.929   Training iter 350, batch loss 0.3089, batch acc 0.8740
11:23:04.283   Training iter 400, batch loss 0.3001, batch acc 0.8778
11:23:06.633   Training iter 450, batch loss 0.3332, batch acc 0.8652
11:23:08.966   Training iter 500, batch loss 0.3220, batch acc 0.8706
11:23:11.852   Training iter 550, batch loss 0.3177, batch acc 0.8696
11:23:14.508   Training iter 600, batch loss 0.3381, batch acc 0.8646
11:23:14.510 Testing @ 225 epoch...
11:23:14.562     Testing, total mean loss 0.39685, total acc 0.85020
11:23:14.562 Training @ 226 epoch...
11:23:16.902   Training iter 50, batch loss 0.3073, batch acc 0.8744
11:23:19.226   Training iter 100, batch loss 0.3344, batch acc 0.8648
11:23:21.516   Training iter 150, batch loss 0.3106, batch acc 0.8742
11:23:23.826   Training iter 200, batch loss 0.3236, batch acc 0.8696
11:23:26.132   Training iter 250, batch loss 0.3246, batch acc 0.8682
11:23:28.427   Training iter 300, batch loss 0.3346, batch acc 0.8636
11:23:30.771   Training iter 350, batch loss 0.3040, batch acc 0.8774
11:23:33.054   Training iter 400, batch loss 0.3264, batch acc 0.8668
11:23:35.328   Training iter 450, batch loss 0.3014, batch acc 0.8798
11:23:37.634   Training iter 500, batch loss 0.3216, batch acc 0.8690
11:23:39.971   Training iter 550, batch loss 0.3154, batch acc 0.8700
11:23:42.260   Training iter 600, batch loss 0.3180, batch acc 0.8712
11:23:42.262 Training @ 227 epoch...
11:23:44.571   Training iter 50, batch loss 0.3080, batch acc 0.8742
11:23:46.908   Training iter 100, batch loss 0.3370, batch acc 0.8624
11:23:49.176   Training iter 150, batch loss 0.2992, batch acc 0.8746
11:23:51.445   Training iter 200, batch loss 0.3390, batch acc 0.8608
11:23:53.737   Training iter 250, batch loss 0.3184, batch acc 0.8708
11:23:56.079   Training iter 300, batch loss 0.3012, batch acc 0.8768
11:23:58.374   Training iter 350, batch loss 0.3255, batch acc 0.8658
11:24:00.657   Training iter 400, batch loss 0.3385, batch acc 0.8642
11:24:03.007   Training iter 450, batch loss 0.3178, batch acc 0.8718
11:24:05.331   Training iter 500, batch loss 0.3301, batch acc 0.8664
11:24:07.648   Training iter 550, batch loss 0.3060, batch acc 0.8748
11:24:10.021   Training iter 600, batch loss 0.3050, batch acc 0.8756
11:24:10.023 Training @ 228 epoch...
11:24:12.329   Training iter 50, batch loss 0.3056, batch acc 0.8778
11:24:14.680   Training iter 100, batch loss 0.3198, batch acc 0.8696
11:24:17.012   Training iter 150, batch loss 0.3275, batch acc 0.8660
11:24:19.356   Training iter 200, batch loss 0.3102, batch acc 0.8736
11:24:21.702   Training iter 250, batch loss 0.3220, batch acc 0.8710
11:24:23.973   Training iter 300, batch loss 0.3137, batch acc 0.8718
11:24:26.281   Training iter 350, batch loss 0.3149, batch acc 0.8714
11:24:28.587   Training iter 400, batch loss 0.3136, batch acc 0.8722
11:24:30.992   Training iter 450, batch loss 0.3269, batch acc 0.8684
11:24:33.443   Training iter 500, batch loss 0.3051, batch acc 0.8764
11:24:35.726   Training iter 550, batch loss 0.3165, batch acc 0.8712
11:24:38.049   Training iter 600, batch loss 0.3493, batch acc 0.8600
11:24:38.051 Training @ 229 epoch...
11:24:40.352   Training iter 50, batch loss 0.3374, batch acc 0.8612
11:24:42.637   Training iter 100, batch loss 0.3200, batch acc 0.8728
11:24:44.934   Training iter 150, batch loss 0.3052, batch acc 0.8758
11:24:47.232   Training iter 200, batch loss 0.3196, batch acc 0.8700
11:24:49.577   Training iter 250, batch loss 0.3199, batch acc 0.8680
11:24:51.863   Training iter 300, batch loss 0.3164, batch acc 0.8710
11:24:54.151   Training iter 350, batch loss 0.3166, batch acc 0.8734
11:24:56.431   Training iter 400, batch loss 0.3075, batch acc 0.8756
11:24:58.708   Training iter 450, batch loss 0.3121, batch acc 0.8716
11:25:01.048   Training iter 500, batch loss 0.3292, batch acc 0.8646
11:25:03.470   Training iter 550, batch loss 0.3201, batch acc 0.8712
11:25:05.871   Training iter 600, batch loss 0.3164, batch acc 0.8726
11:25:05.873 Training @ 230 epoch...
11:25:08.236   Training iter 50, batch loss 0.3080, batch acc 0.8744
11:25:10.593   Training iter 100, batch loss 0.3036, batch acc 0.8778
11:25:12.873   Training iter 150, batch loss 0.3301, batch acc 0.8668
11:25:15.165   Training iter 200, batch loss 0.3126, batch acc 0.8734
11:25:17.465   Training iter 250, batch loss 0.3230, batch acc 0.8692
11:25:19.797   Training iter 300, batch loss 0.3041, batch acc 0.8746
11:25:22.110   Training iter 350, batch loss 0.3125, batch acc 0.8718
11:25:24.413   Training iter 400, batch loss 0.3288, batch acc 0.8670
11:25:26.682   Training iter 450, batch loss 0.3363, batch acc 0.8664
11:25:28.955   Training iter 500, batch loss 0.3175, batch acc 0.8694
11:25:31.228   Training iter 550, batch loss 0.3244, batch acc 0.8684
11:25:33.516   Training iter 600, batch loss 0.3285, batch acc 0.8664
11:25:33.518 Testing @ 230 epoch...
11:25:33.569     Testing, total mean loss 0.40210, total acc 0.84930
11:25:33.569 Training @ 231 epoch...
11:25:35.875   Training iter 50, batch loss 0.3081, batch acc 0.8724
11:25:38.221   Training iter 100, batch loss 0.3176, batch acc 0.8710
11:25:40.495   Training iter 150, batch loss 0.3143, batch acc 0.8730
11:25:42.823   Training iter 200, batch loss 0.3209, batch acc 0.8684
11:25:45.152   Training iter 250, batch loss 0.3057, batch acc 0.8774
11:25:47.440   Training iter 300, batch loss 0.3149, batch acc 0.8718
11:25:49.739   Training iter 350, batch loss 0.3165, batch acc 0.8710
11:25:52.058   Training iter 400, batch loss 0.3467, batch acc 0.8584
11:25:54.365   Training iter 450, batch loss 0.3110, batch acc 0.8760
11:25:56.640   Training iter 500, batch loss 0.3156, batch acc 0.8726
11:25:58.944   Training iter 550, batch loss 0.3250, batch acc 0.8674
11:26:01.251   Training iter 600, batch loss 0.3280, batch acc 0.8674
11:26:01.252 Training @ 232 epoch...
11:26:03.551   Training iter 50, batch loss 0.2958, batch acc 0.8816
11:26:05.873   Training iter 100, batch loss 0.3154, batch acc 0.8700
11:26:08.218   Training iter 150, batch loss 0.3197, batch acc 0.8680
11:26:10.509   Training iter 200, batch loss 0.3360, batch acc 0.8620
11:26:12.913   Training iter 250, batch loss 0.3228, batch acc 0.8694
11:26:15.262   Training iter 300, batch loss 0.2996, batch acc 0.8822
11:26:17.643   Training iter 350, batch loss 0.3224, batch acc 0.8680
11:26:19.932   Training iter 400, batch loss 0.3307, batch acc 0.8660
11:26:22.242   Training iter 450, batch loss 0.3269, batch acc 0.8676
11:26:24.555   Training iter 500, batch loss 0.3173, batch acc 0.8718
11:26:26.861   Training iter 550, batch loss 0.3309, batch acc 0.8648
11:26:29.122   Training iter 600, batch loss 0.3106, batch acc 0.8748
11:26:29.124 Training @ 233 epoch...
11:26:31.489   Training iter 50, batch loss 0.3254, batch acc 0.8680
11:26:33.807   Training iter 100, batch loss 0.3079, batch acc 0.8754
11:26:36.146   Training iter 150, batch loss 0.3305, batch acc 0.8646
11:26:38.482   Training iter 200, batch loss 0.3343, batch acc 0.8640
11:26:40.771   Training iter 250, batch loss 0.3257, batch acc 0.8690
11:26:43.057   Training iter 300, batch loss 0.3252, batch acc 0.8684
11:26:45.322   Training iter 350, batch loss 0.2987, batch acc 0.8778
11:26:47.594   Training iter 400, batch loss 0.3233, batch acc 0.8676
11:26:49.869   Training iter 450, batch loss 0.3141, batch acc 0.8712
11:26:52.160   Training iter 500, batch loss 0.3100, batch acc 0.8726
11:26:54.458   Training iter 550, batch loss 0.3112, batch acc 0.8722
11:26:56.749   Training iter 600, batch loss 0.3174, batch acc 0.8720
11:26:56.751 Training @ 234 epoch...
11:26:59.063   Training iter 50, batch loss 0.3186, batch acc 0.8692
11:27:01.364   Training iter 100, batch loss 0.3252, batch acc 0.8656
11:27:03.697   Training iter 150, batch loss 0.3300, batch acc 0.8652
11:27:06.055   Training iter 200, batch loss 0.3156, batch acc 0.8728
11:27:08.397   Training iter 250, batch loss 0.3121, batch acc 0.8754
11:27:10.710   Training iter 300, batch loss 0.3153, batch acc 0.8734
11:27:13.084   Training iter 350, batch loss 0.3072, batch acc 0.8770
11:27:15.432   Training iter 400, batch loss 0.3082, batch acc 0.8760
11:27:17.754   Training iter 450, batch loss 0.3331, batch acc 0.8648
11:27:20.057   Training iter 500, batch loss 0.3240, batch acc 0.8684
11:27:22.356   Training iter 550, batch loss 0.3075, batch acc 0.8744
11:27:24.644   Training iter 600, batch loss 0.3260, batch acc 0.8660
11:27:24.646 Training @ 235 epoch...
11:27:26.955   Training iter 50, batch loss 0.3206, batch acc 0.8694
11:27:29.265   Training iter 100, batch loss 0.3281, batch acc 0.8654
11:27:31.558   Training iter 150, batch loss 0.3116, batch acc 0.8728
11:27:33.831   Training iter 200, batch loss 0.3077, batch acc 0.8768
11:27:36.123   Training iter 250, batch loss 0.3406, batch acc 0.8630
11:27:38.449   Training iter 300, batch loss 0.3248, batch acc 0.8710
11:27:40.724   Training iter 350, batch loss 0.3144, batch acc 0.8732
11:27:43.046   Training iter 400, batch loss 0.3385, batch acc 0.8626
11:27:45.319   Training iter 450, batch loss 0.3069, batch acc 0.8742
11:27:47.666   Training iter 500, batch loss 0.3185, batch acc 0.8710
11:27:49.966   Training iter 550, batch loss 0.3045, batch acc 0.8760
11:27:52.240   Training iter 600, batch loss 0.3027, batch acc 0.8746
11:27:52.241 Testing @ 235 epoch...
11:27:52.293     Testing, total mean loss 0.40278, total acc 0.85130
11:27:52.293 Training @ 236 epoch...
11:27:54.603   Training iter 50, batch loss 0.3103, batch acc 0.8738
11:27:56.947   Training iter 100, batch loss 0.3334, batch acc 0.8642
11:27:59.227   Training iter 150, batch loss 0.3148, batch acc 0.8710
11:28:01.502   Training iter 200, batch loss 0.3162, batch acc 0.8726
11:28:03.808   Training iter 250, batch loss 0.3186, batch acc 0.8720
11:28:06.167   Training iter 300, batch loss 0.2965, batch acc 0.8804
11:28:08.480   Training iter 350, batch loss 0.3295, batch acc 0.8646
11:28:10.798   Training iter 400, batch loss 0.3278, batch acc 0.8674
11:28:13.228   Training iter 450, batch loss 0.3135, batch acc 0.8746
11:28:15.520   Training iter 500, batch loss 0.3289, batch acc 0.8640
11:28:17.807   Training iter 550, batch loss 0.3159, batch acc 0.8712
11:28:20.090   Training iter 600, batch loss 0.3199, batch acc 0.8708
11:28:20.091 Training @ 237 epoch...
11:28:22.352   Training iter 50, batch loss 0.3229, batch acc 0.8674
11:28:24.625   Training iter 100, batch loss 0.3205, batch acc 0.8696
11:28:27.079   Training iter 150, batch loss 0.3235, batch acc 0.8680
11:28:29.388   Training iter 200, batch loss 0.3199, batch acc 0.8676
11:28:31.702   Training iter 250, batch loss 0.3260, batch acc 0.8684
11:28:34.020   Training iter 300, batch loss 0.3022, batch acc 0.8774
11:28:36.313   Training iter 350, batch loss 0.3058, batch acc 0.8772
11:28:38.618   Training iter 400, batch loss 0.3382, batch acc 0.8640
11:28:40.949   Training iter 450, batch loss 0.2952, batch acc 0.8806
11:28:43.264   Training iter 500, batch loss 0.3123, batch acc 0.8742
11:28:45.540   Training iter 550, batch loss 0.3257, batch acc 0.8672
11:28:47.829   Training iter 600, batch loss 0.3232, batch acc 0.8696
11:28:47.831 Training @ 238 epoch...
11:28:50.145   Training iter 50, batch loss 0.3255, batch acc 0.8682
11:28:52.406   Training iter 100, batch loss 0.3315, batch acc 0.8634
11:28:54.662   Training iter 150, batch loss 0.2955, batch acc 0.8800
11:28:56.922   Training iter 200, batch loss 0.3304, batch acc 0.8656
11:28:59.185   Training iter 250, batch loss 0.3100, batch acc 0.8736
11:29:01.483   Training iter 300, batch loss 0.3265, batch acc 0.8690
11:29:03.809   Training iter 350, batch loss 0.3178, batch acc 0.8708
11:29:06.114   Training iter 400, batch loss 0.3404, batch acc 0.8622
11:29:08.393   Training iter 450, batch loss 0.3155, batch acc 0.8738
11:29:10.676   Training iter 500, batch loss 0.2992, batch acc 0.8772
11:29:12.971   Training iter 550, batch loss 0.3252, batch acc 0.8674
11:29:15.283   Training iter 600, batch loss 0.3071, batch acc 0.8752
11:29:15.284 Training @ 239 epoch...
11:29:17.570   Training iter 50, batch loss 0.2927, batch acc 0.8802
11:29:19.866   Training iter 100, batch loss 0.3119, batch acc 0.8722
11:29:22.163   Training iter 150, batch loss 0.3197, batch acc 0.8668
11:29:24.459   Training iter 200, batch loss 0.3123, batch acc 0.8742
11:29:26.748   Training iter 250, batch loss 0.3228, batch acc 0.8682
11:29:29.044   Training iter 300, batch loss 0.3205, batch acc 0.8718
11:29:31.337   Training iter 350, batch loss 0.3404, batch acc 0.8610
11:29:33.653   Training iter 400, batch loss 0.3038, batch acc 0.8764
11:29:35.955   Training iter 450, batch loss 0.3177, batch acc 0.8682
11:29:38.251   Training iter 500, batch loss 0.3320, batch acc 0.8642
11:29:40.572   Training iter 550, batch loss 0.3183, batch acc 0.8714
11:29:42.858   Training iter 600, batch loss 0.3200, batch acc 0.8682
11:29:42.859 Training @ 240 epoch...
11:29:45.169   Training iter 50, batch loss 0.3275, batch acc 0.8680
11:29:47.478   Training iter 100, batch loss 0.3316, batch acc 0.8658
11:29:49.752   Training iter 150, batch loss 0.3113, batch acc 0.8724
11:29:52.042   Training iter 200, batch loss 0.3076, batch acc 0.8748
11:29:54.330   Training iter 250, batch loss 0.2907, batch acc 0.8810
11:29:56.633   Training iter 300, batch loss 0.3374, batch acc 0.8646
11:29:58.906   Training iter 350, batch loss 0.3138, batch acc 0.8718
11:30:01.191   Training iter 400, batch loss 0.3182, batch acc 0.8706
11:30:03.494   Training iter 450, batch loss 0.3229, batch acc 0.8712
11:30:05.794   Training iter 500, batch loss 0.3184, batch acc 0.8696
11:30:08.111   Training iter 550, batch loss 0.3297, batch acc 0.8654
11:30:10.418   Training iter 600, batch loss 0.3095, batch acc 0.8764
11:30:10.419 Testing @ 240 epoch...
11:30:10.471     Testing, total mean loss 0.40201, total acc 0.84970
11:30:10.471 Training @ 241 epoch...
11:30:12.768   Training iter 50, batch loss 0.3024, batch acc 0.8772
11:30:15.033   Training iter 100, batch loss 0.3119, batch acc 0.8732
11:30:17.305   Training iter 150, batch loss 0.3076, batch acc 0.8764
11:30:19.578   Training iter 200, batch loss 0.3353, batch acc 0.8624
11:30:21.852   Training iter 250, batch loss 0.3121, batch acc 0.8748
11:30:24.147   Training iter 300, batch loss 0.3154, batch acc 0.8720
11:30:26.452   Training iter 350, batch loss 0.3217, batch acc 0.8674
11:30:28.728   Training iter 400, batch loss 0.3368, batch acc 0.8642
11:30:31.032   Training iter 450, batch loss 0.3169, batch acc 0.8708
11:30:33.340   Training iter 500, batch loss 0.3149, batch acc 0.8704
11:30:35.646   Training iter 550, batch loss 0.3282, batch acc 0.8646
11:30:37.940   Training iter 600, batch loss 0.3212, batch acc 0.8668
11:30:37.941 Training @ 242 epoch...
11:30:40.244   Training iter 50, batch loss 0.3281, batch acc 0.8674
11:30:42.561   Training iter 100, batch loss 0.3200, batch acc 0.8718
11:30:44.934   Training iter 150, batch loss 0.3224, batch acc 0.8686
11:30:47.225   Training iter 200, batch loss 0.3020, batch acc 0.8762
11:30:49.503   Training iter 250, batch loss 0.3172, batch acc 0.8706
11:30:51.801   Training iter 300, batch loss 0.3073, batch acc 0.8770
11:30:54.101   Training iter 350, batch loss 0.3229, batch acc 0.8684
11:30:56.395   Training iter 400, batch loss 0.3283, batch acc 0.8656
11:30:58.704   Training iter 450, batch loss 0.3202, batch acc 0.8692
11:31:00.997   Training iter 500, batch loss 0.3241, batch acc 0.8674
11:31:03.292   Training iter 550, batch loss 0.3164, batch acc 0.8736
11:31:05.573   Training iter 600, batch loss 0.3091, batch acc 0.8718
11:31:05.574 Training @ 243 epoch...
11:31:07.871   Training iter 50, batch loss 0.3191, batch acc 0.8690
11:31:10.200   Training iter 100, batch loss 0.3122, batch acc 0.8728
11:31:12.518   Training iter 150, batch loss 0.3211, batch acc 0.8708
11:31:14.813   Training iter 200, batch loss 0.3325, batch acc 0.8646
11:31:17.104   Training iter 250, batch loss 0.3113, batch acc 0.8754
11:31:19.382   Training iter 300, batch loss 0.3284, batch acc 0.8686
11:31:21.666   Training iter 350, batch loss 0.3321, batch acc 0.8664
11:31:23.941   Training iter 400, batch loss 0.3129, batch acc 0.8754
11:31:26.222   Training iter 450, batch loss 0.3150, batch acc 0.8696
11:31:28.552   Training iter 500, batch loss 0.3016, batch acc 0.8766
11:31:30.880   Training iter 550, batch loss 0.3014, batch acc 0.8762
11:31:33.160   Training iter 600, batch loss 0.3130, batch acc 0.8704
11:31:33.162 Training @ 244 epoch...
11:31:35.436   Training iter 50, batch loss 0.3045, batch acc 0.8752
11:31:37.733   Training iter 100, batch loss 0.3070, batch acc 0.8768
11:31:40.010   Training iter 150, batch loss 0.3101, batch acc 0.8738
11:31:42.541   Training iter 200, batch loss 0.3048, batch acc 0.8766
11:31:44.876   Training iter 250, batch loss 0.3141, batch acc 0.8730
11:31:47.215   Training iter 300, batch loss 0.3201, batch acc 0.8692
11:31:49.529   Training iter 350, batch loss 0.3501, batch acc 0.8604
11:31:51.840   Training iter 400, batch loss 0.3272, batch acc 0.8662
11:31:54.194   Training iter 450, batch loss 0.3305, batch acc 0.8650
11:31:56.549   Training iter 500, batch loss 0.3167, batch acc 0.8702
11:31:58.857   Training iter 550, batch loss 0.3120, batch acc 0.8724
11:32:01.210   Training iter 600, batch loss 0.3082, batch acc 0.8726
11:32:01.211 Training @ 245 epoch...
11:32:03.754   Training iter 50, batch loss 0.3152, batch acc 0.8722
11:32:06.059   Training iter 100, batch loss 0.3130, batch acc 0.8734
11:32:08.372   Training iter 150, batch loss 0.3197, batch acc 0.8698
11:32:10.754   Training iter 200, batch loss 0.3083, batch acc 0.8728
11:32:13.132   Training iter 250, batch loss 0.3095, batch acc 0.8704
11:32:15.503   Training iter 300, batch loss 0.3203, batch acc 0.8706
11:32:17.812   Training iter 350, batch loss 0.3274, batch acc 0.8664
11:32:20.175   Training iter 400, batch loss 0.3056, batch acc 0.8770
11:32:22.461   Training iter 450, batch loss 0.3261, batch acc 0.8674
11:32:24.730   Training iter 500, batch loss 0.3105, batch acc 0.8756
11:32:27.097   Training iter 550, batch loss 0.3251, batch acc 0.8658
11:32:29.430   Training iter 600, batch loss 0.3259, batch acc 0.8702
11:32:29.432 Testing @ 245 epoch...
11:32:29.484     Testing, total mean loss 0.41429, total acc 0.84970
11:32:29.484 Training @ 246 epoch...
11:32:31.804   Training iter 50, batch loss 0.3144, batch acc 0.8720
11:32:34.247   Training iter 100, batch loss 0.3270, batch acc 0.8702
11:32:36.604   Training iter 150, batch loss 0.2996, batch acc 0.8766
11:32:38.913   Training iter 200, batch loss 0.3033, batch acc 0.8772
11:32:41.213   Training iter 250, batch loss 0.3148, batch acc 0.8728
11:32:43.526   Training iter 300, batch loss 0.3286, batch acc 0.8676
11:32:45.879   Training iter 350, batch loss 0.3146, batch acc 0.8720
11:32:48.250   Training iter 400, batch loss 0.3274, batch acc 0.8682
11:32:50.642   Training iter 450, batch loss 0.3322, batch acc 0.8624
11:32:52.963   Training iter 500, batch loss 0.3102, batch acc 0.8734
11:32:55.236   Training iter 550, batch loss 0.3105, batch acc 0.8740
11:32:57.513   Training iter 600, batch loss 0.3240, batch acc 0.8682
11:32:57.515 Training @ 247 epoch...
11:32:59.784   Training iter 50, batch loss 0.3027, batch acc 0.8764
11:33:02.214   Training iter 100, batch loss 0.3198, batch acc 0.8700
11:33:04.502   Training iter 150, batch loss 0.3276, batch acc 0.8682
11:33:06.835   Training iter 200, batch loss 0.3066, batch acc 0.8748
11:33:09.174   Training iter 250, batch loss 0.3156, batch acc 0.8730
11:33:11.545   Training iter 300, batch loss 0.3286, batch acc 0.8672
11:33:13.795   Training iter 350, batch loss 0.3132, batch acc 0.8742
11:33:16.034   Training iter 400, batch loss 0.3065, batch acc 0.8746
11:33:18.303   Training iter 450, batch loss 0.3086, batch acc 0.8746
11:33:20.547   Training iter 500, batch loss 0.3285, batch acc 0.8682
11:33:22.858   Training iter 550, batch loss 0.3222, batch acc 0.8674
11:33:25.114   Training iter 600, batch loss 0.3350, batch acc 0.8648
11:33:25.116 Training @ 248 epoch...
11:33:27.385   Training iter 50, batch loss 0.3141, batch acc 0.8716
11:33:29.632   Training iter 100, batch loss 0.3078, batch acc 0.8744
11:33:31.881   Training iter 150, batch loss 0.3189, batch acc 0.8702
11:33:34.130   Training iter 200, batch loss 0.3247, batch acc 0.8658
11:33:36.367   Training iter 250, batch loss 0.3390, batch acc 0.8594
11:33:38.612   Training iter 300, batch loss 0.3087, batch acc 0.8744
11:33:40.864   Training iter 350, batch loss 0.3269, batch acc 0.8670
11:33:43.127   Training iter 400, batch loss 0.3043, batch acc 0.8784
11:33:45.371   Training iter 450, batch loss 0.2991, batch acc 0.8804
11:33:47.611   Training iter 500, batch loss 0.3253, batch acc 0.8672
11:33:49.858   Training iter 550, batch loss 0.3249, batch acc 0.8662
11:33:52.103   Training iter 600, batch loss 0.3222, batch acc 0.8682
11:33:52.105 Training @ 249 epoch...
11:33:54.368   Training iter 50, batch loss 0.3298, batch acc 0.8660
11:33:56.616   Training iter 100, batch loss 0.3092, batch acc 0.8742
11:33:58.865   Training iter 150, batch loss 0.3037, batch acc 0.8788
11:34:01.109   Training iter 200, batch loss 0.3435, batch acc 0.8614
11:34:03.377   Training iter 250, batch loss 0.3062, batch acc 0.8744
11:34:05.635   Training iter 300, batch loss 0.3128, batch acc 0.8728
11:34:07.890   Training iter 350, batch loss 0.3416, batch acc 0.8604
11:34:10.135   Training iter 400, batch loss 0.2949, batch acc 0.8816
11:34:12.378   Training iter 450, batch loss 0.3175, batch acc 0.8720
11:34:14.632   Training iter 500, batch loss 0.3141, batch acc 0.8726
11:34:16.886   Training iter 550, batch loss 0.3144, batch acc 0.8722
11:34:19.135   Training iter 600, batch loss 0.3167, batch acc 0.8746
11:34:19.137 Training @ 250 epoch...
11:34:21.392   Training iter 50, batch loss 0.3213, batch acc 0.8698
11:34:23.644   Training iter 100, batch loss 0.2990, batch acc 0.8792
11:34:25.913   Training iter 150, batch loss 0.3232, batch acc 0.8700
11:34:28.177   Training iter 200, batch loss 0.3143, batch acc 0.8718
11:34:30.446   Training iter 250, batch loss 0.3194, batch acc 0.8700
11:34:32.698   Training iter 300, batch loss 0.3159, batch acc 0.8706
11:34:34.955   Training iter 350, batch loss 0.3200, batch acc 0.8698
11:34:37.218   Training iter 400, batch loss 0.3243, batch acc 0.8672
11:34:39.490   Training iter 450, batch loss 0.3306, batch acc 0.8646
11:34:41.742   Training iter 500, batch loss 0.3210, batch acc 0.8672
11:34:44.003   Training iter 550, batch loss 0.3004, batch acc 0.8796
11:34:46.269   Training iter 600, batch loss 0.3147, batch acc 0.8708
11:34:46.270 Testing @ 250 epoch...
11:34:46.321     Testing, total mean loss 0.41508, total acc 0.84660
11:34:46.321 Training @ 251 epoch...
11:34:48.624   Training iter 50, batch loss 0.3195, batch acc 0.8698
11:34:50.903   Training iter 100, batch loss 0.3259, batch acc 0.8682
11:34:53.438   Training iter 150, batch loss 0.3270, batch acc 0.8658
11:34:55.740   Training iter 200, batch loss 0.3093, batch acc 0.8758
11:34:57.977   Training iter 250, batch loss 0.2957, batch acc 0.8836
11:35:00.227   Training iter 300, batch loss 0.3222, batch acc 0.8702
11:35:02.554   Training iter 350, batch loss 0.3226, batch acc 0.8688
11:35:04.882   Training iter 400, batch loss 0.3158, batch acc 0.8682
11:35:07.178   Training iter 450, batch loss 0.3100, batch acc 0.8712
11:35:09.414   Training iter 500, batch loss 0.3359, batch acc 0.8626
11:35:11.638   Training iter 550, batch loss 0.3148, batch acc 0.8722
11:35:13.884   Training iter 600, batch loss 0.3001, batch acc 0.8774
11:35:13.886 Training @ 252 epoch...
11:35:16.194   Training iter 50, batch loss 0.3233, batch acc 0.8690
11:35:18.536   Training iter 100, batch loss 0.3200, batch acc 0.8704
11:35:20.861   Training iter 150, batch loss 0.3180, batch acc 0.8724
11:35:23.130   Training iter 200, batch loss 0.3151, batch acc 0.8748
11:35:25.383   Training iter 250, batch loss 0.3315, batch acc 0.8656
11:35:27.671   Training iter 300, batch loss 0.3230, batch acc 0.8698
11:35:29.996   Training iter 350, batch loss 0.3152, batch acc 0.8732
11:35:32.324   Training iter 400, batch loss 0.3067, batch acc 0.8768
11:35:34.587   Training iter 450, batch loss 0.3217, batch acc 0.8694
11:35:36.844   Training iter 500, batch loss 0.3157, batch acc 0.8696
11:35:39.089   Training iter 550, batch loss 0.3202, batch acc 0.8684
11:35:41.368   Training iter 600, batch loss 0.3060, batch acc 0.8738
11:35:41.370 Training @ 253 epoch...
11:35:43.712   Training iter 50, batch loss 0.3241, batch acc 0.8654
11:35:45.948   Training iter 100, batch loss 0.3380, batch acc 0.8630
11:35:48.197   Training iter 150, batch loss 0.3214, batch acc 0.8682
11:35:50.448   Training iter 200, batch loss 0.3081, batch acc 0.8758
11:35:52.695   Training iter 250, batch loss 0.3122, batch acc 0.8730
11:35:54.910   Training iter 300, batch loss 0.3213, batch acc 0.8724
11:35:57.134   Training iter 350, batch loss 0.3052, batch acc 0.8746
11:35:59.379   Training iter 400, batch loss 0.3017, batch acc 0.8782
11:36:01.679   Training iter 450, batch loss 0.3169, batch acc 0.8704
11:36:03.999   Training iter 500, batch loss 0.3291, batch acc 0.8646
11:36:06.327   Training iter 550, batch loss 0.3119, batch acc 0.8716
11:36:08.591   Training iter 600, batch loss 0.3171, batch acc 0.8702
11:36:08.593 Training @ 254 epoch...
11:36:10.839   Training iter 50, batch loss 0.3074, batch acc 0.8744
11:36:13.159   Training iter 100, batch loss 0.2968, batch acc 0.8788
11:36:15.465   Training iter 150, batch loss 0.3260, batch acc 0.8696
11:36:17.723   Training iter 200, batch loss 0.3314, batch acc 0.8642
11:36:20.061   Training iter 250, batch loss 0.3078, batch acc 0.8742
11:36:22.324   Training iter 300, batch loss 0.3091, batch acc 0.8734
11:36:24.568   Training iter 350, batch loss 0.3203, batch acc 0.8690
11:36:26.817   Training iter 400, batch loss 0.3136, batch acc 0.8712
11:36:29.070   Training iter 450, batch loss 0.2990, batch acc 0.8778
11:36:31.315   Training iter 500, batch loss 0.3317, batch acc 0.8670
11:36:33.564   Training iter 550, batch loss 0.3423, batch acc 0.8604
11:36:35.816   Training iter 600, batch loss 0.3097, batch acc 0.8714
11:36:35.817 Training @ 255 epoch...
11:36:38.076   Training iter 50, batch loss 0.3038, batch acc 0.8768
11:36:40.317   Training iter 100, batch loss 0.3126, batch acc 0.8720
11:36:42.554   Training iter 150, batch loss 0.3038, batch acc 0.8748
11:36:44.782   Training iter 200, batch loss 0.3227, batch acc 0.8668
11:36:47.019   Training iter 250, batch loss 0.3360, batch acc 0.8626
11:36:49.275   Training iter 300, batch loss 0.3137, batch acc 0.8716
11:36:51.546   Training iter 350, batch loss 0.3227, batch acc 0.8702
11:36:53.912   Training iter 400, batch loss 0.3239, batch acc 0.8686
11:36:56.257   Training iter 450, batch loss 0.2882, batch acc 0.8834
11:36:58.526   Training iter 500, batch loss 0.3272, batch acc 0.8682
11:37:00.801   Training iter 550, batch loss 0.3044, batch acc 0.8758
11:37:03.122   Training iter 600, batch loss 0.3408, batch acc 0.8594
11:37:03.124 Testing @ 255 epoch...
11:37:03.178     Testing, total mean loss 0.39385, total acc 0.85270
11:37:03.178 Training @ 256 epoch...
11:37:05.534   Training iter 50, batch loss 0.3069, batch acc 0.8742
11:37:07.876   Training iter 100, batch loss 0.3328, batch acc 0.8638
11:37:10.192   Training iter 150, batch loss 0.3328, batch acc 0.8676
11:37:12.500   Training iter 200, batch loss 0.3113, batch acc 0.8738
11:37:14.804   Training iter 250, batch loss 0.3120, batch acc 0.8730
11:37:17.136   Training iter 300, batch loss 0.3377, batch acc 0.8638
11:37:19.489   Training iter 350, batch loss 0.3110, batch acc 0.8742
11:37:21.829   Training iter 400, batch loss 0.2996, batch acc 0.8788
11:37:24.113   Training iter 450, batch loss 0.3285, batch acc 0.8650
11:37:26.401   Training iter 500, batch loss 0.3196, batch acc 0.8684
11:37:28.691   Training iter 550, batch loss 0.2946, batch acc 0.8818
11:37:30.984   Training iter 600, batch loss 0.3188, batch acc 0.8690
11:37:30.985 Training @ 257 epoch...
11:37:33.306   Training iter 50, batch loss 0.3142, batch acc 0.8726
11:37:35.597   Training iter 100, batch loss 0.3190, batch acc 0.8694
11:37:37.889   Training iter 150, batch loss 0.3123, batch acc 0.8750
11:37:40.234   Training iter 200, batch loss 0.3264, batch acc 0.8666
11:37:42.555   Training iter 250, batch loss 0.3111, batch acc 0.8750
11:37:44.873   Training iter 300, batch loss 0.3171, batch acc 0.8718
11:37:47.172   Training iter 350, batch loss 0.3171, batch acc 0.8688
11:37:49.545   Training iter 400, batch loss 0.3011, batch acc 0.8784
11:37:52.044   Training iter 450, batch loss 0.3305, batch acc 0.8682
11:37:54.528   Training iter 500, batch loss 0.3070, batch acc 0.8736
11:37:57.026   Training iter 550, batch loss 0.3310, batch acc 0.8632
11:37:59.536   Training iter 600, batch loss 0.3359, batch acc 0.8636
11:37:59.538 Training @ 258 epoch...
11:38:02.036   Training iter 50, batch loss 0.3174, batch acc 0.8710
11:38:04.533   Training iter 100, batch loss 0.3224, batch acc 0.8714
11:38:07.058   Training iter 150, batch loss 0.3246, batch acc 0.8656
11:38:09.522   Training iter 200, batch loss 0.3218, batch acc 0.8716
11:38:12.003   Training iter 250, batch loss 0.3026, batch acc 0.8756
11:38:14.520   Training iter 300, batch loss 0.3206, batch acc 0.8686
11:38:17.012   Training iter 350, batch loss 0.3380, batch acc 0.8620
11:38:19.347   Training iter 400, batch loss 0.3322, batch acc 0.8640
11:38:21.649   Training iter 450, batch loss 0.3218, batch acc 0.8692
11:38:23.944   Training iter 500, batch loss 0.3051, batch acc 0.8780
11:38:26.227   Training iter 550, batch loss 0.3082, batch acc 0.8734
11:38:28.518   Training iter 600, batch loss 0.2999, batch acc 0.8782
11:38:28.519 Training @ 259 epoch...
11:38:30.854   Training iter 50, batch loss 0.3188, batch acc 0.8676
11:38:33.142   Training iter 100, batch loss 0.3212, batch acc 0.8690
11:38:35.417   Training iter 150, batch loss 0.2996, batch acc 0.8784
11:38:37.729   Training iter 200, batch loss 0.3270, batch acc 0.8684
11:38:40.078   Training iter 250, batch loss 0.2898, batch acc 0.8814
11:38:42.436   Training iter 300, batch loss 0.3205, batch acc 0.8730
11:38:44.820   Training iter 350, batch loss 0.3267, batch acc 0.8668
11:38:47.220   Training iter 400, batch loss 0.3287, batch acc 0.8638
11:38:49.620   Training iter 450, batch loss 0.3129, batch acc 0.8750
11:38:51.994   Training iter 500, batch loss 0.3276, batch acc 0.8656
11:38:54.372   Training iter 550, batch loss 0.3316, batch acc 0.8642
11:38:56.683   Training iter 600, batch loss 0.3081, batch acc 0.8734
11:38:56.684 Training @ 260 epoch...
11:38:58.977   Training iter 50, batch loss 0.3108, batch acc 0.8752
11:39:01.296   Training iter 100, batch loss 0.3017, batch acc 0.8796
11:39:03.625   Training iter 150, batch loss 0.3089, batch acc 0.8730
11:39:05.910   Training iter 200, batch loss 0.3318, batch acc 0.8658
11:39:08.179   Training iter 250, batch loss 0.3288, batch acc 0.8670
11:39:10.454   Training iter 300, batch loss 0.3360, batch acc 0.8638
11:39:12.737   Training iter 350, batch loss 0.3257, batch acc 0.8660
11:39:15.025   Training iter 400, batch loss 0.3182, batch acc 0.8730
11:39:17.324   Training iter 450, batch loss 0.3139, batch acc 0.8740
11:39:19.612   Training iter 500, batch loss 0.3145, batch acc 0.8706
11:39:21.891   Training iter 550, batch loss 0.3201, batch acc 0.8668
11:39:24.167   Training iter 600, batch loss 0.2942, batch acc 0.8792
11:39:24.168 Testing @ 260 epoch...
11:39:24.220     Testing, total mean loss 0.39630, total acc 0.85220
11:39:24.220 Training @ 261 epoch...
11:39:26.498   Training iter 50, batch loss 0.3247, batch acc 0.8670
11:39:28.767   Training iter 100, batch loss 0.3099, batch acc 0.8722
11:39:31.059   Training iter 150, batch loss 0.3011, batch acc 0.8790
11:39:33.349   Training iter 200, batch loss 0.3097, batch acc 0.8736
11:39:35.638   Training iter 250, batch loss 0.3230, batch acc 0.8704
11:39:37.927   Training iter 300, batch loss 0.3123, batch acc 0.8740
11:39:40.207   Training iter 350, batch loss 0.3239, batch acc 0.8690
11:39:42.490   Training iter 400, batch loss 0.3154, batch acc 0.8710
11:39:44.769   Training iter 450, batch loss 0.3115, batch acc 0.8716
11:39:47.054   Training iter 500, batch loss 0.3251, batch acc 0.8678
11:39:49.331   Training iter 550, batch loss 0.3099, batch acc 0.8730
11:39:51.612   Training iter 600, batch loss 0.3294, batch acc 0.8688
11:39:51.614 Training @ 262 epoch...
11:39:53.914   Training iter 50, batch loss 0.3020, batch acc 0.8786
11:39:56.207   Training iter 100, batch loss 0.3289, batch acc 0.8672
11:39:58.483   Training iter 150, batch loss 0.3075, batch acc 0.8754
11:40:00.765   Training iter 200, batch loss 0.3245, batch acc 0.8674
11:40:03.065   Training iter 250, batch loss 0.3317, batch acc 0.8662
11:40:05.384   Training iter 300, batch loss 0.2976, batch acc 0.8794
11:40:07.694   Training iter 350, batch loss 0.3147, batch acc 0.8728
11:40:10.006   Training iter 400, batch loss 0.3250, batch acc 0.8680
11:40:12.294   Training iter 450, batch loss 0.2982, batch acc 0.8790
11:40:14.581   Training iter 500, batch loss 0.3287, batch acc 0.8654
11:40:16.867   Training iter 550, batch loss 0.3218, batch acc 0.8716
11:40:19.155   Training iter 600, batch loss 0.3129, batch acc 0.8716
11:40:19.157 Training @ 263 epoch...
11:40:21.453   Training iter 50, batch loss 0.3104, batch acc 0.8756
11:40:23.743   Training iter 100, batch loss 0.3350, batch acc 0.8642
11:40:26.035   Training iter 150, batch loss 0.2950, batch acc 0.8810
11:40:28.315   Training iter 200, batch loss 0.3039, batch acc 0.8772
11:40:30.600   Training iter 250, batch loss 0.3205, batch acc 0.8704
11:40:32.880   Training iter 300, batch loss 0.3257, batch acc 0.8668
11:40:35.151   Training iter 350, batch loss 0.3300, batch acc 0.8666
11:40:37.442   Training iter 400, batch loss 0.3101, batch acc 0.8730
11:40:39.729   Training iter 450, batch loss 0.3318, batch acc 0.8648
11:40:42.010   Training iter 500, batch loss 0.2919, batch acc 0.8798
11:40:44.303   Training iter 550, batch loss 0.3329, batch acc 0.8644
11:40:46.589   Training iter 600, batch loss 0.3151, batch acc 0.8708
11:40:46.590 Training @ 264 epoch...
11:40:48.874   Training iter 50, batch loss 0.3279, batch acc 0.8652
11:40:51.157   Training iter 100, batch loss 0.3103, batch acc 0.8754
11:40:53.447   Training iter 150, batch loss 0.2899, batch acc 0.8828
11:40:55.734   Training iter 200, batch loss 0.2939, batch acc 0.8806
11:40:58.028   Training iter 250, batch loss 0.3402, batch acc 0.8624
11:41:00.298   Training iter 300, batch loss 0.3187, batch acc 0.8676
11:41:02.592   Training iter 350, batch loss 0.3235, batch acc 0.8682
11:41:04.885   Training iter 400, batch loss 0.3228, batch acc 0.8708
11:41:07.177   Training iter 450, batch loss 0.3218, batch acc 0.8684
11:41:09.472   Training iter 500, batch loss 0.3141, batch acc 0.8724
11:41:11.772   Training iter 550, batch loss 0.3118, batch acc 0.8726
11:41:14.073   Training iter 600, batch loss 0.3261, batch acc 0.8698
11:41:14.074 Training @ 265 epoch...
11:41:16.353   Training iter 50, batch loss 0.3175, batch acc 0.8700
11:41:18.616   Training iter 100, batch loss 0.2897, batch acc 0.8818
11:41:20.882   Training iter 150, batch loss 0.3131, batch acc 0.8704
11:41:23.152   Training iter 200, batch loss 0.3075, batch acc 0.8758
11:41:25.438   Training iter 250, batch loss 0.3076, batch acc 0.8754
11:41:27.734   Training iter 300, batch loss 0.3408, batch acc 0.8610
11:41:30.023   Training iter 350, batch loss 0.3007, batch acc 0.8776
11:41:32.292   Training iter 400, batch loss 0.3306, batch acc 0.8658
11:41:34.548   Training iter 450, batch loss 0.3239, batch acc 0.8680
11:41:36.814   Training iter 500, batch loss 0.3319, batch acc 0.8650
11:41:39.092   Training iter 550, batch loss 0.3194, batch acc 0.8714
11:41:41.372   Training iter 600, batch loss 0.3122, batch acc 0.8744
11:41:41.374 Testing @ 265 epoch...
11:41:41.426     Testing, total mean loss 0.39338, total acc 0.85370
11:41:41.426 Training @ 266 epoch...
11:41:43.730   Training iter 50, batch loss 0.3293, batch acc 0.8680
11:41:46.032   Training iter 100, batch loss 0.3256, batch acc 0.8668
11:41:48.321   Training iter 150, batch loss 0.3157, batch acc 0.8710
11:41:50.605   Training iter 200, batch loss 0.2886, batch acc 0.8834
11:41:52.903   Training iter 250, batch loss 0.3091, batch acc 0.8710
11:41:55.196   Training iter 300, batch loss 0.3232, batch acc 0.8668
11:41:57.482   Training iter 350, batch loss 0.3214, batch acc 0.8706
11:41:59.767   Training iter 400, batch loss 0.3226, batch acc 0.8684
11:42:02.077   Training iter 450, batch loss 0.3074, batch acc 0.8744
11:42:04.405   Training iter 500, batch loss 0.3183, batch acc 0.8696
11:42:06.711   Training iter 550, batch loss 0.3298, batch acc 0.8652
11:42:09.010   Training iter 600, batch loss 0.3049, batch acc 0.8754
11:42:09.011 Training @ 267 epoch...
11:42:11.302   Training iter 50, batch loss 0.3170, batch acc 0.8730
11:42:13.602   Training iter 100, batch loss 0.2986, batch acc 0.8800
11:42:15.923   Training iter 150, batch loss 0.3020, batch acc 0.8776
11:42:18.238   Training iter 200, batch loss 0.3263, batch acc 0.8682
11:42:20.533   Training iter 250, batch loss 0.3137, batch acc 0.8728
11:42:22.833   Training iter 300, batch loss 0.3111, batch acc 0.8710
11:42:25.134   Training iter 350, batch loss 0.3088, batch acc 0.8732
11:42:27.436   Training iter 400, batch loss 0.3174, batch acc 0.8692
11:42:29.722   Training iter 450, batch loss 0.3196, batch acc 0.8692
11:42:32.023   Training iter 500, batch loss 0.3234, batch acc 0.8668
11:42:34.402   Training iter 550, batch loss 0.3367, batch acc 0.8640
11:42:36.770   Training iter 600, batch loss 0.3259, batch acc 0.8656
11:42:36.772 Training @ 268 epoch...
11:42:39.122   Training iter 50, batch loss 0.3000, batch acc 0.8776
11:42:41.421   Training iter 100, batch loss 0.3198, batch acc 0.8706
11:42:43.735   Training iter 150, batch loss 0.3132, batch acc 0.8746
11:42:46.040   Training iter 200, batch loss 0.3220, batch acc 0.8710
11:42:48.350   Training iter 250, batch loss 0.3235, batch acc 0.8686
11:42:50.660   Training iter 300, batch loss 0.3116, batch acc 0.8728
11:42:52.963   Training iter 350, batch loss 0.3125, batch acc 0.8732
11:42:55.268   Training iter 400, batch loss 0.3195, batch acc 0.8712
11:42:57.576   Training iter 450, batch loss 0.3163, batch acc 0.8718
11:42:59.884   Training iter 500, batch loss 0.3174, batch acc 0.8694
11:43:02.193   Training iter 550, batch loss 0.3177, batch acc 0.8704
11:43:04.494   Training iter 600, batch loss 0.3215, batch acc 0.8688
11:43:04.495 Training @ 269 epoch...
11:43:06.803   Training iter 50, batch loss 0.3064, batch acc 0.8756
11:43:09.074   Training iter 100, batch loss 0.3123, batch acc 0.8738
11:43:11.352   Training iter 150, batch loss 0.3152, batch acc 0.8706
11:43:13.632   Training iter 200, batch loss 0.3089, batch acc 0.8734
11:43:15.910   Training iter 250, batch loss 0.3321, batch acc 0.8638
11:43:18.207   Training iter 300, batch loss 0.3315, batch acc 0.8668
11:43:20.508   Training iter 350, batch loss 0.3046, batch acc 0.8774
11:43:22.809   Training iter 400, batch loss 0.2997, batch acc 0.8776
11:43:25.105   Training iter 450, batch loss 0.3066, batch acc 0.8762
11:43:27.467   Training iter 500, batch loss 0.3226, batch acc 0.8692
11:43:29.800   Training iter 550, batch loss 0.3382, batch acc 0.8636
11:43:32.093   Training iter 600, batch loss 0.3141, batch acc 0.8726
11:43:32.095 Training @ 270 epoch...
11:43:34.411   Training iter 50, batch loss 0.3080, batch acc 0.8730
11:43:36.725   Training iter 100, batch loss 0.3217, batch acc 0.8676
11:43:39.028   Training iter 150, batch loss 0.3210, batch acc 0.8704
11:43:41.325   Training iter 200, batch loss 0.3079, batch acc 0.8756
11:43:43.654   Training iter 250, batch loss 0.3157, batch acc 0.8714
11:43:45.997   Training iter 300, batch loss 0.3161, batch acc 0.8726
11:43:48.331   Training iter 350, batch loss 0.3111, batch acc 0.8734
11:43:50.628   Training iter 400, batch loss 0.3268, batch acc 0.8674
11:43:52.933   Training iter 450, batch loss 0.3090, batch acc 0.8728
11:43:55.230   Training iter 500, batch loss 0.3284, batch acc 0.8670
11:43:57.526   Training iter 550, batch loss 0.2948, batch acc 0.8816
11:43:59.815   Training iter 600, batch loss 0.3237, batch acc 0.8670
11:43:59.816 Testing @ 270 epoch...
11:43:59.868     Testing, total mean loss 0.39607, total acc 0.85280
11:43:59.868 Training @ 271 epoch...
11:44:02.183   Training iter 50, batch loss 0.3174, batch acc 0.8730
11:44:04.502   Training iter 100, batch loss 0.3218, batch acc 0.8700
11:44:06.829   Training iter 150, batch loss 0.3351, batch acc 0.8640
11:44:09.153   Training iter 200, batch loss 0.3313, batch acc 0.8666
11:44:11.465   Training iter 250, batch loss 0.3160, batch acc 0.8728
11:44:13.758   Training iter 300, batch loss 0.3138, batch acc 0.8720
11:44:16.037   Training iter 350, batch loss 0.3175, batch acc 0.8712
11:44:18.331   Training iter 400, batch loss 0.3003, batch acc 0.8764
11:44:20.619   Training iter 450, batch loss 0.3324, batch acc 0.8642
11:44:22.947   Training iter 500, batch loss 0.3104, batch acc 0.8724
11:44:25.285   Training iter 550, batch loss 0.3083, batch acc 0.8738
11:44:28.169   Training iter 600, batch loss 0.2998, batch acc 0.8768
11:44:28.172 Training @ 272 epoch...
11:44:30.713   Training iter 50, batch loss 0.2926, batch acc 0.8818
11:44:32.991   Training iter 100, batch loss 0.3239, batch acc 0.8684
11:44:35.269   Training iter 150, batch loss 0.3265, batch acc 0.8682
11:44:37.621   Training iter 200, batch loss 0.3250, batch acc 0.8700
11:44:39.921   Training iter 250, batch loss 0.3157, batch acc 0.8722
11:44:42.216   Training iter 300, batch loss 0.3198, batch acc 0.8694
11:44:44.540   Training iter 350, batch loss 0.3144, batch acc 0.8738
11:44:46.813   Training iter 400, batch loss 0.3146, batch acc 0.8734
11:44:49.068   Training iter 450, batch loss 0.3115, batch acc 0.8710
11:44:51.318   Training iter 500, batch loss 0.3101, batch acc 0.8720
11:44:53.597   Training iter 550, batch loss 0.3180, batch acc 0.8704
11:44:55.885   Training iter 600, batch loss 0.3244, batch acc 0.8710
11:44:55.887 Training @ 273 epoch...
11:44:58.184   Training iter 50, batch loss 0.3023, batch acc 0.8742
11:45:00.479   Training iter 100, batch loss 0.3145, batch acc 0.8730
11:45:02.802   Training iter 150, batch loss 0.3177, batch acc 0.8706
11:45:05.101   Training iter 200, batch loss 0.3110, batch acc 0.8742
11:45:07.423   Training iter 250, batch loss 0.3162, batch acc 0.8688
11:45:09.715   Training iter 300, batch loss 0.3183, batch acc 0.8708
11:45:12.058   Training iter 350, batch loss 0.3187, batch acc 0.8692
11:45:14.395   Training iter 400, batch loss 0.2925, batch acc 0.8802
11:45:16.713   Training iter 450, batch loss 0.3344, batch acc 0.8648
11:45:18.985   Training iter 500, batch loss 0.3249, batch acc 0.8668
11:45:21.303   Training iter 550, batch loss 0.3211, batch acc 0.8704
11:45:23.628   Training iter 600, batch loss 0.3149, batch acc 0.8730
11:45:23.630 Training @ 274 epoch...
11:45:25.962   Training iter 50, batch loss 0.3176, batch acc 0.8696
11:45:28.278   Training iter 100, batch loss 0.3162, batch acc 0.8690
11:45:30.585   Training iter 150, batch loss 0.3171, batch acc 0.8732
11:45:32.928   Training iter 200, batch loss 0.2849, batch acc 0.8828
11:45:35.202   Training iter 250, batch loss 0.3143, batch acc 0.8714
11:45:37.491   Training iter 300, batch loss 0.3186, batch acc 0.8724
11:45:39.825   Training iter 350, batch loss 0.3048, batch acc 0.8774
11:45:42.159   Training iter 400, batch loss 0.3316, batch acc 0.8668
11:45:44.591   Training iter 450, batch loss 0.3217, batch acc 0.8698
11:45:46.869   Training iter 500, batch loss 0.3246, batch acc 0.8676
11:45:49.164   Training iter 550, batch loss 0.3163, batch acc 0.8716
11:45:51.448   Training iter 600, batch loss 0.3241, batch acc 0.8694
11:45:51.450 Training @ 275 epoch...
11:45:53.752   Training iter 50, batch loss 0.3050, batch acc 0.8742
11:45:56.070   Training iter 100, batch loss 0.3091, batch acc 0.8734
11:45:58.348   Training iter 150, batch loss 0.3089, batch acc 0.8748
11:46:00.659   Training iter 200, batch loss 0.3097, batch acc 0.8750
11:46:02.986   Training iter 250, batch loss 0.3301, batch acc 0.8646
11:46:05.271   Training iter 300, batch loss 0.3292, batch acc 0.8666
11:46:07.529   Training iter 350, batch loss 0.2980, batch acc 0.8788
11:46:09.773   Training iter 400, batch loss 0.3052, batch acc 0.8786
11:46:12.118   Training iter 450, batch loss 0.3372, batch acc 0.8632
11:46:14.471   Training iter 500, batch loss 0.3372, batch acc 0.8620
11:46:16.784   Training iter 550, batch loss 0.3087, batch acc 0.8736
11:46:19.088   Training iter 600, batch loss 0.3145, batch acc 0.8728
11:46:19.089 Testing @ 275 epoch...
11:46:19.141     Testing, total mean loss 0.39263, total acc 0.85210
11:46:19.141 Training @ 276 epoch...
11:46:21.408   Training iter 50, batch loss 0.3173, batch acc 0.8696
11:46:23.680   Training iter 100, batch loss 0.3013, batch acc 0.8782
11:46:25.951   Training iter 150, batch loss 0.3309, batch acc 0.8656
11:46:28.233   Training iter 200, batch loss 0.3102, batch acc 0.8716
11:46:30.501   Training iter 250, batch loss 0.3143, batch acc 0.8734
11:46:32.787   Training iter 300, batch loss 0.3284, batch acc 0.8664
11:46:35.073   Training iter 350, batch loss 0.3214, batch acc 0.8688
11:46:37.401   Training iter 400, batch loss 0.3347, batch acc 0.8646
11:46:39.680   Training iter 450, batch loss 0.3161, batch acc 0.8724
11:46:41.942   Training iter 500, batch loss 0.3013, batch acc 0.8782
11:46:44.214   Training iter 550, batch loss 0.3138, batch acc 0.8730
11:46:46.489   Training iter 600, batch loss 0.3147, batch acc 0.8712
11:46:46.490 Training @ 277 epoch...
11:46:48.774   Training iter 50, batch loss 0.3162, batch acc 0.8734
11:46:51.092   Training iter 100, batch loss 0.2936, batch acc 0.8824
11:46:53.404   Training iter 150, batch loss 0.3262, batch acc 0.8668
11:46:55.670   Training iter 200, batch loss 0.3195, batch acc 0.8704
11:46:57.935   Training iter 250, batch loss 0.3160, batch acc 0.8718
11:47:00.215   Training iter 300, batch loss 0.3418, batch acc 0.8608
11:47:02.582   Training iter 350, batch loss 0.3126, batch acc 0.8730
11:47:04.911   Training iter 400, batch loss 0.3261, batch acc 0.8670
11:47:07.214   Training iter 450, batch loss 0.3189, batch acc 0.8696
11:47:09.489   Training iter 500, batch loss 0.3077, batch acc 0.8756
11:47:11.782   Training iter 550, batch loss 0.3034, batch acc 0.8764
11:47:14.086   Training iter 600, batch loss 0.3158, batch acc 0.8698
11:47:14.088 Training @ 278 epoch...
11:47:16.386   Training iter 50, batch loss 0.2985, batch acc 0.8782
11:47:18.666   Training iter 100, batch loss 0.3315, batch acc 0.8672
11:47:20.947   Training iter 150, batch loss 0.3072, batch acc 0.8746
11:47:23.232   Training iter 200, batch loss 0.3250, batch acc 0.8676
11:47:25.546   Training iter 250, batch loss 0.3220, batch acc 0.8698
11:47:27.845   Training iter 300, batch loss 0.3310, batch acc 0.8648
11:47:30.160   Training iter 350, batch loss 0.2991, batch acc 0.8792
11:47:32.452   Training iter 400, batch loss 0.3259, batch acc 0.8676
11:47:34.734   Training iter 450, batch loss 0.3201, batch acc 0.8682
11:47:37.047   Training iter 500, batch loss 0.3026, batch acc 0.8778
11:47:39.337   Training iter 550, batch loss 0.3098, batch acc 0.8750
11:47:41.618   Training iter 600, batch loss 0.3153, batch acc 0.8736
11:47:41.620 Training @ 279 epoch...
11:47:43.932   Training iter 50, batch loss 0.3001, batch acc 0.8780
11:47:46.249   Training iter 100, batch loss 0.3139, batch acc 0.8718
11:47:48.555   Training iter 150, batch loss 0.2975, batch acc 0.8798
11:47:50.837   Training iter 200, batch loss 0.3085, batch acc 0.8746
11:47:53.133   Training iter 250, batch loss 0.3276, batch acc 0.8660
11:47:55.412   Training iter 300, batch loss 0.3145, batch acc 0.8718
11:47:57.714   Training iter 350, batch loss 0.3240, batch acc 0.8678
11:47:59.998   Training iter 400, batch loss 0.3227, batch acc 0.8692
11:48:02.307   Training iter 450, batch loss 0.3183, batch acc 0.8698
11:48:04.642   Training iter 500, batch loss 0.3333, batch acc 0.8646
11:48:06.942   Training iter 550, batch loss 0.3289, batch acc 0.8672
11:48:09.229   Training iter 600, batch loss 0.3003, batch acc 0.8778
11:48:09.230 Training @ 280 epoch...
11:48:11.522   Training iter 50, batch loss 0.2947, batch acc 0.8790
11:48:13.861   Training iter 100, batch loss 0.3094, batch acc 0.8750
11:48:16.186   Training iter 150, batch loss 0.3196, batch acc 0.8702
11:48:18.447   Training iter 200, batch loss 0.3167, batch acc 0.8730
11:48:20.710   Training iter 250, batch loss 0.3130, batch acc 0.8730
11:48:23.034   Training iter 300, batch loss 0.3231, batch acc 0.8700
11:48:25.324   Training iter 350, batch loss 0.3107, batch acc 0.8734
11:48:27.620   Training iter 400, batch loss 0.3242, batch acc 0.8702
11:48:29.885   Training iter 450, batch loss 0.3192, batch acc 0.8704
11:48:32.139   Training iter 500, batch loss 0.3290, batch acc 0.8664
11:48:34.400   Training iter 550, batch loss 0.3254, batch acc 0.8680
11:48:36.674   Training iter 600, batch loss 0.3186, batch acc 0.8700
11:48:36.676 Testing @ 280 epoch...
11:48:36.727     Testing, total mean loss 0.40124, total acc 0.85130
11:48:36.727 Training @ 281 epoch...
11:48:39.013   Training iter 50, batch loss 0.3155, batch acc 0.8698
11:48:41.292   Training iter 100, batch loss 0.3164, batch acc 0.8726
11:48:43.668   Training iter 150, batch loss 0.3267, batch acc 0.8690
11:48:45.995   Training iter 200, batch loss 0.3124, batch acc 0.8726
11:48:48.290   Training iter 250, batch loss 0.3152, batch acc 0.8724
11:48:50.640   Training iter 300, batch loss 0.3230, batch acc 0.8676
11:48:52.945   Training iter 350, batch loss 0.3113, batch acc 0.8748
11:48:55.205   Training iter 400, batch loss 0.3184, batch acc 0.8708
11:48:57.477   Training iter 450, batch loss 0.3113, batch acc 0.8732
11:48:59.740   Training iter 500, batch loss 0.3193, batch acc 0.8714
11:49:02.012   Training iter 550, batch loss 0.3190, batch acc 0.8716
11:49:04.294   Training iter 600, batch loss 0.3026, batch acc 0.8752
11:49:04.296 Training @ 282 epoch...
11:49:06.584   Training iter 50, batch loss 0.3171, batch acc 0.8712
11:49:08.850   Training iter 100, batch loss 0.3174, batch acc 0.8698
11:49:11.135   Training iter 150, batch loss 0.3319, batch acc 0.8636
11:49:13.449   Training iter 200, batch loss 0.3210, batch acc 0.8698
11:49:15.851   Training iter 250, batch loss 0.2966, batch acc 0.8802
11:49:18.284   Training iter 300, batch loss 0.3112, batch acc 0.8728
11:49:20.573   Training iter 350, batch loss 0.3155, batch acc 0.8708
11:49:22.851   Training iter 400, batch loss 0.3306, batch acc 0.8672
11:49:25.122   Training iter 450, batch loss 0.3198, batch acc 0.8718
11:49:27.402   Training iter 500, batch loss 0.3099, batch acc 0.8734
11:49:29.675   Training iter 550, batch loss 0.3238, batch acc 0.8666
11:49:31.982   Training iter 600, batch loss 0.3099, batch acc 0.8756
11:49:31.984 Training @ 283 epoch...
11:49:34.299   Training iter 50, batch loss 0.3026, batch acc 0.8760
11:49:36.604   Training iter 100, batch loss 0.3155, batch acc 0.8710
11:49:38.923   Training iter 150, batch loss 0.3211, batch acc 0.8704
11:49:41.193   Training iter 200, batch loss 0.3119, batch acc 0.8732
11:49:43.445   Training iter 250, batch loss 0.3030, batch acc 0.8760
11:49:45.699   Training iter 300, batch loss 0.3347, batch acc 0.8624
11:49:47.975   Training iter 350, batch loss 0.3150, batch acc 0.8726
11:49:50.252   Training iter 400, batch loss 0.3059, batch acc 0.8752
11:49:52.529   Training iter 450, batch loss 0.3080, batch acc 0.8774
11:49:54.784   Training iter 500, batch loss 0.3379, batch acc 0.8618
11:49:57.041   Training iter 550, batch loss 0.3170, batch acc 0.8710
11:49:59.303   Training iter 600, batch loss 0.3124, batch acc 0.8712
11:49:59.305 Training @ 284 epoch...
11:50:01.586   Training iter 50, batch loss 0.3173, batch acc 0.8714
11:50:03.893   Training iter 100, batch loss 0.3368, batch acc 0.8606
11:50:06.190   Training iter 150, batch loss 0.2998, batch acc 0.8776
11:50:08.484   Training iter 200, batch loss 0.3142, batch acc 0.8718
11:50:10.753   Training iter 250, batch loss 0.3169, batch acc 0.8702
11:50:13.039   Training iter 300, batch loss 0.3109, batch acc 0.8750
11:50:15.329   Training iter 350, batch loss 0.3034, batch acc 0.8766
11:50:17.593   Training iter 400, batch loss 0.3302, batch acc 0.8694
11:50:19.847   Training iter 450, batch loss 0.3109, batch acc 0.8724
11:50:22.102   Training iter 500, batch loss 0.3153, batch acc 0.8714
11:50:24.355   Training iter 550, batch loss 0.3280, batch acc 0.8646
11:50:27.096   Training iter 600, batch loss 0.3052, batch acc 0.8770
11:50:27.098 Training @ 285 epoch...
11:50:29.410   Training iter 50, batch loss 0.3130, batch acc 0.8716
11:50:31.672   Training iter 100, batch loss 0.3036, batch acc 0.8738
11:50:33.924   Training iter 150, batch loss 0.2982, batch acc 0.8788
11:50:36.188   Training iter 200, batch loss 0.3237, batch acc 0.8654
11:50:38.452   Training iter 250, batch loss 0.3173, batch acc 0.8706
11:50:40.723   Training iter 300, batch loss 0.3188, batch acc 0.8702
11:50:42.985   Training iter 350, batch loss 0.3111, batch acc 0.8730
11:50:45.262   Training iter 400, batch loss 0.3354, batch acc 0.8632
11:50:47.552   Training iter 450, batch loss 0.3202, batch acc 0.8692
11:50:49.835   Training iter 500, batch loss 0.3233, batch acc 0.8710
11:50:52.199   Training iter 550, batch loss 0.3044, batch acc 0.8758
11:50:54.486   Training iter 600, batch loss 0.3279, batch acc 0.8686
11:50:54.487 Testing @ 285 epoch...
11:50:54.538     Testing, total mean loss 0.40040, total acc 0.85080
11:50:54.538 Training @ 286 epoch...
11:50:56.826   Training iter 50, batch loss 0.3120, batch acc 0.8718
11:50:59.114   Training iter 100, batch loss 0.3408, batch acc 0.8600
11:51:01.396   Training iter 150, batch loss 0.2932, batch acc 0.8804
11:51:03.667   Training iter 200, batch loss 0.3103, batch acc 0.8704
11:51:05.941   Training iter 250, batch loss 0.3049, batch acc 0.8774
11:51:08.231   Training iter 300, batch loss 0.3171, batch acc 0.8722
11:51:10.516   Training iter 350, batch loss 0.3223, batch acc 0.8690
11:51:12.817   Training iter 400, batch loss 0.3074, batch acc 0.8748
11:51:15.105   Training iter 450, batch loss 0.3125, batch acc 0.8724
11:51:17.415   Training iter 500, batch loss 0.3198, batch acc 0.8716
11:51:19.715   Training iter 550, batch loss 0.3101, batch acc 0.8760
11:51:21.997   Training iter 600, batch loss 0.3308, batch acc 0.8668
11:51:21.999 Training @ 287 epoch...
11:51:24.327   Training iter 50, batch loss 0.3158, batch acc 0.8690
11:51:26.617   Training iter 100, batch loss 0.3460, batch acc 0.8576
11:51:28.900   Training iter 150, batch loss 0.3162, batch acc 0.8708
11:51:31.195   Training iter 200, batch loss 0.3104, batch acc 0.8730
11:51:33.460   Training iter 250, batch loss 0.2935, batch acc 0.8830
11:51:35.744   Training iter 300, batch loss 0.3260, batch acc 0.8668
11:51:37.985   Training iter 350, batch loss 0.2971, batch acc 0.8778
11:51:40.250   Training iter 400, batch loss 0.3269, batch acc 0.8670
11:51:42.530   Training iter 450, batch loss 0.3173, batch acc 0.8716
11:51:44.829   Training iter 500, batch loss 0.3203, batch acc 0.8688
11:51:47.108   Training iter 550, batch loss 0.3054, batch acc 0.8782
11:51:49.371   Training iter 600, batch loss 0.3183, batch acc 0.8724
11:51:49.373 Training @ 288 epoch...
11:51:51.635   Training iter 50, batch loss 0.3244, batch acc 0.8702
11:51:53.885   Training iter 100, batch loss 0.3205, batch acc 0.8708
11:51:56.136   Training iter 150, batch loss 0.3161, batch acc 0.8704
11:51:58.402   Training iter 200, batch loss 0.3252, batch acc 0.8692
11:52:00.672   Training iter 250, batch loss 0.3184, batch acc 0.8690
11:52:02.964   Training iter 300, batch loss 0.3087, batch acc 0.8744
11:52:05.236   Training iter 350, batch loss 0.3015, batch acc 0.8778
11:52:07.499   Training iter 400, batch loss 0.3140, batch acc 0.8724
11:52:09.737   Training iter 450, batch loss 0.3100, batch acc 0.8728
11:52:11.965   Training iter 500, batch loss 0.3221, batch acc 0.8680
11:52:14.258   Training iter 550, batch loss 0.3107, batch acc 0.8728
11:52:16.534   Training iter 600, batch loss 0.3160, batch acc 0.8704
11:52:16.535 Training @ 289 epoch...
11:52:18.828   Training iter 50, batch loss 0.3068, batch acc 0.8742
11:52:21.130   Training iter 100, batch loss 0.3207, batch acc 0.8666
11:52:23.409   Training iter 150, batch loss 0.3139, batch acc 0.8734
11:52:25.697   Training iter 200, batch loss 0.3210, batch acc 0.8694
11:52:27.997   Training iter 250, batch loss 0.3168, batch acc 0.8702
11:52:30.325   Training iter 300, batch loss 0.3168, batch acc 0.8722
11:52:32.644   Training iter 350, batch loss 0.3153, batch acc 0.8710
11:52:34.931   Training iter 400, batch loss 0.3084, batch acc 0.8744
11:52:37.199   Training iter 450, batch loss 0.3068, batch acc 0.8742
11:52:39.477   Training iter 500, batch loss 0.3174, batch acc 0.8708
11:52:41.757   Training iter 550, batch loss 0.3223, batch acc 0.8676
11:52:44.035   Training iter 600, batch loss 0.3168, batch acc 0.8732
11:52:44.037 Training @ 290 epoch...
11:52:46.352   Training iter 50, batch loss 0.3034, batch acc 0.8778
11:52:48.630   Training iter 100, batch loss 0.3299, batch acc 0.8664
11:52:50.887   Training iter 150, batch loss 0.3325, batch acc 0.8626
11:52:53.139   Training iter 200, batch loss 0.3418, batch acc 0.8608
11:52:55.395   Training iter 250, batch loss 0.3074, batch acc 0.8752
11:52:57.686   Training iter 300, batch loss 0.3086, batch acc 0.8746
11:53:00.033   Training iter 350, batch loss 0.2998, batch acc 0.8792
11:53:02.346   Training iter 400, batch loss 0.2907, batch acc 0.8806
11:53:04.660   Training iter 450, batch loss 0.3165, batch acc 0.8718
11:53:07.005   Training iter 500, batch loss 0.3246, batch acc 0.8690
11:53:09.326   Training iter 550, batch loss 0.3095, batch acc 0.8764
11:53:11.643   Training iter 600, batch loss 0.3172, batch acc 0.8720
11:53:11.645 Testing @ 290 epoch...
11:53:11.695     Testing, total mean loss 0.39604, total acc 0.85250
11:53:11.695 Training @ 291 epoch...
11:53:13.987   Training iter 50, batch loss 0.3066, batch acc 0.8746
11:53:16.279   Training iter 100, batch loss 0.2944, batch acc 0.8798
11:53:18.634   Training iter 150, batch loss 0.3228, batch acc 0.8710
11:53:21.014   Training iter 200, batch loss 0.3319, batch acc 0.8624
11:53:23.345   Training iter 250, batch loss 0.3249, batch acc 0.8652
11:53:25.731   Training iter 300, batch loss 0.3126, batch acc 0.8722
11:53:28.079   Training iter 350, batch loss 0.3174, batch acc 0.8704
11:53:30.365   Training iter 400, batch loss 0.3223, batch acc 0.8684
11:53:32.626   Training iter 450, batch loss 0.3133, batch acc 0.8740
11:53:34.933   Training iter 500, batch loss 0.2998, batch acc 0.8790
11:53:37.198   Training iter 550, batch loss 0.3155, batch acc 0.8704
11:53:39.462   Training iter 600, batch loss 0.3299, batch acc 0.8668
11:53:39.464 Training @ 292 epoch...
11:53:41.783   Training iter 50, batch loss 0.3103, batch acc 0.8738
11:53:44.064   Training iter 100, batch loss 0.3289, batch acc 0.8652
11:53:46.458   Training iter 150, batch loss 0.3240, batch acc 0.8668
11:53:48.730   Training iter 200, batch loss 0.3254, batch acc 0.8684
11:53:51.031   Training iter 250, batch loss 0.3146, batch acc 0.8730
11:53:53.385   Training iter 300, batch loss 0.3022, batch acc 0.8796
11:53:55.758   Training iter 350, batch loss 0.3041, batch acc 0.8766
11:53:58.268   Training iter 400, batch loss 0.3152, batch acc 0.8714
11:54:00.717   Training iter 450, batch loss 0.3242, batch acc 0.8680
11:54:03.608   Training iter 500, batch loss 0.3034, batch acc 0.8742
11:54:05.928   Training iter 550, batch loss 0.3156, batch acc 0.8728
11:54:08.219   Training iter 600, batch loss 0.3205, batch acc 0.8704
11:54:08.221 Training @ 293 epoch...
11:54:10.476   Training iter 50, batch loss 0.2947, batch acc 0.8806
11:54:12.772   Training iter 100, batch loss 0.3300, batch acc 0.8654
11:54:15.017   Training iter 150, batch loss 0.3159, batch acc 0.8718
11:54:17.302   Training iter 200, batch loss 0.3192, batch acc 0.8708
11:54:19.548   Training iter 250, batch loss 0.3080, batch acc 0.8706
11:54:21.792   Training iter 300, batch loss 0.3127, batch acc 0.8732
11:54:24.060   Training iter 350, batch loss 0.3162, batch acc 0.8728
11:54:26.336   Training iter 400, batch loss 0.3002, batch acc 0.8758
11:54:28.598   Training iter 450, batch loss 0.3216, batch acc 0.8682
11:54:30.868   Training iter 500, batch loss 0.3129, batch acc 0.8696
11:54:33.127   Training iter 550, batch loss 0.3332, batch acc 0.8642
11:54:35.387   Training iter 600, batch loss 0.3167, batch acc 0.8716
11:54:35.389 Training @ 294 epoch...
11:54:37.655   Training iter 50, batch loss 0.2895, batch acc 0.8842
11:54:39.927   Training iter 100, batch loss 0.3201, batch acc 0.8674
11:54:42.189   Training iter 150, batch loss 0.2967, batch acc 0.8790
11:54:44.476   Training iter 200, batch loss 0.3048, batch acc 0.8754
11:54:46.749   Training iter 250, batch loss 0.3283, batch acc 0.8668
11:54:49.014   Training iter 300, batch loss 0.3269, batch acc 0.8690
11:54:51.271   Training iter 350, batch loss 0.3168, batch acc 0.8722
11:54:53.536   Training iter 400, batch loss 0.3035, batch acc 0.8758
11:54:55.808   Training iter 450, batch loss 0.3358, batch acc 0.8624
11:54:58.085   Training iter 500, batch loss 0.3342, batch acc 0.8652
11:55:00.349   Training iter 550, batch loss 0.3483, batch acc 0.8600
11:55:02.648   Training iter 600, batch loss 0.2998, batch acc 0.8760
11:55:02.650 Training @ 295 epoch...
11:55:04.924   Training iter 50, batch loss 0.3095, batch acc 0.8736
11:55:07.195   Training iter 100, batch loss 0.3127, batch acc 0.8716
11:55:09.465   Training iter 150, batch loss 0.3272, batch acc 0.8670
11:55:11.742   Training iter 200, batch loss 0.3227, batch acc 0.8676
11:55:14.021   Training iter 250, batch loss 0.3119, batch acc 0.8708
11:55:16.284   Training iter 300, batch loss 0.2927, batch acc 0.8806
11:55:18.547   Training iter 350, batch loss 0.3150, batch acc 0.8736
11:55:20.807   Training iter 400, batch loss 0.3185, batch acc 0.8714
11:55:23.070   Training iter 450, batch loss 0.3070, batch acc 0.8756
11:55:25.338   Training iter 500, batch loss 0.3003, batch acc 0.8784
11:55:27.634   Training iter 550, batch loss 0.3462, batch acc 0.8594
11:55:29.916   Training iter 600, batch loss 0.3192, batch acc 0.8730
11:55:29.918 Testing @ 295 epoch...
11:55:29.968     Testing, total mean loss 0.40514, total acc 0.84910
11:55:29.968 Training @ 296 epoch...
11:55:32.258   Training iter 50, batch loss 0.3194, batch acc 0.8676
11:55:34.520   Training iter 100, batch loss 0.3081, batch acc 0.8748
11:55:36.787   Training iter 150, batch loss 0.3063, batch acc 0.8750
11:55:39.042   Training iter 200, batch loss 0.3174, batch acc 0.8700
11:55:41.297   Training iter 250, batch loss 0.3196, batch acc 0.8696
11:55:43.573   Training iter 300, batch loss 0.3169, batch acc 0.8714
11:55:45.860   Training iter 350, batch loss 0.3022, batch acc 0.8776
11:55:48.137   Training iter 400, batch loss 0.3208, batch acc 0.8686
11:55:50.381   Training iter 450, batch loss 0.3148, batch acc 0.8728
11:55:52.623   Training iter 500, batch loss 0.3138, batch acc 0.8718
11:55:54.869   Training iter 550, batch loss 0.3259, batch acc 0.8668
11:55:57.126   Training iter 600, batch loss 0.3232, batch acc 0.8682
11:55:57.128 Training @ 297 epoch...
11:55:59.386   Training iter 50, batch loss 0.3134, batch acc 0.8700
11:56:01.657   Training iter 100, batch loss 0.3182, batch acc 0.8686
11:56:03.954   Training iter 150, batch loss 0.3011, batch acc 0.8786
11:56:06.233   Training iter 200, batch loss 0.3311, batch acc 0.8674
11:56:08.492   Training iter 250, batch loss 0.3089, batch acc 0.8720
11:56:10.743   Training iter 300, batch loss 0.2990, batch acc 0.8776
11:56:13.017   Training iter 350, batch loss 0.3271, batch acc 0.8668
11:56:15.296   Training iter 400, batch loss 0.3009, batch acc 0.8776
11:56:17.597   Training iter 450, batch loss 0.3069, batch acc 0.8756
11:56:19.882   Training iter 500, batch loss 0.3024, batch acc 0.8770
11:56:22.154   Training iter 550, batch loss 0.3212, batch acc 0.8678
11:56:24.420   Training iter 600, batch loss 0.3410, batch acc 0.8616
11:56:24.422 Training @ 298 epoch...
11:56:26.693   Training iter 50, batch loss 0.3275, batch acc 0.8692
11:56:28.979   Training iter 100, batch loss 0.3030, batch acc 0.8762
11:56:31.245   Training iter 150, batch loss 0.3245, batch acc 0.8676
11:56:33.533   Training iter 200, batch loss 0.3225, batch acc 0.8658
11:56:35.826   Training iter 250, batch loss 0.3192, batch acc 0.8710
11:56:38.131   Training iter 300, batch loss 0.3194, batch acc 0.8714
11:56:40.390   Training iter 350, batch loss 0.3075, batch acc 0.8746
11:56:42.673   Training iter 400, batch loss 0.2999, batch acc 0.8770
11:56:44.946   Training iter 450, batch loss 0.3257, batch acc 0.8678
11:56:47.222   Training iter 500, batch loss 0.3183, batch acc 0.8700
11:56:49.535   Training iter 550, batch loss 0.3050, batch acc 0.8752
11:56:51.961   Training iter 600, batch loss 0.3070, batch acc 0.8776
11:56:51.964 Training @ 299 epoch...
11:56:54.304   Training iter 50, batch loss 0.3048, batch acc 0.8766
11:56:56.544   Training iter 100, batch loss 0.3077, batch acc 0.8764
11:56:58.782   Training iter 150, batch loss 0.3162, batch acc 0.8708
11:57:01.047   Training iter 200, batch loss 0.3168, batch acc 0.8700
11:57:03.326   Training iter 250, batch loss 0.3197, batch acc 0.8720
11:57:05.588   Training iter 300, batch loss 0.3129, batch acc 0.8718
11:57:07.868   Training iter 350, batch loss 0.3355, batch acc 0.8636
11:57:10.176   Training iter 400, batch loss 0.3028, batch acc 0.8766
11:57:12.436   Training iter 450, batch loss 0.3106, batch acc 0.8730
11:57:14.717   Training iter 500, batch loss 0.3072, batch acc 0.8746
11:57:16.990   Training iter 550, batch loss 0.3300, batch acc 0.8638
11:57:19.270   Training iter 600, batch loss 0.3221, batch acc 0.8670
11:57:19.272 Training @ 300 epoch...
11:57:21.573   Training iter 50, batch loss 0.3354, batch acc 0.8630
11:57:23.855   Training iter 100, batch loss 0.3193, batch acc 0.8710
11:57:26.119   Training iter 150, batch loss 0.3068, batch acc 0.8740
11:57:28.421   Training iter 200, batch loss 0.3050, batch acc 0.8766
11:57:30.732   Training iter 250, batch loss 0.3116, batch acc 0.8732
11:57:32.987   Training iter 300, batch loss 0.3158, batch acc 0.8718
11:57:35.238   Training iter 350, batch loss 0.2859, batch acc 0.8846
11:57:37.491   Training iter 400, batch loss 0.3191, batch acc 0.8702
11:57:39.753   Training iter 450, batch loss 0.3119, batch acc 0.8732
11:57:42.005   Training iter 500, batch loss 0.3222, batch acc 0.8688
11:57:44.243   Training iter 550, batch loss 0.3230, batch acc 0.8676
11:57:46.497   Training iter 600, batch loss 0.3148, batch acc 0.8688
11:57:46.499 Testing @ 300 epoch...
11:57:46.551     Testing, total mean loss 0.39972, total acc 0.85090
11:57:46.551 Plot @ 300 epoch...
11:57:46.551 Training @ 301 epoch...
11:57:48.866   Training iter 50, batch loss 0.3212, batch acc 0.8662
11:57:51.107   Training iter 100, batch loss 0.3116, batch acc 0.8734
11:57:53.346   Training iter 150, batch loss 0.3169, batch acc 0.8698
11:57:55.581   Training iter 200, batch loss 0.3250, batch acc 0.8658
11:57:57.826   Training iter 250, batch loss 0.2908, batch acc 0.8828
11:58:00.113   Training iter 300, batch loss 0.3202, batch acc 0.8694
11:58:02.404   Training iter 350, batch loss 0.3194, batch acc 0.8696
11:58:04.662   Training iter 400, batch loss 0.3184, batch acc 0.8704
11:58:06.924   Training iter 450, batch loss 0.3120, batch acc 0.8746
11:58:09.190   Training iter 500, batch loss 0.3108, batch acc 0.8740
11:58:11.470   Training iter 550, batch loss 0.3119, batch acc 0.8742
11:58:13.822   Training iter 600, batch loss 0.3212, batch acc 0.8710
11:58:13.824 Training @ 302 epoch...
11:58:16.204   Training iter 50, batch loss 0.3012, batch acc 0.8750
11:58:18.529   Training iter 100, batch loss 0.3112, batch acc 0.8724
11:58:20.863   Training iter 150, batch loss 0.3086, batch acc 0.8738
11:58:23.185   Training iter 200, batch loss 0.3200, batch acc 0.8698
11:58:25.538   Training iter 250, batch loss 0.3240, batch acc 0.8662
11:58:27.845   Training iter 300, batch loss 0.3261, batch acc 0.8668
11:58:30.139   Training iter 350, batch loss 0.3133, batch acc 0.8726
11:58:32.437   Training iter 400, batch loss 0.3026, batch acc 0.8784
11:58:34.759   Training iter 450, batch loss 0.3252, batch acc 0.8672
11:58:37.214   Training iter 500, batch loss 0.3281, batch acc 0.8666
11:58:39.593   Training iter 550, batch loss 0.3097, batch acc 0.8750
11:58:41.916   Training iter 600, batch loss 0.3100, batch acc 0.8746
11:58:41.918 Training @ 303 epoch...
11:58:44.302   Training iter 50, batch loss 0.3277, batch acc 0.8650
11:58:46.621   Training iter 100, batch loss 0.3303, batch acc 0.8656
11:58:48.897   Training iter 150, batch loss 0.3035, batch acc 0.8774
11:58:51.168   Training iter 200, batch loss 0.3210, batch acc 0.8676
11:58:53.446   Training iter 250, batch loss 0.3188, batch acc 0.8722
11:58:55.794   Training iter 300, batch loss 0.3078, batch acc 0.8750
11:58:58.166   Training iter 350, batch loss 0.3188, batch acc 0.8708
11:59:00.534   Training iter 400, batch loss 0.3004, batch acc 0.8764
11:59:02.876   Training iter 450, batch loss 0.2983, batch acc 0.8784
11:59:05.273   Training iter 500, batch loss 0.3048, batch acc 0.8758
11:59:07.652   Training iter 550, batch loss 0.3367, batch acc 0.8642
11:59:09.945   Training iter 600, batch loss 0.3111, batch acc 0.8760
11:59:09.946 Training @ 304 epoch...
11:59:12.242   Training iter 50, batch loss 0.3080, batch acc 0.8748
11:59:14.560   Training iter 100, batch loss 0.3223, batch acc 0.8686
11:59:16.879   Training iter 150, batch loss 0.3138, batch acc 0.8726
11:59:19.183   Training iter 200, batch loss 0.3096, batch acc 0.8756
11:59:21.471   Training iter 250, batch loss 0.3017, batch acc 0.8770
11:59:23.750   Training iter 300, batch loss 0.3152, batch acc 0.8712
11:59:26.041   Training iter 350, batch loss 0.3351, batch acc 0.8630
11:59:28.332   Training iter 400, batch loss 0.2969, batch acc 0.8794
11:59:30.638   Training iter 450, batch loss 0.3128, batch acc 0.8732
11:59:32.938   Training iter 500, batch loss 0.3225, batch acc 0.8694
11:59:35.228   Training iter 550, batch loss 0.3083, batch acc 0.8750
11:59:37.514   Training iter 600, batch loss 0.3225, batch acc 0.8672
11:59:37.516 Training @ 305 epoch...
11:59:39.869   Training iter 50, batch loss 0.2982, batch acc 0.8792
11:59:42.376   Training iter 100, batch loss 0.3178, batch acc 0.8710
11:59:44.685   Training iter 150, batch loss 0.3400, batch acc 0.8648
11:59:47.012   Training iter 200, batch loss 0.3130, batch acc 0.8732
11:59:49.340   Training iter 250, batch loss 0.3149, batch acc 0.8708
11:59:51.641   Training iter 300, batch loss 0.3077, batch acc 0.8740
11:59:53.927   Training iter 350, batch loss 0.3048, batch acc 0.8742
11:59:56.214   Training iter 400, batch loss 0.3267, batch acc 0.8670
11:59:58.505   Training iter 450, batch loss 0.3129, batch acc 0.8706
12:00:00.809   Training iter 500, batch loss 0.3073, batch acc 0.8762
12:00:03.149   Training iter 550, batch loss 0.3130, batch acc 0.8718
12:00:05.480   Training iter 600, batch loss 0.3342, batch acc 0.8638
12:00:05.482 Testing @ 305 epoch...
12:00:05.534     Testing, total mean loss 0.40914, total acc 0.84790
12:00:05.534 Training @ 306 epoch...
12:00:07.877   Training iter 50, batch loss 0.3093, batch acc 0.8742
12:00:10.202   Training iter 100, batch loss 0.3130, batch acc 0.8736
12:00:12.550   Training iter 150, batch loss 0.3064, batch acc 0.8740
12:00:15.406   Training iter 200, batch loss 0.3178, batch acc 0.8722
12:00:17.741   Training iter 250, batch loss 0.3253, batch acc 0.8680
12:00:20.044   Training iter 300, batch loss 0.3185, batch acc 0.8694
12:00:22.345   Training iter 350, batch loss 0.3068, batch acc 0.8740
12:00:24.643   Training iter 400, batch loss 0.3138, batch acc 0.8708
12:00:26.982   Training iter 450, batch loss 0.3097, batch acc 0.8736
12:00:29.302   Training iter 500, batch loss 0.3303, batch acc 0.8634
12:00:31.676   Training iter 550, batch loss 0.3074, batch acc 0.8766
12:00:34.843   Training iter 600, batch loss 0.3262, batch acc 0.8686
12:00:34.845 Training @ 307 epoch...
12:00:37.155   Training iter 50, batch loss 0.3306, batch acc 0.8624
12:00:39.553   Training iter 100, batch loss 0.3121, batch acc 0.8690
12:00:41.927   Training iter 150, batch loss 0.3127, batch acc 0.8710
12:00:44.351   Training iter 200, batch loss 0.3313, batch acc 0.8650
12:00:46.673   Training iter 250, batch loss 0.3175, batch acc 0.8732
12:00:48.976   Training iter 300, batch loss 0.3029, batch acc 0.8786
12:00:51.296   Training iter 350, batch loss 0.2933, batch acc 0.8814
12:00:53.692   Training iter 400, batch loss 0.3081, batch acc 0.8772
12:00:56.048   Training iter 450, batch loss 0.3166, batch acc 0.8710
12:00:58.344   Training iter 500, batch loss 0.3403, batch acc 0.8628
12:01:00.640   Training iter 550, batch loss 0.3036, batch acc 0.8772
12:01:02.966   Training iter 600, batch loss 0.3218, batch acc 0.8664
12:01:02.968 Training @ 308 epoch...
12:01:05.279   Training iter 50, batch loss 0.3194, batch acc 0.8674
12:01:07.599   Training iter 100, batch loss 0.3176, batch acc 0.8704
12:01:10.018   Training iter 150, batch loss 0.3014, batch acc 0.8750
12:01:12.405   Training iter 200, batch loss 0.2956, batch acc 0.8768
12:01:14.770   Training iter 250, batch loss 0.3162, batch acc 0.8730
12:01:17.071   Training iter 300, batch loss 0.3116, batch acc 0.8726
12:01:19.512   Training iter 350, batch loss 0.3292, batch acc 0.8666
12:01:21.834   Training iter 400, batch loss 0.3116, batch acc 0.8736
12:01:24.116   Training iter 450, batch loss 0.3339, batch acc 0.8642
12:01:26.412   Training iter 500, batch loss 0.3086, batch acc 0.8750
12:01:28.873   Training iter 550, batch loss 0.3000, batch acc 0.8782
12:01:31.273   Training iter 600, batch loss 0.3375, batch acc 0.8622
12:01:31.274 Training @ 309 epoch...
12:01:33.607   Training iter 50, batch loss 0.2956, batch acc 0.8794
12:01:35.899   Training iter 100, batch loss 0.3110, batch acc 0.8732
12:01:38.203   Training iter 150, batch loss 0.3161, batch acc 0.8722
12:01:40.541   Training iter 200, batch loss 0.3138, batch acc 0.8702
12:01:42.870   Training iter 250, batch loss 0.3266, batch acc 0.8666
12:01:45.171   Training iter 300, batch loss 0.3030, batch acc 0.8776
12:01:47.449   Training iter 350, batch loss 0.3006, batch acc 0.8784
12:01:49.759   Training iter 400, batch loss 0.3279, batch acc 0.8674
12:01:52.081   Training iter 450, batch loss 0.2990, batch acc 0.8774
12:01:54.422   Training iter 500, batch loss 0.3170, batch acc 0.8726
12:01:56.735   Training iter 550, batch loss 0.3398, batch acc 0.8614
12:01:59.041   Training iter 600, batch loss 0.3289, batch acc 0.8666
12:01:59.043 Training @ 310 epoch...
12:02:01.357   Training iter 50, batch loss 0.3041, batch acc 0.8738
12:02:03.844   Training iter 100, batch loss 0.3260, batch acc 0.8680
12:02:06.281   Training iter 150, batch loss 0.3044, batch acc 0.8744
12:02:08.695   Training iter 200, batch loss 0.2987, batch acc 0.8784
12:02:11.079   Training iter 250, batch loss 0.2983, batch acc 0.8792
12:02:13.455   Training iter 300, batch loss 0.3098, batch acc 0.8720
12:02:15.809   Training iter 350, batch loss 0.3353, batch acc 0.8664
12:02:18.235   Training iter 400, batch loss 0.3135, batch acc 0.8714
12:02:20.593   Training iter 450, batch loss 0.3041, batch acc 0.8760
12:02:22.942   Training iter 500, batch loss 0.2896, batch acc 0.8828
12:02:25.382   Training iter 550, batch loss 0.3390, batch acc 0.8630
12:02:27.769   Training iter 600, batch loss 0.3421, batch acc 0.8610
12:02:27.770 Testing @ 310 epoch...
12:02:27.822     Testing, total mean loss 0.39362, total acc 0.85270
12:02:27.822 Training @ 311 epoch...
12:02:30.114   Training iter 50, batch loss 0.3225, batch acc 0.8690
12:02:32.443   Training iter 100, batch loss 0.3139, batch acc 0.8724
12:02:34.800   Training iter 150, batch loss 0.3116, batch acc 0.8716
12:02:37.229   Training iter 200, batch loss 0.3084, batch acc 0.8756
12:02:39.627   Training iter 250, batch loss 0.3093, batch acc 0.8742
12:02:42.188   Training iter 300, batch loss 0.3248, batch acc 0.8696
12:02:44.611   Training iter 350, batch loss 0.3157, batch acc 0.8700
12:02:47.244   Training iter 400, batch loss 0.3162, batch acc 0.8722
12:02:49.762   Training iter 450, batch loss 0.3264, batch acc 0.8684
12:02:52.102   Training iter 500, batch loss 0.3072, batch acc 0.8734
12:02:54.449   Training iter 550, batch loss 0.3087, batch acc 0.8742
12:02:56.871   Training iter 600, batch loss 0.3056, batch acc 0.8744
12:02:56.873 Training @ 312 epoch...
12:02:59.191   Training iter 50, batch loss 0.3130, batch acc 0.8718
12:03:01.603   Training iter 100, batch loss 0.2905, batch acc 0.8800
12:03:04.071   Training iter 150, batch loss 0.3148, batch acc 0.8728
12:03:06.380   Training iter 200, batch loss 0.3048, batch acc 0.8750
12:03:08.674   Training iter 250, batch loss 0.3301, batch acc 0.8662
12:03:10.962   Training iter 300, batch loss 0.3089, batch acc 0.8754
12:03:13.260   Training iter 350, batch loss 0.3282, batch acc 0.8662
12:03:15.559   Training iter 400, batch loss 0.3170, batch acc 0.8710
12:03:17.853   Training iter 450, batch loss 0.3041, batch acc 0.8770
12:03:20.144   Training iter 500, batch loss 0.3279, batch acc 0.8644
12:03:22.450   Training iter 550, batch loss 0.2983, batch acc 0.8804
12:03:24.736   Training iter 600, batch loss 0.3309, batch acc 0.8648
12:03:24.738 Training @ 313 epoch...
12:03:27.025   Training iter 50, batch loss 0.3314, batch acc 0.8638
12:03:29.310   Training iter 100, batch loss 0.3167, batch acc 0.8698
12:03:31.598   Training iter 150, batch loss 0.3040, batch acc 0.8770
12:03:33.901   Training iter 200, batch loss 0.3103, batch acc 0.8734
12:03:36.202   Training iter 250, batch loss 0.3207, batch acc 0.8690
12:03:38.492   Training iter 300, batch loss 0.3089, batch acc 0.8760
12:03:40.787   Training iter 350, batch loss 0.3249, batch acc 0.8672
12:03:43.074   Training iter 400, batch loss 0.3035, batch acc 0.8762
12:03:45.361   Training iter 450, batch loss 0.3163, batch acc 0.8708
12:03:47.686   Training iter 500, batch loss 0.3310, batch acc 0.8642
12:03:49.999   Training iter 550, batch loss 0.2952, batch acc 0.8796
12:03:52.299   Training iter 600, batch loss 0.3124, batch acc 0.8738
12:03:52.301 Training @ 314 epoch...
12:03:54.597   Training iter 50, batch loss 0.3167, batch acc 0.8722
12:03:56.874   Training iter 100, batch loss 0.3211, batch acc 0.8686
12:03:59.138   Training iter 150, batch loss 0.3196, batch acc 0.8702
12:04:01.499   Training iter 200, batch loss 0.3197, batch acc 0.8714
12:04:03.821   Training iter 250, batch loss 0.3095, batch acc 0.8744
12:04:06.159   Training iter 300, batch loss 0.3067, batch acc 0.8752
12:04:08.519   Training iter 350, batch loss 0.3130, batch acc 0.8732
12:04:10.862   Training iter 400, batch loss 0.3304, batch acc 0.8640
12:04:13.195   Training iter 450, batch loss 0.2969, batch acc 0.8786
12:04:15.521   Training iter 500, batch loss 0.3137, batch acc 0.8714
12:04:17.805   Training iter 550, batch loss 0.3171, batch acc 0.8714
12:04:20.085   Training iter 600, batch loss 0.3139, batch acc 0.8714
12:04:20.087 Training @ 315 epoch...
12:04:22.398   Training iter 50, batch loss 0.3110, batch acc 0.8734
12:04:24.734   Training iter 100, batch loss 0.3269, batch acc 0.8676
12:04:27.150   Training iter 150, batch loss 0.3128, batch acc 0.8716
12:04:29.488   Training iter 200, batch loss 0.3121, batch acc 0.8722
12:04:31.802   Training iter 250, batch loss 0.3130, batch acc 0.8744
12:04:34.116   Training iter 300, batch loss 0.3020, batch acc 0.8764
12:04:36.404   Training iter 350, batch loss 0.3134, batch acc 0.8704
12:04:38.831   Training iter 400, batch loss 0.3136, batch acc 0.8724
12:04:41.209   Training iter 450, batch loss 0.3331, batch acc 0.8620
12:04:43.500   Training iter 500, batch loss 0.3135, batch acc 0.8714
12:04:45.795   Training iter 550, batch loss 0.3012, batch acc 0.8790
12:04:48.119   Training iter 600, batch loss 0.3246, batch acc 0.8670
12:04:48.120 Testing @ 315 epoch...
12:04:48.173     Testing, total mean loss 0.41402, total acc 0.84800
12:04:48.173 Training @ 316 epoch...
12:04:50.470   Training iter 50, batch loss 0.3080, batch acc 0.8768
12:04:52.780   Training iter 100, batch loss 0.3211, batch acc 0.8708
12:04:55.105   Training iter 150, batch loss 0.3038, batch acc 0.8780
12:04:57.420   Training iter 200, batch loss 0.3261, batch acc 0.8680
12:04:59.716   Training iter 250, batch loss 0.3176, batch acc 0.8712
12:05:02.031   Training iter 300, batch loss 0.3329, batch acc 0.8628
12:05:04.338   Training iter 350, batch loss 0.3199, batch acc 0.8682
12:05:06.668   Training iter 400, batch loss 0.3002, batch acc 0.8776
12:05:09.059   Training iter 450, batch loss 0.3128, batch acc 0.8720
12:05:11.622   Training iter 500, batch loss 0.3134, batch acc 0.8726
12:05:13.910   Training iter 550, batch loss 0.3079, batch acc 0.8738
12:05:16.191   Training iter 600, batch loss 0.3181, batch acc 0.8676
12:05:16.193 Training @ 317 epoch...
12:05:18.472   Training iter 50, batch loss 0.3079, batch acc 0.8752
12:05:20.760   Training iter 100, batch loss 0.3270, batch acc 0.8690
12:05:23.053   Training iter 150, batch loss 0.3315, batch acc 0.8654
12:05:25.427   Training iter 200, batch loss 0.3292, batch acc 0.8676
12:05:27.779   Training iter 250, batch loss 0.3030, batch acc 0.8756
12:05:30.084   Training iter 300, batch loss 0.3125, batch acc 0.8704
12:05:32.398   Training iter 350, batch loss 0.3235, batch acc 0.8654
12:05:34.788   Training iter 400, batch loss 0.2894, batch acc 0.8826
12:05:37.222   Training iter 450, batch loss 0.2995, batch acc 0.8802
12:05:39.644   Training iter 500, batch loss 0.3168, batch acc 0.8710
12:05:42.023   Training iter 550, batch loss 0.3186, batch acc 0.8700
12:05:44.429   Training iter 600, batch loss 0.3190, batch acc 0.8682
12:05:44.431 Training @ 318 epoch...
12:05:46.762   Training iter 50, batch loss 0.3291, batch acc 0.8658
12:05:49.060   Training iter 100, batch loss 0.3044, batch acc 0.8762
12:05:51.361   Training iter 150, batch loss 0.3175, batch acc 0.8690
12:05:53.666   Training iter 200, batch loss 0.3083, batch acc 0.8754
12:05:55.966   Training iter 250, batch loss 0.3161, batch acc 0.8714
12:05:58.269   Training iter 300, batch loss 0.3113, batch acc 0.8752
12:06:00.566   Training iter 350, batch loss 0.3230, batch acc 0.8678
12:06:03.064   Training iter 400, batch loss 0.3157, batch acc 0.8708
12:06:05.412   Training iter 450, batch loss 0.3036, batch acc 0.8762
12:06:07.762   Training iter 500, batch loss 0.3222, batch acc 0.8686
12:06:10.079   Training iter 550, batch loss 0.3051, batch acc 0.8760
12:06:12.422   Training iter 600, batch loss 0.3131, batch acc 0.8734
12:06:12.423 Training @ 319 epoch...
12:06:14.787   Training iter 50, batch loss 0.3065, batch acc 0.8762
12:06:17.117   Training iter 100, batch loss 0.3109, batch acc 0.8736
12:06:19.435   Training iter 150, batch loss 0.2974, batch acc 0.8776
12:06:21.734   Training iter 200, batch loss 0.3056, batch acc 0.8762
12:06:24.026   Training iter 250, batch loss 0.3086, batch acc 0.8742
12:06:26.325   Training iter 300, batch loss 0.3229, batch acc 0.8670
12:06:28.638   Training iter 350, batch loss 0.3005, batch acc 0.8782
12:06:31.093   Training iter 400, batch loss 0.3025, batch acc 0.8768
12:06:33.555   Training iter 450, batch loss 0.3209, batch acc 0.8678
12:06:35.962   Training iter 500, batch loss 0.3348, batch acc 0.8632
12:06:38.492   Training iter 550, batch loss 0.3263, batch acc 0.8672
12:06:41.020   Training iter 600, batch loss 0.3360, batch acc 0.8618
12:06:41.022 Training @ 320 epoch...
12:06:43.520   Training iter 50, batch loss 0.3019, batch acc 0.8766
12:06:46.052   Training iter 100, batch loss 0.3333, batch acc 0.8640
12:06:48.577   Training iter 150, batch loss 0.3112, batch acc 0.8730
12:06:51.080   Training iter 200, batch loss 0.3014, batch acc 0.8780
12:06:53.577   Training iter 250, batch loss 0.3228, batch acc 0.8680
12:06:56.108   Training iter 300, batch loss 0.3078, batch acc 0.8742
12:06:58.638   Training iter 350, batch loss 0.3079, batch acc 0.8752
12:07:00.943   Training iter 400, batch loss 0.3221, batch acc 0.8694
12:07:03.273   Training iter 450, batch loss 0.3430, batch acc 0.8598
12:07:05.596   Training iter 500, batch loss 0.3021, batch acc 0.8762
12:07:07.915   Training iter 550, batch loss 0.3119, batch acc 0.8726
12:07:10.204   Training iter 600, batch loss 0.3238, batch acc 0.8680
12:07:10.206 Testing @ 320 epoch...
12:07:10.259     Testing, total mean loss 0.39580, total acc 0.84980
12:07:10.259 Training @ 321 epoch...
12:07:12.563   Training iter 50, batch loss 0.2926, batch acc 0.8798
12:07:14.873   Training iter 100, batch loss 0.3083, batch acc 0.8726
12:07:17.183   Training iter 150, batch loss 0.3092, batch acc 0.8742
12:07:19.508   Training iter 200, batch loss 0.3054, batch acc 0.8762
12:07:21.831   Training iter 250, batch loss 0.3116, batch acc 0.8738
12:07:24.141   Training iter 300, batch loss 0.3226, batch acc 0.8708
12:07:26.439   Training iter 350, batch loss 0.3241, batch acc 0.8674
12:07:28.742   Training iter 400, batch loss 0.3169, batch acc 0.8682
12:07:31.045   Training iter 450, batch loss 0.3238, batch acc 0.8682
12:07:33.352   Training iter 500, batch loss 0.3168, batch acc 0.8690
12:07:35.662   Training iter 550, batch loss 0.3235, batch acc 0.8674
12:07:37.981   Training iter 600, batch loss 0.3182, batch acc 0.8704
12:07:37.982 Training @ 322 epoch...
12:07:40.306   Training iter 50, batch loss 0.2880, batch acc 0.8818
12:07:42.611   Training iter 100, batch loss 0.3095, batch acc 0.8748
12:07:44.901   Training iter 150, batch loss 0.3236, batch acc 0.8670
12:07:47.205   Training iter 200, batch loss 0.3234, batch acc 0.8656
12:07:49.504   Training iter 250, batch loss 0.3138, batch acc 0.8720
12:07:51.815   Training iter 300, batch loss 0.3086, batch acc 0.8720
12:07:54.153   Training iter 350, batch loss 0.3034, batch acc 0.8770
12:07:56.479   Training iter 400, batch loss 0.3161, batch acc 0.8714
12:07:58.794   Training iter 450, batch loss 0.3074, batch acc 0.8768
12:08:01.108   Training iter 500, batch loss 0.3131, batch acc 0.8696
12:08:03.429   Training iter 550, batch loss 0.3288, batch acc 0.8656
12:08:05.743   Training iter 600, batch loss 0.3280, batch acc 0.8662
12:08:05.745 Training @ 323 epoch...
12:08:08.056   Training iter 50, batch loss 0.3265, batch acc 0.8648
12:08:10.350   Training iter 100, batch loss 0.3239, batch acc 0.8686
12:08:12.633   Training iter 150, batch loss 0.3227, batch acc 0.8686
12:08:14.909   Training iter 200, batch loss 0.2979, batch acc 0.8780
12:08:17.195   Training iter 250, batch loss 0.3037, batch acc 0.8792
12:08:19.563   Training iter 300, batch loss 0.3273, batch acc 0.8640
12:08:21.940   Training iter 350, batch loss 0.3110, batch acc 0.8728
12:08:24.258   Training iter 400, batch loss 0.3149, batch acc 0.8728
12:08:26.569   Training iter 450, batch loss 0.3214, batch acc 0.8688
12:08:28.872   Training iter 500, batch loss 0.3032, batch acc 0.8758
12:08:31.172   Training iter 550, batch loss 0.3100, batch acc 0.8732
12:08:33.462   Training iter 600, batch loss 0.3075, batch acc 0.8758
12:08:33.464 Training @ 324 epoch...
12:08:35.745   Training iter 50, batch loss 0.2972, batch acc 0.8796
12:08:38.071   Training iter 100, batch loss 0.3081, batch acc 0.8736
12:08:40.855   Training iter 150, batch loss 0.3120, batch acc 0.8720
12:08:43.164   Training iter 200, batch loss 0.3040, batch acc 0.8752
12:08:45.456   Training iter 250, batch loss 0.3143, batch acc 0.8694
12:08:47.751   Training iter 300, batch loss 0.3335, batch acc 0.8632
12:08:50.049   Training iter 350, batch loss 0.3011, batch acc 0.8770
12:08:52.350   Training iter 400, batch loss 0.3181, batch acc 0.8688
12:08:54.656   Training iter 450, batch loss 0.3254, batch acc 0.8658
12:08:56.962   Training iter 500, batch loss 0.3125, batch acc 0.8722
12:08:59.262   Training iter 550, batch loss 0.3310, batch acc 0.8646
12:09:01.574   Training iter 600, batch loss 0.3226, batch acc 0.8698
12:09:01.576 Training @ 325 epoch...
12:09:03.897   Training iter 50, batch loss 0.2950, batch acc 0.8802
12:09:06.201   Training iter 100, batch loss 0.3022, batch acc 0.8764
12:09:08.493   Training iter 150, batch loss 0.3253, batch acc 0.8686
12:09:10.791   Training iter 200, batch loss 0.3228, batch acc 0.8686
12:09:13.086   Training iter 250, batch loss 0.3283, batch acc 0.8676
12:09:15.383   Training iter 300, batch loss 0.3113, batch acc 0.8742
12:09:17.687   Training iter 350, batch loss 0.3057, batch acc 0.8740
12:09:19.994   Training iter 400, batch loss 0.3279, batch acc 0.8674
12:09:22.268   Training iter 450, batch loss 0.3111, batch acc 0.8714
12:09:24.542   Training iter 500, batch loss 0.3118, batch acc 0.8742
12:09:26.825   Training iter 550, batch loss 0.3162, batch acc 0.8718
12:09:29.118   Training iter 600, batch loss 0.3139, batch acc 0.8738
12:09:29.120 Testing @ 325 epoch...
12:09:29.171     Testing, total mean loss 0.40510, total acc 0.85010
12:09:29.171 Training @ 326 epoch...
12:09:31.472   Training iter 50, batch loss 0.3046, batch acc 0.8778
12:09:33.764   Training iter 100, batch loss 0.3117, batch acc 0.8736
12:09:36.047   Training iter 150, batch loss 0.3004, batch acc 0.8786
12:09:38.328   Training iter 200, batch loss 0.3272, batch acc 0.8658
12:09:40.588   Training iter 250, batch loss 0.3022, batch acc 0.8766
12:09:42.853   Training iter 300, batch loss 0.3152, batch acc 0.8732
12:09:45.125   Training iter 350, batch loss 0.3124, batch acc 0.8714
12:09:47.402   Training iter 400, batch loss 0.3145, batch acc 0.8720
12:09:49.695   Training iter 450, batch loss 0.3239, batch acc 0.8708
12:09:51.939   Training iter 500, batch loss 0.3444, batch acc 0.8576
12:09:54.194   Training iter 550, batch loss 0.3041, batch acc 0.8744
12:09:56.485   Training iter 600, batch loss 0.3168, batch acc 0.8692
12:09:56.487 Training @ 327 epoch...
12:09:58.792   Training iter 50, batch loss 0.3023, batch acc 0.8740
12:10:01.140   Training iter 100, batch loss 0.3127, batch acc 0.8728
12:10:03.451   Training iter 150, batch loss 0.3001, batch acc 0.8778
12:10:05.738   Training iter 200, batch loss 0.3134, batch acc 0.8740
12:10:08.018   Training iter 250, batch loss 0.3091, batch acc 0.8746
12:10:10.294   Training iter 300, batch loss 0.3227, batch acc 0.8702
12:10:12.583   Training iter 350, batch loss 0.3264, batch acc 0.8658
12:10:14.878   Training iter 400, batch loss 0.3156, batch acc 0.8718
12:10:17.174   Training iter 450, batch loss 0.3322, batch acc 0.8652
12:10:19.460   Training iter 500, batch loss 0.3061, batch acc 0.8750
12:10:21.745   Training iter 550, batch loss 0.3289, batch acc 0.8658
12:10:24.019   Training iter 600, batch loss 0.3104, batch acc 0.8730
12:10:24.021 Training @ 328 epoch...
12:10:26.291   Training iter 50, batch loss 0.3068, batch acc 0.8762
12:10:28.553   Training iter 100, batch loss 0.3110, batch acc 0.8752
12:10:30.818   Training iter 150, batch loss 0.3232, batch acc 0.8682
12:10:33.083   Training iter 200, batch loss 0.3218, batch acc 0.8692
12:10:35.361   Training iter 250, batch loss 0.3082, batch acc 0.8752
12:10:37.637   Training iter 300, batch loss 0.3234, batch acc 0.8690
12:10:39.910   Training iter 350, batch loss 0.3025, batch acc 0.8750
12:10:42.182   Training iter 400, batch loss 0.2982, batch acc 0.8786
12:10:44.450   Training iter 450, batch loss 0.3030, batch acc 0.8762
12:10:46.758   Training iter 500, batch loss 0.3405, batch acc 0.8594
12:10:49.072   Training iter 550, batch loss 0.3150, batch acc 0.8712
12:10:51.341   Training iter 600, batch loss 0.3167, batch acc 0.8690
12:10:51.343 Training @ 329 epoch...
12:10:53.614   Training iter 50, batch loss 0.3111, batch acc 0.8730
12:10:55.883   Training iter 100, batch loss 0.2986, batch acc 0.8790
12:10:58.165   Training iter 150, batch loss 0.3186, batch acc 0.8690
12:11:00.460   Training iter 200, batch loss 0.3035, batch acc 0.8804
12:11:02.745   Training iter 250, batch loss 0.3222, batch acc 0.8694
12:11:05.021   Training iter 300, batch loss 0.3089, batch acc 0.8744
12:11:07.306   Training iter 350, batch loss 0.3234, batch acc 0.8666
12:11:09.654   Training iter 400, batch loss 0.3244, batch acc 0.8664
12:11:11.948   Training iter 450, batch loss 0.3086, batch acc 0.8742
12:11:14.237   Training iter 500, batch loss 0.3144, batch acc 0.8712
12:11:16.545   Training iter 550, batch loss 0.3194, batch acc 0.8698
12:11:18.860   Training iter 600, batch loss 0.3165, batch acc 0.8694
12:11:18.862 Training @ 330 epoch...
12:11:21.140   Training iter 50, batch loss 0.3089, batch acc 0.8744
12:11:23.411   Training iter 100, batch loss 0.3027, batch acc 0.8768
12:11:25.682   Training iter 150, batch loss 0.3248, batch acc 0.8666
12:11:27.951   Training iter 200, batch loss 0.2998, batch acc 0.8794
12:11:30.272   Training iter 250, batch loss 0.3014, batch acc 0.8770
12:11:32.717   Training iter 300, batch loss 0.3243, batch acc 0.8680
12:11:35.005   Training iter 350, batch loss 0.3195, batch acc 0.8700
12:11:37.268   Training iter 400, batch loss 0.3223, batch acc 0.8672
12:11:39.535   Training iter 450, batch loss 0.3252, batch acc 0.8668
12:11:41.828   Training iter 500, batch loss 0.3040, batch acc 0.8754
12:11:44.146   Training iter 550, batch loss 0.3240, batch acc 0.8698
12:11:46.391   Training iter 600, batch loss 0.3141, batch acc 0.8720
12:11:46.393 Testing @ 330 epoch...
12:11:46.443     Testing, total mean loss 0.40191, total acc 0.84910
12:11:46.443 Training @ 331 epoch...
12:11:48.689   Training iter 50, batch loss 0.3277, batch acc 0.8654
12:11:50.934   Training iter 100, batch loss 0.3055, batch acc 0.8764
12:11:53.182   Training iter 150, batch loss 0.3169, batch acc 0.8686
12:11:55.445   Training iter 200, batch loss 0.3059, batch acc 0.8740
12:11:57.720   Training iter 250, batch loss 0.3157, batch acc 0.8728
12:11:59.993   Training iter 300, batch loss 0.3061, batch acc 0.8770
12:12:02.265   Training iter 350, batch loss 0.3156, batch acc 0.8714
12:12:04.539   Training iter 400, batch loss 0.3134, batch acc 0.8706
12:12:06.805   Training iter 450, batch loss 0.3112, batch acc 0.8744
12:12:09.073   Training iter 500, batch loss 0.3242, batch acc 0.8664
12:12:11.343   Training iter 550, batch loss 0.3175, batch acc 0.8708
12:12:13.645   Training iter 600, batch loss 0.3180, batch acc 0.8700
12:12:13.647 Training @ 332 epoch...
12:12:15.919   Training iter 50, batch loss 0.3165, batch acc 0.8704
12:12:18.191   Training iter 100, batch loss 0.3022, batch acc 0.8792
12:12:20.439   Training iter 150, batch loss 0.3152, batch acc 0.8722
12:12:22.688   Training iter 200, batch loss 0.3023, batch acc 0.8762
12:12:24.958   Training iter 250, batch loss 0.3176, batch acc 0.8700
12:12:27.238   Training iter 300, batch loss 0.3118, batch acc 0.8722
12:12:29.592   Training iter 350, batch loss 0.3192, batch acc 0.8706
12:12:31.873   Training iter 400, batch loss 0.3311, batch acc 0.8656
12:12:34.143   Training iter 450, batch loss 0.3082, batch acc 0.8736
12:12:36.406   Training iter 500, batch loss 0.3246, batch acc 0.8674
12:12:38.675   Training iter 550, batch loss 0.3038, batch acc 0.8768
12:12:40.939   Training iter 600, batch loss 0.3167, batch acc 0.8716
12:12:40.941 Training @ 333 epoch...
12:12:43.219   Training iter 50, batch loss 0.3186, batch acc 0.8704
12:12:45.512   Training iter 100, batch loss 0.3135, batch acc 0.8708
12:12:47.807   Training iter 150, batch loss 0.3086, batch acc 0.8742
12:12:50.129   Training iter 200, batch loss 0.3270, batch acc 0.8656
12:12:52.456   Training iter 250, batch loss 0.3028, batch acc 0.8746
12:12:54.796   Training iter 300, batch loss 0.3037, batch acc 0.8766
12:12:57.105   Training iter 350, batch loss 0.3025, batch acc 0.8784
12:12:59.372   Training iter 400, batch loss 0.2971, batch acc 0.8790
12:13:01.628   Training iter 450, batch loss 0.3385, batch acc 0.8640
12:13:03.915   Training iter 500, batch loss 0.2991, batch acc 0.8792
12:13:06.189   Training iter 550, batch loss 0.3034, batch acc 0.8744
12:13:08.458   Training iter 600, batch loss 0.3440, batch acc 0.8590
12:13:08.459 Training @ 334 epoch...
12:13:10.728   Training iter 50, batch loss 0.3235, batch acc 0.8684
12:13:12.995   Training iter 100, batch loss 0.3105, batch acc 0.8726
12:13:15.261   Training iter 150, batch loss 0.3161, batch acc 0.8720
12:13:17.537   Training iter 200, batch loss 0.3032, batch acc 0.8750
12:13:19.805   Training iter 250, batch loss 0.3428, batch acc 0.8600
12:13:22.062   Training iter 300, batch loss 0.3221, batch acc 0.8688
12:13:24.329   Training iter 350, batch loss 0.3124, batch acc 0.8740
12:13:26.591   Training iter 400, batch loss 0.3116, batch acc 0.8734
12:13:28.840   Training iter 450, batch loss 0.2953, batch acc 0.8808
12:13:31.101   Training iter 500, batch loss 0.3275, batch acc 0.8658
12:13:33.381   Training iter 550, batch loss 0.2948, batch acc 0.8790
12:13:35.660   Training iter 600, batch loss 0.3093, batch acc 0.8720
12:13:35.662 Training @ 335 epoch...
12:13:37.942   Training iter 50, batch loss 0.3248, batch acc 0.8662
12:13:40.211   Training iter 100, batch loss 0.3057, batch acc 0.8756
12:13:42.476   Training iter 150, batch loss 0.3126, batch acc 0.8724
12:13:44.737   Training iter 200, batch loss 0.3190, batch acc 0.8700
12:13:47.052   Training iter 250, batch loss 0.3210, batch acc 0.8692
12:13:49.368   Training iter 300, batch loss 0.3090, batch acc 0.8734
12:13:51.680   Training iter 350, batch loss 0.3110, batch acc 0.8730
12:13:53.980   Training iter 400, batch loss 0.3119, batch acc 0.8744
12:13:56.335   Training iter 450, batch loss 0.3241, batch acc 0.8660
12:13:58.579   Training iter 500, batch loss 0.3052, batch acc 0.8768
12:14:00.830   Training iter 550, batch loss 0.3093, batch acc 0.8734
12:14:03.140   Training iter 600, batch loss 0.3130, batch acc 0.8722
12:14:03.142 Testing @ 335 epoch...
12:14:03.192     Testing, total mean loss 0.39615, total acc 0.85240
12:14:03.193 Training @ 336 epoch...
12:14:05.559   Training iter 50, batch loss 0.2998, batch acc 0.8772
12:14:07.863   Training iter 100, batch loss 0.3292, batch acc 0.8658
12:14:10.131   Training iter 150, batch loss 0.3123, batch acc 0.8708
12:14:12.423   Training iter 200, batch loss 0.3177, batch acc 0.8718
12:14:14.713   Training iter 250, batch loss 0.3267, batch acc 0.8670
12:14:17.075   Training iter 300, batch loss 0.3148, batch acc 0.8730
12:14:19.358   Training iter 350, batch loss 0.3031, batch acc 0.8770
12:14:21.640   Training iter 400, batch loss 0.3149, batch acc 0.8744
12:14:23.897   Training iter 450, batch loss 0.3160, batch acc 0.8708
12:14:26.220   Training iter 500, batch loss 0.3094, batch acc 0.8736
12:14:28.530   Training iter 550, batch loss 0.3305, batch acc 0.8656
12:14:30.817   Training iter 600, batch loss 0.2888, batch acc 0.8814
12:14:30.819 Training @ 337 epoch...
12:14:33.141   Training iter 50, batch loss 0.3183, batch acc 0.8702
12:14:35.440   Training iter 100, batch loss 0.3170, batch acc 0.8722
12:14:37.742   Training iter 150, batch loss 0.3140, batch acc 0.8720
12:14:40.049   Training iter 200, batch loss 0.3082, batch acc 0.8736
12:14:42.351   Training iter 250, batch loss 0.3089, batch acc 0.8748
12:14:44.635   Training iter 300, batch loss 0.2993, batch acc 0.8770
12:14:46.918   Training iter 350, batch loss 0.3182, batch acc 0.8694
12:14:49.225   Training iter 400, batch loss 0.3124, batch acc 0.8724
12:14:51.570   Training iter 450, batch loss 0.3187, batch acc 0.8714
12:14:53.904   Training iter 500, batch loss 0.3057, batch acc 0.8744
12:14:56.241   Training iter 550, batch loss 0.3224, batch acc 0.8686
12:14:58.651   Training iter 600, batch loss 0.3204, batch acc 0.8698
12:14:58.653 Training @ 338 epoch...
12:15:01.021   Training iter 50, batch loss 0.3034, batch acc 0.8750
12:15:03.326   Training iter 100, batch loss 0.2978, batch acc 0.8774
12:15:05.596   Training iter 150, batch loss 0.2868, batch acc 0.8860
12:15:07.860   Training iter 200, batch loss 0.3238, batch acc 0.8682
12:15:10.178   Training iter 250, batch loss 0.3161, batch acc 0.8714
12:15:12.496   Training iter 300, batch loss 0.3100, batch acc 0.8734
12:15:14.846   Training iter 350, batch loss 0.3324, batch acc 0.8652
12:15:17.162   Training iter 400, batch loss 0.3112, batch acc 0.8740
12:15:19.471   Training iter 450, batch loss 0.3004, batch acc 0.8772
12:15:21.769   Training iter 500, batch loss 0.3394, batch acc 0.8618
12:15:24.019   Training iter 550, batch loss 0.3141, batch acc 0.8706
12:15:26.331   Training iter 600, batch loss 0.3247, batch acc 0.8680
12:15:26.333 Training @ 339 epoch...
12:15:28.753   Training iter 50, batch loss 0.2988, batch acc 0.8760
12:15:31.067   Training iter 100, batch loss 0.3094, batch acc 0.8716
12:15:33.327   Training iter 150, batch loss 0.3219, batch acc 0.8690
12:15:35.616   Training iter 200, batch loss 0.3271, batch acc 0.8688
12:15:37.892   Training iter 250, batch loss 0.3157, batch acc 0.8730
12:15:40.216   Training iter 300, batch loss 0.3110, batch acc 0.8726
12:15:42.519   Training iter 350, batch loss 0.3064, batch acc 0.8760
12:15:44.826   Training iter 400, batch loss 0.3255, batch acc 0.8670
12:15:47.075   Training iter 450, batch loss 0.2958, batch acc 0.8788
12:15:49.351   Training iter 500, batch loss 0.3192, batch acc 0.8700
12:15:51.563   Training iter 550, batch loss 0.3117, batch acc 0.8720
12:15:53.774   Training iter 600, batch loss 0.3114, batch acc 0.8732
12:15:53.775 Training @ 340 epoch...
12:15:56.006   Training iter 50, batch loss 0.3077, batch acc 0.8742
12:15:58.259   Training iter 100, batch loss 0.3119, batch acc 0.8726
12:16:00.488   Training iter 150, batch loss 0.2913, batch acc 0.8806
12:16:02.764   Training iter 200, batch loss 0.3032, batch acc 0.8770
12:16:05.007   Training iter 250, batch loss 0.3178, batch acc 0.8688
12:16:07.233   Training iter 300, batch loss 0.3237, batch acc 0.8680
12:16:09.425   Training iter 350, batch loss 0.3391, batch acc 0.8612
12:16:11.634   Training iter 400, batch loss 0.3218, batch acc 0.8684
12:16:13.917   Training iter 450, batch loss 0.3093, batch acc 0.8752
12:16:16.180   Training iter 500, batch loss 0.3083, batch acc 0.8748
12:16:18.434   Training iter 550, batch loss 0.3106, batch acc 0.8758
12:16:20.682   Training iter 600, batch loss 0.3157, batch acc 0.8718
12:16:20.684 Testing @ 340 epoch...
12:16:20.735     Testing, total mean loss 0.39602, total acc 0.85300
12:16:20.735 Training @ 341 epoch...
12:16:22.983   Training iter 50, batch loss 0.3000, batch acc 0.8756
12:16:25.222   Training iter 100, batch loss 0.3145, batch acc 0.8714
12:16:27.500   Training iter 150, batch loss 0.3156, batch acc 0.8708
12:16:29.764   Training iter 200, batch loss 0.3230, batch acc 0.8686
12:16:32.045   Training iter 250, batch loss 0.3237, batch acc 0.8696
12:16:34.291   Training iter 300, batch loss 0.3122, batch acc 0.8732
12:16:36.531   Training iter 350, batch loss 0.3217, batch acc 0.8692
12:16:38.744   Training iter 400, batch loss 0.3079, batch acc 0.8748
12:16:40.988   Training iter 450, batch loss 0.3259, batch acc 0.8678
12:16:43.230   Training iter 500, batch loss 0.3046, batch acc 0.8744
12:16:45.475   Training iter 550, batch loss 0.3012, batch acc 0.8762
12:16:47.748   Training iter 600, batch loss 0.3200, batch acc 0.8702
12:16:47.750 Training @ 342 epoch...
12:16:50.027   Training iter 50, batch loss 0.2970, batch acc 0.8780
12:16:52.247   Training iter 100, batch loss 0.3307, batch acc 0.8630
12:16:54.529   Training iter 150, batch loss 0.3066, batch acc 0.8754
12:16:56.761   Training iter 200, batch loss 0.3306, batch acc 0.8664
12:16:59.001   Training iter 250, batch loss 0.3084, batch acc 0.8788
12:17:01.254   Training iter 300, batch loss 0.2976, batch acc 0.8786
12:17:03.549   Training iter 350, batch loss 0.3155, batch acc 0.8726
12:17:05.821   Training iter 400, batch loss 0.3105, batch acc 0.8720
12:17:08.083   Training iter 450, batch loss 0.3241, batch acc 0.8704
12:17:10.322   Training iter 500, batch loss 0.3167, batch acc 0.8716
12:17:12.551   Training iter 550, batch loss 0.3103, batch acc 0.8714
12:17:14.782   Training iter 600, batch loss 0.3237, batch acc 0.8682
12:17:14.783 Training @ 343 epoch...
12:17:17.007   Training iter 50, batch loss 0.3094, batch acc 0.8752
12:17:19.258   Training iter 100, batch loss 0.2970, batch acc 0.8780
12:17:21.492   Training iter 150, batch loss 0.3212, batch acc 0.8678
12:17:23.709   Training iter 200, batch loss 0.3093, batch acc 0.8736
12:17:25.931   Training iter 250, batch loss 0.3060, batch acc 0.8750
12:17:28.159   Training iter 300, batch loss 0.3359, batch acc 0.8628
12:17:30.382   Training iter 350, batch loss 0.3041, batch acc 0.8744
12:17:32.548   Training iter 400, batch loss 0.2890, batch acc 0.8840
12:17:34.743   Training iter 450, batch loss 0.3172, batch acc 0.8714
12:17:36.954   Training iter 500, batch loss 0.3293, batch acc 0.8654
12:17:39.152   Training iter 550, batch loss 0.3240, batch acc 0.8686
12:17:41.357   Training iter 600, batch loss 0.3219, batch acc 0.8706
12:17:41.359 Training @ 344 epoch...
12:17:43.700   Training iter 50, batch loss 0.3144, batch acc 0.8722
12:17:46.003   Training iter 100, batch loss 0.3042, batch acc 0.8740
12:17:48.365   Training iter 150, batch loss 0.3133, batch acc 0.8716
12:17:50.776   Training iter 200, batch loss 0.3185, batch acc 0.8702
12:17:53.194   Training iter 250, batch loss 0.3086, batch acc 0.8748
12:17:55.475   Training iter 300, batch loss 0.3173, batch acc 0.8722
12:17:57.774   Training iter 350, batch loss 0.3137, batch acc 0.8716
12:18:00.030   Training iter 400, batch loss 0.2981, batch acc 0.8768
12:18:02.357   Training iter 450, batch loss 0.3272, batch acc 0.8666
12:18:04.642   Training iter 500, batch loss 0.3167, batch acc 0.8724
12:18:06.936   Training iter 550, batch loss 0.3313, batch acc 0.8664
12:18:09.219   Training iter 600, batch loss 0.3110, batch acc 0.8726
12:18:09.220 Training @ 345 epoch...
12:18:11.497   Training iter 50, batch loss 0.3158, batch acc 0.8706
12:18:13.767   Training iter 100, batch loss 0.3164, batch acc 0.8702
12:18:16.024   Training iter 150, batch loss 0.3123, batch acc 0.8708
12:18:18.292   Training iter 200, batch loss 0.3199, batch acc 0.8710
12:18:20.551   Training iter 250, batch loss 0.3179, batch acc 0.8680
12:18:22.905   Training iter 300, batch loss 0.3163, batch acc 0.8708
12:18:25.584   Training iter 350, batch loss 0.3156, batch acc 0.8702
12:18:28.017   Training iter 400, batch loss 0.2930, batch acc 0.8820
12:18:30.269   Training iter 450, batch loss 0.3296, batch acc 0.8648
12:18:32.516   Training iter 500, batch loss 0.3127, batch acc 0.8718
12:18:34.753   Training iter 550, batch loss 0.3180, batch acc 0.8694
12:18:36.978   Training iter 600, batch loss 0.2967, batch acc 0.8816
12:18:36.980 Testing @ 345 epoch...
12:18:37.031     Testing, total mean loss 0.39510, total acc 0.85180
12:18:37.031 Training @ 346 epoch...
12:18:39.283   Training iter 50, batch loss 0.3179, batch acc 0.8702
12:18:41.529   Training iter 100, batch loss 0.3185, batch acc 0.8692
12:18:43.778   Training iter 150, batch loss 0.3111, batch acc 0.8742
12:18:46.027   Training iter 200, batch loss 0.2991, batch acc 0.8786
12:18:48.266   Training iter 250, batch loss 0.3146, batch acc 0.8722
12:18:50.503   Training iter 300, batch loss 0.2956, batch acc 0.8782
12:18:52.754   Training iter 350, batch loss 0.3142, batch acc 0.8726
12:18:55.015   Training iter 400, batch loss 0.3095, batch acc 0.8744
12:18:57.288   Training iter 450, batch loss 0.3235, batch acc 0.8700
12:18:59.546   Training iter 500, batch loss 0.3312, batch acc 0.8660
12:19:01.784   Training iter 550, batch loss 0.2968, batch acc 0.8776
12:19:04.018   Training iter 600, batch loss 0.3255, batch acc 0.8682
12:19:04.019 Training @ 347 epoch...
12:19:06.264   Training iter 50, batch loss 0.3359, batch acc 0.8622
12:19:08.502   Training iter 100, batch loss 0.3110, batch acc 0.8748
12:19:10.754   Training iter 150, batch loss 0.3190, batch acc 0.8698
12:19:13.020   Training iter 200, batch loss 0.3077, batch acc 0.8744
12:19:15.283   Training iter 250, batch loss 0.3233, batch acc 0.8686
12:19:17.521   Training iter 300, batch loss 0.3195, batch acc 0.8706
12:19:19.742   Training iter 350, batch loss 0.3205, batch acc 0.8702
12:19:21.974   Training iter 400, batch loss 0.2969, batch acc 0.8774
12:19:24.228   Training iter 450, batch loss 0.3158, batch acc 0.8724
12:19:26.494   Training iter 500, batch loss 0.3116, batch acc 0.8746
12:19:28.763   Training iter 550, batch loss 0.3118, batch acc 0.8726
12:19:31.030   Training iter 600, batch loss 0.2933, batch acc 0.8808
12:19:31.033 Training @ 348 epoch...
12:19:33.375   Training iter 50, batch loss 0.3050, batch acc 0.8756
12:19:35.637   Training iter 100, batch loss 0.3066, batch acc 0.8754
12:19:37.894   Training iter 150, batch loss 0.3041, batch acc 0.8760
12:19:40.161   Training iter 200, batch loss 0.3170, batch acc 0.8720
12:19:42.448   Training iter 250, batch loss 0.3103, batch acc 0.8728
12:19:44.753   Training iter 300, batch loss 0.3180, batch acc 0.8714
12:19:47.113   Training iter 350, batch loss 0.3246, batch acc 0.8690
12:19:49.411   Training iter 400, batch loss 0.3067, batch acc 0.8768
12:19:51.703   Training iter 450, batch loss 0.3163, batch acc 0.8690
12:19:54.017   Training iter 500, batch loss 0.3239, batch acc 0.8672
12:19:56.413   Training iter 550, batch loss 0.3221, batch acc 0.8682
12:19:58.756   Training iter 600, batch loss 0.3116, batch acc 0.8722
12:19:58.758 Training @ 349 epoch...
12:20:01.116   Training iter 50, batch loss 0.3269, batch acc 0.8676
12:20:03.429   Training iter 100, batch loss 0.3189, batch acc 0.8712
12:20:05.794   Training iter 150, batch loss 0.3012, batch acc 0.8790
12:20:08.072   Training iter 200, batch loss 0.3107, batch acc 0.8732
12:20:10.356   Training iter 250, batch loss 0.3312, batch acc 0.8650
12:20:12.642   Training iter 300, batch loss 0.3037, batch acc 0.8762
12:20:14.919   Training iter 350, batch loss 0.3137, batch acc 0.8700
12:20:17.233   Training iter 400, batch loss 0.3200, batch acc 0.8692
12:20:19.540   Training iter 450, batch loss 0.3150, batch acc 0.8712
12:20:21.856   Training iter 500, batch loss 0.3008, batch acc 0.8758
12:20:24.171   Training iter 550, batch loss 0.3025, batch acc 0.8772
12:20:26.504   Training iter 600, batch loss 0.3083, batch acc 0.8756
12:20:26.506 Training @ 350 epoch...
12:20:28.822   Training iter 50, batch loss 0.3041, batch acc 0.8756
12:20:31.137   Training iter 100, batch loss 0.3125, batch acc 0.8720
12:20:33.426   Training iter 150, batch loss 0.3271, batch acc 0.8680
12:20:35.691   Training iter 200, batch loss 0.2990, batch acc 0.8784
12:20:37.961   Training iter 250, batch loss 0.3117, batch acc 0.8720
12:20:40.257   Training iter 300, batch loss 0.3223, batch acc 0.8682
12:20:42.577   Training iter 350, batch loss 0.3182, batch acc 0.8692
12:20:44.827   Training iter 400, batch loss 0.3196, batch acc 0.8714
12:20:47.087   Training iter 450, batch loss 0.3137, batch acc 0.8718
12:20:49.337   Training iter 500, batch loss 0.2895, batch acc 0.8820
12:20:51.586   Training iter 550, batch loss 0.3388, batch acc 0.8606
12:20:53.832   Training iter 600, batch loss 0.3082, batch acc 0.8748
12:20:53.834 Testing @ 350 epoch...
12:20:53.883     Testing, total mean loss 0.39475, total acc 0.85200
12:20:53.883 Training @ 351 epoch...
12:20:56.141   Training iter 50, batch loss 0.2997, batch acc 0.8790
12:20:58.384   Training iter 100, batch loss 0.3163, batch acc 0.8706
12:21:00.632   Training iter 150, batch loss 0.3086, batch acc 0.8732
12:21:02.964   Training iter 200, batch loss 0.3144, batch acc 0.8736
12:21:05.230   Training iter 250, batch loss 0.3293, batch acc 0.8646
12:21:07.497   Training iter 300, batch loss 0.3096, batch acc 0.8732
12:21:09.737   Training iter 350, batch loss 0.3099, batch acc 0.8748
12:21:11.954   Training iter 400, batch loss 0.3250, batch acc 0.8668
12:21:14.199   Training iter 450, batch loss 0.3077, batch acc 0.8756
12:21:16.447   Training iter 500, batch loss 0.3042, batch acc 0.8762
12:21:18.716   Training iter 550, batch loss 0.3137, batch acc 0.8720
12:21:21.059   Training iter 600, batch loss 0.3242, batch acc 0.8658
12:21:21.061 Training @ 352 epoch...
12:21:23.416   Training iter 50, batch loss 0.3179, batch acc 0.8712
12:21:25.746   Training iter 100, batch loss 0.3067, batch acc 0.8748
12:21:27.992   Training iter 150, batch loss 0.2966, batch acc 0.8792
12:21:30.244   Training iter 200, batch loss 0.3079, batch acc 0.8734
12:21:32.518   Training iter 250, batch loss 0.3280, batch acc 0.8706
12:21:34.786   Training iter 300, batch loss 0.3108, batch acc 0.8726
12:21:37.038   Training iter 350, batch loss 0.3184, batch acc 0.8704
12:21:39.349   Training iter 400, batch loss 0.3090, batch acc 0.8748
12:21:41.706   Training iter 450, batch loss 0.3232, batch acc 0.8670
12:21:44.143   Training iter 500, batch loss 0.3074, batch acc 0.8730
12:21:46.543   Training iter 550, batch loss 0.3073, batch acc 0.8742
12:21:48.902   Training iter 600, batch loss 0.3255, batch acc 0.8686
12:21:48.904 Training @ 353 epoch...
12:21:51.226   Training iter 50, batch loss 0.3186, batch acc 0.8686
12:21:53.546   Training iter 100, batch loss 0.3126, batch acc 0.8738
12:21:55.814   Training iter 150, batch loss 0.3079, batch acc 0.8732
12:21:58.075   Training iter 200, batch loss 0.3044, batch acc 0.8756
12:22:00.340   Training iter 250, batch loss 0.3049, batch acc 0.8768
12:22:02.651   Training iter 300, batch loss 0.2949, batch acc 0.8810
12:22:04.906   Training iter 350, batch loss 0.3244, batch acc 0.8674
12:22:07.184   Training iter 400, batch loss 0.3120, batch acc 0.8734
12:22:09.474   Training iter 450, batch loss 0.3128, batch acc 0.8726
12:22:11.790   Training iter 500, batch loss 0.3183, batch acc 0.8698
12:22:14.111   Training iter 550, batch loss 0.3301, batch acc 0.8656
12:22:16.374   Training iter 600, batch loss 0.3251, batch acc 0.8682
12:22:16.376 Training @ 354 epoch...
12:22:18.627   Training iter 50, batch loss 0.3027, batch acc 0.8760
12:22:20.906   Training iter 100, batch loss 0.3047, batch acc 0.8768
12:22:23.182   Training iter 150, batch loss 0.3219, batch acc 0.8668
12:22:25.443   Training iter 200, batch loss 0.3126, batch acc 0.8722
12:22:27.706   Training iter 250, batch loss 0.3048, batch acc 0.8774
12:22:29.979   Training iter 300, batch loss 0.3091, batch acc 0.8722
12:22:32.277   Training iter 350, batch loss 0.2961, batch acc 0.8770
12:22:34.628   Training iter 400, batch loss 0.3193, batch acc 0.8674
12:22:36.972   Training iter 450, batch loss 0.3225, batch acc 0.8700
12:22:39.320   Training iter 500, batch loss 0.3288, batch acc 0.8660
12:22:41.692   Training iter 550, batch loss 0.3213, batch acc 0.8680
12:22:44.078   Training iter 600, batch loss 0.3006, batch acc 0.8784
12:22:44.080 Training @ 355 epoch...
12:22:46.347   Training iter 50, batch loss 0.3137, batch acc 0.8706
12:22:48.609   Training iter 100, batch loss 0.3082, batch acc 0.8764
12:22:50.867   Training iter 150, batch loss 0.3159, batch acc 0.8710
12:22:53.131   Training iter 200, batch loss 0.3161, batch acc 0.8732
12:22:55.384   Training iter 250, batch loss 0.3067, batch acc 0.8732
12:22:57.640   Training iter 300, batch loss 0.3200, batch acc 0.8698
12:22:59.895   Training iter 350, batch loss 0.3162, batch acc 0.8702
12:23:02.167   Training iter 400, batch loss 0.3042, batch acc 0.8756
12:23:04.423   Training iter 450, batch loss 0.3181, batch acc 0.8706
12:23:06.663   Training iter 500, batch loss 0.2915, batch acc 0.8804
12:23:08.899   Training iter 550, batch loss 0.3094, batch acc 0.8708
12:23:11.197   Training iter 600, batch loss 0.3316, batch acc 0.8632
12:23:11.199 Testing @ 355 epoch...
12:23:11.252     Testing, total mean loss 0.41113, total acc 0.84830
12:23:11.252 Training @ 356 epoch...
12:23:13.555   Training iter 50, batch loss 0.3191, batch acc 0.8708
12:23:15.856   Training iter 100, batch loss 0.3125, batch acc 0.8726
12:23:18.181   Training iter 150, batch loss 0.3071, batch acc 0.8758
12:23:20.480   Training iter 200, batch loss 0.3099, batch acc 0.8742
12:23:22.802   Training iter 250, batch loss 0.3217, batch acc 0.8696
12:23:25.056   Training iter 300, batch loss 0.3116, batch acc 0.8746
12:23:27.311   Training iter 350, batch loss 0.3025, batch acc 0.8756
12:23:29.566   Training iter 400, batch loss 0.3293, batch acc 0.8650
12:23:31.834   Training iter 450, batch loss 0.3143, batch acc 0.8724
12:23:34.097   Training iter 500, batch loss 0.3007, batch acc 0.8766
12:23:36.361   Training iter 550, batch loss 0.3193, batch acc 0.8704
12:23:38.659   Training iter 600, batch loss 0.3016, batch acc 0.8776
12:23:38.660 Training @ 357 epoch...
12:23:40.955   Training iter 50, batch loss 0.3279, batch acc 0.8668
12:23:43.260   Training iter 100, batch loss 0.3075, batch acc 0.8750
12:23:45.545   Training iter 150, batch loss 0.3169, batch acc 0.8724
12:23:47.854   Training iter 200, batch loss 0.2978, batch acc 0.8778
12:23:50.169   Training iter 250, batch loss 0.2992, batch acc 0.8776
12:23:52.432   Training iter 300, batch loss 0.3212, batch acc 0.8680
12:23:54.666   Training iter 350, batch loss 0.3274, batch acc 0.8654
12:23:56.927   Training iter 400, batch loss 0.3034, batch acc 0.8744
12:23:59.515   Training iter 450, batch loss 0.3136, batch acc 0.8730
12:24:01.859   Training iter 500, batch loss 0.3022, batch acc 0.8760
12:24:04.129   Training iter 550, batch loss 0.3205, batch acc 0.8688
12:24:06.473   Training iter 600, batch loss 0.3233, batch acc 0.8702
12:24:06.475 Training @ 358 epoch...
12:24:08.785   Training iter 50, batch loss 0.3069, batch acc 0.8750
12:24:11.066   Training iter 100, batch loss 0.3106, batch acc 0.8720
12:24:13.337   Training iter 150, batch loss 0.3172, batch acc 0.8698
12:24:15.635   Training iter 200, batch loss 0.3031, batch acc 0.8760
12:24:17.898   Training iter 250, batch loss 0.3416, batch acc 0.8594
12:24:20.183   Training iter 300, batch loss 0.3005, batch acc 0.8770
12:24:22.515   Training iter 350, batch loss 0.3137, batch acc 0.8714
12:24:24.802   Training iter 400, batch loss 0.3091, batch acc 0.8736
12:24:27.050   Training iter 450, batch loss 0.3015, batch acc 0.8758
12:24:29.306   Training iter 500, batch loss 0.3281, batch acc 0.8658
12:24:31.551   Training iter 550, batch loss 0.3143, batch acc 0.8728
12:24:33.782   Training iter 600, batch loss 0.3021, batch acc 0.8778
12:24:33.784 Training @ 359 epoch...
12:24:36.044   Training iter 50, batch loss 0.3172, batch acc 0.8700
12:24:38.317   Training iter 100, batch loss 0.3137, batch acc 0.8708
12:24:40.659   Training iter 150, batch loss 0.3050, batch acc 0.8784
12:24:42.902   Training iter 200, batch loss 0.3148, batch acc 0.8714
12:24:45.138   Training iter 250, batch loss 0.3249, batch acc 0.8678
12:24:47.374   Training iter 300, batch loss 0.3220, batch acc 0.8680
12:24:49.625   Training iter 350, batch loss 0.2998, batch acc 0.8792
12:24:51.935   Training iter 400, batch loss 0.3015, batch acc 0.8780
12:24:54.206   Training iter 450, batch loss 0.3145, batch acc 0.8720
12:24:56.496   Training iter 500, batch loss 0.2952, batch acc 0.8796
12:24:58.788   Training iter 550, batch loss 0.3198, batch acc 0.8700
12:25:01.073   Training iter 600, batch loss 0.3216, batch acc 0.8702
12:25:01.075 Training @ 360 epoch...
12:25:03.405   Training iter 50, batch loss 0.3246, batch acc 0.8680
12:25:05.916   Training iter 100, batch loss 0.2955, batch acc 0.8806
12:25:08.277   Training iter 150, batch loss 0.3274, batch acc 0.8656
12:25:10.602   Training iter 200, batch loss 0.3078, batch acc 0.8742
12:25:12.929   Training iter 250, batch loss 0.3364, batch acc 0.8612
12:25:15.198   Training iter 300, batch loss 0.3101, batch acc 0.8738
12:25:17.488   Training iter 350, batch loss 0.2984, batch acc 0.8780
12:25:20.140   Training iter 400, batch loss 0.3102, batch acc 0.8718
12:25:22.386   Training iter 450, batch loss 0.3125, batch acc 0.8722
12:25:24.650   Training iter 500, batch loss 0.3044, batch acc 0.8756
12:25:26.919   Training iter 550, batch loss 0.3356, batch acc 0.8638
12:25:29.183   Training iter 600, batch loss 0.3011, batch acc 0.8778
12:25:29.185 Testing @ 360 epoch...
12:25:29.235     Testing, total mean loss 0.39071, total acc 0.85290
12:25:29.235 Training @ 361 epoch...
12:25:31.492   Training iter 50, batch loss 0.3304, batch acc 0.8638
12:25:33.741   Training iter 100, batch loss 0.3018, batch acc 0.8766
12:25:35.992   Training iter 150, batch loss 0.3245, batch acc 0.8680
12:25:38.244   Training iter 200, batch loss 0.3039, batch acc 0.8752
12:25:40.491   Training iter 250, batch loss 0.3084, batch acc 0.8754
12:25:42.743   Training iter 300, batch loss 0.3177, batch acc 0.8696
12:25:44.995   Training iter 350, batch loss 0.3072, batch acc 0.8752
12:25:47.226   Training iter 400, batch loss 0.3115, batch acc 0.8718
12:25:49.450   Training iter 450, batch loss 0.3187, batch acc 0.8692
12:25:51.686   Training iter 500, batch loss 0.3064, batch acc 0.8764
12:25:53.942   Training iter 550, batch loss 0.3061, batch acc 0.8770
12:25:56.219   Training iter 600, batch loss 0.3174, batch acc 0.8708
12:25:56.221 Training @ 362 epoch...
12:25:58.476   Training iter 50, batch loss 0.2992, batch acc 0.8786
12:26:00.734   Training iter 100, batch loss 0.3321, batch acc 0.8660
12:26:02.991   Training iter 150, batch loss 0.3193, batch acc 0.8696
12:26:05.241   Training iter 200, batch loss 0.3019, batch acc 0.8770
12:26:07.500   Training iter 250, batch loss 0.3152, batch acc 0.8728
12:26:09.743   Training iter 300, batch loss 0.2980, batch acc 0.8790
12:26:12.002   Training iter 350, batch loss 0.3192, batch acc 0.8680
12:26:14.269   Training iter 400, batch loss 0.3277, batch acc 0.8658
12:26:16.533   Training iter 450, batch loss 0.3197, batch acc 0.8692
12:26:18.791   Training iter 500, batch loss 0.3217, batch acc 0.8696
12:26:21.040   Training iter 550, batch loss 0.3149, batch acc 0.8728
12:26:23.307   Training iter 600, batch loss 0.2902, batch acc 0.8796
12:26:23.309 Training @ 363 epoch...
12:26:25.605   Training iter 50, batch loss 0.3080, batch acc 0.8740
12:26:27.862   Training iter 100, batch loss 0.3015, batch acc 0.8764
12:26:30.129   Training iter 150, batch loss 0.2983, batch acc 0.8764
12:26:32.393   Training iter 200, batch loss 0.3167, batch acc 0.8712
12:26:34.646   Training iter 250, batch loss 0.3017, batch acc 0.8798
12:26:36.895   Training iter 300, batch loss 0.3074, batch acc 0.8746
12:26:39.147   Training iter 350, batch loss 0.2918, batch acc 0.8818
12:26:41.391   Training iter 400, batch loss 0.3230, batch acc 0.8678
12:26:43.638   Training iter 450, batch loss 0.3255, batch acc 0.8690
12:26:45.886   Training iter 500, batch loss 0.3216, batch acc 0.8692
12:26:48.138   Training iter 550, batch loss 0.3254, batch acc 0.8670
12:26:50.401   Training iter 600, batch loss 0.3216, batch acc 0.8700
12:26:50.403 Training @ 364 epoch...
12:26:52.636   Training iter 50, batch loss 0.3042, batch acc 0.8786
12:26:54.889   Training iter 100, batch loss 0.3091, batch acc 0.8732
12:26:57.155   Training iter 150, batch loss 0.3052, batch acc 0.8760
12:26:59.432   Training iter 200, batch loss 0.3187, batch acc 0.8686
12:27:01.684   Training iter 250, batch loss 0.3065, batch acc 0.8746
12:27:03.992   Training iter 300, batch loss 0.3092, batch acc 0.8738
12:27:06.269   Training iter 350, batch loss 0.3084, batch acc 0.8738
12:27:08.515   Training iter 400, batch loss 0.3080, batch acc 0.8736
12:27:10.748   Training iter 450, batch loss 0.3432, batch acc 0.8610
12:27:13.023   Training iter 500, batch loss 0.3129, batch acc 0.8728
12:27:15.343   Training iter 550, batch loss 0.3085, batch acc 0.8714
12:27:17.704   Training iter 600, batch loss 0.3200, batch acc 0.8696
12:27:17.705 Training @ 365 epoch...
12:27:20.061   Training iter 50, batch loss 0.2962, batch acc 0.8788
12:27:22.408   Training iter 100, batch loss 0.3076, batch acc 0.8742
12:27:24.729   Training iter 150, batch loss 0.3248, batch acc 0.8674
12:27:27.049   Training iter 200, batch loss 0.3116, batch acc 0.8710
12:27:29.416   Training iter 250, batch loss 0.2993, batch acc 0.8774
12:27:31.760   Training iter 300, batch loss 0.3259, batch acc 0.8674
12:27:34.138   Training iter 350, batch loss 0.3085, batch acc 0.8754
12:27:36.512   Training iter 400, batch loss 0.2995, batch acc 0.8780
12:27:38.865   Training iter 450, batch loss 0.3145, batch acc 0.8712
12:27:41.206   Training iter 500, batch loss 0.3207, batch acc 0.8718
12:27:43.549   Training iter 550, batch loss 0.3313, batch acc 0.8684
12:27:45.847   Training iter 600, batch loss 0.3181, batch acc 0.8714
12:27:45.849 Testing @ 365 epoch...
12:27:45.899     Testing, total mean loss 0.39154, total acc 0.85180
12:27:45.899 Training @ 366 epoch...
12:27:48.243   Training iter 50, batch loss 0.2991, batch acc 0.8770
12:27:50.564   Training iter 100, batch loss 0.3166, batch acc 0.8720
12:27:52.835   Training iter 150, batch loss 0.3046, batch acc 0.8750
12:27:55.093   Training iter 200, batch loss 0.3108, batch acc 0.8738
12:27:57.341   Training iter 250, batch loss 0.3221, batch acc 0.8684
12:27:59.567   Training iter 300, batch loss 0.3211, batch acc 0.8700
12:28:01.813   Training iter 350, batch loss 0.3033, batch acc 0.8768
12:28:04.080   Training iter 400, batch loss 0.3062, batch acc 0.8762
12:28:06.354   Training iter 450, batch loss 0.3097, batch acc 0.8760
12:28:08.728   Training iter 500, batch loss 0.3266, batch acc 0.8678
12:28:11.107   Training iter 550, batch loss 0.3185, batch acc 0.8714
12:28:13.523   Training iter 600, batch loss 0.3171, batch acc 0.8726
12:28:13.525 Training @ 367 epoch...
12:28:15.889   Training iter 50, batch loss 0.3194, batch acc 0.8698
12:28:18.211   Training iter 100, batch loss 0.2991, batch acc 0.8776
12:28:20.463   Training iter 150, batch loss 0.3081, batch acc 0.8740
12:28:22.721   Training iter 200, batch loss 0.3202, batch acc 0.8684
12:28:24.971   Training iter 250, batch loss 0.3056, batch acc 0.8734
12:28:27.218   Training iter 300, batch loss 0.3186, batch acc 0.8696
12:28:29.471   Training iter 350, batch loss 0.3297, batch acc 0.8640
12:28:31.722   Training iter 400, batch loss 0.3152, batch acc 0.8714
12:28:33.969   Training iter 450, batch loss 0.3108, batch acc 0.8716
12:28:36.219   Training iter 500, batch loss 0.3120, batch acc 0.8718
12:28:38.471   Training iter 550, batch loss 0.3112, batch acc 0.8730
12:28:40.718   Training iter 600, batch loss 0.3072, batch acc 0.8744
12:28:40.720 Training @ 368 epoch...
12:28:42.985   Training iter 50, batch loss 0.3258, batch acc 0.8670
12:28:45.252   Training iter 100, batch loss 0.3107, batch acc 0.8746
12:28:47.481   Training iter 150, batch loss 0.3256, batch acc 0.8684
12:28:49.702   Training iter 200, batch loss 0.3081, batch acc 0.8748
12:28:51.929   Training iter 250, batch loss 0.3052, batch acc 0.8762
12:28:54.221   Training iter 300, batch loss 0.3114, batch acc 0.8736
12:28:56.682   Training iter 350, batch loss 0.3025, batch acc 0.8766
12:28:59.030   Training iter 400, batch loss 0.3138, batch acc 0.8710
12:29:01.343   Training iter 450, batch loss 0.3117, batch acc 0.8734
12:29:03.675   Training iter 500, batch loss 0.3195, batch acc 0.8656
12:29:06.019   Training iter 550, batch loss 0.3074, batch acc 0.8728
12:29:08.268   Training iter 600, batch loss 0.3160, batch acc 0.8710
12:29:08.270 Training @ 369 epoch...
12:29:10.537   Training iter 50, batch loss 0.3078, batch acc 0.8750
12:29:12.802   Training iter 100, batch loss 0.3019, batch acc 0.8786
12:29:15.127   Training iter 150, batch loss 0.3032, batch acc 0.8768
12:29:17.394   Training iter 200, batch loss 0.3206, batch acc 0.8688
12:29:19.639   Training iter 250, batch loss 0.3172, batch acc 0.8700
12:29:21.882   Training iter 300, batch loss 0.3400, batch acc 0.8616
12:29:24.168   Training iter 350, batch loss 0.3222, batch acc 0.8702
12:29:26.429   Training iter 400, batch loss 0.3154, batch acc 0.8736
12:29:28.741   Training iter 450, batch loss 0.3001, batch acc 0.8774
12:29:31.145   Training iter 500, batch loss 0.3124, batch acc 0.8708
12:29:33.557   Training iter 550, batch loss 0.3135, batch acc 0.8704
12:29:35.783   Training iter 600, batch loss 0.3009, batch acc 0.8804
12:29:35.785 Training @ 370 epoch...
12:29:38.028   Training iter 50, batch loss 0.3022, batch acc 0.8768
12:29:40.252   Training iter 100, batch loss 0.3184, batch acc 0.8714
12:29:42.499   Training iter 150, batch loss 0.2987, batch acc 0.8782
12:29:44.750   Training iter 200, batch loss 0.3306, batch acc 0.8672
12:29:47.006   Training iter 250, batch loss 0.3128, batch acc 0.8722
12:29:49.285   Training iter 300, batch loss 0.3162, batch acc 0.8720
12:29:51.547   Training iter 350, batch loss 0.3180, batch acc 0.8706
12:29:53.809   Training iter 400, batch loss 0.3128, batch acc 0.8704
12:29:56.054   Training iter 450, batch loss 0.3075, batch acc 0.8746
12:29:58.317   Training iter 500, batch loss 0.3151, batch acc 0.8712
12:30:00.633   Training iter 550, batch loss 0.3154, batch acc 0.8694
12:30:02.934   Training iter 600, batch loss 0.3050, batch acc 0.8764
12:30:02.936 Testing @ 370 epoch...
12:30:02.988     Testing, total mean loss 0.40058, total acc 0.85070
12:30:02.988 Training @ 371 epoch...
12:30:05.258   Training iter 50, batch loss 0.3145, batch acc 0.8712
12:30:07.520   Training iter 100, batch loss 0.3231, batch acc 0.8686
12:30:09.784   Training iter 150, batch loss 0.3056, batch acc 0.8748
12:30:12.147   Training iter 200, batch loss 0.3035, batch acc 0.8772
12:30:14.435   Training iter 250, batch loss 0.3146, batch acc 0.8730
12:30:16.720   Training iter 300, batch loss 0.3225, batch acc 0.8688
12:30:19.047   Training iter 350, batch loss 0.2976, batch acc 0.8766
12:30:21.356   Training iter 400, batch loss 0.3140, batch acc 0.8708
12:30:23.675   Training iter 450, batch loss 0.3230, batch acc 0.8684
12:30:26.102   Training iter 500, batch loss 0.3119, batch acc 0.8744
12:30:28.458   Training iter 550, batch loss 0.3200, batch acc 0.8700
12:30:30.714   Training iter 600, batch loss 0.3072, batch acc 0.8732
12:30:30.716 Training @ 372 epoch...
12:30:32.987   Training iter 50, batch loss 0.2966, batch acc 0.8772
12:30:35.259   Training iter 100, batch loss 0.2968, batch acc 0.8782
12:30:37.519   Training iter 150, batch loss 0.3114, batch acc 0.8738
12:30:39.764   Training iter 200, batch loss 0.3178, batch acc 0.8716
12:30:42.019   Training iter 250, batch loss 0.3216, batch acc 0.8702
12:30:44.270   Training iter 300, batch loss 0.3133, batch acc 0.8718
12:30:46.525   Training iter 350, batch loss 0.3154, batch acc 0.8706
12:30:48.777   Training iter 400, batch loss 0.3154, batch acc 0.8732
12:30:51.028   Training iter 450, batch loss 0.3148, batch acc 0.8694
12:30:53.273   Training iter 500, batch loss 0.3111, batch acc 0.8744
12:30:55.569   Training iter 550, batch loss 0.3165, batch acc 0.8698
12:30:57.849   Training iter 600, batch loss 0.3272, batch acc 0.8676
12:30:57.851 Training @ 373 epoch...
12:31:00.197   Training iter 50, batch loss 0.3066, batch acc 0.8744
12:31:02.699   Training iter 100, batch loss 0.2906, batch acc 0.8802
12:31:05.053   Training iter 150, batch loss 0.3050, batch acc 0.8754
12:31:07.397   Training iter 200, batch loss 0.3300, batch acc 0.8648
12:31:09.693   Training iter 250, batch loss 0.3128, batch acc 0.8750
12:31:11.990   Training iter 300, batch loss 0.3197, batch acc 0.8688
12:31:14.403   Training iter 350, batch loss 0.3152, batch acc 0.8722
12:31:16.850   Training iter 400, batch loss 0.3157, batch acc 0.8704
12:31:19.289   Training iter 450, batch loss 0.2978, batch acc 0.8782
12:31:21.704   Training iter 500, batch loss 0.3221, batch acc 0.8688
12:31:24.130   Training iter 550, batch loss 0.3561, batch acc 0.8534
12:31:26.552   Training iter 600, batch loss 0.2942, batch acc 0.8792
12:31:26.554 Training @ 374 epoch...
12:31:29.006   Training iter 50, batch loss 0.3182, batch acc 0.8710
12:31:31.439   Training iter 100, batch loss 0.2976, batch acc 0.8802
12:31:33.803   Training iter 150, batch loss 0.3195, batch acc 0.8704
12:31:36.062   Training iter 200, batch loss 0.3033, batch acc 0.8752
12:31:38.304   Training iter 250, batch loss 0.3007, batch acc 0.8772
12:31:40.547   Training iter 300, batch loss 0.3016, batch acc 0.8784
12:31:42.788   Training iter 350, batch loss 0.3160, batch acc 0.8720
12:31:45.033   Training iter 400, batch loss 0.3105, batch acc 0.8740
12:31:47.282   Training iter 450, batch loss 0.3160, batch acc 0.8696
12:31:49.524   Training iter 500, batch loss 0.3160, batch acc 0.8732
12:31:51.783   Training iter 550, batch loss 0.3264, batch acc 0.8662
12:31:54.042   Training iter 600, batch loss 0.3264, batch acc 0.8688
12:31:54.044 Training @ 375 epoch...
12:31:56.306   Training iter 50, batch loss 0.3133, batch acc 0.8718
12:31:58.536   Training iter 100, batch loss 0.3027, batch acc 0.8776
12:32:00.768   Training iter 150, batch loss 0.3219, batch acc 0.8698
12:32:03.018   Training iter 200, batch loss 0.2972, batch acc 0.8784
12:32:05.257   Training iter 250, batch loss 0.3175, batch acc 0.8702
12:32:07.512   Training iter 300, batch loss 0.3094, batch acc 0.8754
12:32:09.778   Training iter 350, batch loss 0.3112, batch acc 0.8728
12:32:12.043   Training iter 400, batch loss 0.3118, batch acc 0.8734
12:32:14.295   Training iter 450, batch loss 0.3198, batch acc 0.8680
12:32:16.542   Training iter 500, batch loss 0.3236, batch acc 0.8684
12:32:18.793   Training iter 550, batch loss 0.3016, batch acc 0.8748
12:32:21.038   Training iter 600, batch loss 0.3233, batch acc 0.8686
12:32:21.040 Testing @ 375 epoch...
12:32:21.090     Testing, total mean loss 0.39579, total acc 0.84940
12:32:21.090 Training @ 376 epoch...
12:32:23.340   Training iter 50, batch loss 0.3097, batch acc 0.8740
12:32:25.577   Training iter 100, batch loss 0.3137, batch acc 0.8714
12:32:27.849   Training iter 150, batch loss 0.3018, batch acc 0.8772
12:32:30.107   Training iter 200, batch loss 0.3018, batch acc 0.8764
12:32:32.354   Training iter 250, batch loss 0.3212, batch acc 0.8686
12:32:34.602   Training iter 300, batch loss 0.3101, batch acc 0.8742
12:32:36.847   Training iter 350, batch loss 0.3246, batch acc 0.8686
12:32:39.098   Training iter 400, batch loss 0.3065, batch acc 0.8750
12:32:41.361   Training iter 450, batch loss 0.3033, batch acc 0.8738
12:32:43.619   Training iter 500, batch loss 0.3244, batch acc 0.8668
12:32:45.865   Training iter 550, batch loss 0.3146, batch acc 0.8738
12:32:48.096   Training iter 600, batch loss 0.3204, batch acc 0.8696
12:32:48.098 Training @ 377 epoch...
12:32:50.330   Training iter 50, batch loss 0.2940, batch acc 0.8816
12:32:52.573   Training iter 100, batch loss 0.3155, batch acc 0.8716
12:32:54.801   Training iter 150, batch loss 0.3195, batch acc 0.8698
12:32:57.054   Training iter 200, batch loss 0.3048, batch acc 0.8752
12:32:59.313   Training iter 250, batch loss 0.3049, batch acc 0.8752
12:33:01.570   Training iter 300, batch loss 0.3110, batch acc 0.8722
12:33:03.830   Training iter 350, batch loss 0.3160, batch acc 0.8694
12:33:06.079   Training iter 400, batch loss 0.3108, batch acc 0.8754
12:33:08.332   Training iter 450, batch loss 0.3151, batch acc 0.8714
12:33:10.564   Training iter 500, batch loss 0.3244, batch acc 0.8670
12:33:12.803   Training iter 550, batch loss 0.3100, batch acc 0.8740
12:33:15.048   Training iter 600, batch loss 0.3233, batch acc 0.8702
12:33:15.049 Training @ 378 epoch...
12:33:17.309   Training iter 50, batch loss 0.3092, batch acc 0.8766
12:33:19.555   Training iter 100, batch loss 0.3166, batch acc 0.8718
12:33:21.805   Training iter 150, batch loss 0.3121, batch acc 0.8732
12:33:24.060   Training iter 200, batch loss 0.3107, batch acc 0.8724
12:33:26.328   Training iter 250, batch loss 0.3111, batch acc 0.8750
12:33:28.595   Training iter 300, batch loss 0.2940, batch acc 0.8810
12:33:30.865   Training iter 350, batch loss 0.3189, batch acc 0.8682
12:33:33.127   Training iter 400, batch loss 0.3209, batch acc 0.8680
12:33:35.376   Training iter 450, batch loss 0.3018, batch acc 0.8768
12:33:37.620   Training iter 500, batch loss 0.3002, batch acc 0.8768
12:33:39.868   Training iter 550, batch loss 0.3412, batch acc 0.8606
12:33:42.115   Training iter 600, batch loss 0.3114, batch acc 0.8728
12:33:42.116 Training @ 379 epoch...
12:33:44.367   Training iter 50, batch loss 0.3208, batch acc 0.8676
12:33:46.633   Training iter 100, batch loss 0.3069, batch acc 0.8762
12:33:48.893   Training iter 150, batch loss 0.2991, batch acc 0.8766
12:33:51.152   Training iter 200, batch loss 0.3109, batch acc 0.8746
12:33:53.395   Training iter 250, batch loss 0.2995, batch acc 0.8790
12:33:55.639   Training iter 300, batch loss 0.2940, batch acc 0.8784
12:33:57.867   Training iter 350, batch loss 0.3216, batch acc 0.8700
12:34:00.113   Training iter 400, batch loss 0.3364, batch acc 0.8594
12:34:02.385   Training iter 450, batch loss 0.3062, batch acc 0.8738
12:34:04.660   Training iter 500, batch loss 0.3072, batch acc 0.8758
12:34:06.928   Training iter 550, batch loss 0.3072, batch acc 0.8764
12:34:09.157   Training iter 600, batch loss 0.3351, batch acc 0.8638
12:34:09.159 Training @ 380 epoch...
12:34:11.391   Training iter 50, batch loss 0.3129, batch acc 0.8722
12:34:13.663   Training iter 100, batch loss 0.3098, batch acc 0.8734
12:34:16.008   Training iter 150, batch loss 0.3067, batch acc 0.8730
12:34:18.678   Training iter 200, batch loss 0.3119, batch acc 0.8726
12:34:20.972   Training iter 250, batch loss 0.2974, batch acc 0.8782
12:34:23.289   Training iter 300, batch loss 0.3215, batch acc 0.8668
12:34:25.623   Training iter 350, batch loss 0.3249, batch acc 0.8684
12:34:27.913   Training iter 400, batch loss 0.3135, batch acc 0.8732
12:34:30.219   Training iter 450, batch loss 0.3061, batch acc 0.8748
12:34:32.519   Training iter 500, batch loss 0.3151, batch acc 0.8712
12:34:34.858   Training iter 550, batch loss 0.3141, batch acc 0.8740
12:34:37.263   Training iter 600, batch loss 0.3156, batch acc 0.8708
12:34:37.265 Testing @ 380 epoch...
12:34:37.316     Testing, total mean loss 0.40054, total acc 0.84990
12:34:37.316 Training @ 381 epoch...
12:34:39.603   Training iter 50, batch loss 0.3114, batch acc 0.8724
12:34:41.883   Training iter 100, batch loss 0.3009, batch acc 0.8778
12:34:44.164   Training iter 150, batch loss 0.3296, batch acc 0.8660
12:34:46.446   Training iter 200, batch loss 0.3314, batch acc 0.8632
12:34:48.727   Training iter 250, batch loss 0.3081, batch acc 0.8746
12:34:51.016   Training iter 300, batch loss 0.3148, batch acc 0.8718
12:34:53.356   Training iter 350, batch loss 0.2993, batch acc 0.8782
12:34:55.659   Training iter 400, batch loss 0.3026, batch acc 0.8768
12:34:57.972   Training iter 450, batch loss 0.3104, batch acc 0.8726
12:35:00.295   Training iter 500, batch loss 0.3158, batch acc 0.8696
12:35:02.629   Training iter 550, batch loss 0.3225, batch acc 0.8670
12:35:04.942   Training iter 600, batch loss 0.3151, batch acc 0.8724
12:35:04.944 Training @ 382 epoch...
12:35:07.284   Training iter 50, batch loss 0.3355, batch acc 0.8628
12:35:09.604   Training iter 100, batch loss 0.3225, batch acc 0.8664
12:35:11.917   Training iter 150, batch loss 0.2998, batch acc 0.8784
12:35:14.241   Training iter 200, batch loss 0.3219, batch acc 0.8670
12:35:16.573   Training iter 250, batch loss 0.3085, batch acc 0.8750
12:35:18.875   Training iter 300, batch loss 0.3102, batch acc 0.8728
12:35:21.160   Training iter 350, batch loss 0.3054, batch acc 0.8730
12:35:23.474   Training iter 400, batch loss 0.3041, batch acc 0.8752
12:35:25.794   Training iter 450, batch loss 0.3174, batch acc 0.8688
12:35:28.275   Training iter 500, batch loss 0.3121, batch acc 0.8742
12:35:30.729   Training iter 550, batch loss 0.3013, batch acc 0.8774
12:35:33.102   Training iter 600, batch loss 0.3078, batch acc 0.8756
12:35:33.104 Training @ 383 epoch...
12:35:35.481   Training iter 50, batch loss 0.3160, batch acc 0.8738
12:35:37.813   Training iter 100, batch loss 0.3085, batch acc 0.8742
12:35:40.135   Training iter 150, batch loss 0.3278, batch acc 0.8654
12:35:42.424   Training iter 200, batch loss 0.3181, batch acc 0.8716
12:35:44.718   Training iter 250, batch loss 0.3060, batch acc 0.8756
12:35:46.997   Training iter 300, batch loss 0.3100, batch acc 0.8736
12:35:49.266   Training iter 350, batch loss 0.2947, batch acc 0.8808
12:35:51.544   Training iter 400, batch loss 0.3202, batch acc 0.8684
12:35:53.832   Training iter 450, batch loss 0.3234, batch acc 0.8688
12:35:56.133   Training iter 500, batch loss 0.3126, batch acc 0.8726
12:35:58.435   Training iter 550, batch loss 0.3171, batch acc 0.8710
12:36:00.739   Training iter 600, batch loss 0.3021, batch acc 0.8766
12:36:00.741 Training @ 384 epoch...
12:36:03.058   Training iter 50, batch loss 0.3192, batch acc 0.8686
12:36:05.406   Training iter 100, batch loss 0.3074, batch acc 0.8768
12:36:07.750   Training iter 150, batch loss 0.3127, batch acc 0.8730
12:36:10.098   Training iter 200, batch loss 0.3124, batch acc 0.8738
12:36:12.459   Training iter 250, batch loss 0.3039, batch acc 0.8768
12:36:14.817   Training iter 300, batch loss 0.3036, batch acc 0.8756
12:36:17.147   Training iter 350, batch loss 0.3210, batch acc 0.8686
12:36:19.418   Training iter 400, batch loss 0.3000, batch acc 0.8784
12:36:21.703   Training iter 450, batch loss 0.3170, batch acc 0.8704
12:36:23.992   Training iter 500, batch loss 0.3169, batch acc 0.8708
12:36:26.291   Training iter 550, batch loss 0.3178, batch acc 0.8692
12:36:28.592   Training iter 600, batch loss 0.3138, batch acc 0.8722
12:36:28.594 Training @ 385 epoch...
12:36:30.947   Training iter 50, batch loss 0.3022, batch acc 0.8772
12:36:33.233   Training iter 100, batch loss 0.3001, batch acc 0.8756
12:36:35.498   Training iter 150, batch loss 0.3064, batch acc 0.8752
12:36:37.781   Training iter 200, batch loss 0.3123, batch acc 0.8722
12:36:40.068   Training iter 250, batch loss 0.3050, batch acc 0.8768
12:36:42.390   Training iter 300, batch loss 0.3149, batch acc 0.8712
12:36:44.679   Training iter 350, batch loss 0.3127, batch acc 0.8712
12:36:47.144   Training iter 400, batch loss 0.3183, batch acc 0.8704
12:36:49.441   Training iter 450, batch loss 0.3148, batch acc 0.8696
12:36:51.739   Training iter 500, batch loss 0.3124, batch acc 0.8716
12:36:54.040   Training iter 550, batch loss 0.3250, batch acc 0.8680
12:36:56.359   Training iter 600, batch loss 0.3338, batch acc 0.8660
12:36:56.361 Testing @ 385 epoch...
12:36:56.416     Testing, total mean loss 0.39816, total acc 0.85130
12:36:56.416 Training @ 386 epoch...
12:36:58.784   Training iter 50, batch loss 0.3245, batch acc 0.8670
12:37:01.110   Training iter 100, batch loss 0.3190, batch acc 0.8700
12:37:03.446   Training iter 150, batch loss 0.2803, batch acc 0.8878
12:37:05.783   Training iter 200, batch loss 0.3090, batch acc 0.8736
12:37:08.136   Training iter 250, batch loss 0.2966, batch acc 0.8794
12:37:10.507   Training iter 300, batch loss 0.3164, batch acc 0.8710
12:37:12.862   Training iter 350, batch loss 0.3203, batch acc 0.8682
12:37:15.293   Training iter 400, batch loss 0.3000, batch acc 0.8786
12:37:17.640   Training iter 450, batch loss 0.3052, batch acc 0.8758
12:37:19.942   Training iter 500, batch loss 0.3245, batch acc 0.8680
12:37:22.245   Training iter 550, batch loss 0.3175, batch acc 0.8724
12:37:24.547   Training iter 600, batch loss 0.3367, batch acc 0.8630
12:37:24.549 Training @ 387 epoch...
12:37:26.845   Training iter 50, batch loss 0.3035, batch acc 0.8780
12:37:29.144   Training iter 100, batch loss 0.2993, batch acc 0.8780
12:37:31.455   Training iter 150, batch loss 0.2997, batch acc 0.8748
12:37:33.777   Training iter 200, batch loss 0.3136, batch acc 0.8704
12:37:36.084   Training iter 250, batch loss 0.3040, batch acc 0.8742
12:37:38.368   Training iter 300, batch loss 0.3311, batch acc 0.8634
12:37:40.653   Training iter 350, batch loss 0.3049, batch acc 0.8770
12:37:43.024   Training iter 400, batch loss 0.2963, batch acc 0.8786
12:37:45.378   Training iter 450, batch loss 0.3273, batch acc 0.8648
12:37:47.711   Training iter 500, batch loss 0.3130, batch acc 0.8738
12:37:50.041   Training iter 550, batch loss 0.3322, batch acc 0.8654
12:37:52.391   Training iter 600, batch loss 0.3326, batch acc 0.8662
12:37:52.392 Training @ 388 epoch...
12:37:54.698   Training iter 50, batch loss 0.2818, batch acc 0.8850
12:37:56.996   Training iter 100, batch loss 0.3174, batch acc 0.8702
12:37:59.368   Training iter 150, batch loss 0.3142, batch acc 0.8718
12:38:01.675   Training iter 200, batch loss 0.3156, batch acc 0.8730
12:38:03.980   Training iter 250, batch loss 0.3299, batch acc 0.8652
12:38:06.277   Training iter 300, batch loss 0.2884, batch acc 0.8822
12:38:08.565   Training iter 350, batch loss 0.3098, batch acc 0.8766
12:38:10.891   Training iter 400, batch loss 0.3320, batch acc 0.8670
12:38:13.309   Training iter 450, batch loss 0.3017, batch acc 0.8756
12:38:15.778   Training iter 500, batch loss 0.3096, batch acc 0.8752
12:38:18.139   Training iter 550, batch loss 0.3388, batch acc 0.8626
12:38:20.435   Training iter 600, batch loss 0.3208, batch acc 0.8670
12:38:20.437 Training @ 389 epoch...
12:38:22.739   Training iter 50, batch loss 0.3001, batch acc 0.8780
12:38:25.039   Training iter 100, batch loss 0.3067, batch acc 0.8744
12:38:27.348   Training iter 150, batch loss 0.3141, batch acc 0.8712
12:38:29.673   Training iter 200, batch loss 0.3331, batch acc 0.8628
12:38:31.983   Training iter 250, batch loss 0.3070, batch acc 0.8760
12:38:34.299   Training iter 300, batch loss 0.3126, batch acc 0.8718
12:38:36.675   Training iter 350, batch loss 0.3206, batch acc 0.8674
12:38:39.048   Training iter 400, batch loss 0.3035, batch acc 0.8772
12:38:41.421   Training iter 450, batch loss 0.3000, batch acc 0.8782
12:38:43.782   Training iter 500, batch loss 0.3140, batch acc 0.8714
12:38:46.137   Training iter 550, batch loss 0.3074, batch acc 0.8744
12:38:48.471   Training iter 600, batch loss 0.3258, batch acc 0.8670
12:38:48.473 Training @ 390 epoch...
12:38:50.818   Training iter 50, batch loss 0.3042, batch acc 0.8760
12:38:53.174   Training iter 100, batch loss 0.3056, batch acc 0.8782
12:38:55.518   Training iter 150, batch loss 0.2989, batch acc 0.8796
12:38:57.841   Training iter 200, batch loss 0.3209, batch acc 0.8698
12:39:00.151   Training iter 250, batch loss 0.3004, batch acc 0.8782
12:39:02.465   Training iter 300, batch loss 0.2965, batch acc 0.8786
12:39:04.790   Training iter 350, batch loss 0.3095, batch acc 0.8736
12:39:07.103   Training iter 400, batch loss 0.3265, batch acc 0.8664
12:39:09.446   Training iter 450, batch loss 0.3145, batch acc 0.8724
12:39:11.762   Training iter 500, batch loss 0.3084, batch acc 0.8736
12:39:14.063   Training iter 550, batch loss 0.3261, batch acc 0.8664
12:39:16.350   Training iter 600, batch loss 0.3375, batch acc 0.8606
12:39:16.352 Testing @ 390 epoch...
12:39:16.404     Testing, total mean loss 0.39843, total acc 0.85060
12:39:16.404 Training @ 391 epoch...
12:39:18.726   Training iter 50, batch loss 0.3199, batch acc 0.8672
12:39:21.056   Training iter 100, batch loss 0.3048, batch acc 0.8746
12:39:23.382   Training iter 150, batch loss 0.3025, batch acc 0.8774
12:39:25.749   Training iter 200, batch loss 0.3206, batch acc 0.8702
12:39:28.136   Training iter 250, batch loss 0.3233, batch acc 0.8674
12:39:30.578   Training iter 300, batch loss 0.3005, batch acc 0.8762
12:39:33.048   Training iter 350, batch loss 0.3050, batch acc 0.8748
12:39:35.396   Training iter 400, batch loss 0.3072, batch acc 0.8742
12:39:37.740   Training iter 450, batch loss 0.3359, batch acc 0.8638
12:39:40.068   Training iter 500, batch loss 0.3054, batch acc 0.8752
12:39:43.044   Training iter 550, batch loss 0.3220, batch acc 0.8678
12:39:45.339   Training iter 600, batch loss 0.3056, batch acc 0.8750
12:39:45.341 Training @ 392 epoch...
12:39:47.685   Training iter 50, batch loss 0.3150, batch acc 0.8714
12:39:49.974   Training iter 100, batch loss 0.3038, batch acc 0.8780
12:39:52.271   Training iter 150, batch loss 0.3121, batch acc 0.8724
12:39:54.594   Training iter 200, batch loss 0.3041, batch acc 0.8734
12:39:56.892   Training iter 250, batch loss 0.3206, batch acc 0.8722
12:39:59.194   Training iter 300, batch loss 0.3149, batch acc 0.8704
12:40:01.515   Training iter 350, batch loss 0.3079, batch acc 0.8740
12:40:03.836   Training iter 400, batch loss 0.3124, batch acc 0.8716
12:40:06.122   Training iter 450, batch loss 0.3002, batch acc 0.8788
12:40:08.405   Training iter 500, batch loss 0.3245, batch acc 0.8688
12:40:10.685   Training iter 550, batch loss 0.3189, batch acc 0.8692
12:40:12.974   Training iter 600, batch loss 0.3192, batch acc 0.8704
12:40:12.976 Training @ 393 epoch...
12:40:15.275   Training iter 50, batch loss 0.3023, batch acc 0.8764
12:40:17.594   Training iter 100, batch loss 0.3250, batch acc 0.8670
12:40:19.879   Training iter 150, batch loss 0.3108, batch acc 0.8728
12:40:22.226   Training iter 200, batch loss 0.3060, batch acc 0.8752
12:40:24.522   Training iter 250, batch loss 0.3115, batch acc 0.8714
12:40:26.795   Training iter 300, batch loss 0.3088, batch acc 0.8754
12:40:29.082   Training iter 350, batch loss 0.3139, batch acc 0.8722
12:40:31.434   Training iter 400, batch loss 0.3068, batch acc 0.8754
12:40:33.744   Training iter 450, batch loss 0.3201, batch acc 0.8708
12:40:36.025   Training iter 500, batch loss 0.3141, batch acc 0.8716
12:40:38.326   Training iter 550, batch loss 0.3157, batch acc 0.8704
12:40:40.651   Training iter 600, batch loss 0.3209, batch acc 0.8688
12:40:40.652 Training @ 394 epoch...
12:40:42.984   Training iter 50, batch loss 0.3146, batch acc 0.8682
12:40:45.331   Training iter 100, batch loss 0.2987, batch acc 0.8784
12:40:47.694   Training iter 150, batch loss 0.3177, batch acc 0.8690
12:40:49.993   Training iter 200, batch loss 0.3008, batch acc 0.8756
12:40:52.266   Training iter 250, batch loss 0.3053, batch acc 0.8764
12:40:54.536   Training iter 300, batch loss 0.3058, batch acc 0.8744
12:40:56.800   Training iter 350, batch loss 0.3207, batch acc 0.8702
12:40:59.073   Training iter 400, batch loss 0.3211, batch acc 0.8694
12:41:01.337   Training iter 450, batch loss 0.3281, batch acc 0.8660
12:41:03.659   Training iter 500, batch loss 0.3236, batch acc 0.8704
12:41:06.036   Training iter 550, batch loss 0.3035, batch acc 0.8762
12:41:08.325   Training iter 600, batch loss 0.3147, batch acc 0.8704
12:41:08.327 Training @ 395 epoch...
12:41:10.636   Training iter 50, batch loss 0.3049, batch acc 0.8756
12:41:13.076   Training iter 100, batch loss 0.3079, batch acc 0.8778
12:41:15.511   Training iter 150, batch loss 0.3078, batch acc 0.8736
12:41:17.970   Training iter 200, batch loss 0.2993, batch acc 0.8772
12:41:20.408   Training iter 250, batch loss 0.3079, batch acc 0.8730
12:41:22.855   Training iter 300, batch loss 0.3181, batch acc 0.8700
12:41:25.320   Training iter 350, batch loss 0.3097, batch acc 0.8744
12:41:27.758   Training iter 400, batch loss 0.3350, batch acc 0.8646
12:41:30.156   Training iter 450, batch loss 0.2979, batch acc 0.8784
12:41:32.432   Training iter 500, batch loss 0.3117, batch acc 0.8726
12:41:34.715   Training iter 550, batch loss 0.3273, batch acc 0.8700
12:41:36.996   Training iter 600, batch loss 0.3118, batch acc 0.8716
12:41:36.998 Testing @ 395 epoch...
12:41:37.050     Testing, total mean loss 0.39342, total acc 0.85340
12:41:37.050 Training @ 396 epoch...
12:41:39.336   Training iter 50, batch loss 0.3128, batch acc 0.8732
12:41:41.606   Training iter 100, batch loss 0.3208, batch acc 0.8714
12:41:43.874   Training iter 150, batch loss 0.3001, batch acc 0.8766
12:41:46.131   Training iter 200, batch loss 0.3293, batch acc 0.8648
12:41:48.373   Training iter 250, batch loss 0.3158, batch acc 0.8708
12:41:50.624   Training iter 300, batch loss 0.2940, batch acc 0.8796
12:41:52.876   Training iter 350, batch loss 0.3126, batch acc 0.8728
12:41:55.140   Training iter 400, batch loss 0.3215, batch acc 0.8702
12:41:57.413   Training iter 450, batch loss 0.2929, batch acc 0.8802
12:41:59.684   Training iter 500, batch loss 0.2997, batch acc 0.8782
12:42:01.967   Training iter 550, batch loss 0.3006, batch acc 0.8756
12:42:04.259   Training iter 600, batch loss 0.3380, batch acc 0.8620
12:42:04.261 Training @ 397 epoch...
12:42:06.545   Training iter 50, batch loss 0.3117, batch acc 0.8712
12:42:08.824   Training iter 100, batch loss 0.3090, batch acc 0.8726
12:42:11.093   Training iter 150, batch loss 0.2890, batch acc 0.8812
12:42:13.371   Training iter 200, batch loss 0.3195, batch acc 0.8724
12:42:15.623   Training iter 250, batch loss 0.3067, batch acc 0.8762
12:42:17.875   Training iter 300, batch loss 0.3295, batch acc 0.8654
12:42:20.108   Training iter 350, batch loss 0.3189, batch acc 0.8698
12:42:22.363   Training iter 400, batch loss 0.3124, batch acc 0.8768
12:42:24.650   Training iter 450, batch loss 0.3189, batch acc 0.8690
12:42:26.952   Training iter 500, batch loss 0.3077, batch acc 0.8780
12:42:29.280   Training iter 550, batch loss 0.3153, batch acc 0.8726
12:42:31.566   Training iter 600, batch loss 0.3108, batch acc 0.8722
12:42:31.568 Training @ 398 epoch...
12:42:33.892   Training iter 50, batch loss 0.3002, batch acc 0.8796
12:42:36.226   Training iter 100, batch loss 0.3246, batch acc 0.8674
12:42:38.568   Training iter 150, batch loss 0.3119, batch acc 0.8724
12:42:40.850   Training iter 200, batch loss 0.3454, batch acc 0.8592
12:42:43.132   Training iter 250, batch loss 0.3158, batch acc 0.8704
12:42:45.412   Training iter 300, batch loss 0.2895, batch acc 0.8814
12:42:47.687   Training iter 350, batch loss 0.3178, batch acc 0.8704
12:42:50.027   Training iter 400, batch loss 0.3161, batch acc 0.8710
12:42:52.376   Training iter 450, batch loss 0.3069, batch acc 0.8754
12:42:54.643   Training iter 500, batch loss 0.3135, batch acc 0.8696
12:42:56.921   Training iter 550, batch loss 0.2891, batch acc 0.8814
12:42:59.213   Training iter 600, batch loss 0.3131, batch acc 0.8704
12:42:59.215 Training @ 399 epoch...
12:43:01.545   Training iter 50, batch loss 0.2989, batch acc 0.8788
12:43:03.858   Training iter 100, batch loss 0.3030, batch acc 0.8768
12:43:06.170   Training iter 150, batch loss 0.3157, batch acc 0.8718
12:43:08.455   Training iter 200, batch loss 0.3042, batch acc 0.8756
12:43:10.739   Training iter 250, batch loss 0.3064, batch acc 0.8738
12:43:13.039   Training iter 300, batch loss 0.3236, batch acc 0.8690
12:43:15.333   Training iter 350, batch loss 0.3207, batch acc 0.8670
12:43:17.633   Training iter 400, batch loss 0.3177, batch acc 0.8706
12:43:19.932   Training iter 450, batch loss 0.3171, batch acc 0.8714
12:43:22.243   Training iter 500, batch loss 0.3278, batch acc 0.8682
12:43:24.560   Training iter 550, batch loss 0.3140, batch acc 0.8724
12:43:26.868   Training iter 600, batch loss 0.3047, batch acc 0.8736
12:43:26.870 Training @ 400 epoch...
12:43:29.167   Training iter 50, batch loss 0.3044, batch acc 0.8756
12:43:31.435   Training iter 100, batch loss 0.3102, batch acc 0.8724
12:43:33.687   Training iter 150, batch loss 0.3146, batch acc 0.8718
12:43:35.928   Training iter 200, batch loss 0.3119, batch acc 0.8740
12:43:38.166   Training iter 250, batch loss 0.3253, batch acc 0.8660
12:43:40.391   Training iter 300, batch loss 0.2912, batch acc 0.8804
12:43:42.633   Training iter 350, batch loss 0.3228, batch acc 0.8652
12:43:44.886   Training iter 400, batch loss 0.3031, batch acc 0.8768
12:43:47.140   Training iter 450, batch loss 0.3134, batch acc 0.8718
12:43:49.409   Training iter 500, batch loss 0.3153, batch acc 0.8712
12:43:51.636   Training iter 550, batch loss 0.3172, batch acc 0.8706
12:43:53.863   Training iter 600, batch loss 0.3178, batch acc 0.8690
12:43:53.865 Testing @ 400 epoch...
12:43:53.914     Testing, total mean loss 0.40184, total acc 0.85010
12:43:53.914 Plot @ 400 epoch...
12:43:53.914 Training @ 401 epoch...
12:43:56.159   Training iter 50, batch loss 0.3088, batch acc 0.8732
12:43:58.435   Training iter 100, batch loss 0.3007, batch acc 0.8760
12:44:00.716   Training iter 150, batch loss 0.3270, batch acc 0.8678
12:44:03.018   Training iter 200, batch loss 0.3216, batch acc 0.8676
12:44:05.319   Training iter 250, batch loss 0.3143, batch acc 0.8704
12:44:07.590   Training iter 300, batch loss 0.3079, batch acc 0.8772
12:44:09.828   Training iter 350, batch loss 0.3116, batch acc 0.8732
12:44:12.096   Training iter 400, batch loss 0.3132, batch acc 0.8706
12:44:14.424   Training iter 450, batch loss 0.3228, batch acc 0.8678
12:44:16.700   Training iter 500, batch loss 0.3020, batch acc 0.8774
12:44:18.966   Training iter 550, batch loss 0.3171, batch acc 0.8728
12:44:21.221   Training iter 600, batch loss 0.2976, batch acc 0.8782
12:44:21.222 Training @ 402 epoch...
12:44:23.515   Training iter 50, batch loss 0.3264, batch acc 0.8650
12:44:25.781   Training iter 100, batch loss 0.3195, batch acc 0.8708
12:44:28.229   Training iter 150, batch loss 0.2955, batch acc 0.8806
12:44:30.764   Training iter 200, batch loss 0.3291, batch acc 0.8666
12:44:33.010   Training iter 250, batch loss 0.3031, batch acc 0.8778
12:44:35.324   Training iter 300, batch loss 0.3179, batch acc 0.8690
12:44:37.619   Training iter 350, batch loss 0.3134, batch acc 0.8744
12:44:39.845   Training iter 400, batch loss 0.3244, batch acc 0.8674
12:44:42.070   Training iter 450, batch loss 0.2929, batch acc 0.8794
12:44:44.293   Training iter 500, batch loss 0.3069, batch acc 0.8740
12:44:46.590   Training iter 550, batch loss 0.3095, batch acc 0.8730
12:44:48.854   Training iter 600, batch loss 0.3063, batch acc 0.8756
12:44:48.856 Training @ 403 epoch...
12:44:51.114   Training iter 50, batch loss 0.3103, batch acc 0.8718
12:44:53.388   Training iter 100, batch loss 0.3254, batch acc 0.8676
12:44:55.652   Training iter 150, batch loss 0.3182, batch acc 0.8666
12:44:57.925   Training iter 200, batch loss 0.3109, batch acc 0.8734
12:45:00.202   Training iter 250, batch loss 0.3089, batch acc 0.8718
12:45:02.481   Training iter 300, batch loss 0.3069, batch acc 0.8752
12:45:04.771   Training iter 350, batch loss 0.3024, batch acc 0.8764
12:45:07.067   Training iter 400, batch loss 0.3133, batch acc 0.8730
12:45:09.373   Training iter 450, batch loss 0.3156, batch acc 0.8720
12:45:11.633   Training iter 500, batch loss 0.2993, batch acc 0.8786
12:45:13.887   Training iter 550, batch loss 0.3150, batch acc 0.8700
12:45:16.143   Training iter 600, batch loss 0.3182, batch acc 0.8726
12:45:16.145 Training @ 404 epoch...
12:45:18.412   Training iter 50, batch loss 0.3087, batch acc 0.8724
12:45:20.682   Training iter 100, batch loss 0.3305, batch acc 0.8660
12:45:22.948   Training iter 150, batch loss 0.3129, batch acc 0.8720
12:45:25.237   Training iter 200, batch loss 0.3049, batch acc 0.8766
12:45:27.528   Training iter 250, batch loss 0.3004, batch acc 0.8744
12:45:29.821   Training iter 300, batch loss 0.3214, batch acc 0.8682
12:45:32.175   Training iter 350, batch loss 0.3150, batch acc 0.8710
12:45:34.488   Training iter 400, batch loss 0.3067, batch acc 0.8748
12:45:36.809   Training iter 450, batch loss 0.2972, batch acc 0.8778
12:45:39.089   Training iter 500, batch loss 0.3117, batch acc 0.8720
12:45:41.355   Training iter 550, batch loss 0.3250, batch acc 0.8670
12:45:43.665   Training iter 600, batch loss 0.3212, batch acc 0.8664
12:45:43.667 Training @ 405 epoch...
12:45:45.976   Training iter 50, batch loss 0.3191, batch acc 0.8694
12:45:48.278   Training iter 100, batch loss 0.3061, batch acc 0.8734
12:45:50.551   Training iter 150, batch loss 0.3042, batch acc 0.8752
12:45:52.827   Training iter 200, batch loss 0.3168, batch acc 0.8700
12:45:55.111   Training iter 250, batch loss 0.3068, batch acc 0.8754
12:45:57.564   Training iter 300, batch loss 0.2979, batch acc 0.8768
12:45:59.914   Training iter 350, batch loss 0.3270, batch acc 0.8668
12:46:02.358   Training iter 400, batch loss 0.3246, batch acc 0.8662
12:46:04.641   Training iter 450, batch loss 0.3188, batch acc 0.8696
12:46:06.929   Training iter 500, batch loss 0.3155, batch acc 0.8732
12:46:09.303   Training iter 550, batch loss 0.3130, batch acc 0.8712
12:46:11.748   Training iter 600, batch loss 0.2978, batch acc 0.8780
12:46:11.750 Testing @ 405 epoch...
12:46:11.807     Testing, total mean loss 0.39667, total acc 0.85200
12:46:11.807 Training @ 406 epoch...
12:46:14.263   Training iter 50, batch loss 0.3168, batch acc 0.8710
12:46:16.692   Training iter 100, batch loss 0.3147, batch acc 0.8706
12:46:19.096   Training iter 150, batch loss 0.2981, batch acc 0.8776
12:46:21.348   Training iter 200, batch loss 0.3023, batch acc 0.8778
12:46:23.602   Training iter 250, batch loss 0.3286, batch acc 0.8654
12:46:25.870   Training iter 300, batch loss 0.2962, batch acc 0.8796
12:46:28.143   Training iter 350, batch loss 0.3166, batch acc 0.8710
12:46:30.410   Training iter 400, batch loss 0.3152, batch acc 0.8716
12:46:32.667   Training iter 450, batch loss 0.2988, batch acc 0.8782
12:46:34.927   Training iter 500, batch loss 0.3156, batch acc 0.8694
12:46:37.192   Training iter 550, batch loss 0.3131, batch acc 0.8726
12:46:39.482   Training iter 600, batch loss 0.3271, batch acc 0.8648
12:46:39.484 Training @ 407 epoch...
12:46:41.799   Training iter 50, batch loss 0.2991, batch acc 0.8798
12:46:44.067   Training iter 100, batch loss 0.3136, batch acc 0.8724
12:46:46.399   Training iter 150, batch loss 0.3092, batch acc 0.8722
12:46:48.707   Training iter 200, batch loss 0.3027, batch acc 0.8766
12:46:51.036   Training iter 250, batch loss 0.3037, batch acc 0.8758
12:46:53.385   Training iter 300, batch loss 0.3245, batch acc 0.8684
12:46:55.729   Training iter 350, batch loss 0.3214, batch acc 0.8702
12:46:58.063   Training iter 400, batch loss 0.3109, batch acc 0.8752
12:47:00.358   Training iter 450, batch loss 0.3094, batch acc 0.8748
12:47:02.672   Training iter 500, batch loss 0.3246, batch acc 0.8650
12:47:04.982   Training iter 550, batch loss 0.3094, batch acc 0.8748
12:47:07.260   Training iter 600, batch loss 0.3211, batch acc 0.8698
12:47:07.261 Training @ 408 epoch...
12:47:09.538   Training iter 50, batch loss 0.2958, batch acc 0.8802
12:47:11.833   Training iter 100, batch loss 0.3127, batch acc 0.8712
12:47:14.120   Training iter 150, batch loss 0.3070, batch acc 0.8722
12:47:16.436   Training iter 200, batch loss 0.3162, batch acc 0.8702
12:47:18.694   Training iter 250, batch loss 0.3002, batch acc 0.8758
12:47:20.943   Training iter 300, batch loss 0.3216, batch acc 0.8664
12:47:23.234   Training iter 350, batch loss 0.3126, batch acc 0.8728
12:47:25.559   Training iter 400, batch loss 0.3344, batch acc 0.8646
12:47:27.793   Training iter 450, batch loss 0.3050, batch acc 0.8762
12:47:30.041   Training iter 500, batch loss 0.3028, batch acc 0.8768
12:47:32.278   Training iter 550, batch loss 0.3105, batch acc 0.8748
12:47:34.524   Training iter 600, batch loss 0.3293, batch acc 0.8670
12:47:34.526 Training @ 409 epoch...
12:47:36.785   Training iter 50, batch loss 0.3034, batch acc 0.8770
12:47:39.123   Training iter 100, batch loss 0.2981, batch acc 0.8788
12:47:41.576   Training iter 150, batch loss 0.3167, batch acc 0.8704
12:47:43.883   Training iter 200, batch loss 0.3153, batch acc 0.8718
12:47:46.245   Training iter 250, batch loss 0.3109, batch acc 0.8726
12:47:48.566   Training iter 300, batch loss 0.2984, batch acc 0.8794
12:47:50.863   Training iter 350, batch loss 0.3229, batch acc 0.8686
12:47:53.154   Training iter 400, batch loss 0.3019, batch acc 0.8776
12:47:55.437   Training iter 450, batch loss 0.3207, batch acc 0.8682
12:47:57.731   Training iter 500, batch loss 0.3045, batch acc 0.8754
12:48:00.040   Training iter 550, batch loss 0.3352, batch acc 0.8636
12:48:02.434   Training iter 600, batch loss 0.3118, batch acc 0.8732
12:48:02.436 Training @ 410 epoch...
12:48:04.958   Training iter 50, batch loss 0.3004, batch acc 0.8766
12:48:07.352   Training iter 100, batch loss 0.3280, batch acc 0.8666
12:48:09.679   Training iter 150, batch loss 0.3244, batch acc 0.8674
12:48:12.140   Training iter 200, batch loss 0.3137, batch acc 0.8720
12:48:14.619   Training iter 250, batch loss 0.3178, batch acc 0.8690
12:48:17.095   Training iter 300, batch loss 0.3048, batch acc 0.8730
12:48:19.608   Training iter 350, batch loss 0.3138, batch acc 0.8692
12:48:22.091   Training iter 400, batch loss 0.3137, batch acc 0.8718
12:48:24.562   Training iter 450, batch loss 0.3155, batch acc 0.8728
12:48:27.036   Training iter 500, batch loss 0.2951, batch acc 0.8818
12:48:29.532   Training iter 550, batch loss 0.3041, batch acc 0.8766
12:48:32.013   Training iter 600, batch loss 0.3136, batch acc 0.8712
12:48:32.015 Testing @ 410 epoch...
12:48:32.074     Testing, total mean loss 0.41114, total acc 0.84770
12:48:32.074 Training @ 411 epoch...
12:48:34.557   Training iter 50, batch loss 0.3155, batch acc 0.8698
12:48:37.057   Training iter 100, batch loss 0.3005, batch acc 0.8788
12:48:39.379   Training iter 150, batch loss 0.3214, batch acc 0.8702
12:48:41.674   Training iter 200, batch loss 0.3188, batch acc 0.8690
12:48:43.956   Training iter 250, batch loss 0.3047, batch acc 0.8746
12:48:46.238   Training iter 300, batch loss 0.3230, batch acc 0.8716
12:48:48.520   Training iter 350, batch loss 0.3178, batch acc 0.8712
12:48:50.806   Training iter 400, batch loss 0.3209, batch acc 0.8698
12:48:53.104   Training iter 450, batch loss 0.3113, batch acc 0.8718
12:48:55.383   Training iter 500, batch loss 0.2985, batch acc 0.8786
12:48:57.658   Training iter 550, batch loss 0.3058, batch acc 0.8760
12:48:59.927   Training iter 600, batch loss 0.3150, batch acc 0.8698
12:48:59.929 Training @ 412 epoch...
12:49:02.240   Training iter 50, batch loss 0.3048, batch acc 0.8754
12:49:04.538   Training iter 100, batch loss 0.3247, batch acc 0.8676
12:49:06.837   Training iter 150, batch loss 0.3196, batch acc 0.8696
12:49:09.127   Training iter 200, batch loss 0.3065, batch acc 0.8768
12:49:11.402   Training iter 250, batch loss 0.3180, batch acc 0.8726
12:49:13.659   Training iter 300, batch loss 0.2882, batch acc 0.8816
12:49:15.912   Training iter 350, batch loss 0.3098, batch acc 0.8736
12:49:18.172   Training iter 400, batch loss 0.2926, batch acc 0.8802
12:49:20.434   Training iter 450, batch loss 0.3222, batch acc 0.8668
12:49:22.715   Training iter 500, batch loss 0.3311, batch acc 0.8654
12:49:24.997   Training iter 550, batch loss 0.3145, batch acc 0.8730
12:49:27.286   Training iter 600, batch loss 0.3154, batch acc 0.8690
12:49:27.288 Training @ 413 epoch...
12:49:29.549   Training iter 50, batch loss 0.3053, batch acc 0.8764
12:49:31.814   Training iter 100, batch loss 0.3040, batch acc 0.8756
12:49:34.074   Training iter 150, batch loss 0.3105, batch acc 0.8732
12:49:36.340   Training iter 200, batch loss 0.3092, batch acc 0.8728
12:49:38.622   Training iter 250, batch loss 0.3160, batch acc 0.8700
12:49:40.913   Training iter 300, batch loss 0.3226, batch acc 0.8722
12:49:43.204   Training iter 350, batch loss 0.3218, batch acc 0.8700
12:49:45.495   Training iter 400, batch loss 0.3137, batch acc 0.8728
12:49:47.793   Training iter 450, batch loss 0.3188, batch acc 0.8698
12:49:50.081   Training iter 500, batch loss 0.3133, batch acc 0.8724
12:49:52.368   Training iter 550, batch loss 0.3007, batch acc 0.8760
12:49:54.655   Training iter 600, batch loss 0.3057, batch acc 0.8752
12:49:54.656 Training @ 414 epoch...
12:49:56.962   Training iter 50, batch loss 0.3169, batch acc 0.8704
12:49:59.269   Training iter 100, batch loss 0.3117, batch acc 0.8716
12:50:01.611   Training iter 150, batch loss 0.3051, batch acc 0.8730
12:50:03.947   Training iter 200, batch loss 0.3162, batch acc 0.8696
12:50:06.235   Training iter 250, batch loss 0.3150, batch acc 0.8692
12:50:08.520   Training iter 300, batch loss 0.3017, batch acc 0.8764
12:50:10.790   Training iter 350, batch loss 0.3293, batch acc 0.8676
12:50:13.062   Training iter 400, batch loss 0.3147, batch acc 0.8692
12:50:15.339   Training iter 450, batch loss 0.3099, batch acc 0.8750
12:50:17.624   Training iter 500, batch loss 0.3129, batch acc 0.8718
12:50:19.894   Training iter 550, batch loss 0.3279, batch acc 0.8678
12:50:22.265   Training iter 600, batch loss 0.2940, batch acc 0.8812
12:50:22.267 Training @ 415 epoch...
12:50:24.543   Training iter 50, batch loss 0.3073, batch acc 0.8750
12:50:26.820   Training iter 100, batch loss 0.2948, batch acc 0.8792
12:50:29.102   Training iter 150, batch loss 0.3402, batch acc 0.8602
12:50:31.386   Training iter 200, batch loss 0.3124, batch acc 0.8714
12:50:33.681   Training iter 250, batch loss 0.3112, batch acc 0.8724
12:50:35.977   Training iter 300, batch loss 0.2907, batch acc 0.8832
12:50:38.256   Training iter 350, batch loss 0.3164, batch acc 0.8712
12:50:40.529   Training iter 400, batch loss 0.2942, batch acc 0.8790
12:50:42.818   Training iter 450, batch loss 0.3199, batch acc 0.8710
12:50:45.135   Training iter 500, batch loss 0.3227, batch acc 0.8682
12:50:47.424   Training iter 550, batch loss 0.3237, batch acc 0.8696
12:50:49.695   Training iter 600, batch loss 0.3082, batch acc 0.8748
12:50:49.697 Testing @ 415 epoch...
12:50:49.748     Testing, total mean loss 0.39655, total acc 0.85080
12:50:49.748 Training @ 416 epoch...
12:50:52.045   Training iter 50, batch loss 0.3093, batch acc 0.8738
12:50:54.316   Training iter 100, batch loss 0.3251, batch acc 0.8690
12:50:56.622   Training iter 150, batch loss 0.2902, batch acc 0.8814
12:50:58.901   Training iter 200, batch loss 0.3050, batch acc 0.8744
12:51:01.184   Training iter 250, batch loss 0.3029, batch acc 0.8754
12:51:03.479   Training iter 300, batch loss 0.3189, batch acc 0.8684
12:51:05.769   Training iter 350, batch loss 0.3152, batch acc 0.8704
12:51:08.046   Training iter 400, batch loss 0.3094, batch acc 0.8738
12:51:10.313   Training iter 450, batch loss 0.3228, batch acc 0.8688
12:51:12.587   Training iter 500, batch loss 0.3123, batch acc 0.8738
12:51:14.861   Training iter 550, batch loss 0.2914, batch acc 0.8798
12:51:17.149   Training iter 600, batch loss 0.3339, batch acc 0.8630
12:51:17.150 Training @ 417 epoch...
12:51:19.442   Training iter 50, batch loss 0.2959, batch acc 0.8788
12:51:21.729   Training iter 100, batch loss 0.3187, batch acc 0.8712
12:51:24.068   Training iter 150, batch loss 0.3103, batch acc 0.8742
12:51:26.444   Training iter 200, batch loss 0.3136, batch acc 0.8714
12:51:28.747   Training iter 250, batch loss 0.3362, batch acc 0.8626
12:51:31.092   Training iter 300, batch loss 0.3118, batch acc 0.8732
12:51:33.409   Training iter 350, batch loss 0.3142, batch acc 0.8702
12:51:35.710   Training iter 400, batch loss 0.3113, batch acc 0.8734
12:51:37.982   Training iter 450, batch loss 0.3216, batch acc 0.8694
12:51:40.267   Training iter 500, batch loss 0.3170, batch acc 0.8718
12:51:42.581   Training iter 550, batch loss 0.2890, batch acc 0.8826
12:51:45.127   Training iter 600, batch loss 0.3069, batch acc 0.8748
12:51:45.129 Training @ 418 epoch...
12:51:47.612   Training iter 50, batch loss 0.3092, batch acc 0.8736
12:51:50.107   Training iter 100, batch loss 0.3142, batch acc 0.8738
12:51:52.603   Training iter 150, batch loss 0.2980, batch acc 0.8790
12:51:55.080   Training iter 200, batch loss 0.3114, batch acc 0.8716
12:51:57.539   Training iter 250, batch loss 0.3231, batch acc 0.8670
12:52:00.009   Training iter 300, batch loss 0.3155, batch acc 0.8726
12:52:02.489   Training iter 350, batch loss 0.3183, batch acc 0.8702
12:52:04.974   Training iter 400, batch loss 0.3129, batch acc 0.8746
12:52:07.387   Training iter 450, batch loss 0.3100, batch acc 0.8722
12:52:09.653   Training iter 500, batch loss 0.3177, batch acc 0.8700
12:52:11.935   Training iter 550, batch loss 0.2979, batch acc 0.8794
12:52:14.216   Training iter 600, batch loss 0.3078, batch acc 0.8714
12:52:14.218 Training @ 419 epoch...
12:52:16.522   Training iter 50, batch loss 0.2964, batch acc 0.8802
12:52:18.864   Training iter 100, batch loss 0.3050, batch acc 0.8736
12:52:21.117   Training iter 150, batch loss 0.3423, batch acc 0.8604
12:52:23.406   Training iter 200, batch loss 0.3059, batch acc 0.8758
12:52:25.699   Training iter 250, batch loss 0.3192, batch acc 0.8688
12:52:27.963   Training iter 300, batch loss 0.3123, batch acc 0.8736
12:52:30.236   Training iter 350, batch loss 0.3060, batch acc 0.8748
12:52:32.507   Training iter 400, batch loss 0.3169, batch acc 0.8708
12:52:34.805   Training iter 450, batch loss 0.3078, batch acc 0.8740
12:52:37.142   Training iter 500, batch loss 0.3084, batch acc 0.8754
12:52:39.451   Training iter 550, batch loss 0.3176, batch acc 0.8720
12:52:41.785   Training iter 600, batch loss 0.3137, batch acc 0.8720
12:52:41.787 Training @ 420 epoch...
12:52:44.172   Training iter 50, batch loss 0.3110, batch acc 0.8742
12:52:46.535   Training iter 100, batch loss 0.3078, batch acc 0.8738
12:52:48.834   Training iter 150, batch loss 0.3252, batch acc 0.8658
12:52:51.153   Training iter 200, batch loss 0.3017, batch acc 0.8772
12:52:53.465   Training iter 250, batch loss 0.3103, batch acc 0.8744
12:52:55.779   Training iter 300, batch loss 0.3164, batch acc 0.8704
12:52:58.101   Training iter 350, batch loss 0.3000, batch acc 0.8788
12:53:00.416   Training iter 400, batch loss 0.3164, batch acc 0.8700
12:53:02.719   Training iter 450, batch loss 0.2995, batch acc 0.8784
12:53:05.025   Training iter 500, batch loss 0.3107, batch acc 0.8744
12:53:07.365   Training iter 550, batch loss 0.3265, batch acc 0.8662
12:53:09.801   Training iter 600, batch loss 0.3127, batch acc 0.8724
12:53:09.803 Testing @ 420 epoch...
12:53:09.857     Testing, total mean loss 0.41553, total acc 0.84710
12:53:09.857 Training @ 421 epoch...
12:53:12.143   Training iter 50, batch loss 0.3130, batch acc 0.8702
12:53:14.442   Training iter 100, batch loss 0.3191, batch acc 0.8688
12:53:16.761   Training iter 150, batch loss 0.3098, batch acc 0.8752
12:53:19.081   Training iter 200, batch loss 0.3090, batch acc 0.8746
12:53:21.411   Training iter 250, batch loss 0.3250, batch acc 0.8682
12:53:23.742   Training iter 300, batch loss 0.3184, batch acc 0.8682
12:53:26.133   Training iter 350, batch loss 0.3057, batch acc 0.8738
12:53:28.502   Training iter 400, batch loss 0.3171, batch acc 0.8698
12:53:30.856   Training iter 450, batch loss 0.2999, batch acc 0.8774
12:53:33.217   Training iter 500, batch loss 0.2964, batch acc 0.8788
12:53:35.567   Training iter 550, batch loss 0.3133, batch acc 0.8730
12:53:37.929   Training iter 600, batch loss 0.3150, batch acc 0.8698
12:53:37.931 Training @ 422 epoch...
12:53:40.294   Training iter 50, batch loss 0.3213, batch acc 0.8684
12:53:42.601   Training iter 100, batch loss 0.3093, batch acc 0.8746
12:53:44.918   Training iter 150, batch loss 0.2982, batch acc 0.8780
12:53:47.248   Training iter 200, batch loss 0.3053, batch acc 0.8748
12:53:49.691   Training iter 250, batch loss 0.3137, batch acc 0.8702
12:53:51.971   Training iter 300, batch loss 0.3177, batch acc 0.8700
12:53:54.239   Training iter 350, batch loss 0.3028, batch acc 0.8772
12:53:56.550   Training iter 400, batch loss 0.3164, batch acc 0.8728
12:53:58.803   Training iter 450, batch loss 0.3020, batch acc 0.8760
12:54:01.072   Training iter 500, batch loss 0.3392, batch acc 0.8596
12:54:03.384   Training iter 550, batch loss 0.3033, batch acc 0.8754
12:54:05.693   Training iter 600, batch loss 0.3126, batch acc 0.8730
12:54:05.695 Training @ 423 epoch...
12:54:08.039   Training iter 50, batch loss 0.3086, batch acc 0.8754
12:54:10.416   Training iter 100, batch loss 0.3317, batch acc 0.8658
12:54:12.681   Training iter 150, batch loss 0.3141, batch acc 0.8740
12:54:14.952   Training iter 200, batch loss 0.3030, batch acc 0.8764
12:54:17.213   Training iter 250, batch loss 0.3054, batch acc 0.8750
12:54:19.473   Training iter 300, batch loss 0.3055, batch acc 0.8732
12:54:21.711   Training iter 350, batch loss 0.3142, batch acc 0.8714
12:54:23.943   Training iter 400, batch loss 0.3076, batch acc 0.8744
12:54:26.221   Training iter 450, batch loss 0.3015, batch acc 0.8750
12:54:28.518   Training iter 500, batch loss 0.3267, batch acc 0.8678
12:54:30.776   Training iter 550, batch loss 0.3098, batch acc 0.8724
12:54:33.095   Training iter 600, batch loss 0.3249, batch acc 0.8650
12:54:33.097 Training @ 424 epoch...
12:54:35.466   Training iter 50, batch loss 0.3309, batch acc 0.8650
12:54:37.764   Training iter 100, batch loss 0.3175, batch acc 0.8708
12:54:40.041   Training iter 150, batch loss 0.3073, batch acc 0.8746
12:54:42.325   Training iter 200, batch loss 0.3150, batch acc 0.8692
12:54:44.605   Training iter 250, batch loss 0.3021, batch acc 0.8754
12:54:46.888   Training iter 300, batch loss 0.3082, batch acc 0.8752
12:54:49.188   Training iter 350, batch loss 0.3123, batch acc 0.8706
12:54:51.474   Training iter 400, batch loss 0.3040, batch acc 0.8754
12:54:53.765   Training iter 450, batch loss 0.3062, batch acc 0.8740
12:54:56.062   Training iter 500, batch loss 0.3054, batch acc 0.8740
12:54:58.385   Training iter 550, batch loss 0.3203, batch acc 0.8708
12:55:00.655   Training iter 600, batch loss 0.3150, batch acc 0.8722
12:55:00.656 Training @ 425 epoch...
12:55:02.954   Training iter 50, batch loss 0.3142, batch acc 0.8690
12:55:05.248   Training iter 100, batch loss 0.3084, batch acc 0.8760
12:55:07.544   Training iter 150, batch loss 0.3138, batch acc 0.8720
12:55:09.836   Training iter 200, batch loss 0.3111, batch acc 0.8740
12:55:12.125   Training iter 250, batch loss 0.2996, batch acc 0.8782
12:55:14.401   Training iter 300, batch loss 0.3085, batch acc 0.8754
12:55:16.701   Training iter 350, batch loss 0.3128, batch acc 0.8720
12:55:18.996   Training iter 400, batch loss 0.2999, batch acc 0.8762
12:55:21.409   Training iter 450, batch loss 0.3016, batch acc 0.8772
12:55:23.865   Training iter 500, batch loss 0.3355, batch acc 0.8634
12:55:26.327   Training iter 550, batch loss 0.3278, batch acc 0.8654
12:55:28.804   Training iter 600, batch loss 0.3221, batch acc 0.8676
12:55:28.806 Testing @ 425 epoch...
12:55:28.863     Testing, total mean loss 0.40215, total acc 0.85060
12:55:28.864 Training @ 426 epoch...
12:55:31.313   Training iter 50, batch loss 0.3163, batch acc 0.8692
12:55:33.775   Training iter 100, batch loss 0.3158, batch acc 0.8718
12:55:36.261   Training iter 150, batch loss 0.2951, batch acc 0.8808
12:55:38.557   Training iter 200, batch loss 0.2974, batch acc 0.8784
12:55:40.841   Training iter 250, batch loss 0.3204, batch acc 0.8714
12:55:43.099   Training iter 300, batch loss 0.3138, batch acc 0.8712
12:55:45.360   Training iter 350, batch loss 0.3221, batch acc 0.8682
12:55:47.609   Training iter 400, batch loss 0.3117, batch acc 0.8700
12:55:49.845   Training iter 450, batch loss 0.2952, batch acc 0.8792
12:55:52.090   Training iter 500, batch loss 0.3146, batch acc 0.8718
12:55:54.368   Training iter 550, batch loss 0.3170, batch acc 0.8694
12:55:56.647   Training iter 600, batch loss 0.3199, batch acc 0.8704
12:55:56.648 Training @ 427 epoch...
12:55:58.916   Training iter 50, batch loss 0.3199, batch acc 0.8678
12:56:01.166   Training iter 100, batch loss 0.3238, batch acc 0.8694
12:56:03.463   Training iter 150, batch loss 0.3042, batch acc 0.8758
12:56:05.768   Training iter 200, batch loss 0.2926, batch acc 0.8824
12:56:08.062   Training iter 250, batch loss 0.3108, batch acc 0.8730
12:56:10.383   Training iter 300, batch loss 0.2935, batch acc 0.8794
12:56:12.694   Training iter 350, batch loss 0.3023, batch acc 0.8742
12:56:14.989   Training iter 400, batch loss 0.3002, batch acc 0.8776
12:56:17.267   Training iter 450, batch loss 0.3138, batch acc 0.8732
12:56:19.541   Training iter 500, batch loss 0.3278, batch acc 0.8670
12:56:21.818   Training iter 550, batch loss 0.3199, batch acc 0.8714
12:56:24.123   Training iter 600, batch loss 0.3264, batch acc 0.8678
12:56:24.124 Training @ 428 epoch...
12:56:26.565   Training iter 50, batch loss 0.2986, batch acc 0.8798
12:56:29.013   Training iter 100, batch loss 0.3080, batch acc 0.8736
12:56:31.296   Training iter 150, batch loss 0.3138, batch acc 0.8710
12:56:33.585   Training iter 200, batch loss 0.2961, batch acc 0.8782
12:56:35.865   Training iter 250, batch loss 0.3014, batch acc 0.8794
12:56:38.207   Training iter 300, batch loss 0.3132, batch acc 0.8730
12:56:40.546   Training iter 350, batch loss 0.3184, batch acc 0.8698
12:56:42.879   Training iter 400, batch loss 0.3051, batch acc 0.8744
12:56:45.174   Training iter 450, batch loss 0.3405, batch acc 0.8606
12:56:47.470   Training iter 500, batch loss 0.3228, batch acc 0.8690
12:56:50.399   Training iter 550, batch loss 0.3139, batch acc 0.8698
12:56:52.938   Training iter 600, batch loss 0.3167, batch acc 0.8682
12:56:52.940 Training @ 429 epoch...
12:56:55.210   Training iter 50, batch loss 0.3305, batch acc 0.8648
12:56:57.477   Training iter 100, batch loss 0.2878, batch acc 0.8828
12:56:59.759   Training iter 150, batch loss 0.2965, batch acc 0.8774
12:57:02.066   Training iter 200, batch loss 0.3107, batch acc 0.8720
12:57:04.348   Training iter 250, batch loss 0.3248, batch acc 0.8666
12:57:06.611   Training iter 300, batch loss 0.3001, batch acc 0.8762
12:57:08.878   Training iter 350, batch loss 0.3073, batch acc 0.8762
12:57:11.165   Training iter 400, batch loss 0.3154, batch acc 0.8706
12:57:13.439   Training iter 450, batch loss 0.3164, batch acc 0.8720
12:57:15.723   Training iter 500, batch loss 0.3145, batch acc 0.8716
12:57:18.004   Training iter 550, batch loss 0.3235, batch acc 0.8688
12:57:20.293   Training iter 600, batch loss 0.3072, batch acc 0.8738
12:57:20.295 Training @ 430 epoch...
12:57:22.537   Training iter 50, batch loss 0.3129, batch acc 0.8690
12:57:24.831   Training iter 100, batch loss 0.2986, batch acc 0.8788
12:57:27.204   Training iter 150, batch loss 0.2897, batch acc 0.8804
12:57:29.481   Training iter 200, batch loss 0.3063, batch acc 0.8738
12:57:31.729   Training iter 250, batch loss 0.3361, batch acc 0.8616
12:57:33.965   Training iter 300, batch loss 0.3163, batch acc 0.8728
12:57:36.230   Training iter 350, batch loss 0.3014, batch acc 0.8768
12:57:38.483   Training iter 400, batch loss 0.3303, batch acc 0.8632
12:57:40.744   Training iter 450, batch loss 0.3418, batch acc 0.8628
12:57:43.011   Training iter 500, batch loss 0.3145, batch acc 0.8738
12:57:45.337   Training iter 550, batch loss 0.3116, batch acc 0.8728
12:57:47.664   Training iter 600, batch loss 0.2957, batch acc 0.8764
12:57:47.666 Testing @ 430 epoch...
12:57:47.718     Testing, total mean loss 0.39174, total acc 0.85220
12:57:47.718 Training @ 431 epoch...
12:57:50.039   Training iter 50, batch loss 0.2996, batch acc 0.8762
12:57:52.404   Training iter 100, batch loss 0.3053, batch acc 0.8764
12:57:54.750   Training iter 150, batch loss 0.2924, batch acc 0.8794
12:57:57.076   Training iter 200, batch loss 0.3333, batch acc 0.8630
12:57:59.424   Training iter 250, batch loss 0.3185, batch acc 0.8732
12:58:01.910   Training iter 300, batch loss 0.3070, batch acc 0.8742
12:58:04.296   Training iter 350, batch loss 0.3105, batch acc 0.8732
12:58:06.603   Training iter 400, batch loss 0.3114, batch acc 0.8722
12:58:09.016   Training iter 450, batch loss 0.2987, batch acc 0.8780
12:58:11.360   Training iter 500, batch loss 0.3184, batch acc 0.8704
12:58:13.712   Training iter 550, batch loss 0.3313, batch acc 0.8636
12:58:16.076   Training iter 600, batch loss 0.3224, batch acc 0.8692
12:58:16.077 Training @ 432 epoch...
12:58:18.448   Training iter 50, batch loss 0.3025, batch acc 0.8784
12:58:20.786   Training iter 100, batch loss 0.3166, batch acc 0.8718
12:58:23.088   Training iter 150, batch loss 0.3096, batch acc 0.8748
12:58:25.404   Training iter 200, batch loss 0.3095, batch acc 0.8738
12:58:27.715   Training iter 250, batch loss 0.2819, batch acc 0.8848
12:58:30.010   Training iter 300, batch loss 0.3154, batch acc 0.8702
12:58:32.295   Training iter 350, batch loss 0.3137, batch acc 0.8706
12:58:34.574   Training iter 400, batch loss 0.3165, batch acc 0.8716
12:58:36.852   Training iter 450, batch loss 0.3204, batch acc 0.8682
12:58:39.172   Training iter 500, batch loss 0.3130, batch acc 0.8718
12:58:41.475   Training iter 550, batch loss 0.3307, batch acc 0.8654
12:58:43.765   Training iter 600, batch loss 0.3148, batch acc 0.8726
12:58:43.767 Training @ 433 epoch...
12:58:46.072   Training iter 50, batch loss 0.3171, batch acc 0.8706
12:58:48.358   Training iter 100, batch loss 0.3161, batch acc 0.8720
12:58:50.667   Training iter 150, batch loss 0.3009, batch acc 0.8768
12:58:52.986   Training iter 200, batch loss 0.3075, batch acc 0.8736
12:58:55.310   Training iter 250, batch loss 0.2927, batch acc 0.8806
12:58:57.624   Training iter 300, batch loss 0.3097, batch acc 0.8732
12:59:00.020   Training iter 350, batch loss 0.3314, batch acc 0.8648
12:59:02.394   Training iter 400, batch loss 0.2943, batch acc 0.8812
12:59:04.733   Training iter 450, batch loss 0.3148, batch acc 0.8730
12:59:07.074   Training iter 500, batch loss 0.3169, batch acc 0.8706
12:59:09.393   Training iter 550, batch loss 0.3085, batch acc 0.8754
12:59:11.721   Training iter 600, batch loss 0.3241, batch acc 0.8682
12:59:11.723 Training @ 434 epoch...
12:59:14.026   Training iter 50, batch loss 0.2938, batch acc 0.8798
12:59:16.329   Training iter 100, batch loss 0.3120, batch acc 0.8734
12:59:18.658   Training iter 150, batch loss 0.3237, batch acc 0.8666
12:59:20.988   Training iter 200, batch loss 0.3251, batch acc 0.8686
12:59:23.321   Training iter 250, batch loss 0.3025, batch acc 0.8776
12:59:25.687   Training iter 300, batch loss 0.3081, batch acc 0.8760
12:59:28.146   Training iter 350, batch loss 0.3153, batch acc 0.8728
12:59:30.437   Training iter 400, batch loss 0.3052, batch acc 0.8742
12:59:32.726   Training iter 450, batch loss 0.2975, batch acc 0.8794
12:59:35.013   Training iter 500, batch loss 0.3225, batch acc 0.8660
12:59:37.320   Training iter 550, batch loss 0.3100, batch acc 0.8726
12:59:39.793   Training iter 600, batch loss 0.3226, batch acc 0.8662
12:59:39.795 Training @ 435 epoch...
12:59:42.394   Training iter 50, batch loss 0.3033, batch acc 0.8794
12:59:44.720   Training iter 100, batch loss 0.3197, batch acc 0.8672
12:59:47.011   Training iter 150, batch loss 0.3095, batch acc 0.8716
12:59:49.302   Training iter 200, batch loss 0.3038, batch acc 0.8766
12:59:51.589   Training iter 250, batch loss 0.3320, batch acc 0.8650
12:59:53.881   Training iter 300, batch loss 0.2939, batch acc 0.8798
12:59:56.169   Training iter 350, batch loss 0.3142, batch acc 0.8718
12:59:58.536   Training iter 400, batch loss 0.3002, batch acc 0.8768
13:00:00.925   Training iter 450, batch loss 0.3181, batch acc 0.8712
13:00:03.391   Training iter 500, batch loss 0.3108, batch acc 0.8720
13:00:05.818   Training iter 550, batch loss 0.3152, batch acc 0.8740
13:00:08.231   Training iter 600, batch loss 0.3170, batch acc 0.8712
13:00:08.233 Testing @ 435 epoch...
13:00:08.287     Testing, total mean loss 0.39262, total acc 0.85190
13:00:08.288 Training @ 436 epoch...
13:00:10.613   Training iter 50, batch loss 0.3099, batch acc 0.8756
13:00:12.948   Training iter 100, batch loss 0.3212, batch acc 0.8710
13:00:15.270   Training iter 150, batch loss 0.3195, batch acc 0.8700
13:00:17.594   Training iter 200, batch loss 0.3064, batch acc 0.8756
13:00:19.909   Training iter 250, batch loss 0.3181, batch acc 0.8690
13:00:22.247   Training iter 300, batch loss 0.3198, batch acc 0.8706
13:00:24.589   Training iter 350, batch loss 0.3111, batch acc 0.8748
13:00:26.945   Training iter 400, batch loss 0.3161, batch acc 0.8710
13:00:29.270   Training iter 450, batch loss 0.3055, batch acc 0.8748
13:00:31.647   Training iter 500, batch loss 0.2938, batch acc 0.8778
13:00:34.005   Training iter 550, batch loss 0.3023, batch acc 0.8756
13:00:36.333   Training iter 600, batch loss 0.3171, batch acc 0.8702
13:00:36.335 Training @ 437 epoch...
13:00:38.743   Training iter 50, batch loss 0.3262, batch acc 0.8654
13:00:41.103   Training iter 100, batch loss 0.3029, batch acc 0.8770
13:00:43.411   Training iter 150, batch loss 0.2988, batch acc 0.8780
13:00:45.731   Training iter 200, batch loss 0.3073, batch acc 0.8760
13:00:48.096   Training iter 250, batch loss 0.3117, batch acc 0.8730
13:00:51.442   Training iter 300, batch loss 0.3106, batch acc 0.8734
13:00:53.835   Training iter 350, batch loss 0.3193, batch acc 0.8690
13:00:56.912   Training iter 400, batch loss 0.3047, batch acc 0.8740
13:00:59.430   Training iter 450, batch loss 0.3077, batch acc 0.8736
13:01:01.986   Training iter 500, batch loss 0.3234, batch acc 0.8690
13:01:04.333   Training iter 550, batch loss 0.3196, batch acc 0.8698
13:01:06.638   Training iter 600, batch loss 0.3098, batch acc 0.8730
13:01:06.639 Training @ 438 epoch...
13:01:08.958   Training iter 50, batch loss 0.3060, batch acc 0.8738
13:01:11.243   Training iter 100, batch loss 0.2956, batch acc 0.8786
13:01:13.529   Training iter 150, batch loss 0.3218, batch acc 0.8704
13:01:15.909   Training iter 200, batch loss 0.2972, batch acc 0.8766
13:01:18.257   Training iter 250, batch loss 0.2887, batch acc 0.8824
13:01:20.586   Training iter 300, batch loss 0.3128, batch acc 0.8724
13:01:22.927   Training iter 350, batch loss 0.3155, batch acc 0.8712
13:01:25.357   Training iter 400, batch loss 0.3052, batch acc 0.8740
13:01:27.778   Training iter 450, batch loss 0.3155, batch acc 0.8710
13:01:30.092   Training iter 500, batch loss 0.3182, batch acc 0.8706
13:01:32.412   Training iter 550, batch loss 0.3344, batch acc 0.8646
13:01:34.737   Training iter 600, batch loss 0.3315, batch acc 0.8648
13:01:34.739 Training @ 439 epoch...
13:01:37.069   Training iter 50, batch loss 0.3215, batch acc 0.8686
13:01:39.413   Training iter 100, batch loss 0.3330, batch acc 0.8634
13:01:41.794   Training iter 150, batch loss 0.3086, batch acc 0.8754
13:01:44.126   Training iter 200, batch loss 0.3146, batch acc 0.8726
13:01:46.460   Training iter 250, batch loss 0.3171, batch acc 0.8720
13:01:48.799   Training iter 300, batch loss 0.3122, batch acc 0.8714
13:01:51.138   Training iter 350, batch loss 0.3010, batch acc 0.8764
13:01:53.499   Training iter 400, batch loss 0.2995, batch acc 0.8774
13:01:55.795   Training iter 450, batch loss 0.3150, batch acc 0.8730
13:01:58.097   Training iter 500, batch loss 0.3177, batch acc 0.8698
13:02:00.393   Training iter 550, batch loss 0.2928, batch acc 0.8804
13:02:02.762   Training iter 600, batch loss 0.3058, batch acc 0.8746
13:02:02.764 Training @ 440 epoch...
13:02:05.122   Training iter 50, batch loss 0.3073, batch acc 0.8748
13:02:07.479   Training iter 100, batch loss 0.3206, batch acc 0.8680
13:02:09.796   Training iter 150, batch loss 0.2976, batch acc 0.8784
13:02:12.094   Training iter 200, batch loss 0.3109, batch acc 0.8734
13:02:14.404   Training iter 250, batch loss 0.2978, batch acc 0.8786
13:02:16.720   Training iter 300, batch loss 0.3176, batch acc 0.8692
13:02:19.034   Training iter 350, batch loss 0.3345, batch acc 0.8636
13:02:21.389   Training iter 400, batch loss 0.3023, batch acc 0.8776
13:02:23.719   Training iter 450, batch loss 0.3122, batch acc 0.8734
13:02:26.064   Training iter 500, batch loss 0.3069, batch acc 0.8748
13:02:28.416   Training iter 550, batch loss 0.3018, batch acc 0.8750
13:02:30.759   Training iter 600, batch loss 0.3226, batch acc 0.8706
13:02:30.760 Testing @ 440 epoch...
13:02:30.814     Testing, total mean loss 0.40471, total acc 0.84820
13:02:30.814 Training @ 441 epoch...
13:02:33.118   Training iter 50, batch loss 0.3224, batch acc 0.8682
13:02:35.420   Training iter 100, batch loss 0.3225, batch acc 0.8676
13:02:37.728   Training iter 150, batch loss 0.3032, batch acc 0.8748
13:02:40.034   Training iter 200, batch loss 0.3000, batch acc 0.8746
13:02:42.391   Training iter 250, batch loss 0.3067, batch acc 0.8752
13:02:44.715   Training iter 300, batch loss 0.3206, batch acc 0.8708
13:02:47.076   Training iter 350, batch loss 0.3212, batch acc 0.8696
13:02:49.389   Training iter 400, batch loss 0.3028, batch acc 0.8778
13:02:51.694   Training iter 450, batch loss 0.3260, batch acc 0.8692
13:02:54.078   Training iter 500, batch loss 0.2964, batch acc 0.8786
13:02:56.492   Training iter 550, batch loss 0.3180, batch acc 0.8690
13:02:58.807   Training iter 600, batch loss 0.3035, batch acc 0.8756
13:02:58.808 Training @ 442 epoch...
13:03:01.107   Training iter 50, batch loss 0.3177, batch acc 0.8690
13:03:03.440   Training iter 100, batch loss 0.3222, batch acc 0.8658
13:03:05.766   Training iter 150, batch loss 0.3106, batch acc 0.8738
13:03:08.281   Training iter 200, batch loss 0.3122, batch acc 0.8744
13:03:10.598   Training iter 250, batch loss 0.3045, batch acc 0.8766
13:03:12.873   Training iter 300, batch loss 0.2982, batch acc 0.8776
13:03:15.169   Training iter 350, batch loss 0.3176, batch acc 0.8694
13:03:17.510   Training iter 400, batch loss 0.2991, batch acc 0.8776
13:03:19.814   Training iter 450, batch loss 0.3080, batch acc 0.8754
13:03:22.182   Training iter 500, batch loss 0.3138, batch acc 0.8724
13:03:24.533   Training iter 550, batch loss 0.3198, batch acc 0.8678
13:03:26.858   Training iter 600, batch loss 0.3148, batch acc 0.8722
13:03:26.860 Training @ 443 epoch...
13:03:29.164   Training iter 50, batch loss 0.3152, batch acc 0.8684
13:03:31.460   Training iter 100, batch loss 0.3194, batch acc 0.8714
13:03:33.741   Training iter 150, batch loss 0.2939, batch acc 0.8802
13:03:36.038   Training iter 200, batch loss 0.3052, batch acc 0.8748
13:03:38.312   Training iter 250, batch loss 0.3331, batch acc 0.8628
13:03:40.594   Training iter 300, batch loss 0.3209, batch acc 0.8710
13:03:42.935   Training iter 350, batch loss 0.3056, batch acc 0.8738
13:03:45.304   Training iter 400, batch loss 0.2980, batch acc 0.8800
13:03:47.625   Training iter 450, batch loss 0.3013, batch acc 0.8764
13:03:49.997   Training iter 500, batch loss 0.3305, batch acc 0.8666
13:03:52.303   Training iter 550, batch loss 0.3034, batch acc 0.8762
13:03:54.606   Training iter 600, batch loss 0.3129, batch acc 0.8724
13:03:54.608 Training @ 444 epoch...
13:03:56.918   Training iter 50, batch loss 0.2988, batch acc 0.8772
13:03:59.236   Training iter 100, batch loss 0.3219, batch acc 0.8678
13:04:01.561   Training iter 150, batch loss 0.3158, batch acc 0.8710
13:04:03.904   Training iter 200, batch loss 0.2972, batch acc 0.8790
13:04:06.214   Training iter 250, batch loss 0.3158, batch acc 0.8732
13:04:08.511   Training iter 300, batch loss 0.3132, batch acc 0.8738
13:04:10.741   Training iter 350, batch loss 0.2943, batch acc 0.8766
13:04:12.965   Training iter 400, batch loss 0.3041, batch acc 0.8756
13:04:15.202   Training iter 450, batch loss 0.3085, batch acc 0.8730
13:04:17.443   Training iter 500, batch loss 0.3211, batch acc 0.8708
13:04:19.713   Training iter 550, batch loss 0.3341, batch acc 0.8628
13:04:21.966   Training iter 600, batch loss 0.3111, batch acc 0.8728
13:04:21.968 Training @ 445 epoch...
13:04:24.240   Training iter 50, batch loss 0.3169, batch acc 0.8690
13:04:26.508   Training iter 100, batch loss 0.3205, batch acc 0.8678
13:04:28.761   Training iter 150, batch loss 0.3301, batch acc 0.8658
13:04:31.027   Training iter 200, batch loss 0.3147, batch acc 0.8712
13:04:33.274   Training iter 250, batch loss 0.3021, batch acc 0.8772
13:04:35.505   Training iter 300, batch loss 0.3011, batch acc 0.8750
13:04:37.757   Training iter 350, batch loss 0.2944, batch acc 0.8784
13:04:39.988   Training iter 400, batch loss 0.3312, batch acc 0.8634
13:04:42.273   Training iter 450, batch loss 0.3042, batch acc 0.8734
13:04:44.526   Training iter 500, batch loss 0.3131, batch acc 0.8746
13:04:46.818   Training iter 550, batch loss 0.3101, batch acc 0.8732
13:04:49.111   Training iter 600, batch loss 0.3136, batch acc 0.8734
13:04:49.112 Testing @ 445 epoch...
13:04:49.164     Testing, total mean loss 0.40024, total acc 0.84980
13:04:49.164 Training @ 446 epoch...
13:04:51.459   Training iter 50, batch loss 0.3086, batch acc 0.8754
13:04:53.744   Training iter 100, batch loss 0.3199, batch acc 0.8712
13:04:56.024   Training iter 150, batch loss 0.2899, batch acc 0.8830
13:04:58.307   Training iter 200, batch loss 0.3034, batch acc 0.8744
13:05:00.579   Training iter 250, batch loss 0.3169, batch acc 0.8708
13:05:02.875   Training iter 300, batch loss 0.3269, batch acc 0.8664
13:05:05.180   Training iter 350, batch loss 0.3139, batch acc 0.8720
13:05:07.482   Training iter 400, batch loss 0.3162, batch acc 0.8702
13:05:09.857   Training iter 450, batch loss 0.3039, batch acc 0.8762
13:05:12.150   Training iter 500, batch loss 0.3265, batch acc 0.8646
13:05:14.432   Training iter 550, batch loss 0.3107, batch acc 0.8732
13:05:16.724   Training iter 600, batch loss 0.3042, batch acc 0.8738
13:05:16.726 Training @ 447 epoch...
13:05:19.227   Training iter 50, batch loss 0.3087, batch acc 0.8742
13:05:21.540   Training iter 100, batch loss 0.3002, batch acc 0.8778
13:05:23.837   Training iter 150, batch loss 0.3006, batch acc 0.8776
13:05:26.131   Training iter 200, batch loss 0.3145, batch acc 0.8712
13:05:28.408   Training iter 250, batch loss 0.3077, batch acc 0.8728
13:05:30.682   Training iter 300, batch loss 0.3242, batch acc 0.8676
13:05:32.953   Training iter 350, batch loss 0.3074, batch acc 0.8754
13:05:35.273   Training iter 400, batch loss 0.3178, batch acc 0.8702
13:05:37.573   Training iter 450, batch loss 0.3167, batch acc 0.8688
13:05:39.929   Training iter 500, batch loss 0.3185, batch acc 0.8720
13:05:42.246   Training iter 550, batch loss 0.3148, batch acc 0.8716
13:05:44.533   Training iter 600, batch loss 0.3023, batch acc 0.8762
13:05:44.535 Training @ 448 epoch...
13:05:46.861   Training iter 50, batch loss 0.3002, batch acc 0.8796
13:05:49.197   Training iter 100, batch loss 0.3182, batch acc 0.8704
13:05:51.475   Training iter 150, batch loss 0.3303, batch acc 0.8638
13:05:53.835   Training iter 200, batch loss 0.3220, batch acc 0.8692
13:05:56.200   Training iter 250, batch loss 0.3115, batch acc 0.8720
13:05:58.497   Training iter 300, batch loss 0.3180, batch acc 0.8688
13:06:00.805   Training iter 350, batch loss 0.2984, batch acc 0.8760
13:06:03.174   Training iter 400, batch loss 0.3092, batch acc 0.8738
13:06:05.513   Training iter 450, batch loss 0.3138, batch acc 0.8744
13:06:07.799   Training iter 500, batch loss 0.2914, batch acc 0.8804
13:06:10.085   Training iter 550, batch loss 0.3114, batch acc 0.8738
13:06:12.424   Training iter 600, batch loss 0.3087, batch acc 0.8740
13:06:12.425 Training @ 449 epoch...
13:06:14.710   Training iter 50, batch loss 0.3253, batch acc 0.8650
13:06:17.021   Training iter 100, batch loss 0.3097, batch acc 0.8714
13:06:19.312   Training iter 150, batch loss 0.2996, batch acc 0.8780
13:06:21.594   Training iter 200, batch loss 0.3186, batch acc 0.8720
13:06:23.883   Training iter 250, batch loss 0.3029, batch acc 0.8758
13:06:26.213   Training iter 300, batch loss 0.3055, batch acc 0.8772
13:06:28.509   Training iter 350, batch loss 0.2998, batch acc 0.8774
13:06:30.812   Training iter 400, batch loss 0.3193, batch acc 0.8722
13:06:33.113   Training iter 450, batch loss 0.3249, batch acc 0.8678
13:06:35.397   Training iter 500, batch loss 0.3147, batch acc 0.8712
13:06:37.709   Training iter 550, batch loss 0.3134, batch acc 0.8708
13:06:40.004   Training iter 600, batch loss 0.3134, batch acc 0.8718
13:06:40.006 Training @ 450 epoch...
13:06:42.345   Training iter 50, batch loss 0.3076, batch acc 0.8746
13:06:44.690   Training iter 100, batch loss 0.3090, batch acc 0.8732
13:06:47.013   Training iter 150, batch loss 0.3112, batch acc 0.8728
13:06:49.349   Training iter 200, batch loss 0.2991, batch acc 0.8780
13:06:51.752   Training iter 250, batch loss 0.3385, batch acc 0.8624
13:06:54.014   Training iter 300, batch loss 0.3120, batch acc 0.8736
13:06:56.279   Training iter 350, batch loss 0.3192, batch acc 0.8686
13:06:58.545   Training iter 400, batch loss 0.3182, batch acc 0.8710
13:07:00.818   Training iter 450, batch loss 0.3040, batch acc 0.8760
13:07:03.106   Training iter 500, batch loss 0.3098, batch acc 0.8730
13:07:05.386   Training iter 550, batch loss 0.3064, batch acc 0.8748
13:07:07.674   Training iter 600, batch loss 0.2940, batch acc 0.8800
13:07:07.676 Testing @ 450 epoch...
13:07:07.728     Testing, total mean loss 0.39613, total acc 0.85200
13:07:07.728 Training @ 451 epoch...
13:07:10.016   Training iter 50, batch loss 0.3194, batch acc 0.8700
13:07:12.298   Training iter 100, batch loss 0.3287, batch acc 0.8680
13:07:14.638   Training iter 150, batch loss 0.3098, batch acc 0.8746
13:07:16.926   Training iter 200, batch loss 0.2924, batch acc 0.8812
13:07:19.194   Training iter 250, batch loss 0.3114, batch acc 0.8720
13:07:21.459   Training iter 300, batch loss 0.3142, batch acc 0.8742
13:07:23.771   Training iter 350, batch loss 0.3013, batch acc 0.8754
13:07:26.050   Training iter 400, batch loss 0.3266, batch acc 0.8658
13:07:28.333   Training iter 450, batch loss 0.3224, batch acc 0.8664
13:07:30.627   Training iter 500, batch loss 0.3174, batch acc 0.8704
13:07:32.949   Training iter 550, batch loss 0.2978, batch acc 0.8768
13:07:35.272   Training iter 600, batch loss 0.3052, batch acc 0.8782
13:07:35.274 Training @ 452 epoch...
13:07:37.561   Training iter 50, batch loss 0.3173, batch acc 0.8702
13:07:39.908   Training iter 100, batch loss 0.3007, batch acc 0.8768
13:07:42.274   Training iter 150, batch loss 0.3257, batch acc 0.8680
13:07:44.653   Training iter 200, batch loss 0.2950, batch acc 0.8792
13:07:47.005   Training iter 250, batch loss 0.3152, batch acc 0.8708
13:07:49.324   Training iter 300, batch loss 0.3324, batch acc 0.8628
13:07:51.625   Training iter 350, batch loss 0.3101, batch acc 0.8746
13:07:53.902   Training iter 400, batch loss 0.3106, batch acc 0.8712
13:07:56.162   Training iter 450, batch loss 0.3129, batch acc 0.8722
13:07:58.491   Training iter 500, batch loss 0.2996, batch acc 0.8768
13:08:00.775   Training iter 550, batch loss 0.3078, batch acc 0.8758
13:08:03.099   Training iter 600, batch loss 0.3118, batch acc 0.8744
13:08:03.101 Training @ 453 epoch...
13:08:05.455   Training iter 50, batch loss 0.2946, batch acc 0.8852
13:08:07.757   Training iter 100, batch loss 0.3094, batch acc 0.8718
13:08:10.116   Training iter 150, batch loss 0.3279, batch acc 0.8644
13:08:12.403   Training iter 200, batch loss 0.2983, batch acc 0.8786
13:08:14.869   Training iter 250, batch loss 0.3134, batch acc 0.8732
13:08:17.318   Training iter 300, batch loss 0.3192, batch acc 0.8688
13:08:19.671   Training iter 350, batch loss 0.3156, batch acc 0.8708
13:08:21.956   Training iter 400, batch loss 0.3138, batch acc 0.8700
13:08:24.307   Training iter 450, batch loss 0.2930, batch acc 0.8814
13:08:26.674   Training iter 500, batch loss 0.3144, batch acc 0.8722
13:08:28.973   Training iter 550, batch loss 0.3303, batch acc 0.8632
13:08:31.275   Training iter 600, batch loss 0.3079, batch acc 0.8750
13:08:31.276 Training @ 454 epoch...
13:08:33.599   Training iter 50, batch loss 0.3058, batch acc 0.8762
13:08:35.956   Training iter 100, batch loss 0.3172, batch acc 0.8710
13:08:38.312   Training iter 150, batch loss 0.3255, batch acc 0.8682
13:08:41.185   Training iter 200, batch loss 0.2985, batch acc 0.8780
13:08:43.508   Training iter 250, batch loss 0.3054, batch acc 0.8758
13:08:45.792   Training iter 300, batch loss 0.2968, batch acc 0.8788
13:08:48.115   Training iter 350, batch loss 0.3097, batch acc 0.8740
13:08:50.455   Training iter 400, batch loss 0.3092, batch acc 0.8746
13:08:52.734   Training iter 450, batch loss 0.3167, batch acc 0.8700
13:08:55.029   Training iter 500, batch loss 0.3101, batch acc 0.8750
13:08:57.321   Training iter 550, batch loss 0.3360, batch acc 0.8618
13:08:59.594   Training iter 600, batch loss 0.3052, batch acc 0.8752
13:08:59.596 Training @ 455 epoch...
13:09:01.881   Training iter 50, batch loss 0.3203, batch acc 0.8696
13:09:04.185   Training iter 100, batch loss 0.3047, batch acc 0.8752
13:09:06.483   Training iter 150, batch loss 0.3051, batch acc 0.8750
13:09:08.776   Training iter 200, batch loss 0.3064, batch acc 0.8746
13:09:11.064   Training iter 250, batch loss 0.3237, batch acc 0.8688
13:09:13.399   Training iter 300, batch loss 0.2959, batch acc 0.8788
13:09:15.755   Training iter 350, batch loss 0.3159, batch acc 0.8712
13:09:18.035   Training iter 400, batch loss 0.3334, batch acc 0.8632
13:09:20.314   Training iter 450, batch loss 0.3035, batch acc 0.8774
13:09:22.668   Training iter 500, batch loss 0.3064, batch acc 0.8748
13:09:25.042   Training iter 550, batch loss 0.3026, batch acc 0.8756
13:09:27.405   Training iter 600, batch loss 0.3130, batch acc 0.8716
13:09:27.407 Testing @ 455 epoch...
13:09:27.459     Testing, total mean loss 0.39681, total acc 0.85130
13:09:27.459 Training @ 456 epoch...
13:09:29.791   Training iter 50, batch loss 0.3109, batch acc 0.8722
13:09:32.129   Training iter 100, batch loss 0.3063, batch acc 0.8750
13:09:34.472   Training iter 150, batch loss 0.2898, batch acc 0.8816
13:09:36.836   Training iter 200, batch loss 0.3137, batch acc 0.8714
13:09:39.152   Training iter 250, batch loss 0.3087, batch acc 0.8734
13:09:41.478   Training iter 300, batch loss 0.3102, batch acc 0.8742
13:09:43.833   Training iter 350, batch loss 0.2966, batch acc 0.8786
13:09:46.180   Training iter 400, batch loss 0.3244, batch acc 0.8666
13:09:48.595   Training iter 450, batch loss 0.3107, batch acc 0.8732
13:09:51.004   Training iter 500, batch loss 0.3278, batch acc 0.8640
13:09:53.289   Training iter 550, batch loss 0.3108, batch acc 0.8726
13:09:55.588   Training iter 600, batch loss 0.3306, batch acc 0.8662
13:09:55.590 Training @ 457 epoch...
13:09:57.899   Training iter 50, batch loss 0.3144, batch acc 0.8720
13:10:00.194   Training iter 100, batch loss 0.2989, batch acc 0.8778
13:10:02.781   Training iter 150, batch loss 0.3081, batch acc 0.8728
13:10:05.550   Training iter 200, batch loss 0.3399, batch acc 0.8606
13:10:07.958   Training iter 250, batch loss 0.3127, batch acc 0.8706
13:10:10.294   Training iter 300, batch loss 0.3076, batch acc 0.8754
13:10:12.589   Training iter 350, batch loss 0.3035, batch acc 0.8742
13:10:14.892   Training iter 400, batch loss 0.3018, batch acc 0.8784
13:10:17.171   Training iter 450, batch loss 0.3188, batch acc 0.8694
13:10:19.431   Training iter 500, batch loss 0.3062, batch acc 0.8738
13:10:21.697   Training iter 550, batch loss 0.3254, batch acc 0.8686
13:10:23.980   Training iter 600, batch loss 0.3049, batch acc 0.8744
13:10:23.981 Training @ 458 epoch...
13:10:26.313   Training iter 50, batch loss 0.3284, batch acc 0.8668
13:10:28.646   Training iter 100, batch loss 0.2988, batch acc 0.8790
13:10:30.972   Training iter 150, batch loss 0.3038, batch acc 0.8760
13:10:33.242   Training iter 200, batch loss 0.3190, batch acc 0.8700
13:10:35.593   Training iter 250, batch loss 0.3048, batch acc 0.8770
13:10:37.935   Training iter 300, batch loss 0.3160, batch acc 0.8700
13:10:40.257   Training iter 350, batch loss 0.3138, batch acc 0.8742
13:10:42.588   Training iter 400, batch loss 0.3100, batch acc 0.8740
13:10:44.868   Training iter 450, batch loss 0.3151, batch acc 0.8738
13:10:47.147   Training iter 500, batch loss 0.3177, batch acc 0.8712
13:10:49.419   Training iter 550, batch loss 0.2955, batch acc 0.8804
13:10:51.734   Training iter 600, batch loss 0.3213, batch acc 0.8692
13:10:51.736 Training @ 459 epoch...
13:10:54.074   Training iter 50, batch loss 0.3029, batch acc 0.8768
13:10:56.459   Training iter 100, batch loss 0.3041, batch acc 0.8778
13:10:58.830   Training iter 150, batch loss 0.3077, batch acc 0.8752
13:11:01.168   Training iter 200, batch loss 0.3041, batch acc 0.8752
13:11:03.652   Training iter 250, batch loss 0.3036, batch acc 0.8774
13:11:06.218   Training iter 300, batch loss 0.3193, batch acc 0.8714
13:11:08.501   Training iter 350, batch loss 0.3140, batch acc 0.8704
13:11:10.758   Training iter 400, batch loss 0.3186, batch acc 0.8702
13:11:13.043   Training iter 450, batch loss 0.3148, batch acc 0.8690
13:11:15.406   Training iter 500, batch loss 0.3168, batch acc 0.8742
13:11:17.732   Training iter 550, batch loss 0.3291, batch acc 0.8640
13:11:20.038   Training iter 600, batch loss 0.2945, batch acc 0.8784
13:11:20.040 Training @ 460 epoch...
13:11:22.293   Training iter 50, batch loss 0.3127, batch acc 0.8714
13:11:24.552   Training iter 100, batch loss 0.2923, batch acc 0.8828
13:11:26.840   Training iter 150, batch loss 0.3149, batch acc 0.8704
13:11:29.108   Training iter 200, batch loss 0.3170, batch acc 0.8714
13:11:31.396   Training iter 250, batch loss 0.3053, batch acc 0.8734
13:11:33.672   Training iter 300, batch loss 0.2992, batch acc 0.8784
13:11:35.951   Training iter 350, batch loss 0.3182, batch acc 0.8692
13:11:38.209   Training iter 400, batch loss 0.3202, batch acc 0.8694
13:11:40.464   Training iter 450, batch loss 0.3069, batch acc 0.8736
13:11:42.731   Training iter 500, batch loss 0.3086, batch acc 0.8730
13:11:45.002   Training iter 550, batch loss 0.3014, batch acc 0.8776
13:11:47.290   Training iter 600, batch loss 0.3317, batch acc 0.8654
13:11:47.292 Testing @ 460 epoch...
13:11:47.342     Testing, total mean loss 0.41092, total acc 0.84930
13:11:47.342 Training @ 461 epoch...
13:11:49.635   Training iter 50, batch loss 0.3222, batch acc 0.8678
13:11:51.933   Training iter 100, batch loss 0.3117, batch acc 0.8718
13:11:54.205   Training iter 150, batch loss 0.3165, batch acc 0.8718
13:11:56.482   Training iter 200, batch loss 0.3348, batch acc 0.8638
13:11:58.749   Training iter 250, batch loss 0.3073, batch acc 0.8744
13:12:01.036   Training iter 300, batch loss 0.3115, batch acc 0.8740
13:12:03.342   Training iter 350, batch loss 0.3211, batch acc 0.8666
13:12:05.640   Training iter 400, batch loss 0.3268, batch acc 0.8690
13:12:07.971   Training iter 450, batch loss 0.2930, batch acc 0.8832
13:12:10.306   Training iter 500, batch loss 0.2938, batch acc 0.8810
13:12:12.656   Training iter 550, batch loss 0.2940, batch acc 0.8792
13:12:14.999   Training iter 600, batch loss 0.3061, batch acc 0.8746
13:12:15.002 Training @ 462 epoch...
13:12:17.347   Training iter 50, batch loss 0.3064, batch acc 0.8750
13:12:19.666   Training iter 100, batch loss 0.3167, batch acc 0.8690
13:12:21.945   Training iter 150, batch loss 0.3242, batch acc 0.8684
13:12:24.285   Training iter 200, batch loss 0.3022, batch acc 0.8770
13:12:26.629   Training iter 250, batch loss 0.3235, batch acc 0.8674
13:12:28.913   Training iter 300, batch loss 0.3093, batch acc 0.8716
13:12:31.195   Training iter 350, batch loss 0.3048, batch acc 0.8772
13:12:33.521   Training iter 400, batch loss 0.3120, batch acc 0.8736
13:12:35.843   Training iter 450, batch loss 0.3158, batch acc 0.8700
13:12:38.180   Training iter 500, batch loss 0.2976, batch acc 0.8794
13:12:40.495   Training iter 550, batch loss 0.3168, batch acc 0.8702
13:12:42.811   Training iter 600, batch loss 0.3158, batch acc 0.8710
13:12:42.813 Training @ 463 epoch...
13:12:45.137   Training iter 50, batch loss 0.3042, batch acc 0.8754
13:12:47.447   Training iter 100, batch loss 0.3109, batch acc 0.8738
13:12:49.752   Training iter 150, batch loss 0.3242, batch acc 0.8678
13:12:52.093   Training iter 200, batch loss 0.2950, batch acc 0.8798
13:12:54.448   Training iter 250, batch loss 0.2961, batch acc 0.8798
13:12:56.791   Training iter 300, batch loss 0.3208, batch acc 0.8694
13:12:59.063   Training iter 350, batch loss 0.3081, batch acc 0.8720
13:13:01.360   Training iter 400, batch loss 0.3145, batch acc 0.8722
13:13:03.641   Training iter 450, batch loss 0.3146, batch acc 0.8708
13:13:05.921   Training iter 500, batch loss 0.3165, batch acc 0.8692
13:13:08.206   Training iter 550, batch loss 0.3137, batch acc 0.8710
13:13:10.497   Training iter 600, batch loss 0.3214, batch acc 0.8684
13:13:10.499 Training @ 464 epoch...
13:13:12.804   Training iter 50, batch loss 0.2939, batch acc 0.8796
13:13:15.135   Training iter 100, batch loss 0.3181, batch acc 0.8706
13:13:17.387   Training iter 150, batch loss 0.2983, batch acc 0.8780
13:13:19.654   Training iter 200, batch loss 0.3133, batch acc 0.8734
13:13:21.944   Training iter 250, batch loss 0.3247, batch acc 0.8678
13:13:24.214   Training iter 300, batch loss 0.3027, batch acc 0.8752
13:13:26.534   Training iter 350, batch loss 0.3064, batch acc 0.8738
13:13:28.847   Training iter 400, batch loss 0.3090, batch acc 0.8736
13:13:31.145   Training iter 450, batch loss 0.3200, batch acc 0.8684
13:13:33.452   Training iter 500, batch loss 0.3376, batch acc 0.8610
13:13:35.774   Training iter 550, batch loss 0.3003, batch acc 0.8794
13:13:38.079   Training iter 600, batch loss 0.3117, batch acc 0.8740
13:13:38.081 Training @ 465 epoch...
13:13:40.359   Training iter 50, batch loss 0.3089, batch acc 0.8750
13:13:42.642   Training iter 100, batch loss 0.3120, batch acc 0.8712
13:13:44.955   Training iter 150, batch loss 0.3094, batch acc 0.8716
13:13:47.273   Training iter 200, batch loss 0.3020, batch acc 0.8776
13:13:49.653   Training iter 250, batch loss 0.2995, batch acc 0.8798
13:13:51.989   Training iter 300, batch loss 0.3279, batch acc 0.8668
13:13:54.283   Training iter 350, batch loss 0.3065, batch acc 0.8760
13:13:56.564   Training iter 400, batch loss 0.3035, batch acc 0.8728
13:13:58.861   Training iter 450, batch loss 0.3109, batch acc 0.8714
13:14:01.238   Training iter 500, batch loss 0.3203, batch acc 0.8692
13:14:03.763   Training iter 550, batch loss 0.3171, batch acc 0.8720
13:14:06.146   Training iter 600, batch loss 0.3084, batch acc 0.8730
13:14:06.147 Testing @ 465 epoch...
13:14:06.201     Testing, total mean loss 0.40362, total acc 0.84960
13:14:06.201 Training @ 466 epoch...
13:14:08.499   Training iter 50, batch loss 0.3028, batch acc 0.8758
13:14:10.752   Training iter 100, batch loss 0.3127, batch acc 0.8712
13:14:13.026   Training iter 150, batch loss 0.3218, batch acc 0.8688
13:14:15.303   Training iter 200, batch loss 0.3228, batch acc 0.8698
13:14:17.587   Training iter 250, batch loss 0.3001, batch acc 0.8772
13:14:19.896   Training iter 300, batch loss 0.3094, batch acc 0.8750
13:14:22.231   Training iter 350, batch loss 0.3047, batch acc 0.8750
13:14:24.593   Training iter 400, batch loss 0.3061, batch acc 0.8748
13:14:27.104   Training iter 450, batch loss 0.2969, batch acc 0.8782
13:14:29.488   Training iter 500, batch loss 0.3213, batch acc 0.8690
13:14:31.956   Training iter 550, batch loss 0.3109, batch acc 0.8718
13:14:34.249   Training iter 600, batch loss 0.3261, batch acc 0.8672
13:14:34.251 Training @ 467 epoch...
13:14:36.569   Training iter 50, batch loss 0.3109, batch acc 0.8752
13:14:38.919   Training iter 100, batch loss 0.2994, batch acc 0.8774
13:14:41.282   Training iter 150, batch loss 0.3168, batch acc 0.8706
13:14:43.695   Training iter 200, batch loss 0.3108, batch acc 0.8710
13:14:46.064   Training iter 250, batch loss 0.3060, batch acc 0.8754
13:14:48.361   Training iter 300, batch loss 0.3172, batch acc 0.8702
13:14:50.640   Training iter 350, batch loss 0.3152, batch acc 0.8714
13:14:52.918   Training iter 400, batch loss 0.2957, batch acc 0.8794
13:14:55.261   Training iter 450, batch loss 0.3205, batch acc 0.8692
13:14:57.537   Training iter 500, batch loss 0.3106, batch acc 0.8734
13:14:59.811   Training iter 550, batch loss 0.3120, batch acc 0.8720
13:15:02.187   Training iter 600, batch loss 0.3141, batch acc 0.8716
13:15:02.189 Training @ 468 epoch...
13:15:04.523   Training iter 50, batch loss 0.3158, batch acc 0.8702
13:15:06.830   Training iter 100, batch loss 0.3270, batch acc 0.8644
13:15:09.118   Training iter 150, batch loss 0.3101, batch acc 0.8738
13:15:11.396   Training iter 200, batch loss 0.2989, batch acc 0.8794
13:15:13.658   Training iter 250, batch loss 0.3199, batch acc 0.8688
13:15:15.926   Training iter 300, batch loss 0.3009, batch acc 0.8776
13:15:18.200   Training iter 350, batch loss 0.3112, batch acc 0.8734
13:15:20.481   Training iter 400, batch loss 0.3109, batch acc 0.8722
13:15:22.818   Training iter 450, batch loss 0.3118, batch acc 0.8718
13:15:25.128   Training iter 500, batch loss 0.3072, batch acc 0.8738
13:15:27.446   Training iter 550, batch loss 0.3122, batch acc 0.8754
13:15:29.799   Training iter 600, batch loss 0.3048, batch acc 0.8746
13:15:29.800 Training @ 469 epoch...
13:15:32.083   Training iter 50, batch loss 0.2961, batch acc 0.8770
13:15:34.377   Training iter 100, batch loss 0.2987, batch acc 0.8798
13:15:36.668   Training iter 150, batch loss 0.3147, batch acc 0.8716
13:15:38.954   Training iter 200, batch loss 0.3008, batch acc 0.8764
13:15:41.233   Training iter 250, batch loss 0.2962, batch acc 0.8806
13:15:43.529   Training iter 300, batch loss 0.3009, batch acc 0.8794
13:15:45.828   Training iter 350, batch loss 0.3104, batch acc 0.8724
13:15:48.153   Training iter 400, batch loss 0.3186, batch acc 0.8692
13:15:50.429   Training iter 450, batch loss 0.3425, batch acc 0.8606
13:15:52.718   Training iter 500, batch loss 0.3234, batch acc 0.8704
13:15:55.052   Training iter 550, batch loss 0.2965, batch acc 0.8762
13:15:57.404   Training iter 600, batch loss 0.3266, batch acc 0.8668
13:15:57.406 Training @ 470 epoch...
13:15:59.697   Training iter 50, batch loss 0.3120, batch acc 0.8716
13:16:01.988   Training iter 100, batch loss 0.3086, batch acc 0.8736
13:16:04.291   Training iter 150, batch loss 0.3103, batch acc 0.8746
13:16:06.605   Training iter 200, batch loss 0.3213, batch acc 0.8698
13:16:08.893   Training iter 250, batch loss 0.3051, batch acc 0.8782
13:16:11.185   Training iter 300, batch loss 0.3257, batch acc 0.8688
13:16:13.447   Training iter 350, batch loss 0.3010, batch acc 0.8792
13:16:15.706   Training iter 400, batch loss 0.3201, batch acc 0.8696
13:16:17.973   Training iter 450, batch loss 0.3097, batch acc 0.8704
13:16:20.253   Training iter 500, batch loss 0.2959, batch acc 0.8784
13:16:22.600   Training iter 550, batch loss 0.3061, batch acc 0.8750
13:16:25.036   Training iter 600, batch loss 0.3066, batch acc 0.8748
13:16:25.038 Testing @ 470 epoch...
13:16:25.095     Testing, total mean loss 0.39598, total acc 0.85140
13:16:25.095 Training @ 471 epoch...
13:16:27.578   Training iter 50, batch loss 0.3063, batch acc 0.8734
13:16:30.041   Training iter 100, batch loss 0.3042, batch acc 0.8752
13:16:32.477   Training iter 150, batch loss 0.3050, batch acc 0.8758
13:16:34.914   Training iter 200, batch loss 0.2970, batch acc 0.8784
13:16:37.373   Training iter 250, batch loss 0.3094, batch acc 0.8736
13:16:39.854   Training iter 300, batch loss 0.3247, batch acc 0.8668
13:16:42.305   Training iter 350, batch loss 0.3258, batch acc 0.8664
13:16:44.584   Training iter 400, batch loss 0.3141, batch acc 0.8708
13:16:46.837   Training iter 450, batch loss 0.3060, batch acc 0.8752
13:16:49.089   Training iter 500, batch loss 0.3113, batch acc 0.8718
13:16:51.387   Training iter 550, batch loss 0.3230, batch acc 0.8700
13:16:53.694   Training iter 600, batch loss 0.3058, batch acc 0.8776
13:16:53.695 Training @ 472 epoch...
13:16:56.013   Training iter 50, batch loss 0.3181, batch acc 0.8708
13:16:58.285   Training iter 100, batch loss 0.2968, batch acc 0.8788
13:17:00.550   Training iter 150, batch loss 0.3348, batch acc 0.8636
13:17:02.843   Training iter 200, batch loss 0.3232, batch acc 0.8682
13:17:05.180   Training iter 250, batch loss 0.3133, batch acc 0.8734
13:17:07.515   Training iter 300, batch loss 0.3004, batch acc 0.8766
13:17:09.785   Training iter 350, batch loss 0.3143, batch acc 0.8738
13:17:12.043   Training iter 400, batch loss 0.3094, batch acc 0.8728
13:17:14.309   Training iter 450, batch loss 0.3166, batch acc 0.8692
13:17:16.561   Training iter 500, batch loss 0.2979, batch acc 0.8780
13:17:18.811   Training iter 550, batch loss 0.3073, batch acc 0.8746
13:17:21.065   Training iter 600, batch loss 0.3088, batch acc 0.8746
13:17:21.067 Training @ 473 epoch...
13:17:23.355   Training iter 50, batch loss 0.3022, batch acc 0.8772
13:17:25.616   Training iter 100, batch loss 0.3173, batch acc 0.8680
13:17:27.997   Training iter 150, batch loss 0.3115, batch acc 0.8708
13:17:30.334   Training iter 200, batch loss 0.3215, batch acc 0.8690
13:17:32.596   Training iter 250, batch loss 0.3279, batch acc 0.8668
13:17:34.912   Training iter 300, batch loss 0.3050, batch acc 0.8752
13:17:37.167   Training iter 350, batch loss 0.2931, batch acc 0.8814
13:17:39.499   Training iter 400, batch loss 0.2943, batch acc 0.8792
13:17:41.815   Training iter 450, batch loss 0.3023, batch acc 0.8754
13:17:44.074   Training iter 500, batch loss 0.3222, batch acc 0.8694
13:17:46.330   Training iter 550, batch loss 0.3095, batch acc 0.8732
13:17:48.578   Training iter 600, batch loss 0.3184, batch acc 0.8706
13:17:48.580 Training @ 474 epoch...
13:17:50.837   Training iter 50, batch loss 0.3146, batch acc 0.8730
13:17:53.124   Training iter 100, batch loss 0.2825, batch acc 0.8842
13:17:55.395   Training iter 150, batch loss 0.3142, batch acc 0.8716
13:17:57.698   Training iter 200, batch loss 0.3236, batch acc 0.8688
13:17:59.988   Training iter 250, batch loss 0.3099, batch acc 0.8754
13:18:02.285   Training iter 300, batch loss 0.3171, batch acc 0.8708
13:18:04.558   Training iter 350, batch loss 0.3035, batch acc 0.8746
13:18:06.818   Training iter 400, batch loss 0.3044, batch acc 0.8738
13:18:09.104   Training iter 450, batch loss 0.3302, batch acc 0.8654
13:18:11.357   Training iter 500, batch loss 0.3176, batch acc 0.8718
13:18:13.606   Training iter 550, batch loss 0.3194, batch acc 0.8674
13:18:15.890   Training iter 600, batch loss 0.2947, batch acc 0.8778
13:18:15.892 Training @ 475 epoch...
13:18:18.177   Training iter 50, batch loss 0.2897, batch acc 0.8826
13:18:20.463   Training iter 100, batch loss 0.3142, batch acc 0.8716
13:18:22.767   Training iter 150, batch loss 0.2982, batch acc 0.8780
13:18:25.075   Training iter 200, batch loss 0.3189, batch acc 0.8714
13:18:27.374   Training iter 250, batch loss 0.3277, batch acc 0.8678
13:18:29.674   Training iter 300, batch loss 0.3160, batch acc 0.8696
13:18:31.987   Training iter 350, batch loss 0.2982, batch acc 0.8772
13:18:34.285   Training iter 400, batch loss 0.3097, batch acc 0.8728
13:18:36.557   Training iter 450, batch loss 0.3125, batch acc 0.8712
13:18:38.818   Training iter 500, batch loss 0.3228, batch acc 0.8676
13:18:41.068   Training iter 550, batch loss 0.3093, batch acc 0.8724
13:18:43.313   Training iter 600, batch loss 0.3220, batch acc 0.8686
13:18:43.315 Testing @ 475 epoch...
13:18:43.365     Testing, total mean loss 0.40032, total acc 0.85060
13:18:43.365 Training @ 476 epoch...
13:18:45.617   Training iter 50, batch loss 0.3044, batch acc 0.8746
13:18:47.893   Training iter 100, batch loss 0.3261, batch acc 0.8658
13:18:50.150   Training iter 150, batch loss 0.3024, batch acc 0.8766
13:18:52.428   Training iter 200, batch loss 0.3183, batch acc 0.8712
13:18:54.684   Training iter 250, batch loss 0.2928, batch acc 0.8808
13:18:56.975   Training iter 300, batch loss 0.3155, batch acc 0.8692
13:18:59.265   Training iter 350, batch loss 0.3119, batch acc 0.8714
13:19:01.508   Training iter 400, batch loss 0.3152, batch acc 0.8700
13:19:03.833   Training iter 450, batch loss 0.3218, batch acc 0.8702
13:19:06.185   Training iter 500, batch loss 0.2985, batch acc 0.8776
13:19:08.443   Training iter 550, batch loss 0.3339, batch acc 0.8644
13:19:10.702   Training iter 600, batch loss 0.3031, batch acc 0.8758
13:19:10.703 Training @ 477 epoch...
13:19:12.954   Training iter 50, batch loss 0.2963, batch acc 0.8770
13:19:15.208   Training iter 100, batch loss 0.3161, batch acc 0.8698
13:19:17.469   Training iter 150, batch loss 0.3047, batch acc 0.8764
13:19:19.732   Training iter 200, batch loss 0.3124, batch acc 0.8714
13:19:21.997   Training iter 250, batch loss 0.3164, batch acc 0.8698
13:19:24.258   Training iter 300, batch loss 0.3128, batch acc 0.8708
13:19:26.556   Training iter 350, batch loss 0.2932, batch acc 0.8796
13:19:28.833   Training iter 400, batch loss 0.3220, batch acc 0.8694
13:19:31.095   Training iter 450, batch loss 0.3212, batch acc 0.8682
13:19:33.352   Training iter 500, batch loss 0.3240, batch acc 0.8696
13:19:35.623   Training iter 550, batch loss 0.3146, batch acc 0.8726
13:19:37.889   Training iter 600, batch loss 0.2996, batch acc 0.8760
13:19:37.891 Training @ 478 epoch...
13:19:40.161   Training iter 50, batch loss 0.3108, batch acc 0.8726
13:19:42.418   Training iter 100, batch loss 0.2975, batch acc 0.8810
13:19:44.680   Training iter 150, batch loss 0.2866, batch acc 0.8820
13:19:47.092   Training iter 200, batch loss 0.3171, batch acc 0.8706
13:19:49.514   Training iter 250, batch loss 0.3219, batch acc 0.8686
13:19:51.903   Training iter 300, batch loss 0.3301, batch acc 0.8642
13:19:54.438   Training iter 350, batch loss 0.3278, batch acc 0.8640
13:19:56.850   Training iter 400, batch loss 0.2968, batch acc 0.8778
13:19:59.117   Training iter 450, batch loss 0.3163, batch acc 0.8698
13:20:01.407   Training iter 500, batch loss 0.3164, batch acc 0.8730
13:20:03.686   Training iter 550, batch loss 0.3062, batch acc 0.8768
13:20:05.950   Training iter 600, batch loss 0.3084, batch acc 0.8746
13:20:05.952 Training @ 479 epoch...
13:20:08.224   Training iter 50, batch loss 0.3112, batch acc 0.8706
13:20:10.492   Training iter 100, batch loss 0.3052, batch acc 0.8762
13:20:12.764   Training iter 150, batch loss 0.3054, batch acc 0.8750
13:20:15.025   Training iter 200, batch loss 0.3193, batch acc 0.8682
13:20:17.316   Training iter 250, batch loss 0.3031, batch acc 0.8758
13:20:19.607   Training iter 300, batch loss 0.3385, batch acc 0.8596
13:20:21.844   Training iter 350, batch loss 0.3064, batch acc 0.8752
13:20:24.103   Training iter 400, batch loss 0.3014, batch acc 0.8762
13:20:26.388   Training iter 450, batch loss 0.3288, batch acc 0.8642
13:20:28.674   Training iter 500, batch loss 0.3039, batch acc 0.8768
13:20:30.927   Training iter 550, batch loss 0.3004, batch acc 0.8782
13:20:33.173   Training iter 600, batch loss 0.3056, batch acc 0.8752
13:20:33.175 Training @ 480 epoch...
13:20:35.418   Training iter 50, batch loss 0.3075, batch acc 0.8768
13:20:37.680   Training iter 100, batch loss 0.3189, batch acc 0.8690
13:20:40.006   Training iter 150, batch loss 0.3145, batch acc 0.8714
13:20:42.279   Training iter 200, batch loss 0.3172, batch acc 0.8702
13:20:44.553   Training iter 250, batch loss 0.2986, batch acc 0.8788
13:20:46.828   Training iter 300, batch loss 0.3051, batch acc 0.8754
13:20:49.102   Training iter 350, batch loss 0.3183, batch acc 0.8686
13:20:51.356   Training iter 400, batch loss 0.3009, batch acc 0.8772
13:20:53.589   Training iter 450, batch loss 0.3061, batch acc 0.8738
13:20:55.828   Training iter 500, batch loss 0.3173, batch acc 0.8700
13:20:58.094   Training iter 550, batch loss 0.3064, batch acc 0.8754
13:21:00.363   Training iter 600, batch loss 0.3227, batch acc 0.8682
13:21:00.365 Testing @ 480 epoch...
13:21:00.415     Testing, total mean loss 0.39541, total acc 0.85220
13:21:00.415 Training @ 481 epoch...
13:21:02.718   Training iter 50, batch loss 0.3259, batch acc 0.8664
13:21:04.990   Training iter 100, batch loss 0.3004, batch acc 0.8778
13:21:07.246   Training iter 150, batch loss 0.3164, batch acc 0.8708
13:21:09.487   Training iter 200, batch loss 0.2994, batch acc 0.8782
13:21:11.726   Training iter 250, batch loss 0.3191, batch acc 0.8698
13:21:13.986   Training iter 300, batch loss 0.3135, batch acc 0.8736
13:21:16.275   Training iter 350, batch loss 0.3087, batch acc 0.8758
13:21:18.553   Training iter 400, batch loss 0.3177, batch acc 0.8690
13:21:20.805   Training iter 450, batch loss 0.3161, batch acc 0.8696
13:21:23.043   Training iter 500, batch loss 0.3162, batch acc 0.8708
13:21:25.277   Training iter 550, batch loss 0.3075, batch acc 0.8750
13:21:27.536   Training iter 600, batch loss 0.2918, batch acc 0.8788
13:21:27.537 Training @ 482 epoch...
13:21:29.809   Training iter 50, batch loss 0.2994, batch acc 0.8770
13:21:32.086   Training iter 100, batch loss 0.2939, batch acc 0.8806
13:21:34.361   Training iter 150, batch loss 0.3058, batch acc 0.8742
13:21:36.632   Training iter 200, batch loss 0.3101, batch acc 0.8734
13:21:38.884   Training iter 250, batch loss 0.3007, batch acc 0.8768
13:21:41.147   Training iter 300, batch loss 0.3189, batch acc 0.8728
13:21:43.429   Training iter 350, batch loss 0.3007, batch acc 0.8772
13:21:45.716   Training iter 400, batch loss 0.3308, batch acc 0.8676
13:21:48.035   Training iter 450, batch loss 0.3199, batch acc 0.8694
13:21:50.362   Training iter 500, batch loss 0.3163, batch acc 0.8706
13:21:52.611   Training iter 550, batch loss 0.3193, batch acc 0.8676
13:21:54.898   Training iter 600, batch loss 0.3230, batch acc 0.8670
13:21:54.900 Training @ 483 epoch...
13:21:57.161   Training iter 50, batch loss 0.3096, batch acc 0.8734
13:21:59.409   Training iter 100, batch loss 0.3148, batch acc 0.8720
13:22:01.659   Training iter 150, batch loss 0.3019, batch acc 0.8784
13:22:03.941   Training iter 200, batch loss 0.3026, batch acc 0.8750
13:22:06.234   Training iter 250, batch loss 0.3193, batch acc 0.8704
13:22:08.529   Training iter 300, batch loss 0.3134, batch acc 0.8716
13:22:10.810   Training iter 350, batch loss 0.3255, batch acc 0.8668
13:22:13.104   Training iter 400, batch loss 0.2949, batch acc 0.8770
13:22:15.401   Training iter 450, batch loss 0.3110, batch acc 0.8734
13:22:17.766   Training iter 500, batch loss 0.3120, batch acc 0.8706
13:22:20.045   Training iter 550, batch loss 0.3073, batch acc 0.8766
13:22:22.341   Training iter 600, batch loss 0.3205, batch acc 0.8678
13:22:22.343 Training @ 484 epoch...
13:22:24.629   Training iter 50, batch loss 0.3119, batch acc 0.8738
13:22:26.878   Training iter 100, batch loss 0.2971, batch acc 0.8796
13:22:29.133   Training iter 150, batch loss 0.3074, batch acc 0.8738
13:22:31.399   Training iter 200, batch loss 0.3106, batch acc 0.8746
13:22:33.662   Training iter 250, batch loss 0.3260, batch acc 0.8664
13:22:35.958   Training iter 300, batch loss 0.3032, batch acc 0.8768
13:22:38.234   Training iter 350, batch loss 0.2936, batch acc 0.8822
13:22:40.497   Training iter 400, batch loss 0.3252, batch acc 0.8682
13:22:42.759   Training iter 450, batch loss 0.3307, batch acc 0.8682
13:22:45.033   Training iter 500, batch loss 0.3080, batch acc 0.8746
13:22:47.298   Training iter 550, batch loss 0.2966, batch acc 0.8774
13:22:49.739   Training iter 600, batch loss 0.3219, batch acc 0.8698
13:22:49.741 Training @ 485 epoch...
13:22:52.300   Training iter 50, batch loss 0.2930, batch acc 0.8822
13:22:54.546   Training iter 100, batch loss 0.3106, batch acc 0.8744
13:22:56.808   Training iter 150, batch loss 0.3020, batch acc 0.8764
13:22:59.086   Training iter 200, batch loss 0.3247, batch acc 0.8676
13:23:01.388   Training iter 250, batch loss 0.3192, batch acc 0.8690
13:23:03.651   Training iter 300, batch loss 0.3205, batch acc 0.8690
13:23:05.906   Training iter 350, batch loss 0.3118, batch acc 0.8730
13:23:08.216   Training iter 400, batch loss 0.2929, batch acc 0.8800
13:23:10.527   Training iter 450, batch loss 0.3090, batch acc 0.8738
13:23:12.813   Training iter 500, batch loss 0.3141, batch acc 0.8730
13:23:15.082   Training iter 550, batch loss 0.3209, batch acc 0.8682
13:23:17.375   Training iter 600, batch loss 0.3071, batch acc 0.8734
13:23:17.377 Testing @ 485 epoch...
13:23:17.431     Testing, total mean loss 0.39502, total acc 0.85110
13:23:17.431 Training @ 486 epoch...
13:23:19.761   Training iter 50, batch loss 0.2972, batch acc 0.8782
13:23:22.080   Training iter 100, batch loss 0.3151, batch acc 0.8702
13:23:24.379   Training iter 150, batch loss 0.3081, batch acc 0.8720
13:23:26.650   Training iter 200, batch loss 0.3308, batch acc 0.8636
13:23:28.944   Training iter 250, batch loss 0.2900, batch acc 0.8838
13:23:31.212   Training iter 300, batch loss 0.3031, batch acc 0.8764
13:23:33.561   Training iter 350, batch loss 0.2997, batch acc 0.8764
13:23:35.827   Training iter 400, batch loss 0.3259, batch acc 0.8662
13:23:38.095   Training iter 450, batch loss 0.3152, batch acc 0.8722
13:23:40.356   Training iter 500, batch loss 0.3206, batch acc 0.8704
13:23:42.680   Training iter 550, batch loss 0.3107, batch acc 0.8730
13:23:45.013   Training iter 600, batch loss 0.3190, batch acc 0.8696
13:23:45.014 Training @ 487 epoch...
13:23:47.340   Training iter 50, batch loss 0.2999, batch acc 0.8778
13:23:49.617   Training iter 100, batch loss 0.3079, batch acc 0.8732
13:23:51.884   Training iter 150, batch loss 0.3100, batch acc 0.8728
13:23:54.159   Training iter 200, batch loss 0.2996, batch acc 0.8802
13:23:56.484   Training iter 250, batch loss 0.3129, batch acc 0.8704
13:23:58.762   Training iter 300, batch loss 0.3137, batch acc 0.8708
13:24:01.036   Training iter 350, batch loss 0.3058, batch acc 0.8746
13:24:03.316   Training iter 400, batch loss 0.3288, batch acc 0.8670
13:24:05.623   Training iter 450, batch loss 0.2911, batch acc 0.8804
13:24:07.905   Training iter 500, batch loss 0.3165, batch acc 0.8704
13:24:10.188   Training iter 550, batch loss 0.3232, batch acc 0.8682
13:24:12.447   Training iter 600, batch loss 0.3195, batch acc 0.8714
13:24:12.449 Training @ 488 epoch...
13:24:14.714   Training iter 50, batch loss 0.2979, batch acc 0.8782
13:24:16.976   Training iter 100, batch loss 0.3072, batch acc 0.8726
13:24:19.265   Training iter 150, batch loss 0.3140, batch acc 0.8728
13:24:21.537   Training iter 200, batch loss 0.3058, batch acc 0.8762
13:24:23.806   Training iter 250, batch loss 0.3090, batch acc 0.8732
13:24:26.133   Training iter 300, batch loss 0.3145, batch acc 0.8728
13:24:28.483   Training iter 350, batch loss 0.3170, batch acc 0.8704
13:24:30.834   Training iter 400, batch loss 0.3023, batch acc 0.8774
13:24:33.149   Training iter 450, batch loss 0.3069, batch acc 0.8736
13:24:35.445   Training iter 500, batch loss 0.3131, batch acc 0.8728
13:24:37.738   Training iter 550, batch loss 0.3201, batch acc 0.8670
13:24:39.998   Training iter 600, batch loss 0.3202, batch acc 0.8698
13:24:40.001 Training @ 489 epoch...
13:24:42.265   Training iter 50, batch loss 0.3133, batch acc 0.8704
13:24:44.539   Training iter 100, batch loss 0.3010, batch acc 0.8776
13:24:46.877   Training iter 150, batch loss 0.3182, batch acc 0.8712
13:24:49.190   Training iter 200, batch loss 0.3037, batch acc 0.8774
13:24:51.449   Training iter 250, batch loss 0.3252, batch acc 0.8682
13:24:53.699   Training iter 300, batch loss 0.3014, batch acc 0.8772
13:24:55.950   Training iter 350, batch loss 0.3077, batch acc 0.8724
13:24:58.239   Training iter 400, batch loss 0.3064, batch acc 0.8728
13:25:00.595   Training iter 450, batch loss 0.3067, batch acc 0.8756
13:25:02.898   Training iter 500, batch loss 0.3129, batch acc 0.8720
13:25:05.243   Training iter 550, batch loss 0.3166, batch acc 0.8726
13:25:07.547   Training iter 600, batch loss 0.3142, batch acc 0.8710
13:25:07.549 Training @ 490 epoch...
13:25:09.851   Training iter 50, batch loss 0.3337, batch acc 0.8628
13:25:12.156   Training iter 100, batch loss 0.3131, batch acc 0.8702
13:25:14.502   Training iter 150, batch loss 0.3129, batch acc 0.8718
13:25:16.766   Training iter 200, batch loss 0.2990, batch acc 0.8790
13:25:19.100   Training iter 250, batch loss 0.3017, batch acc 0.8756
13:25:21.418   Training iter 300, batch loss 0.3246, batch acc 0.8668
13:25:23.720   Training iter 350, batch loss 0.2983, batch acc 0.8784
13:25:26.032   Training iter 400, batch loss 0.3192, batch acc 0.8670
13:25:28.354   Training iter 450, batch loss 0.2870, batch acc 0.8832
13:25:30.675   Training iter 500, batch loss 0.2989, batch acc 0.8766
13:25:33.006   Training iter 550, batch loss 0.3282, batch acc 0.8646
13:25:35.343   Training iter 600, batch loss 0.3199, batch acc 0.8690
13:25:35.345 Testing @ 490 epoch...
13:25:35.398     Testing, total mean loss 0.40093, total acc 0.85120
13:25:35.398 Training @ 491 epoch...
13:25:37.788   Training iter 50, batch loss 0.2929, batch acc 0.8802
13:25:40.201   Training iter 100, batch loss 0.3102, batch acc 0.8758
13:25:42.609   Training iter 150, batch loss 0.3030, batch acc 0.8762
13:25:44.978   Training iter 200, batch loss 0.3237, batch acc 0.8670
13:25:47.333   Training iter 250, batch loss 0.3239, batch acc 0.8674
13:25:49.662   Training iter 300, batch loss 0.3072, batch acc 0.8732
13:25:52.034   Training iter 350, batch loss 0.3117, batch acc 0.8708
13:25:54.345   Training iter 400, batch loss 0.3237, batch acc 0.8676
13:25:56.640   Training iter 450, batch loss 0.3166, batch acc 0.8690
13:25:58.937   Training iter 500, batch loss 0.2939, batch acc 0.8776
13:26:01.236   Training iter 550, batch loss 0.3234, batch acc 0.8684
13:26:03.551   Training iter 600, batch loss 0.3042, batch acc 0.8780
13:26:03.553 Training @ 492 epoch...
13:26:05.866   Training iter 50, batch loss 0.3041, batch acc 0.8756
13:26:08.181   Training iter 100, batch loss 0.3247, batch acc 0.8686
13:26:10.464   Training iter 150, batch loss 0.2995, batch acc 0.8772
13:26:12.749   Training iter 200, batch loss 0.3080, batch acc 0.8728
13:26:15.048   Training iter 250, batch loss 0.3056, batch acc 0.8760
13:26:17.348   Training iter 300, batch loss 0.3144, batch acc 0.8706
13:26:19.695   Training iter 350, batch loss 0.3169, batch acc 0.8710
13:26:22.154   Training iter 400, batch loss 0.3084, batch acc 0.8738
13:26:24.655   Training iter 450, batch loss 0.2931, batch acc 0.8796
13:26:27.041   Training iter 500, batch loss 0.3092, batch acc 0.8736
13:26:29.522   Training iter 550, batch loss 0.3252, batch acc 0.8688
13:26:32.041   Training iter 600, batch loss 0.3190, batch acc 0.8720
13:26:32.043 Training @ 493 epoch...
13:26:34.512   Training iter 50, batch loss 0.3034, batch acc 0.8772
13:26:36.896   Training iter 100, batch loss 0.3353, batch acc 0.8616
13:26:39.271   Training iter 150, batch loss 0.3057, batch acc 0.8762
13:26:41.554   Training iter 200, batch loss 0.3093, batch acc 0.8728
13:26:43.840   Training iter 250, batch loss 0.3275, batch acc 0.8648
13:26:46.134   Training iter 300, batch loss 0.3171, batch acc 0.8694
13:26:48.454   Training iter 350, batch loss 0.3149, batch acc 0.8710
13:26:50.746   Training iter 400, batch loss 0.3026, batch acc 0.8780
13:26:53.049   Training iter 450, batch loss 0.3058, batch acc 0.8752
13:26:55.354   Training iter 500, batch loss 0.3021, batch acc 0.8750
13:26:57.654   Training iter 550, batch loss 0.3025, batch acc 0.8758
13:26:59.941   Training iter 600, batch loss 0.3116, batch acc 0.8746
13:26:59.942 Training @ 494 epoch...
13:27:02.250   Training iter 50, batch loss 0.3051, batch acc 0.8758
13:27:04.555   Training iter 100, batch loss 0.3228, batch acc 0.8676
13:27:06.863   Training iter 150, batch loss 0.3156, batch acc 0.8700
13:27:09.171   Training iter 200, batch loss 0.3190, batch acc 0.8722
13:27:11.475   Training iter 250, batch loss 0.3093, batch acc 0.8720
13:27:13.772   Training iter 300, batch loss 0.2955, batch acc 0.8786
13:27:16.068   Training iter 350, batch loss 0.2961, batch acc 0.8786
13:27:18.359   Training iter 400, batch loss 0.3250, batch acc 0.8654
13:27:20.643   Training iter 450, batch loss 0.3252, batch acc 0.8700
13:27:22.926   Training iter 500, batch loss 0.3114, batch acc 0.8732
13:27:25.312   Training iter 550, batch loss 0.2944, batch acc 0.8794
13:27:27.620   Training iter 600, batch loss 0.3078, batch acc 0.8766
13:27:27.622 Training @ 495 epoch...
13:27:29.929   Training iter 50, batch loss 0.2982, batch acc 0.8794
13:27:32.267   Training iter 100, batch loss 0.2957, batch acc 0.8784
13:27:34.583   Training iter 150, batch loss 0.3100, batch acc 0.8738
13:27:36.850   Training iter 200, batch loss 0.3318, batch acc 0.8648
13:27:39.113   Training iter 250, batch loss 0.3061, batch acc 0.8750
13:27:41.414   Training iter 300, batch loss 0.3194, batch acc 0.8690
13:27:43.785   Training iter 350, batch loss 0.3054, batch acc 0.8770
13:27:46.165   Training iter 400, batch loss 0.3236, batch acc 0.8664
13:27:48.528   Training iter 450, batch loss 0.3002, batch acc 0.8746
13:27:50.790   Training iter 500, batch loss 0.3053, batch acc 0.8732
13:27:53.056   Training iter 550, batch loss 0.3188, batch acc 0.8700
13:27:55.321   Training iter 600, batch loss 0.3081, batch acc 0.8754
13:27:55.323 Testing @ 495 epoch...
13:27:55.374     Testing, total mean loss 0.41373, total acc 0.84440
13:27:55.374 Training @ 496 epoch...
13:27:57.650   Training iter 50, batch loss 0.3055, batch acc 0.8768
13:27:59.917   Training iter 100, batch loss 0.3203, batch acc 0.8672
13:28:02.197   Training iter 150, batch loss 0.3151, batch acc 0.8726
13:28:04.448   Training iter 200, batch loss 0.3052, batch acc 0.8782
13:28:06.703   Training iter 250, batch loss 0.2858, batch acc 0.8832
13:28:08.950   Training iter 300, batch loss 0.2991, batch acc 0.8804
13:28:11.198   Training iter 350, batch loss 0.3134, batch acc 0.8712
13:28:13.445   Training iter 400, batch loss 0.3137, batch acc 0.8718
13:28:15.722   Training iter 450, batch loss 0.3100, batch acc 0.8728
13:28:18.250   Training iter 500, batch loss 0.3108, batch acc 0.8740
13:28:20.524   Training iter 550, batch loss 0.3194, batch acc 0.8692
13:28:22.781   Training iter 600, batch loss 0.3412, batch acc 0.8602
13:28:22.783 Training @ 497 epoch...
13:28:25.038   Training iter 50, batch loss 0.3021, batch acc 0.8762
13:28:27.329   Training iter 100, batch loss 0.3063, batch acc 0.8736
13:28:29.584   Training iter 150, batch loss 0.3231, batch acc 0.8684
13:28:31.853   Training iter 200, batch loss 0.2957, batch acc 0.8790
13:28:34.128   Training iter 250, batch loss 0.3084, batch acc 0.8750
13:28:36.425   Training iter 300, batch loss 0.3070, batch acc 0.8738
13:28:38.743   Training iter 350, batch loss 0.3115, batch acc 0.8744
13:28:40.994   Training iter 400, batch loss 0.3275, batch acc 0.8658
13:28:43.234   Training iter 450, batch loss 0.3005, batch acc 0.8762
13:28:45.499   Training iter 500, batch loss 0.3171, batch acc 0.8694
13:28:47.762   Training iter 550, batch loss 0.3005, batch acc 0.8772
13:28:50.014   Training iter 600, batch loss 0.3263, batch acc 0.8686
13:28:50.016 Training @ 498 epoch...
13:28:52.257   Training iter 50, batch loss 0.2957, batch acc 0.8802
13:28:54.491   Training iter 100, batch loss 0.3125, batch acc 0.8732
13:28:56.798   Training iter 150, batch loss 0.2990, batch acc 0.8774
13:28:59.117   Training iter 200, batch loss 0.3059, batch acc 0.8748
13:29:01.559   Training iter 250, batch loss 0.3240, batch acc 0.8672
13:29:04.384   Training iter 300, batch loss 0.3285, batch acc 0.8656
13:29:06.657   Training iter 350, batch loss 0.3217, batch acc 0.8682
13:29:08.896   Training iter 400, batch loss 0.3001, batch acc 0.8768
13:29:11.148   Training iter 450, batch loss 0.3051, batch acc 0.8748
13:29:13.405   Training iter 500, batch loss 0.3262, batch acc 0.8654
13:29:15.649   Training iter 550, batch loss 0.2980, batch acc 0.8768
13:29:17.900   Training iter 600, batch loss 0.3106, batch acc 0.8734
13:29:17.901 Training @ 499 epoch...
13:29:20.156   Training iter 50, batch loss 0.2983, batch acc 0.8774
13:29:22.423   Training iter 100, batch loss 0.3065, batch acc 0.8766
13:29:24.701   Training iter 150, batch loss 0.3066, batch acc 0.8740
13:29:27.002   Training iter 200, batch loss 0.3154, batch acc 0.8722
13:29:29.280   Training iter 250, batch loss 0.3188, batch acc 0.8702
13:29:31.559   Training iter 300, batch loss 0.3114, batch acc 0.8720
13:29:33.827   Training iter 350, batch loss 0.3193, batch acc 0.8718
13:29:36.093   Training iter 400, batch loss 0.3098, batch acc 0.8738
13:29:38.352   Training iter 450, batch loss 0.2918, batch acc 0.8794
13:29:40.609   Training iter 500, batch loss 0.2975, batch acc 0.8790
13:29:42.856   Training iter 550, batch loss 0.3280, batch acc 0.8652
13:29:45.126   Training iter 600, batch loss 0.3210, batch acc 0.8704
======================================================
13:29:45.128 Testing @ final epoch...
13:29:45.179     Testing, total mean loss 0.39898, total acc 0.85050
training time: 13838 seconds
