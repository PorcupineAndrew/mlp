======================================================
learning_rate: 0.1
weight_decay: 0.0001
momentum: 0.1
batch_size: 100
max_epoch: 500
disp_freq: 50
test_epoch: 5
plot_epoch: 100
network: Lin-784-10 Relu Lin-10-10 Relu
loss: Euclidean
result dir: ./result/exp_5
======================================================
12:58:18.872 Training @ 0 epoch...
12:58:19.375   Training iter 50, batch loss 0.4977, batch acc 0.0910
12:58:19.868   Training iter 100, batch loss 0.4941, batch acc 0.1032
12:58:20.387   Training iter 150, batch loss 0.4901, batch acc 0.1166
12:58:20.911   Training iter 200, batch loss 0.4864, batch acc 0.1108
12:58:21.426   Training iter 250, batch loss 0.4833, batch acc 0.1088
12:58:21.887   Training iter 300, batch loss 0.4801, batch acc 0.1230
12:58:22.354   Training iter 350, batch loss 0.4773, batch acc 0.1138
12:58:22.829   Training iter 400, batch loss 0.4755, batch acc 0.1112
12:58:23.329   Training iter 450, batch loss 0.4727, batch acc 0.1204
12:58:23.807   Training iter 500, batch loss 0.4706, batch acc 0.1340
12:58:24.296   Training iter 550, batch loss 0.4689, batch acc 0.1346
12:58:24.789   Training iter 600, batch loss 0.4671, batch acc 0.1404
12:58:24.790 Testing @ 0 epoch...
12:58:24.827     Testing, total mean loss 0.46669, total acc 0.16570
12:58:24.827 Plot @ 0 epoch...
12:58:24.827 Training @ 1 epoch...
12:58:25.329   Training iter 50, batch loss 0.4657, batch acc 0.1642
12:58:25.789   Training iter 100, batch loss 0.4648, batch acc 0.1806
12:58:26.265   Training iter 150, batch loss 0.4639, batch acc 0.1970
12:58:26.750   Training iter 200, batch loss 0.4628, batch acc 0.2142
12:58:27.237   Training iter 250, batch loss 0.4620, batch acc 0.2080
12:58:27.705   Training iter 300, batch loss 0.4613, batch acc 0.2146
12:58:28.192   Training iter 350, batch loss 0.4619, batch acc 0.2198
12:58:28.671   Training iter 400, batch loss 0.4610, batch acc 0.2236
12:58:29.167   Training iter 450, batch loss 0.4610, batch acc 0.2212
12:58:29.657   Training iter 500, batch loss 0.4599, batch acc 0.2244
12:58:30.154   Training iter 550, batch loss 0.4602, batch acc 0.2258
12:58:30.652   Training iter 600, batch loss 0.4612, batch acc 0.2250
12:58:30.653 Training @ 2 epoch...
12:58:31.165   Training iter 50, batch loss 0.4595, batch acc 0.2512
12:58:31.675   Training iter 100, batch loss 0.4603, batch acc 0.2462
12:58:32.201   Training iter 150, batch loss 0.4593, batch acc 0.2514
12:58:32.723   Training iter 200, batch loss 0.4594, batch acc 0.2250
12:58:33.228   Training iter 250, batch loss 0.4602, batch acc 0.2266
12:58:33.721   Training iter 300, batch loss 0.4590, batch acc 0.2136
12:58:34.175   Training iter 350, batch loss 0.4593, batch acc 0.2216
12:58:34.641   Training iter 400, batch loss 0.4595, batch acc 0.2244
12:58:35.113   Training iter 450, batch loss 0.4591, batch acc 0.2096
12:58:35.582   Training iter 500, batch loss 0.4591, batch acc 0.2142
12:58:36.087   Training iter 550, batch loss 0.4588, batch acc 0.2228
12:58:36.584   Training iter 600, batch loss 0.4591, batch acc 0.2482
12:58:36.585 Training @ 3 epoch...
12:58:37.101   Training iter 50, batch loss 0.4586, batch acc 0.2436
12:58:37.635   Training iter 100, batch loss 0.4598, batch acc 0.2342
12:58:38.178   Training iter 150, batch loss 0.4583, batch acc 0.2504
12:58:38.698   Training iter 200, batch loss 0.4585, batch acc 0.2498
12:58:39.211   Training iter 250, batch loss 0.4578, batch acc 0.2528
12:58:39.728   Training iter 300, batch loss 0.4570, batch acc 0.2574
12:58:40.255   Training iter 350, batch loss 0.4567, batch acc 0.2582
12:58:40.763   Training iter 400, batch loss 0.4581, batch acc 0.2484
12:58:41.268   Training iter 450, batch loss 0.4573, batch acc 0.2610
12:58:41.770   Training iter 500, batch loss 0.4575, batch acc 0.2576
12:58:42.263   Training iter 550, batch loss 0.4570, batch acc 0.2686
12:58:42.767   Training iter 600, batch loss 0.4564, batch acc 0.2684
12:58:42.769 Training @ 4 epoch...
12:58:43.254   Training iter 50, batch loss 0.4565, batch acc 0.2624
12:58:43.740   Training iter 100, batch loss 0.4556, batch acc 0.2584
12:58:44.223   Training iter 150, batch loss 0.4558, batch acc 0.2656
12:58:44.709   Training iter 200, batch loss 0.4564, batch acc 0.2560
12:58:45.212   Training iter 250, batch loss 0.4561, batch acc 0.2604
12:58:45.727   Training iter 300, batch loss 0.4551, batch acc 0.2682
12:58:46.240   Training iter 350, batch loss 0.4554, batch acc 0.2686
12:58:46.756   Training iter 400, batch loss 0.4544, batch acc 0.2772
12:58:47.255   Training iter 450, batch loss 0.4544, batch acc 0.2804
12:58:47.771   Training iter 500, batch loss 0.4545, batch acc 0.2742
12:58:48.282   Training iter 550, batch loss 0.4541, batch acc 0.2792
12:58:48.785   Training iter 600, batch loss 0.4542, batch acc 0.2746
12:58:48.786 Training @ 5 epoch...
12:58:49.305   Training iter 50, batch loss 0.4534, batch acc 0.2774
12:58:49.827   Training iter 100, batch loss 0.4531, batch acc 0.2720
12:58:50.352   Training iter 150, batch loss 0.4516, batch acc 0.2936
12:58:50.860   Training iter 200, batch loss 0.4523, batch acc 0.2996
12:58:51.368   Training iter 250, batch loss 0.4519, batch acc 0.2924
12:58:51.883   Training iter 300, batch loss 0.4516, batch acc 0.2958
12:58:52.399   Training iter 350, batch loss 0.4513, batch acc 0.2850
12:58:52.915   Training iter 400, batch loss 0.4508, batch acc 0.2994
12:58:53.435   Training iter 450, batch loss 0.4508, batch acc 0.2874
12:58:53.987   Training iter 500, batch loss 0.4507, batch acc 0.2886
12:58:54.538   Training iter 550, batch loss 0.4496, batch acc 0.2938
12:58:55.100   Training iter 600, batch loss 0.4500, batch acc 0.2854
12:58:55.101 Testing @ 5 epoch...
12:58:55.138     Testing, total mean loss 0.44921, total acc 0.28830
12:58:55.139 Training @ 6 epoch...
12:58:55.725   Training iter 50, batch loss 0.4489, batch acc 0.2930
12:58:56.315   Training iter 100, batch loss 0.4488, batch acc 0.2998
12:58:56.899   Training iter 150, batch loss 0.4482, batch acc 0.2956
12:58:57.470   Training iter 200, batch loss 0.4471, batch acc 0.2892
12:58:58.026   Training iter 250, batch loss 0.4475, batch acc 0.3004
12:58:58.562   Training iter 300, batch loss 0.4463, batch acc 0.3008
12:58:59.104   Training iter 350, batch loss 0.4445, batch acc 0.2976
12:58:59.642   Training iter 400, batch loss 0.4456, batch acc 0.2934
12:59:00.150   Training iter 450, batch loss 0.4448, batch acc 0.2964
12:59:00.675   Training iter 500, batch loss 0.4440, batch acc 0.3068
12:59:01.205   Training iter 550, batch loss 0.4435, batch acc 0.3130
12:59:01.724   Training iter 600, batch loss 0.4432, batch acc 0.3126
12:59:01.726 Training @ 7 epoch...
12:59:02.285   Training iter 50, batch loss 0.4421, batch acc 0.3110
12:59:02.842   Training iter 100, batch loss 0.4422, batch acc 0.3136
12:59:03.383   Training iter 150, batch loss 0.4410, batch acc 0.3074
12:59:03.997   Training iter 200, batch loss 0.4401, batch acc 0.3158
12:59:04.527   Training iter 250, batch loss 0.4401, batch acc 0.3202
12:59:05.061   Training iter 300, batch loss 0.4391, batch acc 0.3224
12:59:05.601   Training iter 350, batch loss 0.4394, batch acc 0.3208
12:59:06.119   Training iter 400, batch loss 0.4379, batch acc 0.3218
12:59:06.621   Training iter 450, batch loss 0.4374, batch acc 0.3088
12:59:07.113   Training iter 500, batch loss 0.4387, batch acc 0.3094
12:59:07.620   Training iter 550, batch loss 0.4371, batch acc 0.3092
12:59:08.119   Training iter 600, batch loss 0.4354, batch acc 0.3268
12:59:08.120 Training @ 8 epoch...
12:59:08.618   Training iter 50, batch loss 0.4349, batch acc 0.3168
12:59:09.121   Training iter 100, batch loss 0.4341, batch acc 0.3258
12:59:09.634   Training iter 150, batch loss 0.4328, batch acc 0.3242
12:59:10.174   Training iter 200, batch loss 0.4337, batch acc 0.3118
12:59:10.689   Training iter 250, batch loss 0.4331, batch acc 0.3196
12:59:11.201   Training iter 300, batch loss 0.4322, batch acc 0.3080
12:59:11.708   Training iter 350, batch loss 0.4295, batch acc 0.3302
12:59:12.214   Training iter 400, batch loss 0.4316, batch acc 0.3114
12:59:12.718   Training iter 450, batch loss 0.4295, batch acc 0.3200
12:59:13.253   Training iter 500, batch loss 0.4273, batch acc 0.3446
12:59:13.800   Training iter 550, batch loss 0.4277, batch acc 0.3274
12:59:14.346   Training iter 600, batch loss 0.4270, batch acc 0.3192
12:59:14.347 Training @ 9 epoch...
12:59:14.903   Training iter 50, batch loss 0.4285, batch acc 0.3124
12:59:15.449   Training iter 100, batch loss 0.4244, batch acc 0.3312
12:59:15.968   Training iter 150, batch loss 0.4254, batch acc 0.3212
12:59:16.498   Training iter 200, batch loss 0.4253, batch acc 0.3312
12:59:17.029   Training iter 250, batch loss 0.4217, batch acc 0.3490
12:59:17.542   Training iter 300, batch loss 0.4216, batch acc 0.3268
12:59:18.061   Training iter 350, batch loss 0.4214, batch acc 0.3340
12:59:18.585   Training iter 400, batch loss 0.4207, batch acc 0.3386
12:59:19.110   Training iter 450, batch loss 0.4222, batch acc 0.3412
12:59:19.645   Training iter 500, batch loss 0.4194, batch acc 0.3410
12:59:20.164   Training iter 550, batch loss 0.4171, batch acc 0.3476
12:59:20.682   Training iter 600, batch loss 0.4188, batch acc 0.3298
12:59:20.684 Training @ 10 epoch...
12:59:21.206   Training iter 50, batch loss 0.4175, batch acc 0.3360
12:59:21.723   Training iter 100, batch loss 0.4164, batch acc 0.3546
12:59:22.251   Training iter 150, batch loss 0.4168, batch acc 0.3362
12:59:22.769   Training iter 200, batch loss 0.4146, batch acc 0.3380
12:59:23.300   Training iter 250, batch loss 0.4148, batch acc 0.3416
12:59:23.818   Training iter 300, batch loss 0.4139, batch acc 0.3416
12:59:24.340   Training iter 350, batch loss 0.4113, batch acc 0.3490
12:59:24.874   Training iter 400, batch loss 0.4108, batch acc 0.3542
12:59:25.407   Training iter 450, batch loss 0.4118, batch acc 0.3420
12:59:25.958   Training iter 500, batch loss 0.4099, batch acc 0.3542
12:59:26.520   Training iter 550, batch loss 0.4104, batch acc 0.3528
12:59:27.086   Training iter 600, batch loss 0.4080, batch acc 0.3600
12:59:27.088 Testing @ 10 epoch...
12:59:27.125     Testing, total mean loss 0.40874, total acc 0.35140
12:59:27.125 Training @ 11 epoch...
12:59:27.700   Training iter 50, batch loss 0.4073, batch acc 0.3676
12:59:28.239   Training iter 100, batch loss 0.4086, batch acc 0.3460
12:59:28.762   Training iter 150, batch loss 0.4060, batch acc 0.3644
12:59:29.297   Training iter 200, batch loss 0.4059, batch acc 0.3680
12:59:29.839   Training iter 250, batch loss 0.4055, batch acc 0.3670
12:59:30.383   Training iter 300, batch loss 0.4042, batch acc 0.3682
12:59:30.928   Training iter 350, batch loss 0.4036, batch acc 0.3686
12:59:31.471   Training iter 400, batch loss 0.4032, batch acc 0.3770
12:59:32.002   Training iter 450, batch loss 0.4009, batch acc 0.3796
12:59:32.514   Training iter 500, batch loss 0.4038, batch acc 0.3740
12:59:33.036   Training iter 550, batch loss 0.3976, batch acc 0.3964
12:59:33.550   Training iter 600, batch loss 0.4000, batch acc 0.3808
12:59:33.552 Training @ 12 epoch...
12:59:34.076   Training iter 50, batch loss 0.3993, batch acc 0.3806
12:59:34.589   Training iter 100, batch loss 0.3972, batch acc 0.3912
12:59:35.112   Training iter 150, batch loss 0.3977, batch acc 0.3802
12:59:35.616   Training iter 200, batch loss 0.3961, batch acc 0.3920
12:59:36.126   Training iter 250, batch loss 0.3922, batch acc 0.4116
12:59:36.627   Training iter 300, batch loss 0.3944, batch acc 0.3978
12:59:37.137   Training iter 350, batch loss 0.3933, batch acc 0.3972
12:59:37.667   Training iter 400, batch loss 0.3930, batch acc 0.4034
12:59:38.207   Training iter 450, batch loss 0.3957, batch acc 0.3854
12:59:38.716   Training iter 500, batch loss 0.3949, batch acc 0.3918
12:59:39.202   Training iter 550, batch loss 0.3911, batch acc 0.4014
12:59:39.678   Training iter 600, batch loss 0.3923, batch acc 0.4092
12:59:39.680 Training @ 13 epoch...
12:59:40.159   Training iter 50, batch loss 0.3903, batch acc 0.4176
12:59:40.631   Training iter 100, batch loss 0.3888, batch acc 0.4084
12:59:41.107   Training iter 150, batch loss 0.3894, batch acc 0.4112
12:59:41.578   Training iter 200, batch loss 0.3877, batch acc 0.4148
12:59:42.054   Training iter 250, batch loss 0.3896, batch acc 0.4078
12:59:42.536   Training iter 300, batch loss 0.3865, batch acc 0.4158
12:59:43.013   Training iter 350, batch loss 0.3835, batch acc 0.4214
12:59:43.487   Training iter 400, batch loss 0.3852, batch acc 0.4178
12:59:43.951   Training iter 450, batch loss 0.3826, batch acc 0.4318
12:59:44.423   Training iter 500, batch loss 0.3814, batch acc 0.4314
12:59:44.906   Training iter 550, batch loss 0.3810, batch acc 0.4290
12:59:45.375   Training iter 600, batch loss 0.3795, batch acc 0.4368
12:59:45.377 Training @ 14 epoch...
12:59:45.849   Training iter 50, batch loss 0.3787, batch acc 0.4394
12:59:46.311   Training iter 100, batch loss 0.3784, batch acc 0.4336
12:59:46.763   Training iter 150, batch loss 0.3803, batch acc 0.4316
12:59:47.230   Training iter 200, batch loss 0.3765, batch acc 0.4364
12:59:47.701   Training iter 250, batch loss 0.3772, batch acc 0.4300
12:59:48.173   Training iter 300, batch loss 0.3765, batch acc 0.4260
12:59:48.647   Training iter 350, batch loss 0.3770, batch acc 0.4330
12:59:49.112   Training iter 400, batch loss 0.3707, batch acc 0.4594
12:59:49.609   Training iter 450, batch loss 0.3730, batch acc 0.4412
12:59:50.121   Training iter 500, batch loss 0.3749, batch acc 0.4420
12:59:50.628   Training iter 550, batch loss 0.3728, batch acc 0.4410
12:59:51.137   Training iter 600, batch loss 0.3716, batch acc 0.4532
12:59:51.139 Training @ 15 epoch...
12:59:51.638   Training iter 50, batch loss 0.3692, batch acc 0.4574
12:59:52.157   Training iter 100, batch loss 0.3690, batch acc 0.4560
12:59:52.668   Training iter 150, batch loss 0.3703, batch acc 0.4510
12:59:53.187   Training iter 200, batch loss 0.3700, batch acc 0.4514
12:59:53.720   Training iter 250, batch loss 0.3661, batch acc 0.4702
12:59:54.269   Training iter 300, batch loss 0.3661, batch acc 0.4658
12:59:54.828   Training iter 350, batch loss 0.3658, batch acc 0.4648
12:59:55.363   Training iter 400, batch loss 0.3630, batch acc 0.4688
12:59:55.894   Training iter 450, batch loss 0.3622, batch acc 0.4722
12:59:56.421   Training iter 500, batch loss 0.3621, batch acc 0.4702
12:59:56.944   Training iter 550, batch loss 0.3601, batch acc 0.4750
12:59:57.476   Training iter 600, batch loss 0.3592, batch acc 0.4808
12:59:57.478 Testing @ 15 epoch...
12:59:57.516     Testing, total mean loss 0.36106, total acc 0.47550
12:59:57.516 Training @ 16 epoch...
12:59:58.014   Training iter 50, batch loss 0.3610, batch acc 0.4706
12:59:58.533   Training iter 100, batch loss 0.3586, batch acc 0.4842
12:59:59.061   Training iter 150, batch loss 0.3609, batch acc 0.4782
12:59:59.594   Training iter 200, batch loss 0.3558, batch acc 0.5036
13:00:00.148   Training iter 250, batch loss 0.3569, batch acc 0.4816
13:00:00.719   Training iter 300, batch loss 0.3519, batch acc 0.5026
13:00:01.266   Training iter 350, batch loss 0.3526, batch acc 0.4874
13:00:01.853   Training iter 400, batch loss 0.3526, batch acc 0.4924
13:00:02.432   Training iter 450, batch loss 0.3532, batch acc 0.4892
13:00:02.997   Training iter 500, batch loss 0.3503, batch acc 0.5030
13:00:03.583   Training iter 550, batch loss 0.3519, batch acc 0.5044
13:00:04.192   Training iter 600, batch loss 0.3502, batch acc 0.5034
13:00:04.194 Training @ 17 epoch...
13:00:04.761   Training iter 50, batch loss 0.3463, batch acc 0.5108
13:00:05.334   Training iter 100, batch loss 0.3481, batch acc 0.5082
13:00:05.891   Training iter 150, batch loss 0.3475, batch acc 0.5240
13:00:06.469   Training iter 200, batch loss 0.3480, batch acc 0.5164
13:00:07.032   Training iter 250, batch loss 0.3444, batch acc 0.5268
13:00:07.606   Training iter 300, batch loss 0.3462, batch acc 0.5126
13:00:08.175   Training iter 350, batch loss 0.3436, batch acc 0.5162
13:00:08.738   Training iter 400, batch loss 0.3422, batch acc 0.5228
13:00:09.300   Training iter 450, batch loss 0.3396, batch acc 0.5266
13:00:09.864   Training iter 500, batch loss 0.3428, batch acc 0.5176
13:00:10.433   Training iter 550, batch loss 0.3399, batch acc 0.5192
13:00:10.994   Training iter 600, batch loss 0.3430, batch acc 0.5156
13:00:10.996 Training @ 18 epoch...
13:00:11.570   Training iter 50, batch loss 0.3397, batch acc 0.5378
13:00:12.139   Training iter 100, batch loss 0.3385, batch acc 0.5360
13:00:12.719   Training iter 150, batch loss 0.3373, batch acc 0.5432
13:00:13.265   Training iter 200, batch loss 0.3372, batch acc 0.5324
13:00:13.780   Training iter 250, batch loss 0.3351, batch acc 0.5400
13:00:14.295   Training iter 300, batch loss 0.3367, batch acc 0.5442
13:00:14.815   Training iter 350, batch loss 0.3328, batch acc 0.5478
13:00:15.314   Training iter 400, batch loss 0.3348, batch acc 0.5404
13:00:15.817   Training iter 450, batch loss 0.3304, batch acc 0.5534
13:00:16.324   Training iter 500, batch loss 0.3348, batch acc 0.5426
13:00:16.845   Training iter 550, batch loss 0.3273, batch acc 0.5626
13:00:17.362   Training iter 600, batch loss 0.3300, batch acc 0.5630
13:00:17.363 Training @ 19 epoch...
13:00:17.882   Training iter 50, batch loss 0.3313, batch acc 0.5524
13:00:18.425   Training iter 100, batch loss 0.3287, batch acc 0.5660
13:00:18.924   Training iter 150, batch loss 0.3272, batch acc 0.5676
13:00:19.430   Training iter 200, batch loss 0.3246, batch acc 0.5622
13:00:19.928   Training iter 250, batch loss 0.3304, batch acc 0.5562
13:00:20.435   Training iter 300, batch loss 0.3257, batch acc 0.5770
13:00:20.934   Training iter 350, batch loss 0.3221, batch acc 0.5726
13:00:21.454   Training iter 400, batch loss 0.3247, batch acc 0.5726
13:00:21.972   Training iter 450, batch loss 0.3229, batch acc 0.5716
13:00:22.465   Training iter 500, batch loss 0.3231, batch acc 0.5656
13:00:22.953   Training iter 550, batch loss 0.3209, batch acc 0.5730
13:00:23.450   Training iter 600, batch loss 0.3240, batch acc 0.5716
13:00:23.451 Training @ 20 epoch...
13:00:23.952   Training iter 50, batch loss 0.3202, batch acc 0.5770
13:00:24.436   Training iter 100, batch loss 0.3198, batch acc 0.5834
13:00:24.916   Training iter 150, batch loss 0.3138, batch acc 0.5876
13:00:25.417   Training iter 200, batch loss 0.3196, batch acc 0.5778
13:00:25.904   Training iter 250, batch loss 0.3152, batch acc 0.5890
13:00:26.407   Training iter 300, batch loss 0.3176, batch acc 0.5784
13:00:26.899   Training iter 350, batch loss 0.3197, batch acc 0.5894
13:00:27.404   Training iter 400, batch loss 0.3176, batch acc 0.5888
13:00:27.920   Training iter 450, batch loss 0.3159, batch acc 0.5884
13:00:28.450   Training iter 500, batch loss 0.3190, batch acc 0.5790
13:00:28.966   Training iter 550, batch loss 0.3175, batch acc 0.5788
13:00:29.470   Training iter 600, batch loss 0.3084, batch acc 0.6104
13:00:29.472 Testing @ 20 epoch...
13:00:29.509     Testing, total mean loss 0.31368, total acc 0.58930
13:00:29.509 Training @ 21 epoch...
13:00:30.011   Training iter 50, batch loss 0.3120, batch acc 0.5918
13:00:30.529   Training iter 100, batch loss 0.3087, batch acc 0.6046
13:00:31.022   Training iter 150, batch loss 0.3137, batch acc 0.5848
13:00:31.523   Training iter 200, batch loss 0.3068, batch acc 0.6082
13:00:32.050   Training iter 250, batch loss 0.3111, batch acc 0.5968
13:00:32.574   Training iter 300, batch loss 0.3095, batch acc 0.5978
13:00:33.112   Training iter 350, batch loss 0.3092, batch acc 0.6058
13:00:33.653   Training iter 400, batch loss 0.3142, batch acc 0.5868
13:00:34.154   Training iter 450, batch loss 0.3036, batch acc 0.6164
13:00:34.655   Training iter 500, batch loss 0.3050, batch acc 0.6190
13:00:35.141   Training iter 550, batch loss 0.3098, batch acc 0.5950
13:00:35.642   Training iter 600, batch loss 0.3065, batch acc 0.5984
13:00:35.644 Training @ 22 epoch...
13:00:36.150   Training iter 50, batch loss 0.3033, batch acc 0.6074
13:00:36.642   Training iter 100, batch loss 0.3047, batch acc 0.6052
13:00:37.140   Training iter 150, batch loss 0.3050, batch acc 0.6070
13:00:37.621   Training iter 200, batch loss 0.3046, batch acc 0.6100
13:00:38.109   Training iter 250, batch loss 0.3028, batch acc 0.6198
13:00:38.598   Training iter 300, batch loss 0.2994, batch acc 0.6246
13:00:39.082   Training iter 350, batch loss 0.3027, batch acc 0.6042
13:00:39.568   Training iter 400, batch loss 0.3008, batch acc 0.6154
13:00:40.052   Training iter 450, batch loss 0.2978, batch acc 0.6284
13:00:40.531   Training iter 500, batch loss 0.3012, batch acc 0.6064
13:00:40.996   Training iter 550, batch loss 0.2973, batch acc 0.6176
13:00:41.459   Training iter 600, batch loss 0.3016, batch acc 0.6114
13:00:41.461 Training @ 23 epoch...
13:00:41.928   Training iter 50, batch loss 0.2996, batch acc 0.6134
13:00:42.401   Training iter 100, batch loss 0.2945, batch acc 0.6302
13:00:42.883   Training iter 150, batch loss 0.2939, batch acc 0.6292
13:00:43.374   Training iter 200, batch loss 0.2947, batch acc 0.6260
13:00:43.871   Training iter 250, batch loss 0.2955, batch acc 0.6252
13:00:44.397   Training iter 300, batch loss 0.2936, batch acc 0.6290
13:00:44.893   Training iter 350, batch loss 0.3021, batch acc 0.6028
13:00:45.387   Training iter 400, batch loss 0.2962, batch acc 0.6200
13:00:45.920   Training iter 450, batch loss 0.2914, batch acc 0.6354
13:00:46.503   Training iter 500, batch loss 0.2935, batch acc 0.6254
13:00:47.112   Training iter 550, batch loss 0.2877, batch acc 0.6384
13:00:47.685   Training iter 600, batch loss 0.2956, batch acc 0.6166
13:00:47.687 Training @ 24 epoch...
13:00:48.172   Training iter 50, batch loss 0.2923, batch acc 0.6250
13:00:48.656   Training iter 100, batch loss 0.2900, batch acc 0.6324
13:00:49.121   Training iter 150, batch loss 0.2890, batch acc 0.6326
13:00:49.615   Training iter 200, batch loss 0.2894, batch acc 0.6298
13:00:50.107   Training iter 250, batch loss 0.2901, batch acc 0.6278
13:00:50.556   Training iter 300, batch loss 0.2890, batch acc 0.6316
13:00:51.022   Training iter 350, batch loss 0.2899, batch acc 0.6306
13:00:51.477   Training iter 400, batch loss 0.2864, batch acc 0.6388
13:00:51.946   Training iter 450, batch loss 0.2895, batch acc 0.6304
13:00:52.419   Training iter 500, batch loss 0.2862, batch acc 0.6312
13:00:52.901   Training iter 550, batch loss 0.2857, batch acc 0.6328
13:00:53.380   Training iter 600, batch loss 0.2841, batch acc 0.6380
13:00:53.382 Training @ 25 epoch...
13:00:53.855   Training iter 50, batch loss 0.2860, batch acc 0.6360
13:00:54.363   Training iter 100, batch loss 0.2841, batch acc 0.6408
13:00:54.881   Training iter 150, batch loss 0.2843, batch acc 0.6368
13:00:55.423   Training iter 200, batch loss 0.2856, batch acc 0.6336
13:00:55.963   Training iter 250, batch loss 0.2867, batch acc 0.6314
13:00:56.482   Training iter 300, batch loss 0.2780, batch acc 0.6514
13:00:56.986   Training iter 350, batch loss 0.2836, batch acc 0.6362
13:00:57.524   Training iter 400, batch loss 0.2783, batch acc 0.6502
13:00:58.089   Training iter 450, batch loss 0.2832, batch acc 0.6386
13:00:58.618   Training iter 500, batch loss 0.2853, batch acc 0.6312
13:00:59.220   Training iter 550, batch loss 0.2794, batch acc 0.6460
13:00:59.907   Training iter 600, batch loss 0.2756, batch acc 0.6498
13:00:59.910 Testing @ 25 epoch...
13:00:59.966     Testing, total mean loss 0.27963, total acc 0.64070
13:00:59.966 Training @ 26 epoch...
13:01:00.685   Training iter 50, batch loss 0.2782, batch acc 0.6486
13:01:01.374   Training iter 100, batch loss 0.2773, batch acc 0.6480
13:01:02.128   Training iter 150, batch loss 0.2761, batch acc 0.6422
13:01:02.887   Training iter 200, batch loss 0.2838, batch acc 0.6320
13:01:03.632   Training iter 250, batch loss 0.2799, batch acc 0.6444
13:01:04.387   Training iter 300, batch loss 0.2756, batch acc 0.6478
13:01:05.148   Training iter 350, batch loss 0.2764, batch acc 0.6446
13:01:05.899   Training iter 400, batch loss 0.2745, batch acc 0.6464
13:01:06.663   Training iter 450, batch loss 0.2781, batch acc 0.6406
13:01:07.420   Training iter 500, batch loss 0.2765, batch acc 0.6462
13:01:08.050   Training iter 550, batch loss 0.2724, batch acc 0.6630
13:01:08.572   Training iter 600, batch loss 0.2757, batch acc 0.6400
13:01:08.573 Training @ 27 epoch...
13:01:09.088   Training iter 50, batch loss 0.2758, batch acc 0.6450
13:01:09.603   Training iter 100, batch loss 0.2748, batch acc 0.6426
13:01:10.122   Training iter 150, batch loss 0.2698, batch acc 0.6564
13:01:10.640   Training iter 200, batch loss 0.2775, batch acc 0.6402
13:01:11.140   Training iter 250, batch loss 0.2723, batch acc 0.6444
13:01:11.591   Training iter 300, batch loss 0.2747, batch acc 0.6484
13:01:12.075   Training iter 350, batch loss 0.2720, batch acc 0.6528
13:01:12.595   Training iter 400, batch loss 0.2725, batch acc 0.6530
13:01:13.129   Training iter 450, batch loss 0.2693, batch acc 0.6586
13:01:13.670   Training iter 500, batch loss 0.2702, batch acc 0.6580
13:01:14.205   Training iter 550, batch loss 0.2655, batch acc 0.6676
13:01:14.743   Training iter 600, batch loss 0.2701, batch acc 0.6496
13:01:14.745 Training @ 28 epoch...
13:01:15.277   Training iter 50, batch loss 0.2703, batch acc 0.6556
13:01:15.807   Training iter 100, batch loss 0.2736, batch acc 0.6432
13:01:16.330   Training iter 150, batch loss 0.2685, batch acc 0.6528
13:01:16.856   Training iter 200, batch loss 0.2703, batch acc 0.6506
13:01:17.370   Training iter 250, batch loss 0.2633, batch acc 0.6656
13:01:17.882   Training iter 300, batch loss 0.2677, batch acc 0.6558
13:01:18.396   Training iter 350, batch loss 0.2620, batch acc 0.6626
13:01:18.941   Training iter 400, batch loss 0.2684, batch acc 0.6528
13:01:19.491   Training iter 450, batch loss 0.2671, batch acc 0.6544
13:01:20.056   Training iter 500, batch loss 0.2685, batch acc 0.6620
13:01:20.608   Training iter 550, batch loss 0.2628, batch acc 0.6660
13:01:21.151   Training iter 600, batch loss 0.2671, batch acc 0.6520
13:01:21.152 Training @ 29 epoch...
13:01:21.696   Training iter 50, batch loss 0.2666, batch acc 0.6532
13:01:22.245   Training iter 100, batch loss 0.2621, batch acc 0.6636
13:01:22.798   Training iter 150, batch loss 0.2664, batch acc 0.6588
13:01:23.364   Training iter 200, batch loss 0.2615, batch acc 0.6668
13:01:23.983   Training iter 250, batch loss 0.2598, batch acc 0.6650
13:01:24.622   Training iter 300, batch loss 0.2670, batch acc 0.6542
13:01:25.223   Training iter 350, batch loss 0.2670, batch acc 0.6560
13:01:25.708   Training iter 400, batch loss 0.2637, batch acc 0.6612
13:01:26.206   Training iter 450, batch loss 0.2608, batch acc 0.6622
13:01:26.693   Training iter 500, batch loss 0.2646, batch acc 0.6558
13:01:27.202   Training iter 550, batch loss 0.2583, batch acc 0.6718
13:01:27.704   Training iter 600, batch loss 0.2615, batch acc 0.6604
13:01:27.706 Training @ 30 epoch...
13:01:28.227   Training iter 50, batch loss 0.2625, batch acc 0.6666
13:01:28.737   Training iter 100, batch loss 0.2626, batch acc 0.6632
13:01:29.221   Training iter 150, batch loss 0.2631, batch acc 0.6626
13:01:29.714   Training iter 200, batch loss 0.2634, batch acc 0.6594
13:01:30.236   Training iter 250, batch loss 0.2601, batch acc 0.6646
13:01:30.758   Training iter 300, batch loss 0.2563, batch acc 0.6702
13:01:31.283   Training iter 350, batch loss 0.2577, batch acc 0.6712
13:01:31.802   Training iter 400, batch loss 0.2603, batch acc 0.6606
13:01:32.323   Training iter 450, batch loss 0.2567, batch acc 0.6682
13:01:32.835   Training iter 500, batch loss 0.2554, batch acc 0.6650
13:01:33.354   Training iter 550, batch loss 0.2579, batch acc 0.6684
13:01:33.870   Training iter 600, batch loss 0.2571, batch acc 0.6680
13:01:33.872 Testing @ 30 epoch...
13:01:33.909     Testing, total mean loss 0.25720, total acc 0.66710
13:01:33.909 Training @ 31 epoch...
13:01:34.450   Training iter 50, batch loss 0.2576, batch acc 0.6616
13:01:34.981   Training iter 100, batch loss 0.2537, batch acc 0.6746
13:01:35.503   Training iter 150, batch loss 0.2621, batch acc 0.6552
13:01:36.029   Training iter 200, batch loss 0.2587, batch acc 0.6668
13:01:36.550   Training iter 250, batch loss 0.2576, batch acc 0.6662
13:01:37.073   Training iter 300, batch loss 0.2554, batch acc 0.6702
13:01:37.599   Training iter 350, batch loss 0.2541, batch acc 0.6732
13:01:38.132   Training iter 400, batch loss 0.2533, batch acc 0.6750
13:01:38.692   Training iter 450, batch loss 0.2545, batch acc 0.6636
13:01:39.224   Training iter 500, batch loss 0.2582, batch acc 0.6572
13:01:39.771   Training iter 550, batch loss 0.2516, batch acc 0.6754
13:01:40.398   Training iter 600, batch loss 0.2539, batch acc 0.6706
13:01:40.400 Training @ 32 epoch...
13:01:40.966   Training iter 50, batch loss 0.2566, batch acc 0.6650
13:01:41.517   Training iter 100, batch loss 0.2543, batch acc 0.6706
13:01:42.087   Training iter 150, batch loss 0.2522, batch acc 0.6708
13:01:42.646   Training iter 200, batch loss 0.2587, batch acc 0.6576
13:01:43.199   Training iter 250, batch loss 0.2498, batch acc 0.6812
13:01:43.736   Training iter 300, batch loss 0.2534, batch acc 0.6724
13:01:44.261   Training iter 350, batch loss 0.2520, batch acc 0.6774
13:01:44.784   Training iter 400, batch loss 0.2546, batch acc 0.6604
13:01:45.301   Training iter 450, batch loss 0.2509, batch acc 0.6708
13:01:45.824   Training iter 500, batch loss 0.2541, batch acc 0.6696
13:01:46.366   Training iter 550, batch loss 0.2511, batch acc 0.6740
13:01:46.902   Training iter 600, batch loss 0.2440, batch acc 0.6850
13:01:46.904 Training @ 33 epoch...
13:01:47.385   Training iter 50, batch loss 0.2474, batch acc 0.6828
13:01:47.892   Training iter 100, batch loss 0.2539, batch acc 0.6668
13:01:48.373   Training iter 150, batch loss 0.2517, batch acc 0.6702
13:01:48.882   Training iter 200, batch loss 0.2493, batch acc 0.6780
13:01:49.430   Training iter 250, batch loss 0.2493, batch acc 0.6700
13:01:49.949   Training iter 300, batch loss 0.2512, batch acc 0.6728
13:01:50.427   Training iter 350, batch loss 0.2501, batch acc 0.6732
13:01:50.921   Training iter 400, batch loss 0.2470, batch acc 0.6740
13:01:51.385   Training iter 450, batch loss 0.2509, batch acc 0.6734
13:01:51.898   Training iter 500, batch loss 0.2480, batch acc 0.6788
13:01:52.374   Training iter 550, batch loss 0.2469, batch acc 0.6728
13:01:52.897   Training iter 600, batch loss 0.2497, batch acc 0.6702
13:01:52.899 Training @ 34 epoch...
13:01:53.396   Training iter 50, batch loss 0.2448, batch acc 0.6802
13:01:53.922   Training iter 100, batch loss 0.2470, batch acc 0.6718
13:01:54.394   Training iter 150, batch loss 0.2475, batch acc 0.6804
13:01:54.869   Training iter 200, batch loss 0.2499, batch acc 0.6690
13:01:55.351   Training iter 250, batch loss 0.2472, batch acc 0.6762
13:01:55.806   Training iter 300, batch loss 0.2445, batch acc 0.6768
13:01:56.270   Training iter 350, batch loss 0.2457, batch acc 0.6802
13:01:56.742   Training iter 400, batch loss 0.2470, batch acc 0.6778
13:01:57.237   Training iter 450, batch loss 0.2444, batch acc 0.6858
13:01:57.746   Training iter 500, batch loss 0.2467, batch acc 0.6754
13:01:58.240   Training iter 550, batch loss 0.2495, batch acc 0.6686
13:01:58.716   Training iter 600, batch loss 0.2475, batch acc 0.6700
13:01:58.718 Training @ 35 epoch...
13:01:59.194   Training iter 50, batch loss 0.2497, batch acc 0.6692
13:01:59.668   Training iter 100, batch loss 0.2476, batch acc 0.6782
13:02:00.180   Training iter 150, batch loss 0.2451, batch acc 0.6730
13:02:00.732   Training iter 200, batch loss 0.2453, batch acc 0.6806
13:02:01.272   Training iter 250, batch loss 0.2410, batch acc 0.6900
13:02:01.784   Training iter 300, batch loss 0.2461, batch acc 0.6740
13:02:02.341   Training iter 350, batch loss 0.2417, batch acc 0.6832
13:02:02.900   Training iter 400, batch loss 0.2437, batch acc 0.6720
13:02:03.472   Training iter 450, batch loss 0.2396, batch acc 0.6826
13:02:04.031   Training iter 500, batch loss 0.2463, batch acc 0.6746
13:02:04.574   Training iter 550, batch loss 0.2426, batch acc 0.6812
13:02:05.114   Training iter 600, batch loss 0.2421, batch acc 0.6822
13:02:05.115 Testing @ 35 epoch...
13:02:05.154     Testing, total mean loss 0.24231, total acc 0.67900
13:02:05.154 Training @ 36 epoch...
13:02:05.700   Training iter 50, batch loss 0.2409, batch acc 0.6818
13:02:06.250   Training iter 100, batch loss 0.2434, batch acc 0.6716
13:02:06.788   Training iter 150, batch loss 0.2441, batch acc 0.6772
13:02:07.339   Training iter 200, batch loss 0.2431, batch acc 0.6772
13:02:07.871   Training iter 250, batch loss 0.2409, batch acc 0.6788
13:02:08.421   Training iter 300, batch loss 0.2440, batch acc 0.6776
13:02:08.942   Training iter 350, batch loss 0.2424, batch acc 0.6808
13:02:09.463   Training iter 400, batch loss 0.2453, batch acc 0.6742
13:02:09.946   Training iter 450, batch loss 0.2418, batch acc 0.6790
13:02:10.423   Training iter 500, batch loss 0.2426, batch acc 0.6836
13:02:10.904   Training iter 550, batch loss 0.2405, batch acc 0.6780
13:02:11.394   Training iter 600, batch loss 0.2326, batch acc 0.6974
13:02:11.396 Training @ 37 epoch...
13:02:11.909   Training iter 50, batch loss 0.2389, batch acc 0.6846
13:02:12.402   Training iter 100, batch loss 0.2378, batch acc 0.6828
13:02:12.909   Training iter 150, batch loss 0.2380, batch acc 0.6870
13:02:13.392   Training iter 200, batch loss 0.2407, batch acc 0.6798
13:02:13.855   Training iter 250, batch loss 0.2380, batch acc 0.6858
13:02:14.345   Training iter 300, batch loss 0.2383, batch acc 0.6796
13:02:14.823   Training iter 350, batch loss 0.2397, batch acc 0.6808
13:02:15.327   Training iter 400, batch loss 0.2393, batch acc 0.6844
13:02:15.804   Training iter 450, batch loss 0.2418, batch acc 0.6792
13:02:16.284   Training iter 500, batch loss 0.2422, batch acc 0.6776
13:02:16.831   Training iter 550, batch loss 0.2412, batch acc 0.6784
13:02:17.399   Training iter 600, batch loss 0.2388, batch acc 0.6820
13:02:17.401 Training @ 38 epoch...
13:02:17.953   Training iter 50, batch loss 0.2423, batch acc 0.6748
13:02:18.442   Training iter 100, batch loss 0.2334, batch acc 0.6926
13:02:18.920   Training iter 150, batch loss 0.2404, batch acc 0.6738
13:02:19.408   Training iter 200, batch loss 0.2417, batch acc 0.6736
13:02:19.913   Training iter 250, batch loss 0.2388, batch acc 0.6868
13:02:20.383   Training iter 300, batch loss 0.2378, batch acc 0.6860
13:02:20.838   Training iter 350, batch loss 0.2350, batch acc 0.6938
13:02:21.355   Training iter 400, batch loss 0.2367, batch acc 0.6836
13:02:21.860   Training iter 450, batch loss 0.2359, batch acc 0.6946
13:02:22.411   Training iter 500, batch loss 0.2333, batch acc 0.6880
13:02:22.956   Training iter 550, batch loss 0.2322, batch acc 0.6868
13:02:23.486   Training iter 600, batch loss 0.2420, batch acc 0.6764
13:02:23.488 Training @ 39 epoch...
13:02:24.010   Training iter 50, batch loss 0.2338, batch acc 0.6870
13:02:24.564   Training iter 100, batch loss 0.2365, batch acc 0.6832
13:02:25.136   Training iter 150, batch loss 0.2360, batch acc 0.6854
13:02:25.682   Training iter 200, batch loss 0.2361, batch acc 0.6848
13:02:26.235   Training iter 250, batch loss 0.2390, batch acc 0.6776
13:02:26.784   Training iter 300, batch loss 0.2355, batch acc 0.6870
13:02:27.354   Training iter 350, batch loss 0.2421, batch acc 0.6762
13:02:27.897   Training iter 400, batch loss 0.2316, batch acc 0.6942
13:02:28.412   Training iter 450, batch loss 0.2332, batch acc 0.6876
13:02:28.932   Training iter 500, batch loss 0.2398, batch acc 0.6708
13:02:29.458   Training iter 550, batch loss 0.2331, batch acc 0.6920
13:02:29.997   Training iter 600, batch loss 0.2297, batch acc 0.6946
13:02:29.999 Training @ 40 epoch...
13:02:30.520   Training iter 50, batch loss 0.2313, batch acc 0.6910
13:02:31.057   Training iter 100, batch loss 0.2380, batch acc 0.6756
13:02:31.587   Training iter 150, batch loss 0.2350, batch acc 0.6870
13:02:32.112   Training iter 200, batch loss 0.2305, batch acc 0.6906
13:02:32.638   Training iter 250, batch loss 0.2337, batch acc 0.6918
13:02:33.172   Training iter 300, batch loss 0.2347, batch acc 0.6846
13:02:33.718   Training iter 350, batch loss 0.2350, batch acc 0.6836
13:02:34.235   Training iter 400, batch loss 0.2358, batch acc 0.6834
13:02:34.771   Training iter 450, batch loss 0.2345, batch acc 0.6810
13:02:35.318   Training iter 500, batch loss 0.2343, batch acc 0.6852
13:02:35.845   Training iter 550, batch loss 0.2334, batch acc 0.6876
13:02:36.362   Training iter 600, batch loss 0.2283, batch acc 0.6958
13:02:36.363 Testing @ 40 epoch...
13:02:36.402     Testing, total mean loss 0.23208, total acc 0.68800
13:02:36.402 Training @ 41 epoch...
13:02:36.890   Training iter 50, batch loss 0.2324, batch acc 0.6836
13:02:37.384   Training iter 100, batch loss 0.2410, batch acc 0.6676
13:02:37.908   Training iter 150, batch loss 0.2327, batch acc 0.6834
13:02:38.447   Training iter 200, batch loss 0.2338, batch acc 0.6866
13:02:38.987   Training iter 250, batch loss 0.2280, batch acc 0.6998
13:02:39.528   Training iter 300, batch loss 0.2302, batch acc 0.6892
13:02:40.062   Training iter 350, batch loss 0.2323, batch acc 0.6928
13:02:40.595   Training iter 400, batch loss 0.2313, batch acc 0.6890
13:02:41.127   Training iter 450, batch loss 0.2326, batch acc 0.6852
13:02:41.664   Training iter 500, batch loss 0.2317, batch acc 0.6914
13:02:42.194   Training iter 550, batch loss 0.2272, batch acc 0.6936
13:02:42.724   Training iter 600, batch loss 0.2310, batch acc 0.6890
13:02:42.726 Training @ 42 epoch...
13:02:43.234   Training iter 50, batch loss 0.2326, batch acc 0.6826
13:02:43.726   Training iter 100, batch loss 0.2318, batch acc 0.6852
13:02:44.279   Training iter 150, batch loss 0.2346, batch acc 0.6796
13:02:44.742   Training iter 200, batch loss 0.2303, batch acc 0.6898
13:02:45.207   Training iter 250, batch loss 0.2297, batch acc 0.6916
13:02:45.681   Training iter 300, batch loss 0.2288, batch acc 0.6974
13:02:46.165   Training iter 350, batch loss 0.2254, batch acc 0.6972
13:02:46.636   Training iter 400, batch loss 0.2320, batch acc 0.6896
13:02:47.121   Training iter 450, batch loss 0.2316, batch acc 0.6848
13:02:47.604   Training iter 500, batch loss 0.2264, batch acc 0.6926
13:02:48.063   Training iter 550, batch loss 0.2302, batch acc 0.6862
13:02:48.521   Training iter 600, batch loss 0.2320, batch acc 0.6820
13:02:48.522 Training @ 43 epoch...
13:02:48.991   Training iter 50, batch loss 0.2298, batch acc 0.6862
13:02:49.472   Training iter 100, batch loss 0.2284, batch acc 0.6908
13:02:49.955   Training iter 150, batch loss 0.2266, batch acc 0.6948
13:02:50.431   Training iter 200, batch loss 0.2284, batch acc 0.6962
13:02:50.910   Training iter 250, batch loss 0.2302, batch acc 0.6846
13:02:51.419   Training iter 300, batch loss 0.2346, batch acc 0.6820
13:02:51.920   Training iter 350, batch loss 0.2293, batch acc 0.6862
13:02:52.429   Training iter 400, batch loss 0.2314, batch acc 0.6874
13:02:52.930   Training iter 450, batch loss 0.2285, batch acc 0.6876
13:02:53.436   Training iter 500, batch loss 0.2244, batch acc 0.6954
13:02:53.939   Training iter 550, batch loss 0.2283, batch acc 0.6944
13:02:54.479   Training iter 600, batch loss 0.2279, batch acc 0.6918
13:02:54.481 Training @ 44 epoch...
13:02:55.037   Training iter 50, batch loss 0.2309, batch acc 0.6896
13:02:55.588   Training iter 100, batch loss 0.2311, batch acc 0.6864
13:02:56.135   Training iter 150, batch loss 0.2297, batch acc 0.6858
13:02:56.673   Training iter 200, batch loss 0.2311, batch acc 0.6826
13:02:57.227   Training iter 250, batch loss 0.2314, batch acc 0.6852
13:02:57.786   Training iter 300, batch loss 0.2222, batch acc 0.7022
13:02:58.327   Training iter 350, batch loss 0.2254, batch acc 0.6990
13:02:58.875   Training iter 400, batch loss 0.2231, batch acc 0.6998
13:02:59.421   Training iter 450, batch loss 0.2282, batch acc 0.6860
13:02:59.960   Training iter 500, batch loss 0.2272, batch acc 0.6858
13:03:00.466   Training iter 550, batch loss 0.2241, batch acc 0.6956
13:03:00.997   Training iter 600, batch loss 0.2271, batch acc 0.6926
13:03:00.998 Training @ 45 epoch...
13:03:01.560   Training iter 50, batch loss 0.2213, batch acc 0.6970
13:03:02.128   Training iter 100, batch loss 0.2264, batch acc 0.6894
13:03:02.658   Training iter 150, batch loss 0.2242, batch acc 0.7000
13:03:03.208   Training iter 200, batch loss 0.2256, batch acc 0.6926
13:03:03.747   Training iter 250, batch loss 0.2300, batch acc 0.6862
13:03:04.278   Training iter 300, batch loss 0.2241, batch acc 0.6966
13:03:04.809   Training iter 350, batch loss 0.2261, batch acc 0.6956
13:03:05.343   Training iter 400, batch loss 0.2298, batch acc 0.6862
13:03:05.870   Training iter 450, batch loss 0.2259, batch acc 0.6930
13:03:06.387   Training iter 500, batch loss 0.2288, batch acc 0.6852
13:03:06.938   Training iter 550, batch loss 0.2245, batch acc 0.6950
13:03:07.482   Training iter 600, batch loss 0.2296, batch acc 0.6836
13:03:07.484 Testing @ 45 epoch...
13:03:07.521     Testing, total mean loss 0.22491, total acc 0.69240
13:03:07.521 Training @ 46 epoch...
13:03:08.026   Training iter 50, batch loss 0.2248, batch acc 0.6910
13:03:08.546   Training iter 100, batch loss 0.2280, batch acc 0.6846
13:03:09.064   Training iter 150, batch loss 0.2296, batch acc 0.6826
13:03:09.570   Training iter 200, batch loss 0.2195, batch acc 0.7052
13:03:10.099   Training iter 250, batch loss 0.2231, batch acc 0.7030
13:03:10.632   Training iter 300, batch loss 0.2281, batch acc 0.6910
13:03:11.155   Training iter 350, batch loss 0.2281, batch acc 0.6858
13:03:11.688   Training iter 400, batch loss 0.2246, batch acc 0.6940
13:03:12.225   Training iter 450, batch loss 0.2218, batch acc 0.7020
13:03:12.775   Training iter 500, batch loss 0.2221, batch acc 0.6930
13:03:13.345   Training iter 550, batch loss 0.2231, batch acc 0.6948
13:03:13.927   Training iter 600, batch loss 0.2292, batch acc 0.6826
13:03:13.929 Training @ 47 epoch...
13:03:14.535   Training iter 50, batch loss 0.2303, batch acc 0.6842
13:03:15.136   Training iter 100, batch loss 0.2242, batch acc 0.6946
13:03:15.738   Training iter 150, batch loss 0.2269, batch acc 0.6900
13:03:16.264   Training iter 200, batch loss 0.2208, batch acc 0.7002
13:03:16.768   Training iter 250, batch loss 0.2232, batch acc 0.6946
13:03:17.250   Training iter 300, batch loss 0.2256, batch acc 0.6872
13:03:17.738   Training iter 350, batch loss 0.2282, batch acc 0.6872
13:03:18.229   Training iter 400, batch loss 0.2156, batch acc 0.7112
13:03:18.725   Training iter 450, batch loss 0.2241, batch acc 0.6966
13:03:19.190   Training iter 500, batch loss 0.2260, batch acc 0.6878
13:03:19.655   Training iter 550, batch loss 0.2206, batch acc 0.6966
13:03:20.147   Training iter 600, batch loss 0.2235, batch acc 0.6916
13:03:20.149 Training @ 48 epoch...
13:03:20.638   Training iter 50, batch loss 0.2246, batch acc 0.6880
13:03:21.111   Training iter 100, batch loss 0.2215, batch acc 0.6948
13:03:21.576   Training iter 150, batch loss 0.2209, batch acc 0.6980
13:03:22.048   Training iter 200, batch loss 0.2275, batch acc 0.6812
13:03:22.537   Training iter 250, batch loss 0.2225, batch acc 0.7004
13:03:23.023   Training iter 300, batch loss 0.2187, batch acc 0.7012
13:03:23.511   Training iter 350, batch loss 0.2177, batch acc 0.7068
13:03:23.980   Training iter 400, batch loss 0.2285, batch acc 0.6836
13:03:24.476   Training iter 450, batch loss 0.2236, batch acc 0.6916
13:03:24.963   Training iter 500, batch loss 0.2297, batch acc 0.6790
13:03:25.449   Training iter 550, batch loss 0.2221, batch acc 0.6960
13:03:25.952   Training iter 600, batch loss 0.2189, batch acc 0.7020
13:03:25.954 Training @ 49 epoch...
13:03:26.467   Training iter 50, batch loss 0.2244, batch acc 0.6902
13:03:26.967   Training iter 100, batch loss 0.2227, batch acc 0.6956
13:03:27.486   Training iter 150, batch loss 0.2221, batch acc 0.6928
13:03:28.003   Training iter 200, batch loss 0.2258, batch acc 0.6898
13:03:28.529   Training iter 250, batch loss 0.2187, batch acc 0.7006
13:03:29.056   Training iter 300, batch loss 0.2239, batch acc 0.6904
13:03:29.580   Training iter 350, batch loss 0.2200, batch acc 0.7020
13:03:30.083   Training iter 400, batch loss 0.2216, batch acc 0.6954
13:03:30.602   Training iter 450, batch loss 0.2260, batch acc 0.6890
13:03:31.110   Training iter 500, batch loss 0.2207, batch acc 0.6972
13:03:31.615   Training iter 550, batch loss 0.2203, batch acc 0.6980
13:03:32.124   Training iter 600, batch loss 0.2183, batch acc 0.6982
13:03:32.125 Training @ 50 epoch...
13:03:32.600   Training iter 50, batch loss 0.2211, batch acc 0.6972
13:03:33.069   Training iter 100, batch loss 0.2228, batch acc 0.6960
13:03:33.525   Training iter 150, batch loss 0.2181, batch acc 0.7026
13:03:34.002   Training iter 200, batch loss 0.2224, batch acc 0.6996
13:03:34.511   Training iter 250, batch loss 0.2241, batch acc 0.6894
13:03:35.031   Training iter 300, batch loss 0.2235, batch acc 0.6910
13:03:35.544   Training iter 350, batch loss 0.2251, batch acc 0.6842
13:03:36.043   Training iter 400, batch loss 0.2178, batch acc 0.6996
13:03:36.563   Training iter 450, batch loss 0.2189, batch acc 0.6976
13:03:37.094   Training iter 500, batch loss 0.2216, batch acc 0.6934
13:03:37.606   Training iter 550, batch loss 0.2197, batch acc 0.6960
13:03:38.065   Training iter 600, batch loss 0.2185, batch acc 0.7006
13:03:38.067 Testing @ 50 epoch...
13:03:38.103     Testing, total mean loss 0.21984, total acc 0.69550
13:03:38.103 Training @ 51 epoch...
13:03:38.580   Training iter 50, batch loss 0.2212, batch acc 0.6950
13:03:39.066   Training iter 100, batch loss 0.2212, batch acc 0.6954
13:03:39.566   Training iter 150, batch loss 0.2194, batch acc 0.6980
13:03:40.074   Training iter 200, batch loss 0.2201, batch acc 0.6972
13:03:40.559   Training iter 250, batch loss 0.2223, batch acc 0.6964
13:03:41.044   Training iter 300, batch loss 0.2201, batch acc 0.6942
13:03:41.529   Training iter 350, batch loss 0.2193, batch acc 0.6960
13:03:42.012   Training iter 400, batch loss 0.2204, batch acc 0.6950
13:03:42.506   Training iter 450, batch loss 0.2158, batch acc 0.7068
13:03:42.994   Training iter 500, batch loss 0.2176, batch acc 0.6962
13:03:43.481   Training iter 550, batch loss 0.2250, batch acc 0.6922
13:03:43.974   Training iter 600, batch loss 0.2208, batch acc 0.6898
13:03:43.976 Training @ 52 epoch...
13:03:44.484   Training iter 50, batch loss 0.2146, batch acc 0.7080
13:03:44.979   Training iter 100, batch loss 0.2264, batch acc 0.6830
13:03:45.479   Training iter 150, batch loss 0.2159, batch acc 0.7046
13:03:45.977   Training iter 200, batch loss 0.2153, batch acc 0.7030
13:03:46.490   Training iter 250, batch loss 0.2199, batch acc 0.6896
13:03:46.997   Training iter 300, batch loss 0.2213, batch acc 0.6930
13:03:47.503   Training iter 350, batch loss 0.2238, batch acc 0.6918
13:03:48.010   Training iter 400, batch loss 0.2209, batch acc 0.6968
13:03:48.513   Training iter 450, batch loss 0.2231, batch acc 0.6870
13:03:49.009   Training iter 500, batch loss 0.2215, batch acc 0.6904
13:03:49.527   Training iter 550, batch loss 0.2178, batch acc 0.7020
13:03:50.040   Training iter 600, batch loss 0.2128, batch acc 0.7066
13:03:50.042 Training @ 53 epoch...
13:03:50.555   Training iter 50, batch loss 0.2139, batch acc 0.7078
13:03:51.061   Training iter 100, batch loss 0.2158, batch acc 0.6988
13:03:51.571   Training iter 150, batch loss 0.2246, batch acc 0.6890
13:03:52.084   Training iter 200, batch loss 0.2170, batch acc 0.6980
13:03:52.606   Training iter 250, batch loss 0.2193, batch acc 0.6954
13:03:53.086   Training iter 300, batch loss 0.2183, batch acc 0.6964
13:03:53.560   Training iter 350, batch loss 0.2252, batch acc 0.6828
13:03:54.041   Training iter 400, batch loss 0.2197, batch acc 0.6964
13:03:54.536   Training iter 450, batch loss 0.2182, batch acc 0.6980
13:03:55.045   Training iter 500, batch loss 0.2161, batch acc 0.7054
13:03:55.554   Training iter 550, batch loss 0.2134, batch acc 0.7062
13:03:56.059   Training iter 600, batch loss 0.2227, batch acc 0.6900
13:03:56.061 Training @ 54 epoch...
13:03:56.536   Training iter 50, batch loss 0.2220, batch acc 0.6892
13:03:57.011   Training iter 100, batch loss 0.2231, batch acc 0.6904
13:03:57.522   Training iter 150, batch loss 0.2186, batch acc 0.6924
13:03:58.013   Training iter 200, batch loss 0.2181, batch acc 0.6958
13:03:58.544   Training iter 250, batch loss 0.2229, batch acc 0.6870
13:03:59.093   Training iter 300, batch loss 0.2204, batch acc 0.6932
13:03:59.635   Training iter 350, batch loss 0.2114, batch acc 0.7112
13:04:00.193   Training iter 400, batch loss 0.2192, batch acc 0.6964
13:04:00.761   Training iter 450, batch loss 0.2163, batch acc 0.6986
13:04:01.301   Training iter 500, batch loss 0.2122, batch acc 0.7046
13:04:01.878   Training iter 550, batch loss 0.2175, batch acc 0.7008
13:04:02.427   Training iter 600, batch loss 0.2138, batch acc 0.7070
13:04:02.428 Training @ 55 epoch...
13:04:02.964   Training iter 50, batch loss 0.2197, batch acc 0.6914
13:04:03.503   Training iter 100, batch loss 0.2210, batch acc 0.6860
13:04:04.041   Training iter 150, batch loss 0.2214, batch acc 0.6954
13:04:04.571   Training iter 200, batch loss 0.2171, batch acc 0.6956
13:04:05.105   Training iter 250, batch loss 0.2195, batch acc 0.6906
13:04:05.638   Training iter 300, batch loss 0.2126, batch acc 0.7068
13:04:06.175   Training iter 350, batch loss 0.2126, batch acc 0.7076
13:04:06.695   Training iter 400, batch loss 0.2219, batch acc 0.6922
13:04:07.227   Training iter 450, batch loss 0.2173, batch acc 0.7000
13:04:07.760   Training iter 500, batch loss 0.2150, batch acc 0.7030
13:04:08.297   Training iter 550, batch loss 0.2167, batch acc 0.7014
13:04:08.832   Training iter 600, batch loss 0.2122, batch acc 0.7026
13:04:08.834 Testing @ 55 epoch...
13:04:08.874     Testing, total mean loss 0.21604, total acc 0.69770
13:04:08.874 Training @ 56 epoch...
13:04:09.425   Training iter 50, batch loss 0.2224, batch acc 0.6854
13:04:09.961   Training iter 100, batch loss 0.2197, batch acc 0.6970
13:04:10.550   Training iter 150, batch loss 0.2174, batch acc 0.6988
13:04:11.125   Training iter 200, batch loss 0.2100, batch acc 0.7066
13:04:11.697   Training iter 250, batch loss 0.2180, batch acc 0.6974
13:04:12.251   Training iter 300, batch loss 0.2159, batch acc 0.7006
13:04:12.789   Training iter 350, batch loss 0.2163, batch acc 0.7006
13:04:13.321   Training iter 400, batch loss 0.2179, batch acc 0.6966
13:04:13.849   Training iter 450, batch loss 0.2144, batch acc 0.6986
13:04:14.382   Training iter 500, batch loss 0.2132, batch acc 0.7050
13:04:14.943   Training iter 550, batch loss 0.2201, batch acc 0.6918
13:04:15.472   Training iter 600, batch loss 0.2139, batch acc 0.6994
13:04:15.473 Training @ 57 epoch...
13:04:15.992   Training iter 50, batch loss 0.2121, batch acc 0.7076
13:04:16.513   Training iter 100, batch loss 0.2163, batch acc 0.6970
13:04:17.024   Training iter 150, batch loss 0.2149, batch acc 0.7022
13:04:17.551   Training iter 200, batch loss 0.2167, batch acc 0.6964
13:04:18.060   Training iter 250, batch loss 0.2180, batch acc 0.6960
13:04:18.569   Training iter 300, batch loss 0.2174, batch acc 0.6972
13:04:19.072   Training iter 350, batch loss 0.2150, batch acc 0.7002
13:04:19.576   Training iter 400, batch loss 0.2166, batch acc 0.6976
13:04:20.092   Training iter 450, batch loss 0.2196, batch acc 0.6906
13:04:20.574   Training iter 500, batch loss 0.2145, batch acc 0.6962
13:04:21.069   Training iter 550, batch loss 0.2151, batch acc 0.7016
13:04:21.559   Training iter 600, batch loss 0.2154, batch acc 0.7022
13:04:21.561 Training @ 58 epoch...
13:04:22.059   Training iter 50, batch loss 0.2175, batch acc 0.6906
13:04:22.546   Training iter 100, batch loss 0.2160, batch acc 0.6894
13:04:23.040   Training iter 150, batch loss 0.2161, batch acc 0.7056
13:04:23.516   Training iter 200, batch loss 0.2149, batch acc 0.7016
13:04:23.976   Training iter 250, batch loss 0.2159, batch acc 0.7014
13:04:24.453   Training iter 300, batch loss 0.2135, batch acc 0.7070
13:04:24.925   Training iter 350, batch loss 0.2182, batch acc 0.6976
13:04:25.399   Training iter 400, batch loss 0.2135, batch acc 0.6950
13:04:25.845   Training iter 450, batch loss 0.2137, batch acc 0.7028
13:04:26.303   Training iter 500, batch loss 0.2140, batch acc 0.7026
13:04:26.757   Training iter 550, batch loss 0.2181, batch acc 0.6908
13:04:27.257   Training iter 600, batch loss 0.2131, batch acc 0.7034
13:04:27.259 Training @ 59 epoch...
13:04:27.754   Training iter 50, batch loss 0.2200, batch acc 0.6888
13:04:28.231   Training iter 100, batch loss 0.2127, batch acc 0.7038
13:04:28.685   Training iter 150, batch loss 0.2137, batch acc 0.6996
13:04:29.152   Training iter 200, batch loss 0.2163, batch acc 0.6956
13:04:29.613   Training iter 250, batch loss 0.2170, batch acc 0.6990
13:04:30.087   Training iter 300, batch loss 0.2168, batch acc 0.7010
13:04:30.588   Training iter 350, batch loss 0.2123, batch acc 0.7010
13:04:31.123   Training iter 400, batch loss 0.2147, batch acc 0.7000
13:04:31.663   Training iter 450, batch loss 0.2160, batch acc 0.6986
13:04:32.198   Training iter 500, batch loss 0.2181, batch acc 0.6884
13:04:32.740   Training iter 550, batch loss 0.2088, batch acc 0.7114
13:04:33.275   Training iter 600, batch loss 0.2114, batch acc 0.7074
13:04:33.276 Training @ 60 epoch...
13:04:33.805   Training iter 50, batch loss 0.2166, batch acc 0.6950
13:04:34.330   Training iter 100, batch loss 0.2115, batch acc 0.7056
13:04:34.863   Training iter 150, batch loss 0.2155, batch acc 0.6972
13:04:35.402   Training iter 200, batch loss 0.2106, batch acc 0.7100
13:04:35.946   Training iter 250, batch loss 0.2134, batch acc 0.6974
13:04:36.466   Training iter 300, batch loss 0.2137, batch acc 0.7048
13:04:36.947   Training iter 350, batch loss 0.2152, batch acc 0.6982
13:04:37.437   Training iter 400, batch loss 0.2123, batch acc 0.7038
13:04:37.927   Training iter 450, batch loss 0.2172, batch acc 0.6904
13:04:38.415   Training iter 500, batch loss 0.2131, batch acc 0.7052
13:04:38.891   Training iter 550, batch loss 0.2150, batch acc 0.6982
13:04:39.387   Training iter 600, batch loss 0.2172, batch acc 0.6942
13:04:39.388 Testing @ 60 epoch...
13:04:39.425     Testing, total mean loss 0.21311, total acc 0.69970
13:04:39.425 Training @ 61 epoch...
13:04:39.928   Training iter 50, batch loss 0.2142, batch acc 0.6992
13:04:40.410   Training iter 100, batch loss 0.2108, batch acc 0.7054
13:04:40.867   Training iter 150, batch loss 0.2142, batch acc 0.7010
13:04:41.326   Training iter 200, batch loss 0.2114, batch acc 0.7080
13:04:41.783   Training iter 250, batch loss 0.2172, batch acc 0.6926
13:04:42.249   Training iter 300, batch loss 0.2172, batch acc 0.6912
13:04:42.729   Training iter 350, batch loss 0.2086, batch acc 0.7058
13:04:43.198   Training iter 400, batch loss 0.2139, batch acc 0.7008
13:04:43.676   Training iter 450, batch loss 0.2120, batch acc 0.7014
13:04:44.150   Training iter 500, batch loss 0.2182, batch acc 0.6918
13:04:44.612   Training iter 550, batch loss 0.2112, batch acc 0.7108
13:04:45.087   Training iter 600, batch loss 0.2159, batch acc 0.6946
13:04:45.089 Training @ 62 epoch...
13:04:45.570   Training iter 50, batch loss 0.2120, batch acc 0.7012
13:04:46.043   Training iter 100, batch loss 0.2150, batch acc 0.6946
13:04:46.520   Training iter 150, batch loss 0.2179, batch acc 0.6942
13:04:47.017   Training iter 200, batch loss 0.2148, batch acc 0.6966
13:04:47.502   Training iter 250, batch loss 0.2181, batch acc 0.6888
13:04:47.988   Training iter 300, batch loss 0.2108, batch acc 0.7024
13:04:48.468   Training iter 350, batch loss 0.2149, batch acc 0.6974
13:04:48.954   Training iter 400, batch loss 0.2111, batch acc 0.7056
13:04:49.444   Training iter 450, batch loss 0.2106, batch acc 0.7056
13:04:49.940   Training iter 500, batch loss 0.2141, batch acc 0.7062
13:04:50.444   Training iter 550, batch loss 0.2073, batch acc 0.7144
13:04:50.942   Training iter 600, batch loss 0.2123, batch acc 0.6998
13:04:50.943 Training @ 63 epoch...
13:04:51.490   Training iter 50, batch loss 0.2202, batch acc 0.6900
13:04:52.010   Training iter 100, batch loss 0.2100, batch acc 0.7056
13:04:52.547   Training iter 150, batch loss 0.2065, batch acc 0.7124
13:04:53.030   Training iter 200, batch loss 0.2099, batch acc 0.7072
13:04:53.535   Training iter 250, batch loss 0.2144, batch acc 0.6992
13:04:54.020   Training iter 300, batch loss 0.2137, batch acc 0.6984
13:04:54.519   Training iter 350, batch loss 0.2173, batch acc 0.6968
13:04:55.025   Training iter 400, batch loss 0.2151, batch acc 0.6960
13:04:55.526   Training iter 450, batch loss 0.2101, batch acc 0.7056
13:04:56.011   Training iter 500, batch loss 0.2104, batch acc 0.7060
13:04:56.500   Training iter 550, batch loss 0.2126, batch acc 0.6984
13:04:57.045   Training iter 600, batch loss 0.2128, batch acc 0.6970
13:04:57.049 Training @ 64 epoch...
13:04:57.564   Training iter 50, batch loss 0.2099, batch acc 0.7092
13:04:58.060   Training iter 100, batch loss 0.2067, batch acc 0.7146
13:04:58.555   Training iter 150, batch loss 0.2126, batch acc 0.6994
13:04:59.084   Training iter 200, batch loss 0.2094, batch acc 0.7100
13:04:59.614   Training iter 250, batch loss 0.2159, batch acc 0.6934
13:05:00.137   Training iter 300, batch loss 0.2116, batch acc 0.7036
13:05:00.660   Training iter 350, batch loss 0.2112, batch acc 0.7032
13:05:01.230   Training iter 400, batch loss 0.2119, batch acc 0.7002
13:05:01.854   Training iter 450, batch loss 0.2161, batch acc 0.6934
13:05:02.477   Training iter 500, batch loss 0.2119, batch acc 0.7016
13:05:03.082   Training iter 550, batch loss 0.2139, batch acc 0.6984
13:05:03.651   Training iter 600, batch loss 0.2165, batch acc 0.6932
13:05:03.653 Training @ 65 epoch...
13:05:04.244   Training iter 50, batch loss 0.2098, batch acc 0.7074
13:05:04.798   Training iter 100, batch loss 0.2130, batch acc 0.6988
13:05:05.342   Training iter 150, batch loss 0.2097, batch acc 0.7046
13:05:05.889   Training iter 200, batch loss 0.2167, batch acc 0.6928
13:05:06.401   Training iter 250, batch loss 0.2117, batch acc 0.7050
13:05:06.933   Training iter 300, batch loss 0.2092, batch acc 0.7030
13:05:07.488   Training iter 350, batch loss 0.2143, batch acc 0.6974
13:05:08.012   Training iter 400, batch loss 0.2102, batch acc 0.7022
13:05:08.522   Training iter 450, batch loss 0.2123, batch acc 0.7010
13:05:09.007   Training iter 500, batch loss 0.2139, batch acc 0.6980
13:05:09.480   Training iter 550, batch loss 0.2126, batch acc 0.7022
13:05:09.949   Training iter 600, batch loss 0.2088, batch acc 0.7084
13:05:09.951 Testing @ 65 epoch...
13:05:09.988     Testing, total mean loss 0.21077, total acc 0.70060
13:05:09.988 Training @ 66 epoch...
13:05:10.479   Training iter 50, batch loss 0.2105, batch acc 0.7004
13:05:10.950   Training iter 100, batch loss 0.2131, batch acc 0.6984
13:05:11.430   Training iter 150, batch loss 0.2094, batch acc 0.7058
13:05:11.892   Training iter 200, batch loss 0.2134, batch acc 0.6968
13:05:12.356   Training iter 250, batch loss 0.2143, batch acc 0.6972
13:05:12.836   Training iter 300, batch loss 0.2070, batch acc 0.7110
13:05:13.337   Training iter 350, batch loss 0.2109, batch acc 0.7022
13:05:13.833   Training iter 400, batch loss 0.2095, batch acc 0.7068
13:05:14.325   Training iter 450, batch loss 0.2153, batch acc 0.7004
13:05:14.827   Training iter 500, batch loss 0.2080, batch acc 0.7112
13:05:15.324   Training iter 550, batch loss 0.2101, batch acc 0.7008
13:05:15.802   Training iter 600, batch loss 0.2155, batch acc 0.6954
13:05:15.804 Training @ 67 epoch...
13:05:16.299   Training iter 50, batch loss 0.2136, batch acc 0.6982
13:05:16.806   Training iter 100, batch loss 0.2095, batch acc 0.7060
13:05:17.322   Training iter 150, batch loss 0.2080, batch acc 0.7114
13:05:17.817   Training iter 200, batch loss 0.2112, batch acc 0.7010
13:05:18.322   Training iter 250, batch loss 0.2125, batch acc 0.6974
13:05:18.850   Training iter 300, batch loss 0.2072, batch acc 0.7124
13:05:19.389   Training iter 350, batch loss 0.2130, batch acc 0.7004
13:05:19.930   Training iter 400, batch loss 0.2107, batch acc 0.7024
13:05:20.481   Training iter 450, batch loss 0.2098, batch acc 0.7034
13:05:21.022   Training iter 500, batch loss 0.2086, batch acc 0.7022
13:05:21.567   Training iter 550, batch loss 0.2145, batch acc 0.6964
13:05:22.120   Training iter 600, batch loss 0.2133, batch acc 0.6992
13:05:22.122 Training @ 68 epoch...
13:05:22.678   Training iter 50, batch loss 0.2109, batch acc 0.7036
13:05:23.226   Training iter 100, batch loss 0.2131, batch acc 0.6958
13:05:23.762   Training iter 150, batch loss 0.2091, batch acc 0.7034
13:05:24.309   Training iter 200, batch loss 0.2119, batch acc 0.7068
13:05:24.849   Training iter 250, batch loss 0.2118, batch acc 0.7010
13:05:25.391   Training iter 300, batch loss 0.2089, batch acc 0.7052
13:05:25.913   Training iter 350, batch loss 0.2105, batch acc 0.7032
13:05:26.444   Training iter 400, batch loss 0.2064, batch acc 0.7160
13:05:26.968   Training iter 450, batch loss 0.2129, batch acc 0.6982
13:05:27.499   Training iter 500, batch loss 0.2119, batch acc 0.6998
13:05:28.023   Training iter 550, batch loss 0.2049, batch acc 0.7108
13:05:28.531   Training iter 600, batch loss 0.2148, batch acc 0.6926
13:05:28.533 Training @ 69 epoch...
13:05:29.038   Training iter 50, batch loss 0.2065, batch acc 0.7116
13:05:29.514   Training iter 100, batch loss 0.2093, batch acc 0.7052
13:05:29.996   Training iter 150, batch loss 0.2131, batch acc 0.6932
13:05:30.490   Training iter 200, batch loss 0.2060, batch acc 0.7120
13:05:30.985   Training iter 250, batch loss 0.2074, batch acc 0.7088
13:05:31.480   Training iter 300, batch loss 0.2073, batch acc 0.7088
13:05:31.962   Training iter 350, batch loss 0.2089, batch acc 0.7060
13:05:32.435   Training iter 400, batch loss 0.2107, batch acc 0.7038
13:05:32.920   Training iter 450, batch loss 0.2159, batch acc 0.6908
13:05:33.411   Training iter 500, batch loss 0.2135, batch acc 0.6974
13:05:33.891   Training iter 550, batch loss 0.2173, batch acc 0.6882
13:05:34.372   Training iter 600, batch loss 0.2064, batch acc 0.7138
13:05:34.373 Training @ 70 epoch...
13:05:34.861   Training iter 50, batch loss 0.2126, batch acc 0.6940
13:05:35.339   Training iter 100, batch loss 0.2102, batch acc 0.7050
13:05:35.805   Training iter 150, batch loss 0.2076, batch acc 0.7078
13:05:36.301   Training iter 200, batch loss 0.2107, batch acc 0.7036
13:05:36.799   Training iter 250, batch loss 0.2117, batch acc 0.7034
13:05:37.308   Training iter 300, batch loss 0.2085, batch acc 0.7066
13:05:37.797   Training iter 350, batch loss 0.2108, batch acc 0.7046
13:05:38.283   Training iter 400, batch loss 0.2095, batch acc 0.7026
13:05:38.754   Training iter 450, batch loss 0.2083, batch acc 0.7048
13:05:39.257   Training iter 500, batch loss 0.2100, batch acc 0.7006
13:05:39.738   Training iter 550, batch loss 0.2072, batch acc 0.7094
13:05:40.222   Training iter 600, batch loss 0.2105, batch acc 0.6992
13:05:40.223 Testing @ 70 epoch...
13:05:40.260     Testing, total mean loss 0.20876, total acc 0.70240
13:05:40.260 Training @ 71 epoch...
13:05:40.732   Training iter 50, batch loss 0.2053, batch acc 0.7134
13:05:41.227   Training iter 100, batch loss 0.2138, batch acc 0.6954
13:05:41.684   Training iter 150, batch loss 0.2003, batch acc 0.7204
13:05:42.162   Training iter 200, batch loss 0.2043, batch acc 0.7134
13:05:42.615   Training iter 250, batch loss 0.2108, batch acc 0.7000
13:05:43.088   Training iter 300, batch loss 0.2119, batch acc 0.6944
13:05:43.558   Training iter 350, batch loss 0.2135, batch acc 0.6954
13:05:44.020   Training iter 400, batch loss 0.2119, batch acc 0.6952
13:05:44.484   Training iter 450, batch loss 0.2091, batch acc 0.7076
13:05:44.949   Training iter 500, batch loss 0.2047, batch acc 0.7188
13:05:45.428   Training iter 550, batch loss 0.2127, batch acc 0.6974
13:05:45.883   Training iter 600, batch loss 0.2147, batch acc 0.6918
13:05:45.885 Training @ 72 epoch...
13:05:46.360   Training iter 50, batch loss 0.2063, batch acc 0.7126
13:05:46.835   Training iter 100, batch loss 0.2123, batch acc 0.6986
13:05:47.295   Training iter 150, batch loss 0.2076, batch acc 0.7070
13:05:47.764   Training iter 200, batch loss 0.2078, batch acc 0.7038
13:05:48.237   Training iter 250, batch loss 0.2068, batch acc 0.7106
13:05:48.711   Training iter 300, batch loss 0.2116, batch acc 0.6990
13:05:49.186   Training iter 350, batch loss 0.2103, batch acc 0.7050
13:05:49.656   Training iter 400, batch loss 0.2096, batch acc 0.7082
13:05:50.135   Training iter 450, batch loss 0.2091, batch acc 0.7002
13:05:50.620   Training iter 500, batch loss 0.2124, batch acc 0.6980
13:05:51.097   Training iter 550, batch loss 0.2059, batch acc 0.7050
13:05:51.613   Training iter 600, batch loss 0.2091, batch acc 0.7008
13:05:51.614 Training @ 73 epoch...
13:05:52.133   Training iter 50, batch loss 0.2058, batch acc 0.7094
13:05:52.631   Training iter 100, batch loss 0.2108, batch acc 0.7024
13:05:53.181   Training iter 150, batch loss 0.2110, batch acc 0.6982
13:05:53.754   Training iter 200, batch loss 0.2036, batch acc 0.7136
13:05:54.331   Training iter 250, batch loss 0.2092, batch acc 0.7006
13:05:54.887   Training iter 300, batch loss 0.2117, batch acc 0.7044
13:05:55.430   Training iter 350, batch loss 0.2128, batch acc 0.6950
13:05:55.949   Training iter 400, batch loss 0.2090, batch acc 0.7014
13:05:56.464   Training iter 450, batch loss 0.2084, batch acc 0.7040
13:05:56.949   Training iter 500, batch loss 0.2111, batch acc 0.7006
13:05:57.458   Training iter 550, batch loss 0.2033, batch acc 0.7150
13:05:57.938   Training iter 600, batch loss 0.2079, batch acc 0.7070
13:05:57.940 Training @ 74 epoch...
13:05:58.428   Training iter 50, batch loss 0.2137, batch acc 0.6952
13:05:58.897   Training iter 100, batch loss 0.2069, batch acc 0.7032
13:05:59.369   Training iter 150, batch loss 0.2033, batch acc 0.7172
13:05:59.842   Training iter 200, batch loss 0.2173, batch acc 0.6858
13:06:00.366   Training iter 250, batch loss 0.2112, batch acc 0.6982
13:06:00.881   Training iter 300, batch loss 0.2070, batch acc 0.7092
13:06:01.393   Training iter 350, batch loss 0.2042, batch acc 0.7150
13:06:01.937   Training iter 400, batch loss 0.2073, batch acc 0.7096
13:06:02.456   Training iter 450, batch loss 0.2060, batch acc 0.7108
13:06:02.952   Training iter 500, batch loss 0.2044, batch acc 0.7128
13:06:03.456   Training iter 550, batch loss 0.2108, batch acc 0.6978
13:06:03.995   Training iter 600, batch loss 0.2082, batch acc 0.7018
13:06:03.996 Training @ 75 epoch...
13:06:04.518   Training iter 50, batch loss 0.2117, batch acc 0.6996
13:06:05.037   Training iter 100, batch loss 0.2064, batch acc 0.7086
13:06:05.585   Training iter 150, batch loss 0.2103, batch acc 0.6990
13:06:06.135   Training iter 200, batch loss 0.2084, batch acc 0.7020
13:06:06.694   Training iter 250, batch loss 0.2076, batch acc 0.7076
13:06:07.285   Training iter 300, batch loss 0.2097, batch acc 0.7022
13:06:07.862   Training iter 350, batch loss 0.2053, batch acc 0.7062
13:06:08.445   Training iter 400, batch loss 0.2080, batch acc 0.7056
13:06:09.033   Training iter 450, batch loss 0.2080, batch acc 0.7016
13:06:09.599   Training iter 500, batch loss 0.2062, batch acc 0.7080
13:06:10.187   Training iter 550, batch loss 0.2092, batch acc 0.7060
13:06:10.861   Training iter 600, batch loss 0.2054, batch acc 0.7120
13:06:10.863 Testing @ 75 epoch...
13:06:10.917     Testing, total mean loss 0.20702, total acc 0.70340
13:06:10.917 Training @ 76 epoch...
13:06:11.612   Training iter 50, batch loss 0.2086, batch acc 0.7020
13:06:12.270   Training iter 100, batch loss 0.2027, batch acc 0.7216
13:06:12.792   Training iter 150, batch loss 0.2110, batch acc 0.6992
13:06:13.307   Training iter 200, batch loss 0.2038, batch acc 0.7086
13:06:13.833   Training iter 250, batch loss 0.2080, batch acc 0.7046
13:06:14.366   Training iter 300, batch loss 0.2077, batch acc 0.7058
13:06:14.885   Training iter 350, batch loss 0.2046, batch acc 0.7090
13:06:15.398   Training iter 400, batch loss 0.2047, batch acc 0.7078
13:06:15.922   Training iter 450, batch loss 0.2081, batch acc 0.7034
13:06:16.482   Training iter 500, batch loss 0.2149, batch acc 0.6908
13:06:17.042   Training iter 550, batch loss 0.2102, batch acc 0.7008
13:06:17.555   Training iter 600, batch loss 0.2077, batch acc 0.7096
13:06:17.556 Training @ 77 epoch...
13:06:18.078   Training iter 50, batch loss 0.2055, batch acc 0.7112
13:06:18.598   Training iter 100, batch loss 0.2063, batch acc 0.7110
13:06:19.115   Training iter 150, batch loss 0.2080, batch acc 0.7014
13:06:19.634   Training iter 200, batch loss 0.2103, batch acc 0.6990
13:06:20.159   Training iter 250, batch loss 0.2054, batch acc 0.7066
13:06:20.672   Training iter 300, batch loss 0.2009, batch acc 0.7140
13:06:21.186   Training iter 350, batch loss 0.2145, batch acc 0.6924
13:06:21.686   Training iter 400, batch loss 0.2126, batch acc 0.6952
13:06:22.184   Training iter 450, batch loss 0.2084, batch acc 0.7090
13:06:22.706   Training iter 500, batch loss 0.2028, batch acc 0.7132
13:06:23.234   Training iter 550, batch loss 0.2076, batch acc 0.7028
13:06:23.771   Training iter 600, batch loss 0.2062, batch acc 0.7122
13:06:23.772 Training @ 78 epoch...
13:06:24.333   Training iter 50, batch loss 0.2062, batch acc 0.7078
13:06:24.881   Training iter 100, batch loss 0.2025, batch acc 0.7144
13:06:25.424   Training iter 150, batch loss 0.2066, batch acc 0.7052
13:06:25.961   Training iter 200, batch loss 0.2049, batch acc 0.7142
13:06:26.500   Training iter 250, batch loss 0.2053, batch acc 0.7076
13:06:27.026   Training iter 300, batch loss 0.2116, batch acc 0.6950
13:06:27.585   Training iter 350, batch loss 0.2061, batch acc 0.7126
13:06:28.151   Training iter 400, batch loss 0.2124, batch acc 0.6996
13:06:28.706   Training iter 450, batch loss 0.2151, batch acc 0.6874
13:06:29.266   Training iter 500, batch loss 0.2086, batch acc 0.7012
13:06:29.808   Training iter 550, batch loss 0.1999, batch acc 0.7164
13:06:30.326   Training iter 600, batch loss 0.2054, batch acc 0.7058
13:06:30.328 Training @ 79 epoch...
13:06:30.840   Training iter 50, batch loss 0.2068, batch acc 0.7070
13:06:31.333   Training iter 100, batch loss 0.2030, batch acc 0.7172
13:06:31.821   Training iter 150, batch loss 0.2107, batch acc 0.7024
13:06:32.327   Training iter 200, batch loss 0.2060, batch acc 0.7034
13:06:32.811   Training iter 250, batch loss 0.2034, batch acc 0.7122
13:06:33.304   Training iter 300, batch loss 0.1999, batch acc 0.7216
13:06:33.802   Training iter 350, batch loss 0.2078, batch acc 0.6992
13:06:34.285   Training iter 400, batch loss 0.2093, batch acc 0.6972
13:06:34.779   Training iter 450, batch loss 0.2083, batch acc 0.6996
13:06:35.251   Training iter 500, batch loss 0.2124, batch acc 0.6940
13:06:35.722   Training iter 550, batch loss 0.2033, batch acc 0.7114
13:06:36.194   Training iter 600, batch loss 0.2098, batch acc 0.7030
13:06:36.196 Training @ 80 epoch...
13:06:36.680   Training iter 50, batch loss 0.2042, batch acc 0.7118
13:06:37.158   Training iter 100, batch loss 0.2117, batch acc 0.6984
13:06:37.638   Training iter 150, batch loss 0.2077, batch acc 0.7072
13:06:38.110   Training iter 200, batch loss 0.2070, batch acc 0.7050
13:06:38.591   Training iter 250, batch loss 0.2028, batch acc 0.7140
13:06:39.070   Training iter 300, batch loss 0.2046, batch acc 0.7040
13:06:39.559   Training iter 350, batch loss 0.2063, batch acc 0.7040
13:06:40.057   Training iter 400, batch loss 0.2096, batch acc 0.7024
13:06:40.574   Training iter 450, batch loss 0.2083, batch acc 0.7012
13:06:41.069   Training iter 500, batch loss 0.2035, batch acc 0.7102
13:06:41.608   Training iter 550, batch loss 0.2092, batch acc 0.7014
13:06:42.136   Training iter 600, batch loss 0.2024, batch acc 0.7122
13:06:42.138 Testing @ 80 epoch...
13:06:42.176     Testing, total mean loss 0.20549, total acc 0.70550
13:06:42.176 Training @ 81 epoch...
13:06:42.711   Training iter 50, batch loss 0.2024, batch acc 0.7112
13:06:43.253   Training iter 100, batch loss 0.2044, batch acc 0.7078
13:06:43.781   Training iter 150, batch loss 0.2138, batch acc 0.6922
13:06:44.319   Training iter 200, batch loss 0.2004, batch acc 0.7230
13:06:44.866   Training iter 250, batch loss 0.2047, batch acc 0.7112
13:06:45.422   Training iter 300, batch loss 0.2092, batch acc 0.6978
13:06:45.953   Training iter 350, batch loss 0.2107, batch acc 0.6982
13:06:46.478   Training iter 400, batch loss 0.2077, batch acc 0.7008
13:06:46.988   Training iter 450, batch loss 0.2042, batch acc 0.7080
13:06:47.487   Training iter 500, batch loss 0.2054, batch acc 0.7058
13:06:47.987   Training iter 550, batch loss 0.2066, batch acc 0.7052
13:06:48.497   Training iter 600, batch loss 0.2040, batch acc 0.7112
13:06:48.499 Training @ 82 epoch...
13:06:48.995   Training iter 50, batch loss 0.2137, batch acc 0.6906
13:06:49.482   Training iter 100, batch loss 0.2075, batch acc 0.7028
13:06:49.987   Training iter 150, batch loss 0.2081, batch acc 0.6984
13:06:50.498   Training iter 200, batch loss 0.2031, batch acc 0.7130
13:06:50.996   Training iter 250, batch loss 0.2045, batch acc 0.7064
13:06:51.489   Training iter 300, batch loss 0.2038, batch acc 0.7116
13:06:51.971   Training iter 350, batch loss 0.2071, batch acc 0.7014
13:06:52.473   Training iter 400, batch loss 0.2061, batch acc 0.7070
13:06:52.969   Training iter 450, batch loss 0.2004, batch acc 0.7228
13:06:53.459   Training iter 500, batch loss 0.2029, batch acc 0.7136
13:06:53.960   Training iter 550, batch loss 0.2071, batch acc 0.7008
13:06:54.430   Training iter 600, batch loss 0.2060, batch acc 0.7078
13:06:54.431 Training @ 83 epoch...
13:06:54.900   Training iter 50, batch loss 0.2103, batch acc 0.6986
13:06:55.384   Training iter 100, batch loss 0.2066, batch acc 0.7084
13:06:55.884   Training iter 150, batch loss 0.2060, batch acc 0.7024
13:06:56.396   Training iter 200, batch loss 0.2062, batch acc 0.7052
13:06:56.901   Training iter 250, batch loss 0.2071, batch acc 0.7054
13:06:57.413   Training iter 300, batch loss 0.2022, batch acc 0.7130
13:06:57.927   Training iter 350, batch loss 0.1991, batch acc 0.7196
13:06:58.459   Training iter 400, batch loss 0.2045, batch acc 0.7090
13:06:58.997   Training iter 450, batch loss 0.2009, batch acc 0.7154
13:06:59.536   Training iter 500, batch loss 0.2066, batch acc 0.7022
13:07:00.074   Training iter 550, batch loss 0.2104, batch acc 0.6958
13:07:00.622   Training iter 600, batch loss 0.2068, batch acc 0.7062
13:07:00.624 Training @ 84 epoch...
13:07:01.171   Training iter 50, batch loss 0.2085, batch acc 0.6962
13:07:01.742   Training iter 100, batch loss 0.2015, batch acc 0.7158
13:07:02.304   Training iter 150, batch loss 0.2021, batch acc 0.7164
13:07:02.854   Training iter 200, batch loss 0.2063, batch acc 0.7090
13:07:03.394   Training iter 250, batch loss 0.2066, batch acc 0.7016
13:07:03.938   Training iter 300, batch loss 0.2079, batch acc 0.7044
13:07:04.480   Training iter 350, batch loss 0.2037, batch acc 0.7066
13:07:05.043   Training iter 400, batch loss 0.2006, batch acc 0.7152
13:07:05.602   Training iter 450, batch loss 0.2040, batch acc 0.7056
13:07:06.144   Training iter 500, batch loss 0.2089, batch acc 0.6982
13:07:06.680   Training iter 550, batch loss 0.2083, batch acc 0.7022
13:07:07.249   Training iter 600, batch loss 0.2049, batch acc 0.7102
13:07:07.251 Training @ 85 epoch...
13:07:07.820   Training iter 50, batch loss 0.2106, batch acc 0.6992
13:07:08.385   Training iter 100, batch loss 0.2069, batch acc 0.7012
13:07:08.931   Training iter 150, batch loss 0.2072, batch acc 0.7026
13:07:09.474   Training iter 200, batch loss 0.2016, batch acc 0.7160
13:07:10.016   Training iter 250, batch loss 0.2062, batch acc 0.7066
13:07:10.543   Training iter 300, batch loss 0.2053, batch acc 0.7070
13:07:11.072   Training iter 350, batch loss 0.2044, batch acc 0.7108
13:07:11.592   Training iter 400, batch loss 0.2023, batch acc 0.7158
13:07:12.146   Training iter 450, batch loss 0.2007, batch acc 0.7158
13:07:12.726   Training iter 500, batch loss 0.2014, batch acc 0.7102
13:07:13.306   Training iter 550, batch loss 0.2044, batch acc 0.7078
13:07:13.880   Training iter 600, batch loss 0.2090, batch acc 0.6930
13:07:13.882 Testing @ 85 epoch...
13:07:13.922     Testing, total mean loss 0.20406, total acc 0.70650
13:07:13.922 Training @ 86 epoch...
13:07:14.498   Training iter 50, batch loss 0.2039, batch acc 0.7070
13:07:15.069   Training iter 100, batch loss 0.2051, batch acc 0.7086
13:07:15.654   Training iter 150, batch loss 0.2092, batch acc 0.7014
13:07:16.241   Training iter 200, batch loss 0.2038, batch acc 0.7068
13:07:16.826   Training iter 250, batch loss 0.1980, batch acc 0.7186
13:07:17.421   Training iter 300, batch loss 0.2053, batch acc 0.7040
13:07:18.006   Training iter 350, batch loss 0.2039, batch acc 0.7076
13:07:18.559   Training iter 400, batch loss 0.2037, batch acc 0.7112
13:07:19.097   Training iter 450, batch loss 0.2043, batch acc 0.7030
13:07:19.629   Training iter 500, batch loss 0.2092, batch acc 0.6960
13:07:20.159   Training iter 550, batch loss 0.2050, batch acc 0.7110
13:07:20.688   Training iter 600, batch loss 0.2054, batch acc 0.7094
13:07:20.690 Training @ 87 epoch...
13:07:21.230   Training iter 50, batch loss 0.2050, batch acc 0.7034
13:07:21.755   Training iter 100, batch loss 0.2049, batch acc 0.7062
13:07:22.284   Training iter 150, batch loss 0.2062, batch acc 0.7084
13:07:22.822   Training iter 200, batch loss 0.2029, batch acc 0.7114
13:07:23.350   Training iter 250, batch loss 0.2086, batch acc 0.6988
13:07:23.873   Training iter 300, batch loss 0.2052, batch acc 0.7052
13:07:24.412   Training iter 350, batch loss 0.2055, batch acc 0.7034
13:07:24.987   Training iter 400, batch loss 0.2025, batch acc 0.7104
13:07:25.566   Training iter 450, batch loss 0.2061, batch acc 0.7024
13:07:26.125   Training iter 500, batch loss 0.2025, batch acc 0.7080
13:07:26.607   Training iter 550, batch loss 0.2008, batch acc 0.7156
13:07:27.101   Training iter 600, batch loss 0.2033, batch acc 0.7114
13:07:27.103 Training @ 88 epoch...
13:07:27.604   Training iter 50, batch loss 0.1999, batch acc 0.7184
13:07:28.108   Training iter 100, batch loss 0.2024, batch acc 0.7154
13:07:28.647   Training iter 150, batch loss 0.2053, batch acc 0.7042
13:07:29.186   Training iter 200, batch loss 0.2038, batch acc 0.7092
13:07:29.716   Training iter 250, batch loss 0.2026, batch acc 0.7088
13:07:30.257   Training iter 300, batch loss 0.2098, batch acc 0.6986
13:07:30.805   Training iter 350, batch loss 0.2031, batch acc 0.7094
13:07:31.345   Training iter 400, batch loss 0.2057, batch acc 0.7016
13:07:31.885   Training iter 450, batch loss 0.1989, batch acc 0.7188
13:07:32.432   Training iter 500, batch loss 0.2013, batch acc 0.7060
13:07:32.985   Training iter 550, batch loss 0.2072, batch acc 0.7016
13:07:33.536   Training iter 600, batch loss 0.2105, batch acc 0.6966
13:07:33.538 Training @ 89 epoch...
13:07:34.088   Training iter 50, batch loss 0.2037, batch acc 0.7128
13:07:34.613   Training iter 100, batch loss 0.2024, batch acc 0.7128
13:07:35.139   Training iter 150, batch loss 0.2049, batch acc 0.7062
13:07:35.654   Training iter 200, batch loss 0.2096, batch acc 0.6914
13:07:36.145   Training iter 250, batch loss 0.2047, batch acc 0.7044
13:07:36.643   Training iter 300, batch loss 0.2012, batch acc 0.7166
13:07:37.147   Training iter 350, batch loss 0.1992, batch acc 0.7126
13:07:37.650   Training iter 400, batch loss 0.2046, batch acc 0.7020
13:07:38.152   Training iter 450, batch loss 0.1998, batch acc 0.7178
13:07:38.671   Training iter 500, batch loss 0.2064, batch acc 0.7046
13:07:39.201   Training iter 550, batch loss 0.2070, batch acc 0.7028
13:07:39.716   Training iter 600, batch loss 0.2039, batch acc 0.7080
13:07:39.718 Training @ 90 epoch...
13:07:40.249   Training iter 50, batch loss 0.2076, batch acc 0.7024
13:07:40.757   Training iter 100, batch loss 0.2003, batch acc 0.7144
13:07:41.268   Training iter 150, batch loss 0.2002, batch acc 0.7144
13:07:41.783   Training iter 200, batch loss 0.2092, batch acc 0.7004
13:07:42.303   Training iter 250, batch loss 0.2088, batch acc 0.6986
13:07:42.832   Training iter 300, batch loss 0.2025, batch acc 0.7102
13:07:43.363   Training iter 350, batch loss 0.2039, batch acc 0.7054
13:07:43.895   Training iter 400, batch loss 0.2013, batch acc 0.7108
13:07:44.433   Training iter 450, batch loss 0.2034, batch acc 0.7126
13:07:44.962   Training iter 500, batch loss 0.1996, batch acc 0.7174
13:07:45.465   Training iter 550, batch loss 0.2030, batch acc 0.7060
13:07:45.982   Training iter 600, batch loss 0.2045, batch acc 0.7036
13:07:45.983 Testing @ 90 epoch...
13:07:46.025     Testing, total mean loss 0.20280, total acc 0.70760
13:07:46.025 Training @ 91 epoch...
13:07:46.523   Training iter 50, batch loss 0.2034, batch acc 0.7032
13:07:47.007   Training iter 100, batch loss 0.1999, batch acc 0.7136
13:07:47.502   Training iter 150, batch loss 0.2025, batch acc 0.7106
13:07:48.016   Training iter 200, batch loss 0.2054, batch acc 0.7064
13:07:48.534   Training iter 250, batch loss 0.2046, batch acc 0.7056
13:07:49.034   Training iter 300, batch loss 0.2011, batch acc 0.7144
13:07:49.530   Training iter 350, batch loss 0.2029, batch acc 0.7112
13:07:50.029   Training iter 400, batch loss 0.2040, batch acc 0.7094
13:07:50.539   Training iter 450, batch loss 0.2021, batch acc 0.7096
13:07:51.041   Training iter 500, batch loss 0.2024, batch acc 0.7098
13:07:51.526   Training iter 550, batch loss 0.2085, batch acc 0.6976
13:07:52.031   Training iter 600, batch loss 0.2044, batch acc 0.7054
13:07:52.032 Training @ 92 epoch...
13:07:52.524   Training iter 50, batch loss 0.2026, batch acc 0.7112
13:07:53.025   Training iter 100, batch loss 0.1961, batch acc 0.7204
13:07:53.535   Training iter 150, batch loss 0.1988, batch acc 0.7136
13:07:54.018   Training iter 200, batch loss 0.2031, batch acc 0.7094
13:07:54.500   Training iter 250, batch loss 0.2061, batch acc 0.7008
13:07:54.994   Training iter 300, batch loss 0.2034, batch acc 0.7054
13:07:55.538   Training iter 350, batch loss 0.2084, batch acc 0.7000
13:07:56.061   Training iter 400, batch loss 0.2015, batch acc 0.7126
13:07:56.591   Training iter 450, batch loss 0.2062, batch acc 0.7058
13:07:57.111   Training iter 500, batch loss 0.2043, batch acc 0.7068
13:07:57.636   Training iter 550, batch loss 0.2017, batch acc 0.7120
13:07:58.175   Training iter 600, batch loss 0.2063, batch acc 0.7028
13:07:58.177 Training @ 93 epoch...
13:07:58.706   Training iter 50, batch loss 0.2059, batch acc 0.7074
13:07:59.218   Training iter 100, batch loss 0.2002, batch acc 0.7094
13:07:59.723   Training iter 150, batch loss 0.2063, batch acc 0.6990
13:08:00.253   Training iter 200, batch loss 0.2042, batch acc 0.7062
13:08:00.792   Training iter 250, batch loss 0.2054, batch acc 0.7008
13:08:01.344   Training iter 300, batch loss 0.2002, batch acc 0.7136
13:08:01.874   Training iter 350, batch loss 0.2019, batch acc 0.7122
13:08:02.431   Training iter 400, batch loss 0.2020, batch acc 0.7142
13:08:02.964   Training iter 450, batch loss 0.2016, batch acc 0.7124
13:08:03.506   Training iter 500, batch loss 0.2022, batch acc 0.7096
13:08:04.037   Training iter 550, batch loss 0.2010, batch acc 0.7128
13:08:04.551   Training iter 600, batch loss 0.2050, batch acc 0.7028
13:08:04.553 Training @ 94 epoch...
13:08:05.068   Training iter 50, batch loss 0.2023, batch acc 0.7026
13:08:05.596   Training iter 100, batch loss 0.2053, batch acc 0.7002
13:08:06.115   Training iter 150, batch loss 0.2039, batch acc 0.7046
13:08:06.609   Training iter 200, batch loss 0.2041, batch acc 0.7048
13:08:07.060   Training iter 250, batch loss 0.2034, batch acc 0.7112
13:08:07.542   Training iter 300, batch loss 0.2046, batch acc 0.7030
13:08:08.022   Training iter 350, batch loss 0.1989, batch acc 0.7176
13:08:08.511   Training iter 400, batch loss 0.2056, batch acc 0.6982
13:08:09.001   Training iter 450, batch loss 0.2010, batch acc 0.7168
13:08:09.491   Training iter 500, batch loss 0.1995, batch acc 0.7192
13:08:09.986   Training iter 550, batch loss 0.2029, batch acc 0.7104
13:08:10.500   Training iter 600, batch loss 0.2016, batch acc 0.7120
13:08:10.502 Training @ 95 epoch...
13:08:10.998   Training iter 50, batch loss 0.2023, batch acc 0.7106
13:08:11.497   Training iter 100, batch loss 0.2101, batch acc 0.6956
13:08:12.005   Training iter 150, batch loss 0.2002, batch acc 0.7106
13:08:12.518   Training iter 200, batch loss 0.2017, batch acc 0.7122
13:08:13.022   Training iter 250, batch loss 0.1981, batch acc 0.7200
13:08:13.530   Training iter 300, batch loss 0.1989, batch acc 0.7218
13:08:14.039   Training iter 350, batch loss 0.1994, batch acc 0.7134
13:08:14.551   Training iter 400, batch loss 0.2045, batch acc 0.7038
13:08:15.098   Training iter 450, batch loss 0.2049, batch acc 0.7028
13:08:16.134   Training iter 500, batch loss 0.2062, batch acc 0.7008
13:08:16.745   Training iter 550, batch loss 0.2015, batch acc 0.7080
13:08:17.334   Training iter 600, batch loss 0.2026, batch acc 0.7062
13:08:17.336 Testing @ 95 epoch...
13:08:17.375     Testing, total mean loss 0.20165, total acc 0.70840
13:08:17.375 Training @ 96 epoch...
13:08:17.919   Training iter 50, batch loss 0.2041, batch acc 0.7070
13:08:18.432   Training iter 100, batch loss 0.2000, batch acc 0.7154
13:08:18.941   Training iter 150, batch loss 0.1994, batch acc 0.7130
13:08:19.446   Training iter 200, batch loss 0.2034, batch acc 0.7078
13:08:19.966   Training iter 250, batch loss 0.2044, batch acc 0.7050
13:08:20.500   Training iter 300, batch loss 0.2035, batch acc 0.7116
13:08:21.007   Training iter 350, batch loss 0.2066, batch acc 0.7002
13:08:21.504   Training iter 400, batch loss 0.2054, batch acc 0.7022
13:08:22.009   Training iter 450, batch loss 0.1999, batch acc 0.7206
13:08:22.511   Training iter 500, batch loss 0.1997, batch acc 0.7068
13:08:23.013   Training iter 550, batch loss 0.2034, batch acc 0.7036
13:08:23.511   Training iter 600, batch loss 0.1980, batch acc 0.7142
13:08:23.513 Training @ 97 epoch...
13:08:23.982   Training iter 50, batch loss 0.1984, batch acc 0.7184
13:08:24.447   Training iter 100, batch loss 0.2061, batch acc 0.7004
13:08:24.931   Training iter 150, batch loss 0.2052, batch acc 0.7054
13:08:25.446   Training iter 200, batch loss 0.2005, batch acc 0.7130
13:08:25.939   Training iter 250, batch loss 0.2026, batch acc 0.7092
13:08:26.435   Training iter 300, batch loss 0.1972, batch acc 0.7214
13:08:26.919   Training iter 350, batch loss 0.2020, batch acc 0.7098
13:08:27.422   Training iter 400, batch loss 0.2030, batch acc 0.7048
13:08:27.928   Training iter 450, batch loss 0.2049, batch acc 0.6972
13:08:28.431   Training iter 500, batch loss 0.2023, batch acc 0.7052
13:08:28.908   Training iter 550, batch loss 0.1978, batch acc 0.7188
13:08:29.388   Training iter 600, batch loss 0.2051, batch acc 0.7050
13:08:29.390 Training @ 98 epoch...
13:08:29.894   Training iter 50, batch loss 0.2036, batch acc 0.7058
13:08:30.425   Training iter 100, batch loss 0.2013, batch acc 0.7122
13:08:30.934   Training iter 150, batch loss 0.1960, batch acc 0.7188
13:08:31.420   Training iter 200, batch loss 0.2001, batch acc 0.7126
13:08:31.924   Training iter 250, batch loss 0.2059, batch acc 0.6996
13:08:32.466   Training iter 300, batch loss 0.1987, batch acc 0.7148
13:08:33.035   Training iter 350, batch loss 0.2010, batch acc 0.7108
13:08:33.598   Training iter 400, batch loss 0.1985, batch acc 0.7168
13:08:34.158   Training iter 450, batch loss 0.2072, batch acc 0.7018
13:08:34.710   Training iter 500, batch loss 0.2034, batch acc 0.7082
13:08:35.277   Training iter 550, batch loss 0.2037, batch acc 0.7042
13:08:35.831   Training iter 600, batch loss 0.2030, batch acc 0.7064
13:08:35.832 Training @ 99 epoch...
13:08:36.386   Training iter 50, batch loss 0.1970, batch acc 0.7188
13:08:36.943   Training iter 100, batch loss 0.1952, batch acc 0.7252
13:08:37.500   Training iter 150, batch loss 0.1994, batch acc 0.7152
13:08:38.049   Training iter 200, batch loss 0.2033, batch acc 0.7026
13:08:38.562   Training iter 250, batch loss 0.1999, batch acc 0.7148
13:08:39.079   Training iter 300, batch loss 0.1983, batch acc 0.7188
13:08:39.593   Training iter 350, batch loss 0.2061, batch acc 0.7024
13:08:40.126   Training iter 400, batch loss 0.2061, batch acc 0.6954
13:08:40.640   Training iter 450, batch loss 0.1972, batch acc 0.7166
13:08:41.153   Training iter 500, batch loss 0.2067, batch acc 0.6990
13:08:41.668   Training iter 550, batch loss 0.2050, batch acc 0.7032
13:08:42.192   Training iter 600, batch loss 0.2059, batch acc 0.7016
13:08:42.194 Training @ 100 epoch...
13:08:42.733   Training iter 50, batch loss 0.2048, batch acc 0.7058
13:08:43.268   Training iter 100, batch loss 0.1959, batch acc 0.7260
13:08:43.783   Training iter 150, batch loss 0.2017, batch acc 0.7078
13:08:44.306   Training iter 200, batch loss 0.1957, batch acc 0.7134
13:08:44.841   Training iter 250, batch loss 0.2004, batch acc 0.7104
13:08:45.386   Training iter 300, batch loss 0.2016, batch acc 0.7106
13:08:45.901   Training iter 350, batch loss 0.2058, batch acc 0.7000
13:08:46.416   Training iter 400, batch loss 0.2044, batch acc 0.7032
13:08:46.930   Training iter 450, batch loss 0.1995, batch acc 0.7136
13:08:47.434   Training iter 500, batch loss 0.2030, batch acc 0.7052
13:08:47.943   Training iter 550, batch loss 0.2017, batch acc 0.7136
13:08:48.490   Training iter 600, batch loss 0.2030, batch acc 0.7064
13:08:48.492 Testing @ 100 epoch...
13:08:48.529     Testing, total mean loss 0.20059, total acc 0.70930
13:08:48.530 Plot @ 100 epoch...
13:08:48.530 Training @ 101 epoch...
13:08:49.068   Training iter 50, batch loss 0.2032, batch acc 0.7048
13:08:49.597   Training iter 100, batch loss 0.1938, batch acc 0.7234
13:08:50.136   Training iter 150, batch loss 0.2001, batch acc 0.7116
13:08:50.677   Training iter 200, batch loss 0.2017, batch acc 0.7092
13:08:51.209   Training iter 250, batch loss 0.2004, batch acc 0.7120
13:08:51.738   Training iter 300, batch loss 0.2035, batch acc 0.7062
13:08:52.278   Training iter 350, batch loss 0.2014, batch acc 0.7114
13:08:52.814   Training iter 400, batch loss 0.2031, batch acc 0.7082
13:08:53.360   Training iter 450, batch loss 0.1978, batch acc 0.7198
13:08:53.885   Training iter 500, batch loss 0.2070, batch acc 0.6912
13:08:54.379   Training iter 550, batch loss 0.1978, batch acc 0.7168
13:08:54.865   Training iter 600, batch loss 0.2052, batch acc 0.7046
13:08:54.866 Training @ 102 epoch...
13:08:55.393   Training iter 50, batch loss 0.2013, batch acc 0.7124
13:08:55.895   Training iter 100, batch loss 0.1948, batch acc 0.7190
13:08:56.423   Training iter 150, batch loss 0.2029, batch acc 0.7056
13:08:56.918   Training iter 200, batch loss 0.2084, batch acc 0.6958
13:08:57.428   Training iter 250, batch loss 0.2000, batch acc 0.7150
13:08:57.943   Training iter 300, batch loss 0.1995, batch acc 0.7156
13:08:58.451   Training iter 350, batch loss 0.1996, batch acc 0.7118
13:08:58.942   Training iter 400, batch loss 0.2037, batch acc 0.7064
13:08:59.409   Training iter 450, batch loss 0.1994, batch acc 0.7190
13:08:59.877   Training iter 500, batch loss 0.2048, batch acc 0.7010
13:09:00.341   Training iter 550, batch loss 0.1956, batch acc 0.7188
13:09:00.835   Training iter 600, batch loss 0.2028, batch acc 0.7040
13:09:00.836 Training @ 103 epoch...
13:09:01.360   Training iter 50, batch loss 0.2017, batch acc 0.7070
13:09:01.908   Training iter 100, batch loss 0.2037, batch acc 0.7034
13:09:02.482   Training iter 150, batch loss 0.2040, batch acc 0.7072
13:09:03.007   Training iter 200, batch loss 0.1990, batch acc 0.7150
13:09:03.546   Training iter 250, batch loss 0.2024, batch acc 0.7112
13:09:04.100   Training iter 300, batch loss 0.2013, batch acc 0.7086
13:09:04.679   Training iter 350, batch loss 0.2039, batch acc 0.7022
13:09:05.226   Training iter 400, batch loss 0.2003, batch acc 0.7094
13:09:05.754   Training iter 450, batch loss 0.2049, batch acc 0.7052
13:09:06.326   Training iter 500, batch loss 0.1948, batch acc 0.7230
13:09:06.889   Training iter 550, batch loss 0.1985, batch acc 0.7168
13:09:07.428   Training iter 600, batch loss 0.1960, batch acc 0.7178
13:09:07.430 Training @ 104 epoch...
13:09:07.941   Training iter 50, batch loss 0.2027, batch acc 0.7004
13:09:08.460   Training iter 100, batch loss 0.2025, batch acc 0.7082
13:09:08.991   Training iter 150, batch loss 0.2003, batch acc 0.7140
13:09:09.505   Training iter 200, batch loss 0.1980, batch acc 0.7154
13:09:10.009   Training iter 250, batch loss 0.2013, batch acc 0.7072
13:09:10.499   Training iter 300, batch loss 0.1956, batch acc 0.7222
13:09:10.960   Training iter 350, batch loss 0.2028, batch acc 0.7096
13:09:11.430   Training iter 400, batch loss 0.2022, batch acc 0.7096
13:09:11.896   Training iter 450, batch loss 0.1994, batch acc 0.7128
13:09:12.385   Training iter 500, batch loss 0.1987, batch acc 0.7178
13:09:12.882   Training iter 550, batch loss 0.2037, batch acc 0.7064
13:09:13.438   Training iter 600, batch loss 0.2010, batch acc 0.7056
13:09:13.440 Training @ 105 epoch...
13:09:13.995   Training iter 50, batch loss 0.2055, batch acc 0.7010
13:09:14.547   Training iter 100, batch loss 0.2022, batch acc 0.7066
13:09:15.038   Training iter 150, batch loss 0.2027, batch acc 0.7090
13:09:15.511   Training iter 200, batch loss 0.2033, batch acc 0.7032
13:09:15.990   Training iter 250, batch loss 0.2011, batch acc 0.7092
13:09:16.482   Training iter 300, batch loss 0.2036, batch acc 0.7060
13:09:16.955   Training iter 350, batch loss 0.2021, batch acc 0.7078
13:09:17.458   Training iter 400, batch loss 0.1965, batch acc 0.7206
13:09:17.933   Training iter 450, batch loss 0.1993, batch acc 0.7108
13:09:18.399   Training iter 500, batch loss 0.1936, batch acc 0.7250
13:09:18.860   Training iter 550, batch loss 0.1993, batch acc 0.7122
13:09:19.321   Training iter 600, batch loss 0.1967, batch acc 0.7202
13:09:19.323 Testing @ 105 epoch...
13:09:19.361     Testing, total mean loss 0.19965, total acc 0.71050
13:09:19.361 Training @ 106 epoch...
13:09:19.843   Training iter 50, batch loss 0.2011, batch acc 0.7106
13:09:20.367   Training iter 100, batch loss 0.2005, batch acc 0.7150
13:09:20.901   Training iter 150, batch loss 0.1979, batch acc 0.7164
13:09:21.402   Training iter 200, batch loss 0.1959, batch acc 0.7182
13:09:21.905   Training iter 250, batch loss 0.2057, batch acc 0.7028
13:09:22.492   Training iter 300, batch loss 0.1991, batch acc 0.7156
13:09:23.236   Training iter 350, batch loss 0.2002, batch acc 0.7094
13:09:23.828   Training iter 400, batch loss 0.2038, batch acc 0.7032
13:09:24.371   Training iter 450, batch loss 0.2006, batch acc 0.7112
13:09:24.909   Training iter 500, batch loss 0.1984, batch acc 0.7146
13:09:25.458   Training iter 550, batch loss 0.2013, batch acc 0.7054
13:09:25.964   Training iter 600, batch loss 0.1993, batch acc 0.7108
13:09:25.965 Training @ 107 epoch...
13:09:26.470   Training iter 50, batch loss 0.1987, batch acc 0.7158
13:09:26.968   Training iter 100, batch loss 0.2031, batch acc 0.7076
13:09:27.476   Training iter 150, batch loss 0.2006, batch acc 0.7058
13:09:27.990   Training iter 200, batch loss 0.2027, batch acc 0.7100
13:09:28.523   Training iter 250, batch loss 0.2012, batch acc 0.7094
13:09:29.037   Training iter 300, batch loss 0.2033, batch acc 0.7072
13:09:29.543   Training iter 350, batch loss 0.1976, batch acc 0.7178
13:09:30.026   Training iter 400, batch loss 0.1988, batch acc 0.7144
13:09:30.507   Training iter 450, batch loss 0.2013, batch acc 0.7070
13:09:30.988   Training iter 500, batch loss 0.1949, batch acc 0.7190
13:09:31.474   Training iter 550, batch loss 0.2026, batch acc 0.7078
13:09:31.959   Training iter 600, batch loss 0.1970, batch acc 0.7184
13:09:31.961 Training @ 108 epoch...
13:09:32.445   Training iter 50, batch loss 0.1970, batch acc 0.7196
13:09:32.931   Training iter 100, batch loss 0.2015, batch acc 0.7124
13:09:33.427   Training iter 150, batch loss 0.1990, batch acc 0.7122
13:09:33.920   Training iter 200, batch loss 0.2002, batch acc 0.7140
13:09:34.394   Training iter 250, batch loss 0.1986, batch acc 0.7178
13:09:34.876   Training iter 300, batch loss 0.2005, batch acc 0.7060
13:09:35.372   Training iter 350, batch loss 0.1971, batch acc 0.7178
13:09:35.845   Training iter 400, batch loss 0.2007, batch acc 0.7076
13:09:36.332   Training iter 450, batch loss 0.2011, batch acc 0.7072
13:09:36.805   Training iter 500, batch loss 0.1992, batch acc 0.7126
13:09:37.289   Training iter 550, batch loss 0.2048, batch acc 0.7014
13:09:37.772   Training iter 600, batch loss 0.2001, batch acc 0.7130
13:09:37.774 Training @ 109 epoch...
13:09:38.260   Training iter 50, batch loss 0.1943, batch acc 0.7218
13:09:38.738   Training iter 100, batch loss 0.1945, batch acc 0.7214
13:09:39.376   Training iter 150, batch loss 0.1990, batch acc 0.7112
13:09:39.936   Training iter 200, batch loss 0.2028, batch acc 0.7056
13:09:40.461   Training iter 250, batch loss 0.1970, batch acc 0.7138
13:09:40.968   Training iter 300, batch loss 0.2009, batch acc 0.7102
13:09:41.505   Training iter 350, batch loss 0.2009, batch acc 0.7098
13:09:42.021   Training iter 400, batch loss 0.2021, batch acc 0.7116
13:09:42.529   Training iter 450, batch loss 0.2021, batch acc 0.7092
13:09:43.038   Training iter 500, batch loss 0.1992, batch acc 0.7130
13:09:43.544   Training iter 550, batch loss 0.2032, batch acc 0.7064
13:09:44.038   Training iter 600, batch loss 0.2019, batch acc 0.7060
13:09:44.039 Training @ 110 epoch...
13:09:44.523   Training iter 50, batch loss 0.1976, batch acc 0.7170
13:09:45.017   Training iter 100, batch loss 0.1995, batch acc 0.7094
13:09:45.522   Training iter 150, batch loss 0.2071, batch acc 0.6950
13:09:46.013   Training iter 200, batch loss 0.2014, batch acc 0.7078
13:09:46.501   Training iter 250, batch loss 0.1995, batch acc 0.7136
13:09:46.981   Training iter 300, batch loss 0.2021, batch acc 0.7078
13:09:47.458   Training iter 350, batch loss 0.1993, batch acc 0.7138
13:09:47.942   Training iter 400, batch loss 0.1968, batch acc 0.7134
13:09:48.436   Training iter 450, batch loss 0.2002, batch acc 0.7106
13:09:48.922   Training iter 500, batch loss 0.1959, batch acc 0.7230
13:09:49.405   Training iter 550, batch loss 0.1954, batch acc 0.7202
13:09:49.885   Training iter 600, batch loss 0.2012, batch acc 0.7124
13:09:49.887 Testing @ 110 epoch...
13:09:49.924     Testing, total mean loss 0.19881, total acc 0.71120
13:09:49.924 Training @ 111 epoch...
13:09:50.411   Training iter 50, batch loss 0.1942, batch acc 0.7222
13:09:50.925   Training iter 100, batch loss 0.1961, batch acc 0.7178
13:09:51.410   Training iter 150, batch loss 0.2021, batch acc 0.7048
13:09:51.905   Training iter 200, batch loss 0.1975, batch acc 0.7132
13:09:52.433   Training iter 250, batch loss 0.2027, batch acc 0.7114
13:09:52.962   Training iter 300, batch loss 0.2065, batch acc 0.7036
13:09:53.490   Training iter 350, batch loss 0.1955, batch acc 0.7174
13:09:54.020   Training iter 400, batch loss 0.2004, batch acc 0.7118
13:09:54.535   Training iter 450, batch loss 0.2000, batch acc 0.7112
13:09:55.027   Training iter 500, batch loss 0.2041, batch acc 0.7028
13:09:55.518   Training iter 550, batch loss 0.1996, batch acc 0.7120
13:09:55.986   Training iter 600, batch loss 0.1952, batch acc 0.7172
13:09:55.988 Training @ 112 epoch...
13:09:56.473   Training iter 50, batch loss 0.1964, batch acc 0.7178
13:09:56.956   Training iter 100, batch loss 0.1996, batch acc 0.7128
13:09:57.456   Training iter 150, batch loss 0.2014, batch acc 0.7090
13:09:57.942   Training iter 200, batch loss 0.1981, batch acc 0.7140
13:09:58.431   Training iter 250, batch loss 0.1966, batch acc 0.7164
13:09:58.912   Training iter 300, batch loss 0.1984, batch acc 0.7144
13:09:59.397   Training iter 350, batch loss 0.1960, batch acc 0.7176
13:09:59.884   Training iter 400, batch loss 0.1993, batch acc 0.7110
13:10:00.367   Training iter 450, batch loss 0.2016, batch acc 0.7070
13:10:00.836   Training iter 500, batch loss 0.2037, batch acc 0.7042
13:10:01.344   Training iter 550, batch loss 0.2005, batch acc 0.7086
13:10:01.875   Training iter 600, batch loss 0.2004, batch acc 0.7142
13:10:01.877 Training @ 113 epoch...
13:10:02.436   Training iter 50, batch loss 0.2064, batch acc 0.7044
13:10:02.952   Training iter 100, batch loss 0.2020, batch acc 0.7046
13:10:03.458   Training iter 150, batch loss 0.1929, batch acc 0.7240
13:10:03.986   Training iter 200, batch loss 0.1960, batch acc 0.7182
13:10:04.505   Training iter 250, batch loss 0.1961, batch acc 0.7200
13:10:05.031   Training iter 300, batch loss 0.1963, batch acc 0.7192
13:10:05.555   Training iter 350, batch loss 0.1977, batch acc 0.7146
13:10:06.081   Training iter 400, batch loss 0.1986, batch acc 0.7144
13:10:06.581   Training iter 450, batch loss 0.1984, batch acc 0.7138
13:10:07.087   Training iter 500, batch loss 0.2026, batch acc 0.7034
13:10:07.616   Training iter 550, batch loss 0.2011, batch acc 0.7054
13:10:08.137   Training iter 600, batch loss 0.2022, batch acc 0.7088
13:10:08.139 Training @ 114 epoch...
13:10:08.672   Training iter 50, batch loss 0.2021, batch acc 0.7108
13:10:09.173   Training iter 100, batch loss 0.1970, batch acc 0.7148
13:10:09.675   Training iter 150, batch loss 0.2001, batch acc 0.7154
13:10:10.186   Training iter 200, batch loss 0.1994, batch acc 0.7098
13:10:10.691   Training iter 250, batch loss 0.1981, batch acc 0.7154
13:10:11.200   Training iter 300, batch loss 0.1948, batch acc 0.7222
13:10:11.706   Training iter 350, batch loss 0.2004, batch acc 0.7078
13:10:12.245   Training iter 400, batch loss 0.2002, batch acc 0.7074
13:10:12.815   Training iter 450, batch loss 0.1989, batch acc 0.7122
13:10:13.388   Training iter 500, batch loss 0.2009, batch acc 0.7102
13:10:13.963   Training iter 550, batch loss 0.2006, batch acc 0.7068
13:10:14.489   Training iter 600, batch loss 0.1959, batch acc 0.7188
13:10:14.491 Training @ 115 epoch...
13:10:15.015   Training iter 50, batch loss 0.1974, batch acc 0.7110
13:10:15.540   Training iter 100, batch loss 0.2023, batch acc 0.7078
13:10:16.071   Training iter 150, batch loss 0.2012, batch acc 0.7066
13:10:16.596   Training iter 200, batch loss 0.2010, batch acc 0.7086
13:10:17.125   Training iter 250, batch loss 0.1956, batch acc 0.7194
13:10:17.636   Training iter 300, batch loss 0.1971, batch acc 0.7172
13:10:18.144   Training iter 350, batch loss 0.2015, batch acc 0.7088
13:10:18.656   Training iter 400, batch loss 0.1991, batch acc 0.7124
13:10:19.157   Training iter 450, batch loss 0.1962, batch acc 0.7198
13:10:19.665   Training iter 500, batch loss 0.1990, batch acc 0.7128
13:10:20.179   Training iter 550, batch loss 0.2004, batch acc 0.7122
13:10:20.700   Training iter 600, batch loss 0.1956, batch acc 0.7176
13:10:20.701 Testing @ 115 epoch...
13:10:20.738     Testing, total mean loss 0.19807, total acc 0.71170
13:10:20.738 Training @ 116 epoch...
13:10:21.248   Training iter 50, batch loss 0.2000, batch acc 0.7116
13:10:21.756   Training iter 100, batch loss 0.2004, batch acc 0.7096
13:10:22.263   Training iter 150, batch loss 0.1970, batch acc 0.7136
13:10:22.783   Training iter 200, batch loss 0.1970, batch acc 0.7196
13:10:23.311   Training iter 250, batch loss 0.1983, batch acc 0.7098
13:10:23.848   Training iter 300, batch loss 0.1977, batch acc 0.7174
13:10:24.401   Training iter 350, batch loss 0.2017, batch acc 0.7048
13:10:24.956   Training iter 400, batch loss 0.1956, batch acc 0.7158
13:10:25.494   Training iter 450, batch loss 0.1961, batch acc 0.7192
13:10:26.038   Training iter 500, batch loss 0.1992, batch acc 0.7146
13:10:26.587   Training iter 550, batch loss 0.2035, batch acc 0.7066
13:10:27.129   Training iter 600, batch loss 0.1984, batch acc 0.7120
13:10:27.131 Training @ 117 epoch...
13:10:27.710   Training iter 50, batch loss 0.2046, batch acc 0.7044
13:10:28.262   Training iter 100, batch loss 0.2005, batch acc 0.7108
13:10:28.814   Training iter 150, batch loss 0.1978, batch acc 0.7154
13:10:29.340   Training iter 200, batch loss 0.1997, batch acc 0.7138
13:10:29.868   Training iter 250, batch loss 0.2022, batch acc 0.7046
13:10:30.353   Training iter 300, batch loss 0.1995, batch acc 0.7122
13:10:30.833   Training iter 350, batch loss 0.1983, batch acc 0.7144
13:10:31.301   Training iter 400, batch loss 0.1965, batch acc 0.7166
13:10:31.782   Training iter 450, batch loss 0.1942, batch acc 0.7196
13:10:32.287   Training iter 500, batch loss 0.1949, batch acc 0.7182
13:10:32.794   Training iter 550, batch loss 0.1974, batch acc 0.7124
13:10:33.312   Training iter 600, batch loss 0.1978, batch acc 0.7156
13:10:33.314 Training @ 118 epoch...
13:10:33.828   Training iter 50, batch loss 0.1981, batch acc 0.7150
13:10:34.340   Training iter 100, batch loss 0.1997, batch acc 0.7134
13:10:34.857   Training iter 150, batch loss 0.2014, batch acc 0.7046
13:10:35.358   Training iter 200, batch loss 0.1935, batch acc 0.7216
13:10:35.852   Training iter 250, batch loss 0.2020, batch acc 0.7048
13:10:36.359   Training iter 300, batch loss 0.1971, batch acc 0.7150
13:10:36.860   Training iter 350, batch loss 0.1969, batch acc 0.7164
13:10:37.369   Training iter 400, batch loss 0.1991, batch acc 0.7146
13:10:37.853   Training iter 450, batch loss 0.2051, batch acc 0.6998
13:10:38.353   Training iter 500, batch loss 0.1950, batch acc 0.7204
13:10:38.850   Training iter 550, batch loss 0.1953, batch acc 0.7208
13:10:39.348   Training iter 600, batch loss 0.1984, batch acc 0.7144
13:10:39.350 Training @ 119 epoch...
13:10:39.867   Training iter 50, batch loss 0.2034, batch acc 0.7016
13:10:40.410   Training iter 100, batch loss 0.1957, batch acc 0.7198
13:10:40.942   Training iter 150, batch loss 0.1981, batch acc 0.7134
13:10:41.488   Training iter 200, batch loss 0.1973, batch acc 0.7164
13:10:42.017   Training iter 250, batch loss 0.1965, batch acc 0.7164
13:10:42.545   Training iter 300, batch loss 0.1944, batch acc 0.7230
13:10:43.083   Training iter 350, batch loss 0.2028, batch acc 0.7054
13:10:43.608   Training iter 400, batch loss 0.1983, batch acc 0.7134
13:10:44.138   Training iter 450, batch loss 0.1973, batch acc 0.7158
13:10:44.674   Training iter 500, batch loss 0.2002, batch acc 0.7078
13:10:45.214   Training iter 550, batch loss 0.1957, batch acc 0.7202
13:10:45.739   Training iter 600, batch loss 0.2005, batch acc 0.7100
13:10:45.741 Training @ 120 epoch...
13:10:46.259   Training iter 50, batch loss 0.2008, batch acc 0.7060
13:10:46.761   Training iter 100, batch loss 0.1997, batch acc 0.7088
13:10:47.249   Training iter 150, batch loss 0.2024, batch acc 0.7028
13:10:47.751   Training iter 200, batch loss 0.1945, batch acc 0.7174
13:10:48.243   Training iter 250, batch loss 0.1991, batch acc 0.7160
13:10:48.721   Training iter 300, batch loss 0.2007, batch acc 0.7128
13:10:49.172   Training iter 350, batch loss 0.1964, batch acc 0.7200
13:10:49.620   Training iter 400, batch loss 0.2015, batch acc 0.7068
13:10:50.078   Training iter 450, batch loss 0.1938, batch acc 0.7258
13:10:50.542   Training iter 500, batch loss 0.1933, batch acc 0.7232
13:10:51.017   Training iter 550, batch loss 0.1982, batch acc 0.7120
13:10:51.491   Training iter 600, batch loss 0.1981, batch acc 0.7138
13:10:51.492 Testing @ 120 epoch...
13:10:51.529     Testing, total mean loss 0.19739, total acc 0.71180
13:10:51.529 Training @ 121 epoch...
13:10:51.988   Training iter 50, batch loss 0.2034, batch acc 0.7058
13:10:52.452   Training iter 100, batch loss 0.2000, batch acc 0.7048
13:10:52.919   Training iter 150, batch loss 0.1986, batch acc 0.7136
13:10:53.405   Training iter 200, batch loss 0.2018, batch acc 0.7056
13:10:53.867   Training iter 250, batch loss 0.1995, batch acc 0.7146
13:10:54.330   Training iter 300, batch loss 0.1966, batch acc 0.7142
13:10:54.796   Training iter 350, batch loss 0.1956, batch acc 0.7220
13:10:55.270   Training iter 400, batch loss 0.1965, batch acc 0.7172
13:10:55.763   Training iter 450, batch loss 0.1950, batch acc 0.7196
13:10:56.254   Training iter 500, batch loss 0.1998, batch acc 0.7088
13:10:56.720   Training iter 550, batch loss 0.1938, batch acc 0.7240
13:10:57.190   Training iter 600, batch loss 0.1963, batch acc 0.7160
13:10:57.191 Training @ 122 epoch...
13:10:57.670   Training iter 50, batch loss 0.1969, batch acc 0.7158
13:10:58.160   Training iter 100, batch loss 0.1929, batch acc 0.7214
13:10:58.618   Training iter 150, batch loss 0.2008, batch acc 0.7086
13:10:59.091   Training iter 200, batch loss 0.1973, batch acc 0.7160
13:10:59.565   Training iter 250, batch loss 0.2005, batch acc 0.7086
13:11:00.056   Training iter 300, batch loss 0.1946, batch acc 0.7186
13:11:00.530   Training iter 350, batch loss 0.1981, batch acc 0.7116
13:11:00.993   Training iter 400, batch loss 0.2038, batch acc 0.7018
13:11:01.519   Training iter 450, batch loss 0.1987, batch acc 0.7138
13:11:02.042   Training iter 500, batch loss 0.1996, batch acc 0.7140
13:11:02.558   Training iter 550, batch loss 0.1925, batch acc 0.7280
13:11:03.084   Training iter 600, batch loss 0.1999, batch acc 0.7082
13:11:03.086 Training @ 123 epoch...
13:11:03.601   Training iter 50, batch loss 0.2034, batch acc 0.7040
13:11:04.131   Training iter 100, batch loss 0.2015, batch acc 0.7064
13:11:04.654   Training iter 150, batch loss 0.1924, batch acc 0.7210
13:11:05.185   Training iter 200, batch loss 0.1943, batch acc 0.7214
13:11:05.709   Training iter 250, batch loss 0.1987, batch acc 0.7120
13:11:06.279   Training iter 300, batch loss 0.1976, batch acc 0.7182
13:11:06.839   Training iter 350, batch loss 0.2035, batch acc 0.7032
13:11:07.376   Training iter 400, batch loss 0.1981, batch acc 0.7132
13:11:07.880   Training iter 450, batch loss 0.1998, batch acc 0.7136
13:11:08.402   Training iter 500, batch loss 0.1921, batch acc 0.7278
13:11:08.910   Training iter 550, batch loss 0.1967, batch acc 0.7146
13:11:09.425   Training iter 600, batch loss 0.1957, batch acc 0.7138
13:11:09.426 Training @ 124 epoch...
13:11:09.943   Training iter 50, batch loss 0.2016, batch acc 0.7066
13:11:10.462   Training iter 100, batch loss 0.2005, batch acc 0.7074
13:11:10.955   Training iter 150, batch loss 0.1929, batch acc 0.7212
13:11:11.453   Training iter 200, batch loss 0.1948, batch acc 0.7220
13:11:11.942   Training iter 250, batch loss 0.1919, batch acc 0.7254
13:11:12.446   Training iter 300, batch loss 0.1987, batch acc 0.7128
13:11:12.961   Training iter 350, batch loss 0.2016, batch acc 0.7100
13:11:13.477   Training iter 400, batch loss 0.1981, batch acc 0.7102
13:11:13.989   Training iter 450, batch loss 0.2016, batch acc 0.7062
13:11:14.499   Training iter 500, batch loss 0.1970, batch acc 0.7160
13:11:15.006   Training iter 550, batch loss 0.1994, batch acc 0.7128
13:11:15.528   Training iter 600, batch loss 0.1946, batch acc 0.7218
13:11:15.529 Training @ 125 epoch...
13:11:16.052   Training iter 50, batch loss 0.1926, batch acc 0.7212
13:11:16.552   Training iter 100, batch loss 0.2008, batch acc 0.7070
13:11:17.038   Training iter 150, batch loss 0.1948, batch acc 0.7220
13:11:17.498   Training iter 200, batch loss 0.1944, batch acc 0.7210
13:11:17.961   Training iter 250, batch loss 0.2008, batch acc 0.7086
13:11:18.434   Training iter 300, batch loss 0.2003, batch acc 0.7130
13:11:18.888   Training iter 350, batch loss 0.2002, batch acc 0.7080
13:11:19.352   Training iter 400, batch loss 0.1952, batch acc 0.7206
13:11:19.815   Training iter 450, batch loss 0.1967, batch acc 0.7146
13:11:20.289   Training iter 500, batch loss 0.1992, batch acc 0.7124
13:11:20.766   Training iter 550, batch loss 0.1979, batch acc 0.7144
13:11:21.226   Training iter 600, batch loss 0.1983, batch acc 0.7100
13:11:21.227 Testing @ 125 epoch...
13:11:21.264     Testing, total mean loss 0.19678, total acc 0.71210
13:11:21.264 Training @ 126 epoch...
13:11:21.737   Training iter 50, batch loss 0.2010, batch acc 0.7098
13:11:22.202   Training iter 100, batch loss 0.1969, batch acc 0.7112
13:11:22.663   Training iter 150, batch loss 0.1979, batch acc 0.7128
13:11:23.136   Training iter 200, batch loss 0.2014, batch acc 0.7110
13:11:23.603   Training iter 250, batch loss 0.1976, batch acc 0.7160
13:11:24.069   Training iter 300, batch loss 0.1950, batch acc 0.7202
13:11:24.529   Training iter 350, batch loss 0.1924, batch acc 0.7218
13:11:25.006   Training iter 400, batch loss 0.1987, batch acc 0.7098
13:11:25.515   Training iter 450, batch loss 0.1948, batch acc 0.7230
13:11:26.020   Training iter 500, batch loss 0.1962, batch acc 0.7202
13:11:26.524   Training iter 550, batch loss 0.2010, batch acc 0.7052
13:11:27.025   Training iter 600, batch loss 0.1970, batch acc 0.7124
13:11:27.026 Training @ 127 epoch...
13:11:27.546   Training iter 50, batch loss 0.1963, batch acc 0.7146
13:11:28.064   Training iter 100, batch loss 0.1979, batch acc 0.7152
13:11:28.582   Training iter 150, batch loss 0.1962, batch acc 0.7190
13:11:29.101   Training iter 200, batch loss 0.1964, batch acc 0.7198
13:11:29.616   Training iter 250, batch loss 0.1960, batch acc 0.7164
13:11:30.145   Training iter 300, batch loss 0.1970, batch acc 0.7136
13:11:30.682   Training iter 350, batch loss 0.1982, batch acc 0.7098
13:11:31.187   Training iter 400, batch loss 0.2016, batch acc 0.7078
13:11:31.661   Training iter 450, batch loss 0.1993, batch acc 0.7072
13:11:32.149   Training iter 500, batch loss 0.1999, batch acc 0.7104
13:11:32.637   Training iter 550, batch loss 0.1952, batch acc 0.7188
13:11:33.120   Training iter 600, batch loss 0.1945, batch acc 0.7186
13:11:33.122 Training @ 128 epoch...
13:11:33.583   Training iter 50, batch loss 0.1961, batch acc 0.7164
13:11:34.056   Training iter 100, batch loss 0.2001, batch acc 0.7102
13:11:34.521   Training iter 150, batch loss 0.1986, batch acc 0.7084
13:11:34.986   Training iter 200, batch loss 0.1975, batch acc 0.7116
13:11:35.469   Training iter 250, batch loss 0.1982, batch acc 0.7138
13:11:35.942   Training iter 300, batch loss 0.1947, batch acc 0.7238
13:11:36.419   Training iter 350, batch loss 0.1959, batch acc 0.7142
13:11:36.903   Training iter 400, batch loss 0.1968, batch acc 0.7156
13:11:37.403   Training iter 450, batch loss 0.1956, batch acc 0.7190
13:11:37.903   Training iter 500, batch loss 0.2019, batch acc 0.7050
13:11:38.390   Training iter 550, batch loss 0.1937, batch acc 0.7214
13:11:38.862   Training iter 600, batch loss 0.1979, batch acc 0.7142
13:11:38.864 Training @ 129 epoch...
13:11:39.353   Training iter 50, batch loss 0.1934, batch acc 0.7218
13:11:39.844   Training iter 100, batch loss 0.2020, batch acc 0.7044
13:11:40.362   Training iter 150, batch loss 0.1955, batch acc 0.7188
13:11:40.999   Training iter 200, batch loss 0.1905, batch acc 0.7280
13:11:41.605   Training iter 250, batch loss 0.2010, batch acc 0.7064
13:11:42.155   Training iter 300, batch loss 0.1961, batch acc 0.7172
13:11:42.619   Training iter 350, batch loss 0.1946, batch acc 0.7204
13:11:43.089   Training iter 400, batch loss 0.1993, batch acc 0.7070
13:11:43.568   Training iter 450, batch loss 0.1980, batch acc 0.7156
13:11:44.048   Training iter 500, batch loss 0.1963, batch acc 0.7164
13:11:44.511   Training iter 550, batch loss 0.1997, batch acc 0.7078
13:11:44.993   Training iter 600, batch loss 0.1993, batch acc 0.7086
13:11:44.995 Training @ 130 epoch...
13:11:45.480   Training iter 50, batch loss 0.1966, batch acc 0.7142
13:11:45.951   Training iter 100, batch loss 0.2002, batch acc 0.7088
13:11:46.461   Training iter 150, batch loss 0.1991, batch acc 0.7070
13:11:46.994   Training iter 200, batch loss 0.1985, batch acc 0.7156
13:11:47.553   Training iter 250, batch loss 0.1950, batch acc 0.7208
13:11:48.078   Training iter 300, batch loss 0.1969, batch acc 0.7132
13:11:48.602   Training iter 350, batch loss 0.1972, batch acc 0.7176
13:11:49.111   Training iter 400, batch loss 0.1962, batch acc 0.7158
13:11:49.603   Training iter 450, batch loss 0.1971, batch acc 0.7102
13:11:50.084   Training iter 500, batch loss 0.1956, batch acc 0.7180
13:11:50.554   Training iter 550, batch loss 0.1965, batch acc 0.7166
13:11:51.018   Training iter 600, batch loss 0.1955, batch acc 0.7190
13:11:51.019 Testing @ 130 epoch...
13:11:51.056     Testing, total mean loss 0.19626, total acc 0.71390
13:11:51.056 Training @ 131 epoch...
13:11:51.509   Training iter 50, batch loss 0.1980, batch acc 0.7130
13:11:51.961   Training iter 100, batch loss 0.2015, batch acc 0.7070
13:11:52.415   Training iter 150, batch loss 0.1957, batch acc 0.7176
13:11:52.885   Training iter 200, batch loss 0.1961, batch acc 0.7160
13:11:53.366   Training iter 250, batch loss 0.1936, batch acc 0.7236
13:11:53.832   Training iter 300, batch loss 0.1988, batch acc 0.7068
13:11:54.302   Training iter 350, batch loss 0.1998, batch acc 0.7114
13:11:54.783   Training iter 400, batch loss 0.2004, batch acc 0.7104
13:11:55.285   Training iter 450, batch loss 0.1931, batch acc 0.7214
13:11:55.775   Training iter 500, batch loss 0.1971, batch acc 0.7140
13:11:56.260   Training iter 550, batch loss 0.1948, batch acc 0.7184
13:11:56.747   Training iter 600, batch loss 0.1945, batch acc 0.7174
13:11:56.749 Training @ 132 epoch...
13:11:57.249   Training iter 50, batch loss 0.1949, batch acc 0.7166
13:11:57.745   Training iter 100, batch loss 0.2000, batch acc 0.7096
13:11:58.234   Training iter 150, batch loss 0.1919, batch acc 0.7230
13:11:58.722   Training iter 200, batch loss 0.1983, batch acc 0.7130
13:11:59.217   Training iter 250, batch loss 0.1990, batch acc 0.7100
13:11:59.709   Training iter 300, batch loss 0.1953, batch acc 0.7162
13:12:00.250   Training iter 350, batch loss 0.1960, batch acc 0.7160
13:12:00.781   Training iter 400, batch loss 0.1952, batch acc 0.7184
13:12:01.301   Training iter 450, batch loss 0.1986, batch acc 0.7132
13:12:01.839   Training iter 500, batch loss 0.2019, batch acc 0.7026
13:12:02.385   Training iter 550, batch loss 0.1965, batch acc 0.7156
13:12:02.914   Training iter 600, batch loss 0.1944, batch acc 0.7214
13:12:02.916 Training @ 133 epoch...
13:12:03.457   Training iter 50, batch loss 0.1971, batch acc 0.7110
13:12:03.988   Training iter 100, batch loss 0.1981, batch acc 0.7132
13:12:04.525   Training iter 150, batch loss 0.2000, batch acc 0.7070
13:12:05.062   Training iter 200, batch loss 0.1947, batch acc 0.7224
13:12:05.598   Training iter 250, batch loss 0.2021, batch acc 0.6996
13:12:06.126   Training iter 300, batch loss 0.1966, batch acc 0.7212
13:12:06.615   Training iter 350, batch loss 0.1962, batch acc 0.7178
13:12:07.119   Training iter 400, batch loss 0.1919, batch acc 0.7206
13:12:07.640   Training iter 450, batch loss 0.1949, batch acc 0.7210
13:12:08.143   Training iter 500, batch loss 0.2003, batch acc 0.7078
13:12:08.638   Training iter 550, batch loss 0.1919, batch acc 0.7230
13:12:09.129   Training iter 600, batch loss 0.1971, batch acc 0.7160
13:12:09.131 Training @ 134 epoch...
13:12:09.631   Training iter 50, batch loss 0.1971, batch acc 0.7118
13:12:10.127   Training iter 100, batch loss 0.1965, batch acc 0.7132
13:12:10.597   Training iter 150, batch loss 0.1945, batch acc 0.7186
13:12:11.086   Training iter 200, batch loss 0.1976, batch acc 0.7150
13:12:11.577   Training iter 250, batch loss 0.1964, batch acc 0.7152
13:12:12.067   Training iter 300, batch loss 0.1960, batch acc 0.7198
13:12:12.566   Training iter 350, batch loss 0.2007, batch acc 0.7048
13:12:13.067   Training iter 400, batch loss 0.1967, batch acc 0.7160
13:12:13.560   Training iter 450, batch loss 0.1969, batch acc 0.7180
13:12:14.054   Training iter 500, batch loss 0.1967, batch acc 0.7166
13:12:14.549   Training iter 550, batch loss 0.1989, batch acc 0.7098
13:12:15.032   Training iter 600, batch loss 0.1918, batch acc 0.7210
13:12:15.033 Training @ 135 epoch...
13:12:15.531   Training iter 50, batch loss 0.1940, batch acc 0.7192
13:12:16.030   Training iter 100, batch loss 0.1945, batch acc 0.7218
13:12:16.534   Training iter 150, batch loss 0.1947, batch acc 0.7166
13:12:17.018   Training iter 200, batch loss 0.1931, batch acc 0.7202
13:12:17.506   Training iter 250, batch loss 0.1975, batch acc 0.7168
13:12:17.998   Training iter 300, batch loss 0.1969, batch acc 0.7126
13:12:18.480   Training iter 350, batch loss 0.1993, batch acc 0.7098
13:12:18.964   Training iter 400, batch loss 0.1972, batch acc 0.7154
13:12:19.450   Training iter 450, batch loss 0.1971, batch acc 0.7116
13:12:19.938   Training iter 500, batch loss 0.2009, batch acc 0.7116
13:12:20.449   Training iter 550, batch loss 0.2002, batch acc 0.7058
13:12:20.949   Training iter 600, batch loss 0.1932, batch acc 0.7194
13:12:20.951 Testing @ 135 epoch...
13:12:20.987     Testing, total mean loss 0.19575, total acc 0.71340
13:12:20.988 Training @ 136 epoch...
13:12:21.493   Training iter 50, batch loss 0.1947, batch acc 0.7180
13:12:21.989   Training iter 100, batch loss 0.1876, batch acc 0.7320
13:12:22.493   Training iter 150, batch loss 0.1934, batch acc 0.7226
13:12:22.991   Training iter 200, batch loss 0.1984, batch acc 0.7094
13:12:23.493   Training iter 250, batch loss 0.1969, batch acc 0.7154
13:12:23.991   Training iter 300, batch loss 0.1953, batch acc 0.7148
13:12:24.498   Training iter 350, batch loss 0.2016, batch acc 0.7072
13:12:25.007   Training iter 400, batch loss 0.1936, batch acc 0.7178
13:12:25.531   Training iter 450, batch loss 0.2009, batch acc 0.7074
13:12:26.056   Training iter 500, batch loss 0.1968, batch acc 0.7144
13:12:26.556   Training iter 550, batch loss 0.1974, batch acc 0.7126
13:12:27.040   Training iter 600, batch loss 0.2008, batch acc 0.7092
13:12:27.042 Training @ 137 epoch...
13:12:27.528   Training iter 50, batch loss 0.1987, batch acc 0.7104
13:12:28.006   Training iter 100, batch loss 0.1921, batch acc 0.7248
13:12:28.490   Training iter 150, batch loss 0.1991, batch acc 0.7154
13:12:28.961   Training iter 200, batch loss 0.1956, batch acc 0.7128
13:12:29.432   Training iter 250, batch loss 0.1955, batch acc 0.7152
13:12:29.935   Training iter 300, batch loss 0.1975, batch acc 0.7154
13:12:30.448   Training iter 350, batch loss 0.1995, batch acc 0.7078
13:12:30.926   Training iter 400, batch loss 0.1980, batch acc 0.7098
13:12:31.390   Training iter 450, batch loss 0.1919, batch acc 0.7198
13:12:31.896   Training iter 500, batch loss 0.1985, batch acc 0.7154
13:12:32.414   Training iter 550, batch loss 0.1958, batch acc 0.7130
13:12:32.937   Training iter 600, batch loss 0.1943, batch acc 0.7232
13:12:32.939 Training @ 138 epoch...
13:12:33.459   Training iter 50, batch loss 0.1944, batch acc 0.7152
13:12:33.963   Training iter 100, batch loss 0.1965, batch acc 0.7142
13:12:34.479   Training iter 150, batch loss 0.1939, batch acc 0.7208
13:12:35.002   Training iter 200, batch loss 0.1951, batch acc 0.7200
13:12:35.509   Training iter 250, batch loss 0.1928, batch acc 0.7230
13:12:36.029   Training iter 300, batch loss 0.2018, batch acc 0.7040
13:12:36.517   Training iter 350, batch loss 0.1976, batch acc 0.7136
13:12:37.002   Training iter 400, batch loss 0.1997, batch acc 0.7128
13:12:37.505   Training iter 450, batch loss 0.1937, batch acc 0.7206
13:12:37.965   Training iter 500, batch loss 0.1970, batch acc 0.7088
13:12:38.412   Training iter 550, batch loss 0.1973, batch acc 0.7108
13:12:38.859   Training iter 600, batch loss 0.1956, batch acc 0.7188
13:12:38.861 Training @ 139 epoch...
13:12:39.316   Training iter 50, batch loss 0.1994, batch acc 0.7118
13:12:39.761   Training iter 100, batch loss 0.1958, batch acc 0.7172
13:12:40.237   Training iter 150, batch loss 0.1971, batch acc 0.7140
13:12:40.710   Training iter 200, batch loss 0.1936, batch acc 0.7164
13:12:41.178   Training iter 250, batch loss 0.1917, batch acc 0.7230
13:12:41.646   Training iter 300, batch loss 0.1944, batch acc 0.7164
13:12:42.116   Training iter 350, batch loss 0.1944, batch acc 0.7184
13:12:42.622   Training iter 400, batch loss 0.1987, batch acc 0.7112
13:12:43.130   Training iter 450, batch loss 0.1950, batch acc 0.7206
13:12:43.633   Training iter 500, batch loss 0.1982, batch acc 0.7102
13:12:44.120   Training iter 550, batch loss 0.2006, batch acc 0.7062
13:12:44.606   Training iter 600, batch loss 0.1952, batch acc 0.7182
13:12:44.608 Training @ 140 epoch...
13:12:45.100   Training iter 50, batch loss 0.1921, batch acc 0.7242
13:12:45.596   Training iter 100, batch loss 0.1960, batch acc 0.7176
13:12:46.096   Training iter 150, batch loss 0.1998, batch acc 0.7068
13:12:46.573   Training iter 200, batch loss 0.1972, batch acc 0.7168
13:12:47.043   Training iter 250, batch loss 0.1975, batch acc 0.7128
13:12:47.513   Training iter 300, batch loss 0.1972, batch acc 0.7128
13:12:48.030   Training iter 350, batch loss 0.1969, batch acc 0.7108
13:12:48.546   Training iter 400, batch loss 0.1977, batch acc 0.7096
13:12:49.056   Training iter 450, batch loss 0.1927, batch acc 0.7222
13:12:49.569   Training iter 500, batch loss 0.1950, batch acc 0.7178
13:12:50.082   Training iter 550, batch loss 0.1973, batch acc 0.7140
13:12:50.593   Training iter 600, batch loss 0.1941, batch acc 0.7190
13:12:50.595 Testing @ 140 epoch...
13:12:50.632     Testing, total mean loss 0.19532, total acc 0.71380
13:12:50.632 Training @ 141 epoch...
13:12:51.141   Training iter 50, batch loss 0.1967, batch acc 0.7132
13:12:51.652   Training iter 100, batch loss 0.1925, batch acc 0.7240
13:12:52.154   Training iter 150, batch loss 0.1993, batch acc 0.7106
13:12:52.651   Training iter 200, batch loss 0.1915, batch acc 0.7236
13:12:53.156   Training iter 250, batch loss 0.1950, batch acc 0.7162
13:12:53.652   Training iter 300, batch loss 0.1960, batch acc 0.7106
13:12:54.104   Training iter 350, batch loss 0.1971, batch acc 0.7104
13:12:54.569   Training iter 400, batch loss 0.2037, batch acc 0.7014
13:12:55.037   Training iter 450, batch loss 0.1890, batch acc 0.7340
13:12:55.529   Training iter 500, batch loss 0.1962, batch acc 0.7188
13:12:56.014   Training iter 550, batch loss 0.1945, batch acc 0.7158
13:12:56.495   Training iter 600, batch loss 0.2007, batch acc 0.7074
13:12:56.497 Training @ 142 epoch...
13:12:56.979   Training iter 50, batch loss 0.1948, batch acc 0.7162
13:12:57.479   Training iter 100, batch loss 0.1927, batch acc 0.7206
13:12:57.957   Training iter 150, batch loss 0.1943, batch acc 0.7166
13:12:58.419   Training iter 200, batch loss 0.1967, batch acc 0.7142
13:12:58.878   Training iter 250, batch loss 0.1974, batch acc 0.7152
13:12:59.333   Training iter 300, batch loss 0.2019, batch acc 0.7050
13:12:59.786   Training iter 350, batch loss 0.1919, batch acc 0.7226
13:13:00.241   Training iter 400, batch loss 0.1958, batch acc 0.7172
13:13:00.672   Training iter 450, batch loss 0.1965, batch acc 0.7126
13:13:01.130   Training iter 500, batch loss 0.1969, batch acc 0.7180
13:13:01.633   Training iter 550, batch loss 0.1940, batch acc 0.7200
13:13:02.176   Training iter 600, batch loss 0.1984, batch acc 0.7108
13:13:02.177 Training @ 143 epoch...
13:13:02.708   Training iter 50, batch loss 0.1925, batch acc 0.7200
13:13:03.239   Training iter 100, batch loss 0.1991, batch acc 0.7074
13:13:03.784   Training iter 150, batch loss 0.1976, batch acc 0.7130
13:13:04.332   Training iter 200, batch loss 0.1979, batch acc 0.7132
13:13:04.870   Training iter 250, batch loss 0.1977, batch acc 0.7124
13:13:05.396   Training iter 300, batch loss 0.1960, batch acc 0.7182
13:13:05.945   Training iter 350, batch loss 0.1953, batch acc 0.7154
13:13:06.496   Training iter 400, batch loss 0.1979, batch acc 0.7132
13:13:07.015   Training iter 450, batch loss 0.1899, batch acc 0.7284
13:13:07.535   Training iter 500, batch loss 0.1913, batch acc 0.7248
13:13:08.058   Training iter 550, batch loss 0.1994, batch acc 0.7056
13:13:08.592   Training iter 600, batch loss 0.1958, batch acc 0.7172
13:13:08.594 Training @ 144 epoch...
13:13:09.116   Training iter 50, batch loss 0.1922, batch acc 0.7244
13:13:09.631   Training iter 100, batch loss 0.2001, batch acc 0.7072
13:13:10.123   Training iter 150, batch loss 0.1959, batch acc 0.7162
13:13:10.613   Training iter 200, batch loss 0.1915, batch acc 0.7212
13:13:11.085   Training iter 250, batch loss 0.1954, batch acc 0.7182
13:13:11.564   Training iter 300, batch loss 0.2015, batch acc 0.7058
13:13:12.044   Training iter 350, batch loss 0.1968, batch acc 0.7138
13:13:12.524   Training iter 400, batch loss 0.1996, batch acc 0.7070
13:13:13.010   Training iter 450, batch loss 0.1960, batch acc 0.7168
13:13:13.494   Training iter 500, batch loss 0.1930, batch acc 0.7200
13:13:13.979   Training iter 550, batch loss 0.1959, batch acc 0.7122
13:13:14.458   Training iter 600, batch loss 0.1917, batch acc 0.7246
13:13:14.460 Training @ 145 epoch...
13:13:14.935   Training iter 50, batch loss 0.1944, batch acc 0.7170
13:13:15.422   Training iter 100, batch loss 0.1996, batch acc 0.7064
13:13:15.907   Training iter 150, batch loss 0.1978, batch acc 0.7142
13:13:16.396   Training iter 200, batch loss 0.1879, batch acc 0.7290
13:13:16.886   Training iter 250, batch loss 0.1951, batch acc 0.7182
13:13:17.375   Training iter 300, batch loss 0.2019, batch acc 0.7050
13:13:17.864   Training iter 350, batch loss 0.1932, batch acc 0.7224
13:13:18.339   Training iter 400, batch loss 0.1971, batch acc 0.7144
13:13:18.787   Training iter 450, batch loss 0.1944, batch acc 0.7164
13:13:19.256   Training iter 500, batch loss 0.1995, batch acc 0.7080
13:13:19.738   Training iter 550, batch loss 0.1965, batch acc 0.7156
13:13:20.223   Training iter 600, batch loss 0.1911, batch acc 0.7240
13:13:20.225 Testing @ 145 epoch...
13:13:20.264     Testing, total mean loss 0.19494, total acc 0.71460
13:13:20.264 Training @ 146 epoch...
13:13:20.740   Training iter 50, batch loss 0.1972, batch acc 0.7148
13:13:21.226   Training iter 100, batch loss 0.1959, batch acc 0.7142
13:13:21.697   Training iter 150, batch loss 0.1958, batch acc 0.7146
13:13:22.173   Training iter 200, batch loss 0.1952, batch acc 0.7176
13:13:22.651   Training iter 250, batch loss 0.1952, batch acc 0.7176
13:13:23.135   Training iter 300, batch loss 0.1974, batch acc 0.7154
13:13:23.619   Training iter 350, batch loss 0.1924, batch acc 0.7200
13:13:24.098   Training iter 400, batch loss 0.1950, batch acc 0.7150
13:13:24.577   Training iter 450, batch loss 0.1940, batch acc 0.7174
13:13:25.068   Training iter 500, batch loss 0.1993, batch acc 0.7110
13:13:25.579   Training iter 550, batch loss 0.1961, batch acc 0.7138
13:13:26.086   Training iter 600, batch loss 0.1940, batch acc 0.7196
13:13:26.088 Training @ 147 epoch...
13:13:26.601   Training iter 50, batch loss 0.1954, batch acc 0.7112
13:13:27.123   Training iter 100, batch loss 0.2035, batch acc 0.7012
13:13:27.616   Training iter 150, batch loss 0.1938, batch acc 0.7154
13:13:28.106   Training iter 200, batch loss 0.1969, batch acc 0.7150
13:13:28.579   Training iter 250, batch loss 0.1917, batch acc 0.7270
13:13:29.064   Training iter 300, batch loss 0.1899, batch acc 0.7288
13:13:29.553   Training iter 350, batch loss 0.1987, batch acc 0.7096
13:13:30.042   Training iter 400, batch loss 0.1989, batch acc 0.7066
13:13:30.537   Training iter 450, batch loss 0.1903, batch acc 0.7258
13:13:31.067   Training iter 500, batch loss 0.1957, batch acc 0.7172
13:13:31.633   Training iter 550, batch loss 0.1988, batch acc 0.7116
13:13:32.176   Training iter 600, batch loss 0.1933, batch acc 0.7226
13:13:32.178 Training @ 148 epoch...
13:13:32.699   Training iter 50, batch loss 0.1942, batch acc 0.7158
13:13:33.208   Training iter 100, batch loss 0.1953, batch acc 0.7176
13:13:33.701   Training iter 150, batch loss 0.1934, batch acc 0.7212
13:13:34.198   Training iter 200, batch loss 0.1881, batch acc 0.7282
13:13:34.696   Training iter 250, batch loss 0.2042, batch acc 0.6978
13:13:35.214   Training iter 300, batch loss 0.1958, batch acc 0.7136
13:13:35.720   Training iter 350, batch loss 0.1916, batch acc 0.7242
13:13:36.233   Training iter 400, batch loss 0.1944, batch acc 0.7166
13:13:36.799   Training iter 450, batch loss 0.1954, batch acc 0.7152
13:13:37.514   Training iter 500, batch loss 0.1954, batch acc 0.7168
13:13:38.057   Training iter 550, batch loss 0.1990, batch acc 0.7104
13:13:38.572   Training iter 600, batch loss 0.1990, batch acc 0.7106
13:13:38.573 Training @ 149 epoch...
13:13:39.080   Training iter 50, batch loss 0.1948, batch acc 0.7158
13:13:39.584   Training iter 100, batch loss 0.1970, batch acc 0.7116
13:13:40.087   Training iter 150, batch loss 0.1962, batch acc 0.7164
13:13:40.601   Training iter 200, batch loss 0.1955, batch acc 0.7154
13:13:41.119   Training iter 250, batch loss 0.1990, batch acc 0.7096
13:13:41.593   Training iter 300, batch loss 0.1939, batch acc 0.7134
13:13:42.053   Training iter 350, batch loss 0.1978, batch acc 0.7102
13:13:42.542   Training iter 400, batch loss 0.1973, batch acc 0.7100
13:13:43.038   Training iter 450, batch loss 0.1952, batch acc 0.7168
13:13:43.523   Training iter 500, batch loss 0.1905, batch acc 0.7280
13:13:43.999   Training iter 550, batch loss 0.1953, batch acc 0.7208
13:13:44.482   Training iter 600, batch loss 0.1924, batch acc 0.7236
13:13:44.483 Training @ 150 epoch...
13:13:44.961   Training iter 50, batch loss 0.1963, batch acc 0.7162
13:13:45.451   Training iter 100, batch loss 0.2001, batch acc 0.7038
13:13:45.940   Training iter 150, batch loss 0.1922, batch acc 0.7228
13:13:46.433   Training iter 200, batch loss 0.1950, batch acc 0.7180
13:13:46.926   Training iter 250, batch loss 0.1924, batch acc 0.7222
13:13:47.406   Training iter 300, batch loss 0.1888, batch acc 0.7274
13:13:47.896   Training iter 350, batch loss 0.1968, batch acc 0.7118
13:13:48.402   Training iter 400, batch loss 0.1939, batch acc 0.7206
13:13:48.889   Training iter 450, batch loss 0.1956, batch acc 0.7168
13:13:49.377   Training iter 500, batch loss 0.1998, batch acc 0.7084
13:13:49.873   Training iter 550, batch loss 0.1949, batch acc 0.7196
13:13:50.368   Training iter 600, batch loss 0.1985, batch acc 0.7068
13:13:50.370 Testing @ 150 epoch...
13:13:50.408     Testing, total mean loss 0.19460, total acc 0.71450
13:13:50.408 Training @ 151 epoch...
13:13:50.910   Training iter 50, batch loss 0.1883, batch acc 0.7282
13:13:51.405   Training iter 100, batch loss 0.1973, batch acc 0.7152
13:13:51.880   Training iter 150, batch loss 0.1952, batch acc 0.7154
13:13:52.359   Training iter 200, batch loss 0.1991, batch acc 0.7070
13:13:52.842   Training iter 250, batch loss 0.1954, batch acc 0.7178
13:13:53.349   Training iter 300, batch loss 0.1946, batch acc 0.7192
13:13:53.852   Training iter 350, batch loss 0.1948, batch acc 0.7172
13:13:54.371   Training iter 400, batch loss 0.1940, batch acc 0.7156
13:13:54.897   Training iter 450, batch loss 0.1978, batch acc 0.7084
13:13:55.430   Training iter 500, batch loss 0.2001, batch acc 0.7080
13:13:55.968   Training iter 550, batch loss 0.1948, batch acc 0.7180
13:13:56.536   Training iter 600, batch loss 0.1920, batch acc 0.7222
13:13:56.538 Training @ 152 epoch...
13:13:57.047   Training iter 50, batch loss 0.1938, batch acc 0.7178
13:13:57.498   Training iter 100, batch loss 0.1973, batch acc 0.7096
13:13:57.953   Training iter 150, batch loss 0.2007, batch acc 0.7052
13:13:58.410   Training iter 200, batch loss 0.1889, batch acc 0.7316
13:13:58.865   Training iter 250, batch loss 0.1914, batch acc 0.7262
13:13:59.317   Training iter 300, batch loss 0.1940, batch acc 0.7208
13:13:59.768   Training iter 350, batch loss 0.1963, batch acc 0.7150
13:14:00.234   Training iter 400, batch loss 0.1967, batch acc 0.7122
13:14:00.693   Training iter 450, batch loss 0.1928, batch acc 0.7210
13:14:01.159   Training iter 500, batch loss 0.1953, batch acc 0.7136
13:14:01.695   Training iter 550, batch loss 0.1996, batch acc 0.7054
13:14:02.240   Training iter 600, batch loss 0.1957, batch acc 0.7186
13:14:02.241 Training @ 153 epoch...
13:14:02.767   Training iter 50, batch loss 0.1911, batch acc 0.7246
13:14:03.316   Training iter 100, batch loss 0.1944, batch acc 0.7170
13:14:03.853   Training iter 150, batch loss 0.1971, batch acc 0.7112
13:14:04.394   Training iter 200, batch loss 0.1919, batch acc 0.7228
13:14:04.939   Training iter 250, batch loss 0.1977, batch acc 0.7110
13:14:05.469   Training iter 300, batch loss 0.1958, batch acc 0.7142
13:14:05.992   Training iter 350, batch loss 0.2015, batch acc 0.7076
13:14:06.524   Training iter 400, batch loss 0.1987, batch acc 0.7076
13:14:07.042   Training iter 450, batch loss 0.1889, batch acc 0.7284
13:14:07.553   Training iter 500, batch loss 0.1942, batch acc 0.7190
13:14:08.076   Training iter 550, batch loss 0.1972, batch acc 0.7152
13:14:08.604   Training iter 600, batch loss 0.1933, batch acc 0.7178
13:14:08.606 Training @ 154 epoch...
13:14:09.137   Training iter 50, batch loss 0.1959, batch acc 0.7134
13:14:09.675   Training iter 100, batch loss 0.1928, batch acc 0.7230
13:14:10.217   Training iter 150, batch loss 0.1973, batch acc 0.7098
13:14:10.752   Training iter 200, batch loss 0.1939, batch acc 0.7138
13:14:11.275   Training iter 250, batch loss 0.1923, batch acc 0.7220
13:14:11.809   Training iter 300, batch loss 0.1987, batch acc 0.7082
13:14:12.341   Training iter 350, batch loss 0.1944, batch acc 0.7188
13:14:12.886   Training iter 400, batch loss 0.1966, batch acc 0.7124
13:14:13.406   Training iter 450, batch loss 0.1916, batch acc 0.7250
13:14:13.906   Training iter 500, batch loss 0.1945, batch acc 0.7186
13:14:14.403   Training iter 550, batch loss 0.1971, batch acc 0.7116
13:14:14.882   Training iter 600, batch loss 0.1959, batch acc 0.7212
13:14:14.884 Training @ 155 epoch...
13:14:15.386   Training iter 50, batch loss 0.1936, batch acc 0.7214
13:14:15.873   Training iter 100, batch loss 0.1963, batch acc 0.7194
13:14:16.389   Training iter 150, batch loss 0.1952, batch acc 0.7160
13:14:16.877   Training iter 200, batch loss 0.1955, batch acc 0.7148
13:14:17.368   Training iter 250, batch loss 0.1890, batch acc 0.7284
13:14:17.863   Training iter 300, batch loss 0.1965, batch acc 0.7126
13:14:18.392   Training iter 350, batch loss 0.1922, batch acc 0.7210
13:14:18.906   Training iter 400, batch loss 0.1952, batch acc 0.7168
13:14:19.389   Training iter 450, batch loss 0.1908, batch acc 0.7232
13:14:19.879   Training iter 500, batch loss 0.1979, batch acc 0.7126
13:14:20.389   Training iter 550, batch loss 0.1956, batch acc 0.7126
13:14:20.912   Training iter 600, batch loss 0.2024, batch acc 0.6988
13:14:20.913 Testing @ 155 epoch...
13:14:20.953     Testing, total mean loss 0.19430, total acc 0.71520
13:14:20.953 Training @ 156 epoch...
13:14:21.463   Training iter 50, batch loss 0.1998, batch acc 0.7044
13:14:21.950   Training iter 100, batch loss 0.1920, batch acc 0.7226
13:14:22.445   Training iter 150, batch loss 0.1920, batch acc 0.7240
13:14:22.966   Training iter 200, batch loss 0.1965, batch acc 0.7148
13:14:23.513   Training iter 250, batch loss 0.1987, batch acc 0.7104
13:14:24.054   Training iter 300, batch loss 0.1951, batch acc 0.7184
13:14:24.580   Training iter 350, batch loss 0.1953, batch acc 0.7164
13:14:25.135   Training iter 400, batch loss 0.1905, batch acc 0.7238
13:14:25.675   Training iter 450, batch loss 0.1938, batch acc 0.7190
13:14:26.231   Training iter 500, batch loss 0.1967, batch acc 0.7110
13:14:26.775   Training iter 550, batch loss 0.1951, batch acc 0.7162
13:14:27.310   Training iter 600, batch loss 0.1940, batch acc 0.7196
13:14:27.312 Training @ 157 epoch...
13:14:27.860   Training iter 50, batch loss 0.1935, batch acc 0.7222
13:14:28.431   Training iter 100, batch loss 0.1929, batch acc 0.7208
13:14:29.010   Training iter 150, batch loss 0.1969, batch acc 0.7096
13:14:29.565   Training iter 200, batch loss 0.1932, batch acc 0.7182
13:14:30.052   Training iter 250, batch loss 0.1977, batch acc 0.7112
13:14:30.539   Training iter 300, batch loss 0.1962, batch acc 0.7146
13:14:31.024   Training iter 350, batch loss 0.1961, batch acc 0.7130
13:14:31.514   Training iter 400, batch loss 0.1914, batch acc 0.7234
13:14:31.984   Training iter 450, batch loss 0.1974, batch acc 0.7130
13:14:32.475   Training iter 500, batch loss 0.1946, batch acc 0.7166
13:14:32.975   Training iter 550, batch loss 0.1970, batch acc 0.7118
13:14:33.492   Training iter 600, batch loss 0.1920, batch acc 0.7234
13:14:33.493 Training @ 158 epoch...
13:14:34.027   Training iter 50, batch loss 0.1924, batch acc 0.7214
13:14:34.539   Training iter 100, batch loss 0.1957, batch acc 0.7138
13:14:35.058   Training iter 150, batch loss 0.1927, batch acc 0.7232
13:14:35.544   Training iter 200, batch loss 0.1952, batch acc 0.7176
13:14:36.027   Training iter 250, batch loss 0.1973, batch acc 0.7122
13:14:36.508   Training iter 300, batch loss 0.1946, batch acc 0.7184
13:14:36.993   Training iter 350, batch loss 0.1943, batch acc 0.7168
13:14:37.481   Training iter 400, batch loss 0.1932, batch acc 0.7158
13:14:37.961   Training iter 450, batch loss 0.1938, batch acc 0.7206
13:14:38.459   Training iter 500, batch loss 0.1980, batch acc 0.7084
13:14:38.957   Training iter 550, batch loss 0.1944, batch acc 0.7186
13:14:39.472   Training iter 600, batch loss 0.1964, batch acc 0.7130
13:14:39.474 Training @ 159 epoch...
13:14:40.003   Training iter 50, batch loss 0.1962, batch acc 0.7178
13:14:40.528   Training iter 100, batch loss 0.1944, batch acc 0.7172
13:14:41.064   Training iter 150, batch loss 0.1908, batch acc 0.7228
13:14:41.623   Training iter 200, batch loss 0.1983, batch acc 0.7102
13:14:42.188   Training iter 250, batch loss 0.1903, batch acc 0.7226
13:14:42.748   Training iter 300, batch loss 0.2002, batch acc 0.7026
13:14:43.310   Training iter 350, batch loss 0.1911, batch acc 0.7232
13:14:43.857   Training iter 400, batch loss 0.1935, batch acc 0.7154
13:14:44.408   Training iter 450, batch loss 0.1969, batch acc 0.7146
13:14:44.945   Training iter 500, batch loss 0.2012, batch acc 0.7102
13:14:45.484   Training iter 550, batch loss 0.1951, batch acc 0.7178
13:14:46.022   Training iter 600, batch loss 0.1894, batch acc 0.7260
13:14:46.024 Training @ 160 epoch...
13:14:46.545   Training iter 50, batch loss 0.1951, batch acc 0.7118
13:14:47.024   Training iter 100, batch loss 0.1983, batch acc 0.7114
13:14:47.501   Training iter 150, batch loss 0.1889, batch acc 0.7320
13:14:47.977   Training iter 200, batch loss 0.1953, batch acc 0.7130
13:14:48.459   Training iter 250, batch loss 0.1970, batch acc 0.7134
13:14:48.935   Training iter 300, batch loss 0.1934, batch acc 0.7192
13:14:49.399   Training iter 350, batch loss 0.1974, batch acc 0.7120
13:14:49.855   Training iter 400, batch loss 0.1958, batch acc 0.7130
13:14:50.348   Training iter 450, batch loss 0.1915, batch acc 0.7228
13:14:50.838   Training iter 500, batch loss 0.1943, batch acc 0.7158
13:14:51.337   Training iter 550, batch loss 0.1936, batch acc 0.7194
13:14:51.826   Training iter 600, batch loss 0.1961, batch acc 0.7162
13:14:51.828 Testing @ 160 epoch...
13:14:51.868     Testing, total mean loss 0.19401, total acc 0.71460
13:14:51.868 Training @ 161 epoch...
13:14:52.377   Training iter 50, batch loss 0.1972, batch acc 0.7126
13:14:52.849   Training iter 100, batch loss 0.1925, batch acc 0.7246
13:14:53.324   Training iter 150, batch loss 0.1942, batch acc 0.7156
13:14:53.832   Training iter 200, batch loss 0.1884, batch acc 0.7256
13:14:54.349   Training iter 250, batch loss 0.1930, batch acc 0.7176
13:14:54.865   Training iter 300, batch loss 0.1952, batch acc 0.7156
13:14:55.403   Training iter 350, batch loss 0.1978, batch acc 0.7146
13:14:55.941   Training iter 400, batch loss 0.1969, batch acc 0.7136
13:14:56.494   Training iter 450, batch loss 0.1922, batch acc 0.7228
13:14:57.041   Training iter 500, batch loss 0.1913, batch acc 0.7230
13:14:57.585   Training iter 550, batch loss 0.2018, batch acc 0.7010
13:14:58.144   Training iter 600, batch loss 0.1954, batch acc 0.7166
13:14:58.145 Training @ 162 epoch...
13:14:58.681   Training iter 50, batch loss 0.1921, batch acc 0.7254
13:14:59.216   Training iter 100, batch loss 0.1992, batch acc 0.7070
13:14:59.722   Training iter 150, batch loss 0.1917, batch acc 0.7206
13:15:00.239   Training iter 200, batch loss 0.1940, batch acc 0.7198
13:15:00.753   Training iter 250, batch loss 0.1946, batch acc 0.7184
13:15:01.262   Training iter 300, batch loss 0.1933, batch acc 0.7162
13:15:01.814   Training iter 350, batch loss 0.1882, batch acc 0.7274
13:15:02.315   Training iter 400, batch loss 0.1957, batch acc 0.7176
13:15:02.805   Training iter 450, batch loss 0.1977, batch acc 0.7098
13:15:03.305   Training iter 500, batch loss 0.1963, batch acc 0.7100
13:15:03.793   Training iter 550, batch loss 0.1945, batch acc 0.7138
13:15:04.288   Training iter 600, batch loss 0.1979, batch acc 0.7164
13:15:04.290 Training @ 163 epoch...
13:15:04.787   Training iter 50, batch loss 0.1986, batch acc 0.7112
13:15:05.281   Training iter 100, batch loss 0.1938, batch acc 0.7170
13:15:05.783   Training iter 150, batch loss 0.1972, batch acc 0.7092
13:15:06.288   Training iter 200, batch loss 0.1941, batch acc 0.7148
13:15:06.770   Training iter 250, batch loss 0.1934, batch acc 0.7220
13:15:07.248   Training iter 300, batch loss 0.1927, batch acc 0.7212
13:15:07.724   Training iter 350, batch loss 0.1879, batch acc 0.7300
13:15:08.214   Training iter 400, batch loss 0.1952, batch acc 0.7132
13:15:08.715   Training iter 450, batch loss 0.1979, batch acc 0.7154
13:15:09.198   Training iter 500, batch loss 0.1959, batch acc 0.7154
13:15:09.673   Training iter 550, batch loss 0.1921, batch acc 0.7204
13:15:10.168   Training iter 600, batch loss 0.1961, batch acc 0.7144
13:15:10.170 Training @ 164 epoch...
13:15:10.655   Training iter 50, batch loss 0.1932, batch acc 0.7176
13:15:11.147   Training iter 100, batch loss 0.1902, batch acc 0.7250
13:15:11.618   Training iter 150, batch loss 0.2026, batch acc 0.6996
13:15:12.092   Training iter 200, batch loss 0.1990, batch acc 0.7082
13:15:12.610   Training iter 250, batch loss 0.1902, batch acc 0.7284
13:15:13.124   Training iter 300, batch loss 0.1977, batch acc 0.7126
13:15:13.641   Training iter 350, batch loss 0.1924, batch acc 0.7178
13:15:14.168   Training iter 400, batch loss 0.1964, batch acc 0.7140
13:15:14.702   Training iter 450, batch loss 0.1941, batch acc 0.7200
13:15:15.238   Training iter 500, batch loss 0.1927, batch acc 0.7198
13:15:15.806   Training iter 550, batch loss 0.1925, batch acc 0.7232
13:15:16.377   Training iter 600, batch loss 0.1930, batch acc 0.7200
13:15:16.378 Training @ 165 epoch...
13:15:16.950   Training iter 50, batch loss 0.1943, batch acc 0.7174
13:15:17.514   Training iter 100, batch loss 0.1930, batch acc 0.7240
13:15:18.074   Training iter 150, batch loss 0.1951, batch acc 0.7154
13:15:18.629   Training iter 200, batch loss 0.1939, batch acc 0.7162
13:15:19.140   Training iter 250, batch loss 0.1914, batch acc 0.7218
13:15:19.649   Training iter 300, batch loss 0.1957, batch acc 0.7110
13:15:20.158   Training iter 350, batch loss 0.1926, batch acc 0.7212
13:15:20.663   Training iter 400, batch loss 0.1947, batch acc 0.7162
13:15:21.161   Training iter 450, batch loss 0.1967, batch acc 0.7158
13:15:21.666   Training iter 500, batch loss 0.1954, batch acc 0.7174
13:15:22.167   Training iter 550, batch loss 0.1934, batch acc 0.7170
13:15:22.677   Training iter 600, batch loss 0.1972, batch acc 0.7118
13:15:22.678 Testing @ 165 epoch...
13:15:22.715     Testing, total mean loss 0.19373, total acc 0.71480
13:15:22.715 Training @ 166 epoch...
13:15:23.235   Training iter 50, batch loss 0.1951, batch acc 0.7160
13:15:23.736   Training iter 100, batch loss 0.1959, batch acc 0.7132
13:15:24.249   Training iter 150, batch loss 0.1923, batch acc 0.7186
13:15:24.751   Training iter 200, batch loss 0.1942, batch acc 0.7186
13:15:25.280   Training iter 250, batch loss 0.1974, batch acc 0.7134
13:15:25.844   Training iter 300, batch loss 0.1974, batch acc 0.7130
13:15:26.403   Training iter 350, batch loss 0.1954, batch acc 0.7168
13:15:26.959   Training iter 400, batch loss 0.1967, batch acc 0.7120
13:15:27.470   Training iter 450, batch loss 0.1869, batch acc 0.7330
13:15:27.974   Training iter 500, batch loss 0.1918, batch acc 0.7212
13:15:28.489   Training iter 550, batch loss 0.1926, batch acc 0.7206
13:15:29.023   Training iter 600, batch loss 0.1970, batch acc 0.7110
13:15:29.025 Training @ 167 epoch...
13:15:29.579   Training iter 50, batch loss 0.1943, batch acc 0.7162
13:15:30.142   Training iter 100, batch loss 0.2030, batch acc 0.7022
13:15:30.687   Training iter 150, batch loss 0.1960, batch acc 0.7146
13:15:31.235   Training iter 200, batch loss 0.1976, batch acc 0.7054
13:15:31.782   Training iter 250, batch loss 0.1973, batch acc 0.7136
13:15:32.328   Training iter 300, batch loss 0.1901, batch acc 0.7234
13:15:32.869   Training iter 350, batch loss 0.1968, batch acc 0.7110
13:15:33.421   Training iter 400, batch loss 0.1904, batch acc 0.7248
13:15:33.959   Training iter 450, batch loss 0.1937, batch acc 0.7190
13:15:34.491   Training iter 500, batch loss 0.1881, batch acc 0.7296
13:15:35.004   Training iter 550, batch loss 0.1885, batch acc 0.7338
13:15:35.509   Training iter 600, batch loss 0.1964, batch acc 0.7128
13:15:35.510 Training @ 168 epoch...
13:15:36.029   Training iter 50, batch loss 0.1956, batch acc 0.7158
13:15:36.533   Training iter 100, batch loss 0.1982, batch acc 0.7080
13:15:37.051   Training iter 150, batch loss 0.1908, batch acc 0.7232
13:15:37.575   Training iter 200, batch loss 0.1902, batch acc 0.7304
13:15:38.112   Training iter 250, batch loss 0.1902, batch acc 0.7216
13:15:38.651   Training iter 300, batch loss 0.1960, batch acc 0.7124
13:15:39.192   Training iter 350, batch loss 0.1962, batch acc 0.7120
13:15:39.719   Training iter 400, batch loss 0.1939, batch acc 0.7172
13:15:40.255   Training iter 450, batch loss 0.1899, batch acc 0.7232
13:15:40.788   Training iter 500, batch loss 0.1921, batch acc 0.7206
13:15:41.350   Training iter 550, batch loss 0.2009, batch acc 0.7072
13:15:41.887   Training iter 600, batch loss 0.1975, batch acc 0.7116
13:15:41.889 Training @ 169 epoch...
13:15:42.433   Training iter 50, batch loss 0.1949, batch acc 0.7126
13:15:43.022   Training iter 100, batch loss 0.1925, batch acc 0.7228
13:15:43.577   Training iter 150, batch loss 0.1940, batch acc 0.7212
13:15:44.130   Training iter 200, batch loss 0.1922, batch acc 0.7224
13:15:44.691   Training iter 250, batch loss 0.1948, batch acc 0.7160
13:15:45.275   Training iter 300, batch loss 0.1953, batch acc 0.7168
13:15:45.851   Training iter 350, batch loss 0.1881, batch acc 0.7278
13:15:46.429   Training iter 400, batch loss 0.1903, batch acc 0.7250
13:15:46.978   Training iter 450, batch loss 0.2006, batch acc 0.7084
13:15:47.522   Training iter 500, batch loss 0.1966, batch acc 0.7122
13:15:48.064   Training iter 550, batch loss 0.1979, batch acc 0.7050
13:15:48.616   Training iter 600, batch loss 0.1940, batch acc 0.7158
13:15:48.618 Training @ 170 epoch...
13:15:49.174   Training iter 50, batch loss 0.1950, batch acc 0.7186
13:15:49.730   Training iter 100, batch loss 0.1966, batch acc 0.7166
13:15:50.287   Training iter 150, batch loss 0.1944, batch acc 0.7144
13:15:50.819   Training iter 200, batch loss 0.1943, batch acc 0.7198
13:15:51.325   Training iter 250, batch loss 0.1923, batch acc 0.7196
13:15:51.835   Training iter 300, batch loss 0.1931, batch acc 0.7206
13:15:52.334   Training iter 350, batch loss 0.1928, batch acc 0.7204
13:15:52.841   Training iter 400, batch loss 0.1908, batch acc 0.7234
13:15:53.360   Training iter 450, batch loss 0.1980, batch acc 0.7030
13:15:53.861   Training iter 500, batch loss 0.1931, batch acc 0.7174
13:15:54.380   Training iter 550, batch loss 0.1946, batch acc 0.7178
13:15:54.905   Training iter 600, batch loss 0.1955, batch acc 0.7166
13:15:54.907 Testing @ 170 epoch...
13:15:54.944     Testing, total mean loss 0.19347, total acc 0.71470
13:15:54.944 Training @ 171 epoch...
13:15:55.467   Training iter 50, batch loss 0.1957, batch acc 0.7124
13:15:55.964   Training iter 100, batch loss 0.1922, batch acc 0.7196
13:15:56.475   Training iter 150, batch loss 0.1979, batch acc 0.7118
13:15:56.969   Training iter 200, batch loss 0.1908, batch acc 0.7254
13:15:57.475   Training iter 250, batch loss 0.1907, batch acc 0.7208
13:15:57.972   Training iter 300, batch loss 0.1939, batch acc 0.7170
13:15:58.465   Training iter 350, batch loss 0.1973, batch acc 0.7112
13:15:58.960   Training iter 400, batch loss 0.1957, batch acc 0.7168
13:15:59.472   Training iter 450, batch loss 0.1973, batch acc 0.7112
13:15:59.971   Training iter 500, batch loss 0.1942, batch acc 0.7168
13:16:00.494   Training iter 550, batch loss 0.1915, batch acc 0.7236
13:16:01.027   Training iter 600, batch loss 0.1925, batch acc 0.7196
13:16:01.029 Training @ 172 epoch...
13:16:01.591   Training iter 50, batch loss 0.1919, batch acc 0.7220
13:16:02.163   Training iter 100, batch loss 0.1889, batch acc 0.7274
13:16:02.700   Training iter 150, batch loss 0.1921, batch acc 0.7224
13:16:03.243   Training iter 200, batch loss 0.1979, batch acc 0.7102
13:16:03.780   Training iter 250, batch loss 0.1919, batch acc 0.7234
13:16:04.309   Training iter 300, batch loss 0.1972, batch acc 0.7098
13:16:04.840   Training iter 350, batch loss 0.1985, batch acc 0.7082
13:16:05.376   Training iter 400, batch loss 0.1965, batch acc 0.7118
13:16:05.909   Training iter 450, batch loss 0.1962, batch acc 0.7164
13:16:06.441   Training iter 500, batch loss 0.1958, batch acc 0.7136
13:16:06.942   Training iter 550, batch loss 0.1918, batch acc 0.7186
13:16:07.425   Training iter 600, batch loss 0.1907, batch acc 0.7242
13:16:07.427 Training @ 173 epoch...
13:16:07.914   Training iter 50, batch loss 0.1930, batch acc 0.7182
13:16:08.399   Training iter 100, batch loss 0.1985, batch acc 0.7142
13:16:08.890   Training iter 150, batch loss 0.1939, batch acc 0.7212
13:16:09.394   Training iter 200, batch loss 0.1953, batch acc 0.7128
13:16:09.891   Training iter 250, batch loss 0.1933, batch acc 0.7166
13:16:10.396   Training iter 300, batch loss 0.1916, batch acc 0.7200
13:16:10.890   Training iter 350, batch loss 0.1944, batch acc 0.7136
13:16:11.394   Training iter 400, batch loss 0.1940, batch acc 0.7176
13:16:11.882   Training iter 450, batch loss 0.1943, batch acc 0.7144
13:16:12.381   Training iter 500, batch loss 0.1957, batch acc 0.7150
13:16:12.881   Training iter 550, batch loss 0.1934, batch acc 0.7208
13:16:13.376   Training iter 600, batch loss 0.1913, batch acc 0.7246
13:16:13.378 Training @ 174 epoch...
13:16:13.869   Training iter 50, batch loss 0.1972, batch acc 0.7094
13:16:14.378   Training iter 100, batch loss 0.1869, batch acc 0.7346
13:16:14.884   Training iter 150, batch loss 0.1947, batch acc 0.7130
13:16:15.389   Training iter 200, batch loss 0.1974, batch acc 0.7062
13:16:15.900   Training iter 250, batch loss 0.1940, batch acc 0.7206
13:16:16.404   Training iter 300, batch loss 0.1946, batch acc 0.7148
13:16:16.902   Training iter 350, batch loss 0.1958, batch acc 0.7130
13:16:17.386   Training iter 400, batch loss 0.1974, batch acc 0.7120
13:16:17.883   Training iter 450, batch loss 0.1909, batch acc 0.7262
13:16:18.387   Training iter 500, batch loss 0.1971, batch acc 0.7130
13:16:18.885   Training iter 550, batch loss 0.1930, batch acc 0.7182
13:16:19.374   Training iter 600, batch loss 0.1891, batch acc 0.7256
13:16:19.375 Training @ 175 epoch...
13:16:19.908   Training iter 50, batch loss 0.1956, batch acc 0.7160
13:16:20.460   Training iter 100, batch loss 0.1933, batch acc 0.7176
13:16:21.017   Training iter 150, batch loss 0.1869, batch acc 0.7326
13:16:21.552   Training iter 200, batch loss 0.1980, batch acc 0.7072
13:16:22.023   Training iter 250, batch loss 0.1998, batch acc 0.7072
13:16:22.528   Training iter 300, batch loss 0.1971, batch acc 0.7104
13:16:23.026   Training iter 350, batch loss 0.1902, batch acc 0.7236
13:16:23.528   Training iter 400, batch loss 0.1920, batch acc 0.7208
13:16:24.029   Training iter 450, batch loss 0.1939, batch acc 0.7154
13:16:24.536   Training iter 500, batch loss 0.1910, batch acc 0.7228
13:16:25.027   Training iter 550, batch loss 0.1986, batch acc 0.7102
13:16:25.590   Training iter 600, batch loss 0.1912, batch acc 0.7256
13:16:25.592 Testing @ 175 epoch...
13:16:25.631     Testing, total mean loss 0.19328, total acc 0.71500
13:16:25.631 Training @ 176 epoch...
13:16:26.130   Training iter 50, batch loss 0.1953, batch acc 0.7152
13:16:26.617   Training iter 100, batch loss 0.1963, batch acc 0.7096
13:16:27.105   Training iter 150, batch loss 0.1936, batch acc 0.7226
13:16:27.616   Training iter 200, batch loss 0.1971, batch acc 0.7114
13:16:28.120   Training iter 250, batch loss 0.1932, batch acc 0.7206
13:16:28.786   Training iter 300, batch loss 0.1896, batch acc 0.7264
13:16:29.324   Training iter 350, batch loss 0.1893, batch acc 0.7278
13:16:29.830   Training iter 400, batch loss 0.1949, batch acc 0.7160
13:16:30.340   Training iter 450, batch loss 0.1937, batch acc 0.7196
13:16:30.857   Training iter 500, batch loss 0.1915, batch acc 0.7178
13:16:31.341   Training iter 550, batch loss 0.1935, batch acc 0.7166
13:16:31.838   Training iter 600, batch loss 0.1990, batch acc 0.7074
13:16:31.840 Training @ 177 epoch...
13:16:32.329   Training iter 50, batch loss 0.2007, batch acc 0.7054
13:16:32.804   Training iter 100, batch loss 0.1934, batch acc 0.7174
13:16:33.297   Training iter 150, batch loss 0.1891, batch acc 0.7278
13:16:33.778   Training iter 200, batch loss 0.1888, batch acc 0.7268
13:16:34.261   Training iter 250, batch loss 0.1928, batch acc 0.7196
13:16:34.769   Training iter 300, batch loss 0.2005, batch acc 0.7072
13:16:35.255   Training iter 350, batch loss 0.1912, batch acc 0.7214
13:16:35.725   Training iter 400, batch loss 0.1930, batch acc 0.7174
13:16:36.205   Training iter 450, batch loss 0.1947, batch acc 0.7154
13:16:36.680   Training iter 500, batch loss 0.1921, batch acc 0.7186
13:16:37.163   Training iter 550, batch loss 0.1973, batch acc 0.7134
13:16:37.662   Training iter 600, batch loss 0.1929, batch acc 0.7206
13:16:37.663 Training @ 178 epoch...
13:16:38.163   Training iter 50, batch loss 0.1946, batch acc 0.7202
13:16:38.648   Training iter 100, batch loss 0.1894, batch acc 0.7246
13:16:39.135   Training iter 150, batch loss 0.1875, batch acc 0.7326
13:16:39.603   Training iter 200, batch loss 0.1986, batch acc 0.7064
13:16:40.094   Training iter 250, batch loss 0.1963, batch acc 0.7072
13:16:40.572   Training iter 300, batch loss 0.1892, batch acc 0.7244
13:16:41.052   Training iter 350, batch loss 0.1973, batch acc 0.7114
13:16:41.557   Training iter 400, batch loss 0.1957, batch acc 0.7154
13:16:42.048   Training iter 450, batch loss 0.1964, batch acc 0.7116
13:16:42.547   Training iter 500, batch loss 0.1955, batch acc 0.7184
13:16:43.051   Training iter 550, batch loss 0.1939, batch acc 0.7184
13:16:43.541   Training iter 600, batch loss 0.1916, batch acc 0.7192
13:16:43.543 Training @ 179 epoch...
13:16:44.050   Training iter 50, batch loss 0.1947, batch acc 0.7156
13:16:44.539   Training iter 100, batch loss 0.1947, batch acc 0.7134
13:16:45.044   Training iter 150, batch loss 0.1952, batch acc 0.7156
13:16:45.535   Training iter 200, batch loss 0.1963, batch acc 0.7124
13:16:46.021   Training iter 250, batch loss 0.1892, batch acc 0.7210
13:16:46.499   Training iter 300, batch loss 0.1949, batch acc 0.7162
13:16:46.984   Training iter 350, batch loss 0.1985, batch acc 0.7102
13:16:47.484   Training iter 400, batch loss 0.1933, batch acc 0.7202
13:16:47.969   Training iter 450, batch loss 0.1958, batch acc 0.7152
13:16:48.458   Training iter 500, batch loss 0.1911, batch acc 0.7222
13:16:48.942   Training iter 550, batch loss 0.1915, batch acc 0.7286
13:16:49.435   Training iter 600, batch loss 0.1901, batch acc 0.7212
13:16:49.436 Training @ 180 epoch...
13:16:49.941   Training iter 50, batch loss 0.1903, batch acc 0.7294
13:16:50.456   Training iter 100, batch loss 0.1934, batch acc 0.7188
13:16:50.969   Training iter 150, batch loss 0.1949, batch acc 0.7136
13:16:51.482   Training iter 200, batch loss 0.1888, batch acc 0.7276
13:16:51.976   Training iter 250, batch loss 0.1926, batch acc 0.7202
13:16:52.442   Training iter 300, batch loss 0.1979, batch acc 0.7100
13:16:52.895   Training iter 350, batch loss 0.1974, batch acc 0.7120
13:16:53.376   Training iter 400, batch loss 0.1964, batch acc 0.7108
13:16:53.852   Training iter 450, batch loss 0.1950, batch acc 0.7130
13:16:54.332   Training iter 500, batch loss 0.1912, batch acc 0.7196
13:16:54.820   Training iter 550, batch loss 0.1910, batch acc 0.7274
13:16:55.311   Training iter 600, batch loss 0.1962, batch acc 0.7086
13:16:55.313 Testing @ 180 epoch...
13:16:55.355     Testing, total mean loss 0.19301, total acc 0.71470
13:16:55.355 Training @ 181 epoch...
13:16:55.861   Training iter 50, batch loss 0.1948, batch acc 0.7172
13:16:56.390   Training iter 100, batch loss 0.1964, batch acc 0.7092
13:16:56.936   Training iter 150, batch loss 0.1967, batch acc 0.7102
13:16:57.454   Training iter 200, batch loss 0.1882, batch acc 0.7298
13:16:57.975   Training iter 250, batch loss 0.1920, batch acc 0.7226
13:16:58.512   Training iter 300, batch loss 0.1960, batch acc 0.7048
13:16:59.029   Training iter 350, batch loss 0.1939, batch acc 0.7160
13:16:59.547   Training iter 400, batch loss 0.1936, batch acc 0.7194
13:17:00.060   Training iter 450, batch loss 0.1946, batch acc 0.7224
13:17:00.548   Training iter 500, batch loss 0.1940, batch acc 0.7216
13:17:01.026   Training iter 550, batch loss 0.1904, batch acc 0.7216
13:17:01.562   Training iter 600, batch loss 0.1939, batch acc 0.7184
13:17:01.564 Training @ 182 epoch...
13:17:02.103   Training iter 50, batch loss 0.1905, batch acc 0.7212
13:17:02.630   Training iter 100, batch loss 0.1930, batch acc 0.7186
13:17:03.137   Training iter 150, batch loss 0.1911, batch acc 0.7224
13:17:03.640   Training iter 200, batch loss 0.2005, batch acc 0.7084
13:17:04.167   Training iter 250, batch loss 0.1964, batch acc 0.7134
13:17:04.702   Training iter 300, batch loss 0.1896, batch acc 0.7260
13:17:05.208   Training iter 350, batch loss 0.1955, batch acc 0.7142
13:17:05.715   Training iter 400, batch loss 0.1889, batch acc 0.7284
13:17:06.276   Training iter 450, batch loss 0.1967, batch acc 0.7112
13:17:06.839   Training iter 500, batch loss 0.1924, batch acc 0.7176
13:17:07.392   Training iter 550, batch loss 0.1946, batch acc 0.7146
13:17:07.903   Training iter 600, batch loss 0.1949, batch acc 0.7166
13:17:07.905 Training @ 183 epoch...
13:17:08.380   Training iter 50, batch loss 0.1921, batch acc 0.7216
13:17:08.835   Training iter 100, batch loss 0.1976, batch acc 0.7100
13:17:09.315   Training iter 150, batch loss 0.1925, batch acc 0.7228
13:17:09.777   Training iter 200, batch loss 0.1885, batch acc 0.7308
13:17:10.230   Training iter 250, batch loss 0.1922, batch acc 0.7188
13:17:10.682   Training iter 300, batch loss 0.2003, batch acc 0.7012
13:17:11.135   Training iter 350, batch loss 0.1894, batch acc 0.7254
13:17:11.582   Training iter 400, batch loss 0.1885, batch acc 0.7254
13:17:12.032   Training iter 450, batch loss 0.2006, batch acc 0.7046
13:17:12.489   Training iter 500, batch loss 0.1932, batch acc 0.7184
13:17:12.946   Training iter 550, batch loss 0.1934, batch acc 0.7198
13:17:13.406   Training iter 600, batch loss 0.1951, batch acc 0.7150
13:17:13.408 Training @ 184 epoch...
13:17:13.859   Training iter 50, batch loss 0.1942, batch acc 0.7186
13:17:14.325   Training iter 100, batch loss 0.1925, batch acc 0.7170
13:17:14.781   Training iter 150, batch loss 0.1929, batch acc 0.7244
13:17:15.260   Training iter 200, batch loss 0.1964, batch acc 0.7118
13:17:15.737   Training iter 250, batch loss 0.1925, batch acc 0.7202
13:17:16.187   Training iter 300, batch loss 0.1941, batch acc 0.7210
13:17:16.634   Training iter 350, batch loss 0.1936, batch acc 0.7150
13:17:17.087   Training iter 400, batch loss 0.1935, batch acc 0.7168
13:17:17.555   Training iter 450, batch loss 0.1919, batch acc 0.7194
13:17:18.015   Training iter 500, batch loss 0.1976, batch acc 0.7082
13:17:18.497   Training iter 550, batch loss 0.1936, batch acc 0.7168
13:17:18.967   Training iter 600, batch loss 0.1903, batch acc 0.7258
13:17:18.969 Training @ 185 epoch...
13:17:19.432   Training iter 50, batch loss 0.1961, batch acc 0.7062
13:17:19.931   Training iter 100, batch loss 0.1899, batch acc 0.7260
13:17:20.454   Training iter 150, batch loss 0.1897, batch acc 0.7286
13:17:20.955   Training iter 200, batch loss 0.1963, batch acc 0.7130
13:17:21.431   Training iter 250, batch loss 0.1906, batch acc 0.7242
13:17:21.902   Training iter 300, batch loss 0.1950, batch acc 0.7160
13:17:22.394   Training iter 350, batch loss 0.1962, batch acc 0.7138
13:17:22.900   Training iter 400, batch loss 0.1925, batch acc 0.7186
13:17:23.399   Training iter 450, batch loss 0.1967, batch acc 0.7084
13:17:23.938   Training iter 500, batch loss 0.1966, batch acc 0.7140
13:17:24.425   Training iter 550, batch loss 0.1952, batch acc 0.7164
13:17:24.941   Training iter 600, batch loss 0.1877, batch acc 0.7304
13:17:24.943 Testing @ 185 epoch...
13:17:24.980     Testing, total mean loss 0.19289, total acc 0.71500
13:17:24.980 Training @ 186 epoch...
13:17:25.519   Training iter 50, batch loss 0.1894, batch acc 0.7232
13:17:26.037   Training iter 100, batch loss 0.1939, batch acc 0.7216
13:17:26.526   Training iter 150, batch loss 0.1959, batch acc 0.7128
13:17:27.014   Training iter 200, batch loss 0.1944, batch acc 0.7166
13:17:27.502   Training iter 250, batch loss 0.1942, batch acc 0.7138
13:17:27.984   Training iter 300, batch loss 0.1907, batch acc 0.7240
13:17:28.458   Training iter 350, batch loss 0.1938, batch acc 0.7202
13:17:28.941   Training iter 400, batch loss 0.1958, batch acc 0.7114
13:17:29.396   Training iter 450, batch loss 0.1928, batch acc 0.7184
13:17:29.841   Training iter 500, batch loss 0.1927, batch acc 0.7186
13:17:30.300   Training iter 550, batch loss 0.1950, batch acc 0.7164
13:17:30.754   Training iter 600, batch loss 0.1934, batch acc 0.7170
13:17:30.756 Training @ 187 epoch...
13:17:31.200   Training iter 50, batch loss 0.1948, batch acc 0.7160
13:17:31.647   Training iter 100, batch loss 0.1919, batch acc 0.7272
13:17:32.108   Training iter 150, batch loss 0.1936, batch acc 0.7146
13:17:32.590   Training iter 200, batch loss 0.1901, batch acc 0.7214
13:17:33.082   Training iter 250, batch loss 0.1948, batch acc 0.7158
13:17:33.559   Training iter 300, batch loss 0.1941, batch acc 0.7158
13:17:34.041   Training iter 350, batch loss 0.1974, batch acc 0.7080
13:17:34.521   Training iter 400, batch loss 0.1917, batch acc 0.7220
13:17:35.006   Training iter 450, batch loss 0.1968, batch acc 0.7132
13:17:35.504   Training iter 500, batch loss 0.1904, batch acc 0.7272
13:17:35.976   Training iter 550, batch loss 0.1934, batch acc 0.7174
13:17:36.477   Training iter 600, batch loss 0.1927, batch acc 0.7160
13:17:36.479 Training @ 188 epoch...
13:17:36.997   Training iter 50, batch loss 0.1933, batch acc 0.7172
13:17:37.511   Training iter 100, batch loss 0.1963, batch acc 0.7134
13:17:38.022   Training iter 150, batch loss 0.1905, batch acc 0.7242
13:17:38.529   Training iter 200, batch loss 0.1955, batch acc 0.7166
13:17:39.032   Training iter 250, batch loss 0.1942, batch acc 0.7158
13:17:39.531   Training iter 300, batch loss 0.1920, batch acc 0.7244
13:17:40.040   Training iter 350, batch loss 0.1965, batch acc 0.7124
13:17:40.558   Training iter 400, batch loss 0.1922, batch acc 0.7220
13:17:41.060   Training iter 450, batch loss 0.1882, batch acc 0.7242
13:17:41.554   Training iter 500, batch loss 0.1974, batch acc 0.7090
13:17:42.057   Training iter 550, batch loss 0.1904, batch acc 0.7214
13:17:42.551   Training iter 600, batch loss 0.1946, batch acc 0.7146
13:17:42.553 Training @ 189 epoch...
13:17:43.030   Training iter 50, batch loss 0.1931, batch acc 0.7194
13:17:43.513   Training iter 100, batch loss 0.1923, batch acc 0.7200
13:17:43.992   Training iter 150, batch loss 0.1900, batch acc 0.7206
13:17:44.482   Training iter 200, batch loss 0.1912, batch acc 0.7206
13:17:44.971   Training iter 250, batch loss 0.1944, batch acc 0.7208
13:17:45.463   Training iter 300, batch loss 0.1926, batch acc 0.7212
13:17:45.945   Training iter 350, batch loss 0.1933, batch acc 0.7198
13:17:46.446   Training iter 400, batch loss 0.1927, batch acc 0.7196
13:17:46.934   Training iter 450, batch loss 0.1946, batch acc 0.7146
13:17:47.423   Training iter 500, batch loss 0.1937, batch acc 0.7148
13:17:47.893   Training iter 550, batch loss 0.1940, batch acc 0.7170
13:17:48.380   Training iter 600, batch loss 0.1989, batch acc 0.7064
13:17:48.382 Training @ 190 epoch...
13:17:48.867   Training iter 50, batch loss 0.1928, batch acc 0.7202
13:17:49.405   Training iter 100, batch loss 0.1940, batch acc 0.7182
13:17:49.877   Training iter 150, batch loss 0.1964, batch acc 0.7152
13:17:50.363   Training iter 200, batch loss 0.1935, batch acc 0.7196
13:17:50.867   Training iter 250, batch loss 0.1962, batch acc 0.7136
13:17:51.382   Training iter 300, batch loss 0.1966, batch acc 0.7094
13:17:51.875   Training iter 350, batch loss 0.1951, batch acc 0.7140
13:17:52.358   Training iter 400, batch loss 0.1913, batch acc 0.7240
13:17:52.851   Training iter 450, batch loss 0.1906, batch acc 0.7172
13:17:53.355   Training iter 500, batch loss 0.1872, batch acc 0.7294
13:17:53.851   Training iter 550, batch loss 0.1939, batch acc 0.7190
13:17:54.351   Training iter 600, batch loss 0.1928, batch acc 0.7160
13:17:54.352 Testing @ 190 epoch...
13:17:54.389     Testing, total mean loss 0.19269, total acc 0.71480
13:17:54.389 Training @ 191 epoch...
13:17:54.892   Training iter 50, batch loss 0.1925, batch acc 0.7208
13:17:55.396   Training iter 100, batch loss 0.1958, batch acc 0.7124
13:17:55.887   Training iter 150, batch loss 0.1952, batch acc 0.7132
13:17:56.370   Training iter 200, batch loss 0.1927, batch acc 0.7188
13:17:56.875   Training iter 250, batch loss 0.1875, batch acc 0.7294
13:17:57.374   Training iter 300, batch loss 0.1933, batch acc 0.7190
13:17:57.870   Training iter 350, batch loss 0.1908, batch acc 0.7234
13:17:58.371   Training iter 400, batch loss 0.1945, batch acc 0.7202
13:17:58.878   Training iter 450, batch loss 0.1969, batch acc 0.7106
13:17:59.376   Training iter 500, batch loss 0.1872, batch acc 0.7278
13:17:59.858   Training iter 550, batch loss 0.1997, batch acc 0.7032
13:18:00.363   Training iter 600, batch loss 0.1936, batch acc 0.7170
13:18:00.365 Training @ 192 epoch...
13:18:00.877   Training iter 50, batch loss 0.1859, batch acc 0.7316
13:18:01.398   Training iter 100, batch loss 0.1891, batch acc 0.7274
13:18:01.953   Training iter 150, batch loss 0.1921, batch acc 0.7210
13:18:02.493   Training iter 200, batch loss 0.1929, batch acc 0.7216
13:18:03.031   Training iter 250, batch loss 0.1966, batch acc 0.7092
13:18:03.584   Training iter 300, batch loss 0.1967, batch acc 0.7128
13:18:04.101   Training iter 350, batch loss 0.1945, batch acc 0.7170
13:18:04.616   Training iter 400, batch loss 0.1936, batch acc 0.7166
13:18:05.115   Training iter 450, batch loss 0.1974, batch acc 0.7068
13:18:05.627   Training iter 500, batch loss 0.1919, batch acc 0.7212
13:18:06.133   Training iter 550, batch loss 0.1961, batch acc 0.7130
13:18:06.647   Training iter 600, batch loss 0.1925, batch acc 0.7186
13:18:06.648 Training @ 193 epoch...
13:18:07.141   Training iter 50, batch loss 0.1939, batch acc 0.7166
13:18:07.620   Training iter 100, batch loss 0.1901, batch acc 0.7242
13:18:08.085   Training iter 150, batch loss 0.1944, batch acc 0.7190
13:18:08.553   Training iter 200, batch loss 0.1966, batch acc 0.7146
13:18:09.025   Training iter 250, batch loss 0.1929, batch acc 0.7148
13:18:09.535   Training iter 300, batch loss 0.1915, batch acc 0.7212
13:18:10.013   Training iter 350, batch loss 0.1894, batch acc 0.7268
13:18:10.503   Training iter 400, batch loss 0.1954, batch acc 0.7132
13:18:10.991   Training iter 450, batch loss 0.1902, batch acc 0.7246
13:18:11.479   Training iter 500, batch loss 0.1920, batch acc 0.7224
13:18:11.953   Training iter 550, batch loss 0.1991, batch acc 0.7076
13:18:12.469   Training iter 600, batch loss 0.1934, batch acc 0.7140
13:18:12.471 Training @ 194 epoch...
13:18:12.991   Training iter 50, batch loss 0.1921, batch acc 0.7194
13:18:13.502   Training iter 100, batch loss 0.1972, batch acc 0.7102
13:18:14.025   Training iter 150, batch loss 0.1910, batch acc 0.7242
13:18:14.549   Training iter 200, batch loss 0.1878, batch acc 0.7276
13:18:15.071   Training iter 250, batch loss 0.1950, batch acc 0.7130
13:18:15.565   Training iter 300, batch loss 0.1965, batch acc 0.7130
13:18:16.065   Training iter 350, batch loss 0.1913, batch acc 0.7252
13:18:16.559   Training iter 400, batch loss 0.1948, batch acc 0.7148
13:18:17.056   Training iter 450, batch loss 0.1925, batch acc 0.7178
13:18:17.544   Training iter 500, batch loss 0.1939, batch acc 0.7202
13:18:18.033   Training iter 550, batch loss 0.1912, batch acc 0.7212
13:18:18.530   Training iter 600, batch loss 0.1952, batch acc 0.7120
13:18:18.532 Training @ 195 epoch...
13:18:19.034   Training iter 50, batch loss 0.1932, batch acc 0.7206
13:18:19.522   Training iter 100, batch loss 0.1942, batch acc 0.7146
13:18:20.012   Training iter 150, batch loss 0.1922, batch acc 0.7206
13:18:20.500   Training iter 200, batch loss 0.1922, batch acc 0.7226
13:18:20.981   Training iter 250, batch loss 0.1957, batch acc 0.7124
13:18:21.466   Training iter 300, batch loss 0.1924, batch acc 0.7200
13:18:21.952   Training iter 350, batch loss 0.1917, batch acc 0.7202
13:18:22.454   Training iter 400, batch loss 0.1925, batch acc 0.7208
13:18:22.963   Training iter 450, batch loss 0.1924, batch acc 0.7186
13:18:23.476   Training iter 500, batch loss 0.1884, batch acc 0.7288
13:18:23.978   Training iter 550, batch loss 0.1962, batch acc 0.7084
13:18:24.493   Training iter 600, batch loss 0.1969, batch acc 0.7120
13:18:24.495 Testing @ 195 epoch...
13:18:24.532     Testing, total mean loss 0.19250, total acc 0.71550
13:18:24.532 Training @ 196 epoch...
13:18:25.039   Training iter 50, batch loss 0.1941, batch acc 0.7126
13:18:25.578   Training iter 100, batch loss 0.1946, batch acc 0.7124
13:18:26.124   Training iter 150, batch loss 0.1907, batch acc 0.7216
13:18:26.668   Training iter 200, batch loss 0.1921, batch acc 0.7238
13:18:27.203   Training iter 250, batch loss 0.1897, batch acc 0.7246
13:18:27.741   Training iter 300, batch loss 0.1933, batch acc 0.7172
13:18:28.284   Training iter 350, batch loss 0.2030, batch acc 0.7004
13:18:28.816   Training iter 400, batch loss 0.1913, batch acc 0.7222
13:18:29.359   Training iter 450, batch loss 0.1953, batch acc 0.7160
13:18:29.880   Training iter 500, batch loss 0.1937, batch acc 0.7194
13:18:30.424   Training iter 550, batch loss 0.1885, batch acc 0.7264
13:18:30.951   Training iter 600, batch loss 0.1913, batch acc 0.7214
13:18:30.953 Training @ 197 epoch...
13:18:31.466   Training iter 50, batch loss 0.1971, batch acc 0.7152
13:18:31.964   Training iter 100, batch loss 0.1898, batch acc 0.7252
13:18:32.453   Training iter 150, batch loss 0.1945, batch acc 0.7140
13:18:32.940   Training iter 200, batch loss 0.1919, batch acc 0.7202
13:18:33.436   Training iter 250, batch loss 0.1902, batch acc 0.7224
13:18:33.920   Training iter 300, batch loss 0.1965, batch acc 0.7114
13:18:34.410   Training iter 350, batch loss 0.1899, batch acc 0.7234
13:18:34.920   Training iter 400, batch loss 0.1931, batch acc 0.7196
13:18:35.443   Training iter 450, batch loss 0.1910, batch acc 0.7216
13:18:35.952   Training iter 500, batch loss 0.1961, batch acc 0.7136
13:18:36.456   Training iter 550, batch loss 0.1955, batch acc 0.7138
13:18:36.962   Training iter 600, batch loss 0.1918, batch acc 0.7172
13:18:36.963 Training @ 198 epoch...
13:18:37.470   Training iter 50, batch loss 0.1904, batch acc 0.7224
13:18:37.975   Training iter 100, batch loss 0.1971, batch acc 0.7078
13:18:38.487   Training iter 150, batch loss 0.1916, batch acc 0.7236
13:18:38.992   Training iter 200, batch loss 0.1903, batch acc 0.7220
13:18:39.503   Training iter 250, batch loss 0.1912, batch acc 0.7242
13:18:40.020   Training iter 300, batch loss 0.1916, batch acc 0.7184
13:18:40.546   Training iter 350, batch loss 0.1914, batch acc 0.7204
13:18:41.066   Training iter 400, batch loss 0.1956, batch acc 0.7158
13:18:41.600   Training iter 450, batch loss 0.1912, batch acc 0.7210
13:18:42.141   Training iter 500, batch loss 0.1981, batch acc 0.7100
13:18:42.679   Training iter 550, batch loss 0.1929, batch acc 0.7214
13:18:43.215   Training iter 600, batch loss 0.1957, batch acc 0.7118
13:18:43.216 Training @ 199 epoch...
13:18:43.738   Training iter 50, batch loss 0.1894, batch acc 0.7204
13:18:44.266   Training iter 100, batch loss 0.1941, batch acc 0.7172
13:18:44.787   Training iter 150, batch loss 0.1936, batch acc 0.7168
13:18:45.319   Training iter 200, batch loss 0.1933, batch acc 0.7184
13:18:45.848   Training iter 250, batch loss 0.1906, batch acc 0.7246
13:18:46.414   Training iter 300, batch loss 0.1906, batch acc 0.7226
13:18:46.995   Training iter 350, batch loss 0.1949, batch acc 0.7148
13:18:47.564   Training iter 400, batch loss 0.1964, batch acc 0.7112
13:18:48.109   Training iter 450, batch loss 0.1956, batch acc 0.7110
13:18:48.597   Training iter 500, batch loss 0.1958, batch acc 0.7130
13:18:49.106   Training iter 550, batch loss 0.1922, batch acc 0.7216
13:18:49.607   Training iter 600, batch loss 0.1902, batch acc 0.7252
13:18:49.609 Training @ 200 epoch...
13:18:50.127   Training iter 50, batch loss 0.1948, batch acc 0.7152
13:18:50.638   Training iter 100, batch loss 0.1911, batch acc 0.7158
13:18:51.155   Training iter 150, batch loss 0.1933, batch acc 0.7216
13:18:51.660   Training iter 200, batch loss 0.1967, batch acc 0.7104
13:18:52.152   Training iter 250, batch loss 0.1917, batch acc 0.7204
13:18:52.641   Training iter 300, batch loss 0.1928, batch acc 0.7174
13:18:53.126   Training iter 350, batch loss 0.1937, batch acc 0.7184
13:18:53.627   Training iter 400, batch loss 0.1940, batch acc 0.7174
13:18:54.126   Training iter 450, batch loss 0.1990, batch acc 0.7112
13:18:54.627   Training iter 500, batch loss 0.1865, batch acc 0.7300
13:18:55.133   Training iter 550, batch loss 0.1892, batch acc 0.7230
13:18:55.639   Training iter 600, batch loss 0.1934, batch acc 0.7172
13:18:55.641 Testing @ 200 epoch...
13:18:55.677     Testing, total mean loss 0.19231, total acc 0.71520
13:18:55.677 Plot @ 200 epoch...
13:18:55.677 Training @ 201 epoch...
13:18:56.194   Training iter 50, batch loss 0.1910, batch acc 0.7224
13:18:56.713   Training iter 100, batch loss 0.1959, batch acc 0.7138
13:18:57.223   Training iter 150, batch loss 0.1912, batch acc 0.7226
13:18:57.754   Training iter 200, batch loss 0.1908, batch acc 0.7256
13:18:58.301   Training iter 250, batch loss 0.1951, batch acc 0.7140
13:18:58.837   Training iter 300, batch loss 0.1941, batch acc 0.7176
13:18:59.370   Training iter 350, batch loss 0.1933, batch acc 0.7186
13:18:59.900   Training iter 400, batch loss 0.1951, batch acc 0.7134
13:19:00.442   Training iter 450, batch loss 0.1890, batch acc 0.7258
13:19:00.972   Training iter 500, batch loss 0.1935, batch acc 0.7162
13:19:01.514   Training iter 550, batch loss 0.1950, batch acc 0.7146
13:19:02.076   Training iter 600, batch loss 0.1918, batch acc 0.7150
13:19:02.078 Training @ 202 epoch...
13:19:02.598   Training iter 50, batch loss 0.1968, batch acc 0.7092
13:19:03.120   Training iter 100, batch loss 0.1947, batch acc 0.7148
13:19:03.611   Training iter 150, batch loss 0.1949, batch acc 0.7174
13:19:04.091   Training iter 200, batch loss 0.1899, batch acc 0.7244
13:19:04.590   Training iter 250, batch loss 0.1878, batch acc 0.7278
13:19:05.087   Training iter 300, batch loss 0.1948, batch acc 0.7114
13:19:05.569   Training iter 350, batch loss 0.1996, batch acc 0.7086
13:19:06.024   Training iter 400, batch loss 0.1928, batch acc 0.7206
13:19:06.523   Training iter 450, batch loss 0.1897, batch acc 0.7248
13:19:07.037   Training iter 500, batch loss 0.1946, batch acc 0.7136
13:19:07.592   Training iter 550, batch loss 0.1907, batch acc 0.7186
13:19:08.120   Training iter 600, batch loss 0.1893, batch acc 0.7284
13:19:08.122 Training @ 203 epoch...
13:19:08.654   Training iter 50, batch loss 0.1925, batch acc 0.7188
13:19:09.181   Training iter 100, batch loss 0.1905, batch acc 0.7234
13:19:09.704   Training iter 150, batch loss 0.1912, batch acc 0.7206
13:19:10.235   Training iter 200, batch loss 0.1959, batch acc 0.7150
13:19:10.758   Training iter 250, batch loss 0.1943, batch acc 0.7168
13:19:11.290   Training iter 300, batch loss 0.1933, batch acc 0.7162
13:19:11.827   Training iter 350, batch loss 0.1911, batch acc 0.7212
13:19:12.345   Training iter 400, batch loss 0.1968, batch acc 0.7128
13:19:12.865   Training iter 450, batch loss 0.1920, batch acc 0.7166
13:19:13.401   Training iter 500, batch loss 0.1902, batch acc 0.7198
13:19:13.957   Training iter 550, batch loss 0.1928, batch acc 0.7190
13:19:14.499   Training iter 600, batch loss 0.1943, batch acc 0.7202
13:19:14.501 Training @ 204 epoch...
13:19:15.039   Training iter 50, batch loss 0.1900, batch acc 0.7256
13:19:15.561   Training iter 100, batch loss 0.1964, batch acc 0.7106
13:19:16.075   Training iter 150, batch loss 0.1936, batch acc 0.7144
13:19:16.577   Training iter 200, batch loss 0.1954, batch acc 0.7136
13:19:17.077   Training iter 250, batch loss 0.1931, batch acc 0.7196
13:19:17.576   Training iter 300, batch loss 0.1944, batch acc 0.7168
13:19:18.090   Training iter 350, batch loss 0.1918, batch acc 0.7176
13:19:18.629   Training iter 400, batch loss 0.1925, batch acc 0.7232
13:19:19.142   Training iter 450, batch loss 0.1908, batch acc 0.7206
13:19:19.629   Training iter 500, batch loss 0.1888, batch acc 0.7278
13:19:20.107   Training iter 550, batch loss 0.1945, batch acc 0.7134
13:19:20.598   Training iter 600, batch loss 0.1934, batch acc 0.7174
13:19:20.600 Training @ 205 epoch...
13:19:21.094   Training iter 50, batch loss 0.1906, batch acc 0.7224
13:19:21.582   Training iter 100, batch loss 0.1914, batch acc 0.7176
13:19:22.053   Training iter 150, batch loss 0.1964, batch acc 0.7064
13:19:22.519   Training iter 200, batch loss 0.1971, batch acc 0.7072
13:19:22.991   Training iter 250, batch loss 0.1901, batch acc 0.7204
13:19:23.473   Training iter 300, batch loss 0.1936, batch acc 0.7194
13:19:23.947   Training iter 350, batch loss 0.1921, batch acc 0.7254
13:19:24.427   Training iter 400, batch loss 0.1965, batch acc 0.7154
13:19:24.900   Training iter 450, batch loss 0.1879, batch acc 0.7288
13:19:25.388   Training iter 500, batch loss 0.1902, batch acc 0.7256
13:19:25.870   Training iter 550, batch loss 0.1939, batch acc 0.7192
13:19:26.359   Training iter 600, batch loss 0.1944, batch acc 0.7134
13:19:26.361 Testing @ 205 epoch...
13:19:26.398     Testing, total mean loss 0.19217, total acc 0.71550
13:19:26.398 Training @ 206 epoch...
13:19:26.891   Training iter 50, batch loss 0.1959, batch acc 0.7122
13:19:27.389   Training iter 100, batch loss 0.1903, batch acc 0.7192
13:19:27.892   Training iter 150, batch loss 0.1953, batch acc 0.7154
13:19:28.387   Training iter 200, batch loss 0.1953, batch acc 0.7146
13:19:28.914   Training iter 250, batch loss 0.1960, batch acc 0.7144
13:19:29.453   Training iter 300, batch loss 0.1949, batch acc 0.7124
13:19:29.989   Training iter 350, batch loss 0.1887, batch acc 0.7260
13:19:30.501   Training iter 400, batch loss 0.1933, batch acc 0.7182
13:19:31.003   Training iter 450, batch loss 0.1942, batch acc 0.7172
13:19:31.504   Training iter 500, batch loss 0.1948, batch acc 0.7144
13:19:32.004   Training iter 550, batch loss 0.1858, batch acc 0.7292
13:19:32.512   Training iter 600, batch loss 0.1895, batch acc 0.7260
13:19:32.514 Training @ 207 epoch...
13:19:33.033   Training iter 50, batch loss 0.1929, batch acc 0.7176
13:19:33.557   Training iter 100, batch loss 0.1913, batch acc 0.7204
13:19:34.062   Training iter 150, batch loss 0.1938, batch acc 0.7178
13:19:34.573   Training iter 200, batch loss 0.1918, batch acc 0.7222
13:19:35.082   Training iter 250, batch loss 0.1894, batch acc 0.7212
13:19:35.552   Training iter 300, batch loss 0.1913, batch acc 0.7214
13:19:36.017   Training iter 350, batch loss 0.1944, batch acc 0.7136
13:19:36.476   Training iter 400, batch loss 0.1931, batch acc 0.7180
13:19:36.935   Training iter 450, batch loss 0.1957, batch acc 0.7148
13:19:37.381   Training iter 500, batch loss 0.1915, batch acc 0.7182
13:19:37.828   Training iter 550, batch loss 0.1965, batch acc 0.7128
13:19:38.282   Training iter 600, batch loss 0.1918, batch acc 0.7218
13:19:38.284 Training @ 208 epoch...
13:19:38.762   Training iter 50, batch loss 0.1910, batch acc 0.7190
13:19:39.238   Training iter 100, batch loss 0.1961, batch acc 0.7136
13:19:39.737   Training iter 150, batch loss 0.1967, batch acc 0.7138
13:19:40.247   Training iter 200, batch loss 0.1907, batch acc 0.7242
13:19:40.756   Training iter 250, batch loss 0.1921, batch acc 0.7220
13:19:41.238   Training iter 300, batch loss 0.1914, batch acc 0.7198
13:19:41.736   Training iter 350, batch loss 0.1921, batch acc 0.7178
13:19:42.218   Training iter 400, batch loss 0.1939, batch acc 0.7170
13:19:42.689   Training iter 450, batch loss 0.1935, batch acc 0.7190
13:19:43.169   Training iter 500, batch loss 0.1917, batch acc 0.7176
13:19:43.678   Training iter 550, batch loss 0.1906, batch acc 0.7198
13:19:44.145   Training iter 600, batch loss 0.1934, batch acc 0.7186
13:19:44.147 Training @ 209 epoch...
13:19:44.679   Training iter 50, batch loss 0.1902, batch acc 0.7234
13:19:45.230   Training iter 100, batch loss 0.1935, batch acc 0.7202
13:19:45.791   Training iter 150, batch loss 0.1974, batch acc 0.7122
13:19:46.329   Training iter 200, batch loss 0.1949, batch acc 0.7152
13:19:46.835   Training iter 250, batch loss 0.1952, batch acc 0.7136
13:19:47.349   Training iter 300, batch loss 0.1910, batch acc 0.7194
13:19:47.882   Training iter 350, batch loss 0.1944, batch acc 0.7144
13:19:48.401   Training iter 400, batch loss 0.1884, batch acc 0.7278
13:19:48.928   Training iter 450, batch loss 0.1945, batch acc 0.7152
13:19:49.445   Training iter 500, batch loss 0.1882, batch acc 0.7268
13:19:49.958   Training iter 550, batch loss 0.1931, batch acc 0.7152
13:19:50.480   Training iter 600, batch loss 0.1920, batch acc 0.7200
13:19:50.482 Training @ 210 epoch...
13:19:51.006   Training iter 50, batch loss 0.1920, batch acc 0.7210
13:19:51.539   Training iter 100, batch loss 0.1891, batch acc 0.7258
13:19:52.044   Training iter 150, batch loss 0.1981, batch acc 0.7042
13:19:52.581   Training iter 200, batch loss 0.1900, batch acc 0.7216
13:19:53.111   Training iter 250, batch loss 0.1956, batch acc 0.7104
13:19:53.630   Training iter 300, batch loss 0.1945, batch acc 0.7156
13:19:54.158   Training iter 350, batch loss 0.1876, batch acc 0.7310
13:19:54.693   Training iter 400, batch loss 0.1978, batch acc 0.7084
13:19:55.229   Training iter 450, batch loss 0.1937, batch acc 0.7142
13:19:55.770   Training iter 500, batch loss 0.1939, batch acc 0.7170
13:19:56.303   Training iter 550, batch loss 0.1908, batch acc 0.7270
13:19:56.828   Training iter 600, batch loss 0.1893, batch acc 0.7262
13:19:56.829 Testing @ 210 epoch...
13:19:56.868     Testing, total mean loss 0.19208, total acc 0.71640
13:19:56.869 Training @ 211 epoch...
13:19:57.394   Training iter 50, batch loss 0.1957, batch acc 0.7110
13:19:57.947   Training iter 100, batch loss 0.1970, batch acc 0.7096
13:19:58.477   Training iter 150, batch loss 0.1975, batch acc 0.7124
13:19:58.993   Training iter 200, batch loss 0.1898, batch acc 0.7294
13:19:59.533   Training iter 250, batch loss 0.1961, batch acc 0.7094
13:20:00.037   Training iter 300, batch loss 0.1910, batch acc 0.7222
13:20:00.578   Training iter 350, batch loss 0.1911, batch acc 0.7218
13:20:01.146   Training iter 400, batch loss 0.1925, batch acc 0.7174
13:20:01.781   Training iter 450, batch loss 0.1963, batch acc 0.7156
13:20:02.366   Training iter 500, batch loss 0.1879, batch acc 0.7280
13:20:02.929   Training iter 550, batch loss 0.1906, batch acc 0.7210
13:20:03.478   Training iter 600, batch loss 0.1866, batch acc 0.7282
13:20:03.480 Training @ 212 epoch...
13:20:04.040   Training iter 50, batch loss 0.1900, batch acc 0.7210
13:20:04.593   Training iter 100, batch loss 0.1965, batch acc 0.7142
13:20:05.150   Training iter 150, batch loss 0.1955, batch acc 0.7138
13:20:05.720   Training iter 200, batch loss 0.1918, batch acc 0.7238
13:20:06.276   Training iter 250, batch loss 0.1860, batch acc 0.7306
13:20:06.825   Training iter 300, batch loss 0.1947, batch acc 0.7152
13:20:07.381   Training iter 350, batch loss 0.1918, batch acc 0.7162
13:20:07.894   Training iter 400, batch loss 0.1972, batch acc 0.7074
13:20:08.423   Training iter 450, batch loss 0.1916, batch acc 0.7272
13:20:08.915   Training iter 500, batch loss 0.1909, batch acc 0.7218
13:20:09.396   Training iter 550, batch loss 0.1935, batch acc 0.7112
13:20:09.863   Training iter 600, batch loss 0.1921, batch acc 0.7196
13:20:09.865 Training @ 213 epoch...
13:20:10.355   Training iter 50, batch loss 0.1911, batch acc 0.7210
13:20:10.852   Training iter 100, batch loss 0.1963, batch acc 0.7128
13:20:11.333   Training iter 150, batch loss 0.1923, batch acc 0.7190
13:20:11.811   Training iter 200, batch loss 0.1929, batch acc 0.7222
13:20:12.309   Training iter 250, batch loss 0.1946, batch acc 0.7122
13:20:12.825   Training iter 300, batch loss 0.1910, batch acc 0.7276
13:20:13.337   Training iter 350, batch loss 0.1906, batch acc 0.7196
13:20:13.839   Training iter 400, batch loss 0.1953, batch acc 0.7126
13:20:14.342   Training iter 450, batch loss 0.1910, batch acc 0.7204
13:20:14.843   Training iter 500, batch loss 0.1868, batch acc 0.7290
13:20:15.323   Training iter 550, batch loss 0.1945, batch acc 0.7138
13:20:15.760   Training iter 600, batch loss 0.1950, batch acc 0.7152
13:20:15.761 Training @ 214 epoch...
13:20:16.197   Training iter 50, batch loss 0.1923, batch acc 0.7222
13:20:16.638   Training iter 100, batch loss 0.1936, batch acc 0.7164
13:20:17.097   Training iter 150, batch loss 0.1953, batch acc 0.7132
13:20:17.552   Training iter 200, batch loss 0.1932, batch acc 0.7184
13:20:18.022   Training iter 250, batch loss 0.1938, batch acc 0.7142
13:20:18.518   Training iter 300, batch loss 0.1926, batch acc 0.7176
13:20:19.022   Training iter 350, batch loss 0.1916, batch acc 0.7214
13:20:19.521   Training iter 400, batch loss 0.1922, batch acc 0.7188
13:20:20.014   Training iter 450, batch loss 0.1911, batch acc 0.7202
13:20:20.508   Training iter 500, batch loss 0.1903, batch acc 0.7254
13:20:20.970   Training iter 550, batch loss 0.1936, batch acc 0.7142
13:20:21.435   Training iter 600, batch loss 0.1913, batch acc 0.7228
13:20:21.437 Training @ 215 epoch...
13:20:21.916   Training iter 50, batch loss 0.1967, batch acc 0.7098
13:20:22.399   Training iter 100, batch loss 0.1971, batch acc 0.7080
13:20:22.893   Training iter 150, batch loss 0.1926, batch acc 0.7246
13:20:23.367   Training iter 200, batch loss 0.1963, batch acc 0.7138
13:20:23.847   Training iter 250, batch loss 0.1902, batch acc 0.7244
13:20:24.339   Training iter 300, batch loss 0.1868, batch acc 0.7276
13:20:24.856   Training iter 350, batch loss 0.1883, batch acc 0.7304
13:20:25.382   Training iter 400, batch loss 0.1960, batch acc 0.7122
13:20:25.889   Training iter 450, batch loss 0.1881, batch acc 0.7220
13:20:26.397   Training iter 500, batch loss 0.1928, batch acc 0.7208
13:20:26.931   Training iter 550, batch loss 0.1949, batch acc 0.7120
13:20:27.453   Training iter 600, batch loss 0.1908, batch acc 0.7178
13:20:27.455 Testing @ 215 epoch...
13:20:27.492     Testing, total mean loss 0.19192, total acc 0.71510
13:20:27.492 Training @ 216 epoch...
13:20:28.010   Training iter 50, batch loss 0.1941, batch acc 0.7166
13:20:28.523   Training iter 100, batch loss 0.1921, batch acc 0.7200
13:20:29.055   Training iter 150, batch loss 0.1876, batch acc 0.7256
13:20:29.582   Training iter 200, batch loss 0.1921, batch acc 0.7174
13:20:30.124   Training iter 250, batch loss 0.1940, batch acc 0.7186
13:20:30.632   Training iter 300, batch loss 0.1928, batch acc 0.7178
13:20:31.144   Training iter 350, batch loss 0.1941, batch acc 0.7170
13:20:31.651   Training iter 400, batch loss 0.1944, batch acc 0.7146
13:20:32.170   Training iter 450, batch loss 0.1922, batch acc 0.7180
13:20:32.690   Training iter 500, batch loss 0.1916, batch acc 0.7198
13:20:33.235   Training iter 550, batch loss 0.1920, batch acc 0.7234
13:20:33.778   Training iter 600, batch loss 0.1934, batch acc 0.7160
13:20:33.780 Training @ 217 epoch...
13:20:34.328   Training iter 50, batch loss 0.1922, batch acc 0.7206
13:20:34.886   Training iter 100, batch loss 0.1885, batch acc 0.7272
13:20:35.449   Training iter 150, batch loss 0.1923, batch acc 0.7206
13:20:35.998   Training iter 200, batch loss 0.1917, batch acc 0.7180
13:20:36.541   Training iter 250, batch loss 0.1944, batch acc 0.7136
13:20:37.077   Training iter 300, batch loss 0.1931, batch acc 0.7192
13:20:37.618   Training iter 350, batch loss 0.1939, batch acc 0.7142
13:20:38.168   Training iter 400, batch loss 0.1968, batch acc 0.7154
13:20:38.711   Training iter 450, batch loss 0.1893, batch acc 0.7218
13:20:39.278   Training iter 500, batch loss 0.1949, batch acc 0.7126
13:20:39.823   Training iter 550, batch loss 0.1950, batch acc 0.7168
13:20:40.411   Training iter 600, batch loss 0.1880, batch acc 0.7238
13:20:40.413 Training @ 218 epoch...
13:20:41.106   Training iter 50, batch loss 0.1911, batch acc 0.7212
13:20:41.725   Training iter 100, batch loss 0.1888, batch acc 0.7232
13:20:42.251   Training iter 150, batch loss 0.1928, batch acc 0.7186
13:20:42.725   Training iter 200, batch loss 0.1950, batch acc 0.7128
13:20:43.230   Training iter 250, batch loss 0.1938, batch acc 0.7158
13:20:43.742   Training iter 300, batch loss 0.1917, batch acc 0.7214
13:20:44.242   Training iter 350, batch loss 0.1907, batch acc 0.7216
13:20:44.722   Training iter 400, batch loss 0.2036, batch acc 0.7006
13:20:45.208   Training iter 450, batch loss 0.1880, batch acc 0.7244
13:20:45.710   Training iter 500, batch loss 0.1867, batch acc 0.7298
13:20:46.197   Training iter 550, batch loss 0.1948, batch acc 0.7172
13:20:46.666   Training iter 600, batch loss 0.1928, batch acc 0.7160
13:20:46.668 Training @ 219 epoch...
13:20:47.141   Training iter 50, batch loss 0.1906, batch acc 0.7240
13:20:47.614   Training iter 100, batch loss 0.1908, batch acc 0.7218
13:20:48.106   Training iter 150, batch loss 0.1925, batch acc 0.7162
13:20:48.593   Training iter 200, batch loss 0.1928, batch acc 0.7208
13:20:49.082   Training iter 250, batch loss 0.1930, batch acc 0.7160
13:20:49.593   Training iter 300, batch loss 0.1929, batch acc 0.7184
13:20:50.113   Training iter 350, batch loss 0.1888, batch acc 0.7248
13:20:50.582   Training iter 400, batch loss 0.1940, batch acc 0.7194
13:20:51.064   Training iter 450, batch loss 0.1954, batch acc 0.7110
13:20:51.539   Training iter 500, batch loss 0.1886, batch acc 0.7276
13:20:52.014   Training iter 550, batch loss 0.1922, batch acc 0.7190
13:20:52.488   Training iter 600, batch loss 0.1977, batch acc 0.7076
13:20:52.490 Training @ 220 epoch...
13:20:52.990   Training iter 50, batch loss 0.1925, batch acc 0.7210
13:20:53.482   Training iter 100, batch loss 0.1888, batch acc 0.7302
13:20:53.963   Training iter 150, batch loss 0.1902, batch acc 0.7206
13:20:54.460   Training iter 200, batch loss 0.1915, batch acc 0.7164
13:20:54.950   Training iter 250, batch loss 0.1926, batch acc 0.7204
13:20:55.464   Training iter 300, batch loss 0.1947, batch acc 0.7160
13:20:55.904   Training iter 350, batch loss 0.1935, batch acc 0.7166
13:20:56.362   Training iter 400, batch loss 0.1935, batch acc 0.7176
13:20:56.836   Training iter 450, batch loss 0.1963, batch acc 0.7094
13:20:57.321   Training iter 500, batch loss 0.1889, batch acc 0.7224
13:20:57.796   Training iter 550, batch loss 0.1903, batch acc 0.7260
13:20:58.276   Training iter 600, batch loss 0.1964, batch acc 0.7054
13:20:58.278 Testing @ 220 epoch...
13:20:58.315     Testing, total mean loss 0.19174, total acc 0.71580
13:20:58.315 Training @ 221 epoch...
13:20:58.798   Training iter 50, batch loss 0.1908, batch acc 0.7244
13:20:59.267   Training iter 100, batch loss 0.1886, batch acc 0.7254
13:20:59.726   Training iter 150, batch loss 0.2000, batch acc 0.7056
13:21:00.197   Training iter 200, batch loss 0.1899, batch acc 0.7216
13:21:00.664   Training iter 250, batch loss 0.1911, batch acc 0.7208
13:21:01.122   Training iter 300, batch loss 0.1943, batch acc 0.7174
13:21:01.607   Training iter 350, batch loss 0.1965, batch acc 0.7090
13:21:02.160   Training iter 400, batch loss 0.1938, batch acc 0.7166
13:21:02.678   Training iter 450, batch loss 0.1902, batch acc 0.7232
13:21:03.180   Training iter 500, batch loss 0.1935, batch acc 0.7180
13:21:03.677   Training iter 550, batch loss 0.1901, batch acc 0.7224
13:21:04.179   Training iter 600, batch loss 0.1902, batch acc 0.7220
13:21:04.180 Training @ 222 epoch...
13:21:04.693   Training iter 50, batch loss 0.1904, batch acc 0.7224
13:21:05.192   Training iter 100, batch loss 0.1945, batch acc 0.7166
13:21:05.710   Training iter 150, batch loss 0.1882, batch acc 0.7290
13:21:06.252   Training iter 200, batch loss 0.1928, batch acc 0.7170
13:21:06.765   Training iter 250, batch loss 0.1875, batch acc 0.7268
13:21:07.315   Training iter 300, batch loss 0.1900, batch acc 0.7190
13:21:07.863   Training iter 350, batch loss 0.1935, batch acc 0.7144
13:21:08.395   Training iter 400, batch loss 0.1925, batch acc 0.7210
13:21:08.889   Training iter 450, batch loss 0.1986, batch acc 0.7074
13:21:09.405   Training iter 500, batch loss 0.1918, batch acc 0.7180
13:21:09.924   Training iter 550, batch loss 0.1966, batch acc 0.7128
13:21:10.452   Training iter 600, batch loss 0.1921, batch acc 0.7218
13:21:10.454 Training @ 223 epoch...
13:21:10.999   Training iter 50, batch loss 0.1935, batch acc 0.7146
13:21:11.521   Training iter 100, batch loss 0.1965, batch acc 0.7076
13:21:12.003   Training iter 150, batch loss 0.1917, batch acc 0.7216
13:21:12.484   Training iter 200, batch loss 0.1908, batch acc 0.7230
13:21:12.965   Training iter 250, batch loss 0.1921, batch acc 0.7194
13:21:13.453   Training iter 300, batch loss 0.1963, batch acc 0.7104
13:21:13.921   Training iter 350, batch loss 0.1903, batch acc 0.7222
13:21:14.427   Training iter 400, batch loss 0.1916, batch acc 0.7198
13:21:14.916   Training iter 450, batch loss 0.1915, batch acc 0.7234
13:21:15.431   Training iter 500, batch loss 0.1890, batch acc 0.7260
13:21:15.956   Training iter 550, batch loss 0.1925, batch acc 0.7192
13:21:16.470   Training iter 600, batch loss 0.1923, batch acc 0.7190
13:21:16.472 Training @ 224 epoch...
13:21:16.990   Training iter 50, batch loss 0.1927, batch acc 0.7204
13:21:17.502   Training iter 100, batch loss 0.1960, batch acc 0.7124
13:21:18.002   Training iter 150, batch loss 0.1922, batch acc 0.7158
13:21:18.510   Training iter 200, batch loss 0.1981, batch acc 0.7096
13:21:19.008   Training iter 250, batch loss 0.1893, batch acc 0.7234
13:21:19.497   Training iter 300, batch loss 0.1937, batch acc 0.7166
13:21:19.997   Training iter 350, batch loss 0.1952, batch acc 0.7124
13:21:20.481   Training iter 400, batch loss 0.1843, batch acc 0.7364
13:21:20.948   Training iter 450, batch loss 0.1939, batch acc 0.7128
13:21:21.419   Training iter 500, batch loss 0.1895, batch acc 0.7264
13:21:21.912   Training iter 550, batch loss 0.1897, batch acc 0.7268
13:21:22.426   Training iter 600, batch loss 0.1933, batch acc 0.7132
13:21:22.427 Training @ 225 epoch...
13:21:22.938   Training iter 50, batch loss 0.1988, batch acc 0.7084
13:21:23.442   Training iter 100, batch loss 0.1948, batch acc 0.7168
13:21:23.950   Training iter 150, batch loss 0.1884, batch acc 0.7210
13:21:24.446   Training iter 200, batch loss 0.1937, batch acc 0.7174
13:21:24.941   Training iter 250, batch loss 0.1877, batch acc 0.7270
13:21:25.451   Training iter 300, batch loss 0.1914, batch acc 0.7206
13:21:25.952   Training iter 350, batch loss 0.1897, batch acc 0.7248
13:21:26.465   Training iter 400, batch loss 0.1910, batch acc 0.7224
13:21:26.972   Training iter 450, batch loss 0.1957, batch acc 0.7146
13:21:27.497   Training iter 500, batch loss 0.1920, batch acc 0.7198
13:21:28.017   Training iter 550, batch loss 0.1935, batch acc 0.7168
13:21:28.537   Training iter 600, batch loss 0.1909, batch acc 0.7174
13:21:28.539 Testing @ 225 epoch...
13:21:28.576     Testing, total mean loss 0.19172, total acc 0.71650
13:21:28.576 Training @ 226 epoch...
13:21:29.074   Training iter 50, batch loss 0.1905, batch acc 0.7208
13:21:29.563   Training iter 100, batch loss 0.1909, batch acc 0.7240
13:21:30.050   Training iter 150, batch loss 0.1912, batch acc 0.7276
13:21:30.530   Training iter 200, batch loss 0.1886, batch acc 0.7266
13:21:31.009   Training iter 250, batch loss 0.1967, batch acc 0.7056
13:21:31.484   Training iter 300, batch loss 0.1969, batch acc 0.7110
13:21:31.967   Training iter 350, batch loss 0.1897, batch acc 0.7230
13:21:32.442   Training iter 400, batch loss 0.1885, batch acc 0.7260
13:21:32.915   Training iter 450, batch loss 0.1955, batch acc 0.7106
13:21:33.462   Training iter 500, batch loss 0.1930, batch acc 0.7154
13:21:34.020   Training iter 550, batch loss 0.1965, batch acc 0.7076
13:21:34.576   Training iter 600, batch loss 0.1894, batch acc 0.7288
13:21:34.578 Training @ 227 epoch...
13:21:35.098   Training iter 50, batch loss 0.1973, batch acc 0.7082
13:21:35.574   Training iter 100, batch loss 0.1988, batch acc 0.7042
13:21:36.057   Training iter 150, batch loss 0.1887, batch acc 0.7266
13:21:36.580   Training iter 200, batch loss 0.1909, batch acc 0.7238
13:21:37.097   Training iter 250, batch loss 0.1940, batch acc 0.7162
13:21:37.615   Training iter 300, batch loss 0.1931, batch acc 0.7218
13:21:38.118   Training iter 350, batch loss 0.1900, batch acc 0.7228
13:21:38.608   Training iter 400, batch loss 0.1932, batch acc 0.7142
13:21:39.097   Training iter 450, batch loss 0.1903, batch acc 0.7208
13:21:39.587   Training iter 500, batch loss 0.1886, batch acc 0.7274
13:21:40.082   Training iter 550, batch loss 0.1894, batch acc 0.7212
13:21:40.579   Training iter 600, batch loss 0.1928, batch acc 0.7186
13:21:40.581 Training @ 228 epoch...
13:21:41.090   Training iter 50, batch loss 0.1945, batch acc 0.7118
13:21:41.602   Training iter 100, batch loss 0.1906, batch acc 0.7208
13:21:42.107   Training iter 150, batch loss 0.1915, batch acc 0.7244
13:21:42.622   Training iter 200, batch loss 0.1918, batch acc 0.7162
13:21:43.124   Training iter 250, batch loss 0.1969, batch acc 0.7136
13:21:43.637   Training iter 300, batch loss 0.1888, batch acc 0.7242
13:21:44.137   Training iter 350, batch loss 0.1919, batch acc 0.7206
13:21:44.638   Training iter 400, batch loss 0.1923, batch acc 0.7196
13:21:45.135   Training iter 450, batch loss 0.1929, batch acc 0.7136
13:21:45.639   Training iter 500, batch loss 0.1924, batch acc 0.7214
13:21:46.157   Training iter 550, batch loss 0.1884, batch acc 0.7256
13:21:46.658   Training iter 600, batch loss 0.1948, batch acc 0.7142
13:21:46.659 Training @ 229 epoch...
13:21:47.155   Training iter 50, batch loss 0.1893, batch acc 0.7238
13:21:47.647   Training iter 100, batch loss 0.1914, batch acc 0.7184
13:21:48.139   Training iter 150, batch loss 0.1957, batch acc 0.7152
13:21:48.635   Training iter 200, batch loss 0.1872, batch acc 0.7312
13:21:49.139   Training iter 250, batch loss 0.1953, batch acc 0.7114
13:21:49.634   Training iter 300, batch loss 0.1948, batch acc 0.7138
13:21:50.123   Training iter 350, batch loss 0.1889, batch acc 0.7244
13:21:50.625   Training iter 400, batch loss 0.1861, batch acc 0.7298
13:21:51.137   Training iter 450, batch loss 0.1968, batch acc 0.7098
13:21:51.642   Training iter 500, batch loss 0.1960, batch acc 0.7146
13:21:52.144   Training iter 550, batch loss 0.1921, batch acc 0.7178
13:21:52.655   Training iter 600, batch loss 0.1928, batch acc 0.7180
13:21:52.656 Training @ 230 epoch...
13:21:53.177   Training iter 50, batch loss 0.1924, batch acc 0.7168
13:21:53.687   Training iter 100, batch loss 0.1980, batch acc 0.7098
13:21:54.196   Training iter 150, batch loss 0.1922, batch acc 0.7206
13:21:54.707   Training iter 200, batch loss 0.1955, batch acc 0.7116
13:21:55.217   Training iter 250, batch loss 0.1879, batch acc 0.7278
13:21:55.721   Training iter 300, batch loss 0.1899, batch acc 0.7210
13:21:56.222   Training iter 350, batch loss 0.1939, batch acc 0.7168
13:21:56.713   Training iter 400, batch loss 0.1912, batch acc 0.7186
13:21:57.208   Training iter 450, batch loss 0.1923, batch acc 0.7206
13:21:57.707   Training iter 500, batch loss 0.1919, batch acc 0.7204
13:21:58.195   Training iter 550, batch loss 0.1923, batch acc 0.7196
13:21:58.677   Training iter 600, batch loss 0.1885, batch acc 0.7246
13:21:58.679 Testing @ 230 epoch...
13:21:58.716     Testing, total mean loss 0.19156, total acc 0.71600
13:21:58.716 Training @ 231 epoch...
13:21:59.211   Training iter 50, batch loss 0.1893, batch acc 0.7226
13:21:59.720   Training iter 100, batch loss 0.1908, batch acc 0.7194
13:22:00.245   Training iter 150, batch loss 0.1908, batch acc 0.7202
13:22:00.748   Training iter 200, batch loss 0.1889, batch acc 0.7298
13:22:01.269   Training iter 250, batch loss 0.1943, batch acc 0.7150
13:22:01.806   Training iter 300, batch loss 0.1945, batch acc 0.7112
13:22:02.326   Training iter 350, batch loss 0.1942, batch acc 0.7188
13:22:02.856   Training iter 400, batch loss 0.1961, batch acc 0.7108
13:22:03.383   Training iter 450, batch loss 0.1907, batch acc 0.7210
13:22:03.904   Training iter 500, batch loss 0.1888, batch acc 0.7242
13:22:04.435   Training iter 550, batch loss 0.1933, batch acc 0.7196
13:22:04.967   Training iter 600, batch loss 0.1943, batch acc 0.7162
13:22:04.969 Training @ 232 epoch...
13:22:05.466   Training iter 50, batch loss 0.1890, batch acc 0.7216
13:22:05.937   Training iter 100, batch loss 0.1930, batch acc 0.7182
13:22:06.428   Training iter 150, batch loss 0.1931, batch acc 0.7230
13:22:06.927   Training iter 200, batch loss 0.1934, batch acc 0.7170
13:22:07.406   Training iter 250, batch loss 0.1894, batch acc 0.7238
13:22:07.860   Training iter 300, batch loss 0.1952, batch acc 0.7112
13:22:08.323   Training iter 350, batch loss 0.1968, batch acc 0.7108
13:22:08.754   Training iter 400, batch loss 0.1909, batch acc 0.7210
13:22:09.184   Training iter 450, batch loss 0.1899, batch acc 0.7246
13:22:09.622   Training iter 500, batch loss 0.1899, batch acc 0.7216
13:22:10.075   Training iter 550, batch loss 0.1906, batch acc 0.7214
13:22:10.548   Training iter 600, batch loss 0.1943, batch acc 0.7148
13:22:10.550 Training @ 233 epoch...
13:22:11.006   Training iter 50, batch loss 0.1961, batch acc 0.7102
13:22:11.450   Training iter 100, batch loss 0.1977, batch acc 0.7082
13:22:11.892   Training iter 150, batch loss 0.1905, batch acc 0.7214
13:22:12.345   Training iter 200, batch loss 0.1935, batch acc 0.7120
13:22:12.822   Training iter 250, batch loss 0.1889, batch acc 0.7236
13:22:13.298   Training iter 300, batch loss 0.1918, batch acc 0.7246
13:22:13.742   Training iter 350, batch loss 0.1906, batch acc 0.7224
13:22:14.208   Training iter 400, batch loss 0.1945, batch acc 0.7126
13:22:14.685   Training iter 450, batch loss 0.1919, batch acc 0.7188
13:22:15.173   Training iter 500, batch loss 0.1905, batch acc 0.7242
13:22:15.666   Training iter 550, batch loss 0.1888, batch acc 0.7250
13:22:16.155   Training iter 600, batch loss 0.1904, batch acc 0.7226
13:22:16.157 Training @ 234 epoch...
13:22:16.646   Training iter 50, batch loss 0.1933, batch acc 0.7174
13:22:17.123   Training iter 100, batch loss 0.1919, batch acc 0.7150
13:22:17.605   Training iter 150, batch loss 0.1922, batch acc 0.7210
13:22:18.082   Training iter 200, batch loss 0.1883, batch acc 0.7268
13:22:18.554   Training iter 250, batch loss 0.1896, batch acc 0.7290
13:22:19.025   Training iter 300, batch loss 0.1950, batch acc 0.7132
13:22:19.489   Training iter 350, batch loss 0.1932, batch acc 0.7144
13:22:19.983   Training iter 400, batch loss 0.1929, batch acc 0.7180
13:22:20.435   Training iter 450, batch loss 0.1921, batch acc 0.7186
13:22:20.876   Training iter 500, batch loss 0.1963, batch acc 0.7128
13:22:21.323   Training iter 550, batch loss 0.1907, batch acc 0.7174
13:22:21.755   Training iter 600, batch loss 0.1896, batch acc 0.7248
13:22:21.756 Training @ 235 epoch...
13:22:22.192   Training iter 50, batch loss 0.1889, batch acc 0.7204
13:22:22.641   Training iter 100, batch loss 0.1855, batch acc 0.7322
13:22:23.096   Training iter 150, batch loss 0.1924, batch acc 0.7154
13:22:23.540   Training iter 200, batch loss 0.1943, batch acc 0.7164
13:22:23.996   Training iter 250, batch loss 0.1914, batch acc 0.7198
13:22:24.444   Training iter 300, batch loss 0.1865, batch acc 0.7358
13:22:24.892   Training iter 350, batch loss 0.1988, batch acc 0.7052
13:22:25.350   Training iter 400, batch loss 0.1934, batch acc 0.7170
13:22:25.855   Training iter 450, batch loss 0.1912, batch acc 0.7172
13:22:26.359   Training iter 500, batch loss 0.1973, batch acc 0.7100
13:22:26.872   Training iter 550, batch loss 0.1932, batch acc 0.7176
13:22:27.416   Training iter 600, batch loss 0.1919, batch acc 0.7208
13:22:27.417 Testing @ 235 epoch...
13:22:27.454     Testing, total mean loss 0.19138, total acc 0.71560
13:22:27.454 Training @ 236 epoch...
13:22:28.005   Training iter 50, batch loss 0.1858, batch acc 0.7354
13:22:28.538   Training iter 100, batch loss 0.1921, batch acc 0.7160
13:22:29.072   Training iter 150, batch loss 0.1909, batch acc 0.7226
13:22:29.602   Training iter 200, batch loss 0.1954, batch acc 0.7122
13:22:30.139   Training iter 250, batch loss 0.1906, batch acc 0.7252
13:22:30.680   Training iter 300, batch loss 0.1898, batch acc 0.7210
13:22:31.205   Training iter 350, batch loss 0.1904, batch acc 0.7224
13:22:31.717   Training iter 400, batch loss 0.1958, batch acc 0.7082
13:22:32.224   Training iter 450, batch loss 0.1896, batch acc 0.7254
13:22:32.746   Training iter 500, batch loss 0.1943, batch acc 0.7148
13:22:33.257   Training iter 550, batch loss 0.1936, batch acc 0.7148
13:22:33.760   Training iter 600, batch loss 0.1962, batch acc 0.7088
13:22:33.761 Training @ 237 epoch...
13:22:34.276   Training iter 50, batch loss 0.1879, batch acc 0.7284
13:22:34.796   Training iter 100, batch loss 0.1899, batch acc 0.7244
13:22:35.308   Training iter 150, batch loss 0.1926, batch acc 0.7174
13:22:35.798   Training iter 200, batch loss 0.1935, batch acc 0.7186
13:22:36.302   Training iter 250, batch loss 0.1925, batch acc 0.7162
13:22:36.793   Training iter 300, batch loss 0.1943, batch acc 0.7138
13:22:37.289   Training iter 350, batch loss 0.1986, batch acc 0.7068
13:22:37.790   Training iter 400, batch loss 0.1924, batch acc 0.7184
13:22:38.301   Training iter 450, batch loss 0.1945, batch acc 0.7134
13:22:38.806   Training iter 500, batch loss 0.1914, batch acc 0.7234
13:22:39.298   Training iter 550, batch loss 0.1903, batch acc 0.7212
13:22:39.742   Training iter 600, batch loss 0.1862, batch acc 0.7278
13:22:39.744 Training @ 238 epoch...
13:22:40.221   Training iter 50, batch loss 0.1960, batch acc 0.7092
13:22:40.702   Training iter 100, batch loss 0.1933, batch acc 0.7174
13:22:41.165   Training iter 150, batch loss 0.1917, batch acc 0.7198
13:22:41.660   Training iter 200, batch loss 0.1907, batch acc 0.7232
13:22:42.149   Training iter 250, batch loss 0.1938, batch acc 0.7148
13:22:42.642   Training iter 300, batch loss 0.1892, batch acc 0.7246
13:22:43.154   Training iter 350, batch loss 0.1865, batch acc 0.7270
13:22:43.670   Training iter 400, batch loss 0.1897, batch acc 0.7220
13:22:44.175   Training iter 450, batch loss 0.1915, batch acc 0.7178
13:22:44.674   Training iter 500, batch loss 0.1933, batch acc 0.7192
13:22:45.184   Training iter 550, batch loss 0.1954, batch acc 0.7142
13:22:45.669   Training iter 600, batch loss 0.1928, batch acc 0.7218
13:22:45.670 Training @ 239 epoch...
13:22:46.137   Training iter 50, batch loss 0.1911, batch acc 0.7204
13:22:46.588   Training iter 100, batch loss 0.1965, batch acc 0.7102
13:22:47.045   Training iter 150, batch loss 0.1924, batch acc 0.7132
13:22:47.503   Training iter 200, batch loss 0.1942, batch acc 0.7130
13:22:47.965   Training iter 250, batch loss 0.1896, batch acc 0.7220
13:22:48.430   Training iter 300, batch loss 0.1908, batch acc 0.7198
13:22:48.882   Training iter 350, batch loss 0.1937, batch acc 0.7178
13:22:49.337   Training iter 400, batch loss 0.1907, batch acc 0.7228
13:22:49.794   Training iter 450, batch loss 0.1854, batch acc 0.7334
13:22:50.258   Training iter 500, batch loss 0.1909, batch acc 0.7232
13:22:50.715   Training iter 550, batch loss 0.1956, batch acc 0.7118
13:22:51.171   Training iter 600, batch loss 0.1927, batch acc 0.7226
13:22:51.173 Training @ 240 epoch...
13:22:51.638   Training iter 50, batch loss 0.1917, batch acc 0.7142
13:22:52.093   Training iter 100, batch loss 0.1961, batch acc 0.7140
13:22:52.567   Training iter 150, batch loss 0.1899, batch acc 0.7234
13:22:53.040   Training iter 200, batch loss 0.1906, batch acc 0.7184
13:22:53.514   Training iter 250, batch loss 0.1902, batch acc 0.7228
13:22:53.966   Training iter 300, batch loss 0.1893, batch acc 0.7248
13:22:54.409   Training iter 350, batch loss 0.1893, batch acc 0.7288
13:22:54.859   Training iter 400, batch loss 0.1890, batch acc 0.7300
13:22:55.316   Training iter 450, batch loss 0.1919, batch acc 0.7200
13:22:55.762   Training iter 500, batch loss 0.1967, batch acc 0.7066
13:22:56.218   Training iter 550, batch loss 0.1942, batch acc 0.7140
13:22:56.695   Training iter 600, batch loss 0.1944, batch acc 0.7132
13:22:56.697 Testing @ 240 epoch...
13:22:56.734     Testing, total mean loss 0.19132, total acc 0.71610
13:22:56.734 Training @ 241 epoch...
13:22:57.213   Training iter 50, batch loss 0.1897, batch acc 0.7216
13:22:57.683   Training iter 100, batch loss 0.1897, batch acc 0.7236
13:22:58.136   Training iter 150, batch loss 0.1917, batch acc 0.7168
13:22:58.609   Training iter 200, batch loss 0.1939, batch acc 0.7146
13:22:59.069   Training iter 250, batch loss 0.1911, batch acc 0.7230
13:22:59.525   Training iter 300, batch loss 0.1914, batch acc 0.7216
13:22:59.984   Training iter 350, batch loss 0.1925, batch acc 0.7138
13:23:00.435   Training iter 400, batch loss 0.1900, batch acc 0.7252
13:23:00.896   Training iter 450, batch loss 0.1917, batch acc 0.7212
13:23:01.367   Training iter 500, batch loss 0.1953, batch acc 0.7142
13:23:01.884   Training iter 550, batch loss 0.1933, batch acc 0.7188
13:23:02.394   Training iter 600, batch loss 0.1928, batch acc 0.7158
13:23:02.396 Training @ 242 epoch...
13:23:02.922   Training iter 50, batch loss 0.1963, batch acc 0.7134
13:23:03.437   Training iter 100, batch loss 0.1922, batch acc 0.7216
13:23:03.938   Training iter 150, batch loss 0.1901, batch acc 0.7196
13:23:04.447   Training iter 200, batch loss 0.1952, batch acc 0.7102
13:23:05.012   Training iter 250, batch loss 0.1898, batch acc 0.7240
13:23:05.573   Training iter 300, batch loss 0.1944, batch acc 0.7140
13:23:06.140   Training iter 350, batch loss 0.1915, batch acc 0.7172
13:23:06.665   Training iter 400, batch loss 0.1851, batch acc 0.7338
13:23:07.196   Training iter 450, batch loss 0.1842, batch acc 0.7342
13:23:07.713   Training iter 500, batch loss 0.1938, batch acc 0.7144
13:23:08.210   Training iter 550, batch loss 0.1962, batch acc 0.7110
13:23:08.701   Training iter 600, batch loss 0.1940, batch acc 0.7162
13:23:08.703 Training @ 243 epoch...
13:23:09.205   Training iter 50, batch loss 0.1935, batch acc 0.7150
13:23:09.699   Training iter 100, batch loss 0.1876, batch acc 0.7278
13:23:10.195   Training iter 150, batch loss 0.1922, batch acc 0.7182
13:23:10.679   Training iter 200, batch loss 0.1951, batch acc 0.7110
13:23:11.164   Training iter 250, batch loss 0.1923, batch acc 0.7186
13:23:11.648   Training iter 300, batch loss 0.1948, batch acc 0.7168
13:23:12.131   Training iter 350, batch loss 0.1873, batch acc 0.7290
13:23:12.614   Training iter 400, batch loss 0.1946, batch acc 0.7146
13:23:13.102   Training iter 450, batch loss 0.1916, batch acc 0.7176
13:23:13.573   Training iter 500, batch loss 0.1929, batch acc 0.7200
13:23:14.033   Training iter 550, batch loss 0.1901, batch acc 0.7202
13:23:14.491   Training iter 600, batch loss 0.1907, batch acc 0.7190
13:23:14.493 Training @ 244 epoch...
13:23:14.987   Training iter 50, batch loss 0.1927, batch acc 0.7116
13:23:15.489   Training iter 100, batch loss 0.1950, batch acc 0.7174
13:23:15.992   Training iter 150, batch loss 0.1924, batch acc 0.7228
13:23:16.499   Training iter 200, batch loss 0.1885, batch acc 0.7298
13:23:16.994   Training iter 250, batch loss 0.1899, batch acc 0.7288
13:23:17.491   Training iter 300, batch loss 0.1925, batch acc 0.7166
13:23:17.990   Training iter 350, batch loss 0.1870, batch acc 0.7262
13:23:18.510   Training iter 400, batch loss 0.1916, batch acc 0.7172
13:23:19.030   Training iter 450, batch loss 0.1893, batch acc 0.7256
13:23:19.525   Training iter 500, batch loss 0.1944, batch acc 0.7120
13:23:20.027   Training iter 550, batch loss 0.1908, batch acc 0.7200
13:23:20.520   Training iter 600, batch loss 0.1981, batch acc 0.7042
13:23:20.521 Training @ 245 epoch...
13:23:21.015   Training iter 50, batch loss 0.1970, batch acc 0.7108
13:23:21.499   Training iter 100, batch loss 0.1965, batch acc 0.7106
13:23:21.986   Training iter 150, batch loss 0.1930, batch acc 0.7108
13:23:22.482   Training iter 200, batch loss 0.1897, batch acc 0.7238
13:23:22.978   Training iter 250, batch loss 0.1932, batch acc 0.7152
13:23:23.489   Training iter 300, batch loss 0.1945, batch acc 0.7100
13:23:23.983   Training iter 350, batch loss 0.1902, batch acc 0.7236
13:23:24.490   Training iter 400, batch loss 0.1909, batch acc 0.7228
13:23:24.995   Training iter 450, batch loss 0.1932, batch acc 0.7204
13:23:25.518   Training iter 500, batch loss 0.1885, batch acc 0.7280
13:23:26.047   Training iter 550, batch loss 0.1872, batch acc 0.7280
13:23:26.544   Training iter 600, batch loss 0.1883, batch acc 0.7254
13:23:26.545 Testing @ 245 epoch...
13:23:26.582     Testing, total mean loss 0.19117, total acc 0.71540
13:23:26.582 Training @ 246 epoch...
13:23:27.097   Training iter 50, batch loss 0.1958, batch acc 0.7094
13:23:27.600   Training iter 100, batch loss 0.1900, batch acc 0.7232
13:23:28.101   Training iter 150, batch loss 0.1946, batch acc 0.7098
13:23:28.593   Training iter 200, batch loss 0.1941, batch acc 0.7158
13:23:29.092   Training iter 250, batch loss 0.1964, batch acc 0.7106
13:23:29.591   Training iter 300, batch loss 0.1927, batch acc 0.7184
13:23:30.104   Training iter 350, batch loss 0.1926, batch acc 0.7186
13:23:30.621   Training iter 400, batch loss 0.1869, batch acc 0.7310
13:23:31.138   Training iter 450, batch loss 0.1867, batch acc 0.7278
13:23:31.652   Training iter 500, batch loss 0.1925, batch acc 0.7172
13:23:32.157   Training iter 550, batch loss 0.1914, batch acc 0.7224
13:23:32.673   Training iter 600, batch loss 0.1882, batch acc 0.7266
13:23:32.675 Training @ 247 epoch...
13:23:33.203   Training iter 50, batch loss 0.1937, batch acc 0.7148
13:23:33.702   Training iter 100, batch loss 0.1905, batch acc 0.7202
13:23:34.199   Training iter 150, batch loss 0.1961, batch acc 0.7140
13:23:34.690   Training iter 200, batch loss 0.1929, batch acc 0.7174
13:23:35.195   Training iter 250, batch loss 0.1911, batch acc 0.7240
13:23:35.707   Training iter 300, batch loss 0.1918, batch acc 0.7196
13:23:36.214   Training iter 350, batch loss 0.1942, batch acc 0.7130
13:23:36.712   Training iter 400, batch loss 0.1934, batch acc 0.7142
13:23:37.204   Training iter 450, batch loss 0.1876, batch acc 0.7258
13:23:37.700   Training iter 500, batch loss 0.1910, batch acc 0.7232
13:23:38.201   Training iter 550, batch loss 0.1880, batch acc 0.7254
13:23:38.704   Training iter 600, batch loss 0.1913, batch acc 0.7206
13:23:38.706 Training @ 248 epoch...
13:23:39.206   Training iter 50, batch loss 0.1895, batch acc 0.7226
13:23:39.674   Training iter 100, batch loss 0.1905, batch acc 0.7170
13:23:40.164   Training iter 150, batch loss 0.1950, batch acc 0.7130
13:23:40.655   Training iter 200, batch loss 0.1869, batch acc 0.7294
13:23:41.128   Training iter 250, batch loss 0.1957, batch acc 0.7114
13:23:41.601   Training iter 300, batch loss 0.1906, batch acc 0.7220
13:23:42.090   Training iter 350, batch loss 0.1939, batch acc 0.7186
13:23:42.581   Training iter 400, batch loss 0.1893, batch acc 0.7268
13:23:43.074   Training iter 450, batch loss 0.1933, batch acc 0.7144
13:23:43.560   Training iter 500, batch loss 0.1920, batch acc 0.7198
13:23:44.043   Training iter 550, batch loss 0.1960, batch acc 0.7092
13:23:44.530   Training iter 600, batch loss 0.1885, batch acc 0.7288
13:23:44.531 Training @ 249 epoch...
13:23:45.003   Training iter 50, batch loss 0.1941, batch acc 0.7128
13:23:45.479   Training iter 100, batch loss 0.1855, batch acc 0.7270
13:23:45.959   Training iter 150, batch loss 0.1926, batch acc 0.7162
13:23:46.444   Training iter 200, batch loss 0.1895, batch acc 0.7246
13:23:46.927   Training iter 250, batch loss 0.1902, batch acc 0.7250
13:23:47.402   Training iter 300, batch loss 0.1886, batch acc 0.7218
13:23:47.879   Training iter 350, batch loss 0.1959, batch acc 0.7154
13:23:48.367   Training iter 400, batch loss 0.1919, batch acc 0.7172
13:23:48.852   Training iter 450, batch loss 0.1910, batch acc 0.7242
13:23:49.339   Training iter 500, batch loss 0.1934, batch acc 0.7160
13:23:49.823   Training iter 550, batch loss 0.1953, batch acc 0.7138
13:23:50.309   Training iter 600, batch loss 0.1930, batch acc 0.7168
13:23:50.310 Training @ 250 epoch...
13:23:50.798   Training iter 50, batch loss 0.1921, batch acc 0.7184
13:23:51.310   Training iter 100, batch loss 0.1937, batch acc 0.7140
13:23:51.810   Training iter 150, batch loss 0.1904, batch acc 0.7172
13:23:52.293   Training iter 200, batch loss 0.1953, batch acc 0.7102
13:23:52.768   Training iter 250, batch loss 0.1902, batch acc 0.7260
13:23:53.232   Training iter 300, batch loss 0.1930, batch acc 0.7164
13:23:53.704   Training iter 350, batch loss 0.1989, batch acc 0.7058
13:23:54.187   Training iter 400, batch loss 0.1876, batch acc 0.7262
13:23:54.666   Training iter 450, batch loss 0.1915, batch acc 0.7186
13:23:55.159   Training iter 500, batch loss 0.1930, batch acc 0.7194
13:23:55.642   Training iter 550, batch loss 0.1865, batch acc 0.7340
13:23:56.130   Training iter 600, batch loss 0.1886, batch acc 0.7266
13:23:56.132 Testing @ 250 epoch...
13:23:56.169     Testing, total mean loss 0.19111, total acc 0.71620
13:23:56.169 Training @ 251 epoch...
13:23:56.657   Training iter 50, batch loss 0.1951, batch acc 0.7150
13:23:57.148   Training iter 100, batch loss 0.1879, batch acc 0.7246
13:23:57.646   Training iter 150, batch loss 0.1967, batch acc 0.7120
13:23:58.144   Training iter 200, batch loss 0.1875, batch acc 0.7268
13:23:58.643   Training iter 250, batch loss 0.1885, batch acc 0.7212
13:23:59.170   Training iter 300, batch loss 0.1922, batch acc 0.7154
13:23:59.737   Training iter 350, batch loss 0.1906, batch acc 0.7230
13:24:00.313   Training iter 400, batch loss 0.1946, batch acc 0.7166
13:24:00.874   Training iter 450, batch loss 0.1926, batch acc 0.7190
13:24:01.388   Training iter 500, batch loss 0.1916, batch acc 0.7210
13:24:01.935   Training iter 550, batch loss 0.1929, batch acc 0.7194
13:24:02.519   Training iter 600, batch loss 0.1904, batch acc 0.7188
13:24:02.520 Training @ 252 epoch...
13:24:03.093   Training iter 50, batch loss 0.1895, batch acc 0.7236
13:24:03.657   Training iter 100, batch loss 0.1952, batch acc 0.7134
13:24:04.227   Training iter 150, batch loss 0.1951, batch acc 0.7136
13:24:04.768   Training iter 200, batch loss 0.1891, batch acc 0.7246
13:24:05.290   Training iter 250, batch loss 0.1893, batch acc 0.7232
13:24:05.816   Training iter 300, batch loss 0.1899, batch acc 0.7196
13:24:06.359   Training iter 350, batch loss 0.1901, batch acc 0.7214
13:24:06.903   Training iter 400, batch loss 0.1908, batch acc 0.7198
13:24:07.434   Training iter 450, batch loss 0.1926, batch acc 0.7214
13:24:07.956   Training iter 500, batch loss 0.1928, batch acc 0.7182
13:24:08.468   Training iter 550, batch loss 0.1925, batch acc 0.7168
13:24:08.979   Training iter 600, batch loss 0.1936, batch acc 0.7186
13:24:08.981 Training @ 253 epoch...
13:24:09.477   Training iter 50, batch loss 0.1862, batch acc 0.7332
13:24:09.979   Training iter 100, batch loss 0.1919, batch acc 0.7164
13:24:10.528   Training iter 150, batch loss 0.1906, batch acc 0.7262
13:24:11.052   Training iter 200, batch loss 0.1961, batch acc 0.7100
13:24:11.540   Training iter 250, batch loss 0.1943, batch acc 0.7162
13:24:12.024   Training iter 300, batch loss 0.1858, batch acc 0.7288
13:24:12.512   Training iter 350, batch loss 0.1936, batch acc 0.7174
13:24:13.015   Training iter 400, batch loss 0.1919, batch acc 0.7192
13:24:13.513   Training iter 450, batch loss 0.1953, batch acc 0.7128
13:24:14.007   Training iter 500, batch loss 0.1937, batch acc 0.7104
13:24:14.493   Training iter 550, batch loss 0.1896, batch acc 0.7222
13:24:14.981   Training iter 600, batch loss 0.1909, batch acc 0.7216
13:24:14.983 Training @ 254 epoch...
13:24:15.487   Training iter 50, batch loss 0.1937, batch acc 0.7140
13:24:15.971   Training iter 100, batch loss 0.1930, batch acc 0.7186
13:24:16.467   Training iter 150, batch loss 0.1948, batch acc 0.7120
13:24:16.977   Training iter 200, batch loss 0.1936, batch acc 0.7144
13:24:17.488   Training iter 250, batch loss 0.1861, batch acc 0.7314
13:24:18.006   Training iter 300, batch loss 0.1922, batch acc 0.7178
13:24:18.541   Training iter 350, batch loss 0.1910, batch acc 0.7204
13:24:19.068   Training iter 400, batch loss 0.1930, batch acc 0.7212
13:24:19.619   Training iter 450, batch loss 0.1878, batch acc 0.7276
13:24:20.161   Training iter 500, batch loss 0.1900, batch acc 0.7208
13:24:20.713   Training iter 550, batch loss 0.1927, batch acc 0.7168
13:24:21.253   Training iter 600, batch loss 0.1917, batch acc 0.7190
13:24:21.255 Training @ 255 epoch...
13:24:21.796   Training iter 50, batch loss 0.1914, batch acc 0.7180
13:24:22.334   Training iter 100, batch loss 0.1874, batch acc 0.7298
13:24:22.848   Training iter 150, batch loss 0.1928, batch acc 0.7182
13:24:23.348   Training iter 200, batch loss 0.1935, batch acc 0.7146
13:24:23.842   Training iter 250, batch loss 0.1945, batch acc 0.7120
13:24:24.366   Training iter 300, batch loss 0.1913, batch acc 0.7208
13:24:24.867   Training iter 350, batch loss 0.1881, batch acc 0.7288
13:24:25.370   Training iter 400, batch loss 0.1898, batch acc 0.7216
13:24:25.872   Training iter 450, batch loss 0.1930, batch acc 0.7188
13:24:26.366   Training iter 500, batch loss 0.1868, batch acc 0.7272
13:24:26.867   Training iter 550, batch loss 0.1958, batch acc 0.7120
13:24:27.371   Training iter 600, batch loss 0.1951, batch acc 0.7102
13:24:27.372 Testing @ 255 epoch...
13:24:27.409     Testing, total mean loss 0.19096, total acc 0.71710
13:24:27.410 Training @ 256 epoch...
13:24:27.933   Training iter 50, batch loss 0.1960, batch acc 0.7116
13:24:28.454   Training iter 100, batch loss 0.1869, batch acc 0.7286
13:24:28.985   Training iter 150, batch loss 0.1915, batch acc 0.7220
13:24:29.505   Training iter 200, batch loss 0.1931, batch acc 0.7162
13:24:30.016   Training iter 250, batch loss 0.1920, batch acc 0.7186
13:24:30.510   Training iter 300, batch loss 0.1869, batch acc 0.7298
13:24:30.997   Training iter 350, batch loss 0.1911, batch acc 0.7240
13:24:31.487   Training iter 400, batch loss 0.1875, batch acc 0.7252
13:24:31.970   Training iter 450, batch loss 0.1932, batch acc 0.7174
13:24:32.465   Training iter 500, batch loss 0.1923, batch acc 0.7176
13:24:32.949   Training iter 550, batch loss 0.1938, batch acc 0.7146
13:24:33.442   Training iter 600, batch loss 0.1950, batch acc 0.7104
13:24:33.444 Training @ 257 epoch...
13:24:33.934   Training iter 50, batch loss 0.1917, batch acc 0.7150
13:24:34.412   Training iter 100, batch loss 0.1943, batch acc 0.7146
13:24:34.908   Training iter 150, batch loss 0.1945, batch acc 0.7132
13:24:35.435   Training iter 200, batch loss 0.1883, batch acc 0.7258
13:24:35.949   Training iter 250, batch loss 0.1945, batch acc 0.7146
13:24:36.461   Training iter 300, batch loss 0.1914, batch acc 0.7228
13:24:36.975   Training iter 350, batch loss 0.1917, batch acc 0.7200
13:24:37.486   Training iter 400, batch loss 0.1887, batch acc 0.7264
13:24:38.003   Training iter 450, batch loss 0.1902, batch acc 0.7246
13:24:38.518   Training iter 500, batch loss 0.1874, batch acc 0.7278
13:24:39.022   Training iter 550, batch loss 0.1894, batch acc 0.7206
13:24:39.506   Training iter 600, batch loss 0.1970, batch acc 0.7084
13:24:39.508 Training @ 258 epoch...
13:24:39.961   Training iter 50, batch loss 0.1927, batch acc 0.7160
13:24:40.423   Training iter 100, batch loss 0.1881, batch acc 0.7256
13:24:40.883   Training iter 150, batch loss 0.1927, batch acc 0.7156
13:24:41.335   Training iter 200, batch loss 0.1972, batch acc 0.7068
13:24:41.803   Training iter 250, batch loss 0.1900, batch acc 0.7254
13:24:42.265   Training iter 300, batch loss 0.1857, batch acc 0.7318
13:24:42.733   Training iter 350, batch loss 0.1914, batch acc 0.7202
13:24:43.221   Training iter 400, batch loss 0.1934, batch acc 0.7176
13:24:43.723   Training iter 450, batch loss 0.1936, batch acc 0.7162
13:24:44.232   Training iter 500, batch loss 0.1909, batch acc 0.7170
13:24:44.725   Training iter 550, batch loss 0.1889, batch acc 0.7262
13:24:45.224   Training iter 600, batch loss 0.1941, batch acc 0.7142
13:24:45.226 Training @ 259 epoch...
13:24:45.739   Training iter 50, batch loss 0.1943, batch acc 0.7154
13:24:46.256   Training iter 100, batch loss 0.1906, batch acc 0.7248
13:24:46.754   Training iter 150, batch loss 0.1909, batch acc 0.7208
13:24:47.229   Training iter 200, batch loss 0.1925, batch acc 0.7194
13:24:47.719   Training iter 250, batch loss 0.1887, batch acc 0.7264
13:24:48.230   Training iter 300, batch loss 0.1921, batch acc 0.7210
13:24:48.756   Training iter 350, batch loss 0.1922, batch acc 0.7150
13:24:49.281   Training iter 400, batch loss 0.1920, batch acc 0.7144
13:24:49.813   Training iter 450, batch loss 0.1933, batch acc 0.7140
13:24:50.343   Training iter 500, batch loss 0.1904, batch acc 0.7194
13:24:50.863   Training iter 550, batch loss 0.1930, batch acc 0.7182
13:24:51.388   Training iter 600, batch loss 0.1886, batch acc 0.7262
13:24:51.390 Training @ 260 epoch...
13:24:51.917   Training iter 50, batch loss 0.1931, batch acc 0.7192
13:24:52.438   Training iter 100, batch loss 0.1938, batch acc 0.7164
13:24:52.967   Training iter 150, batch loss 0.1928, batch acc 0.7154
13:24:53.502   Training iter 200, batch loss 0.1913, batch acc 0.7182
13:24:54.023   Training iter 250, batch loss 0.1866, batch acc 0.7270
13:24:54.525   Training iter 300, batch loss 0.1931, batch acc 0.7172
13:24:55.012   Training iter 350, batch loss 0.1914, batch acc 0.7182
13:24:55.507   Training iter 400, batch loss 0.1925, batch acc 0.7218
13:24:55.993   Training iter 450, batch loss 0.1891, batch acc 0.7216
13:24:56.478   Training iter 500, batch loss 0.1920, batch acc 0.7180
13:24:56.963   Training iter 550, batch loss 0.1905, batch acc 0.7202
13:24:57.466   Training iter 600, batch loss 0.1921, batch acc 0.7222
13:24:57.467 Testing @ 260 epoch...
13:24:57.505     Testing, total mean loss 0.19089, total acc 0.71640
13:24:57.505 Training @ 261 epoch...
13:24:58.047   Training iter 50, batch loss 0.1928, batch acc 0.7174
13:24:58.592   Training iter 100, batch loss 0.1911, batch acc 0.7236
13:24:59.133   Training iter 150, batch loss 0.1898, batch acc 0.7212
13:24:59.607   Training iter 200, batch loss 0.1913, batch acc 0.7206
13:25:00.059   Training iter 250, batch loss 0.1934, batch acc 0.7138
13:25:00.562   Training iter 300, batch loss 0.1879, batch acc 0.7232
13:25:01.064   Training iter 350, batch loss 0.1967, batch acc 0.7136
13:25:01.569   Training iter 400, batch loss 0.1916, batch acc 0.7134
13:25:02.112   Training iter 450, batch loss 0.1931, batch acc 0.7192
13:25:02.618   Training iter 500, batch loss 0.1909, batch acc 0.7188
13:25:03.082   Training iter 550, batch loss 0.1893, batch acc 0.7234
13:25:03.544   Training iter 600, batch loss 0.1902, batch acc 0.7236
13:25:03.546 Training @ 262 epoch...
13:25:04.007   Training iter 50, batch loss 0.1921, batch acc 0.7218
13:25:04.461   Training iter 100, batch loss 0.1885, batch acc 0.7274
13:25:04.929   Training iter 150, batch loss 0.1909, batch acc 0.7210
13:25:05.393   Training iter 200, batch loss 0.1937, batch acc 0.7118
13:25:05.849   Training iter 250, batch loss 0.1865, batch acc 0.7288
13:25:06.312   Training iter 300, batch loss 0.1921, batch acc 0.7146
13:25:06.778   Training iter 350, batch loss 0.1917, batch acc 0.7170
13:25:07.262   Training iter 400, batch loss 0.1956, batch acc 0.7152
13:25:07.736   Training iter 450, batch loss 0.1969, batch acc 0.7122
13:25:08.205   Training iter 500, batch loss 0.1878, batch acc 0.7234
13:25:08.686   Training iter 550, batch loss 0.1908, batch acc 0.7190
13:25:09.150   Training iter 600, batch loss 0.1913, batch acc 0.7192
13:25:09.152 Training @ 263 epoch...
13:25:09.629   Training iter 50, batch loss 0.1945, batch acc 0.7150
13:25:10.124   Training iter 100, batch loss 0.1978, batch acc 0.7074
13:25:10.622   Training iter 150, batch loss 0.1882, batch acc 0.7286
13:25:11.111   Training iter 200, batch loss 0.1868, batch acc 0.7260
13:25:11.580   Training iter 250, batch loss 0.1918, batch acc 0.7186
13:25:12.056   Training iter 300, batch loss 0.1946, batch acc 0.7166
13:25:12.536   Training iter 350, batch loss 0.1908, batch acc 0.7182
13:25:13.031   Training iter 400, batch loss 0.1924, batch acc 0.7178
13:25:13.526   Training iter 450, batch loss 0.1872, batch acc 0.7280
13:25:14.022   Training iter 500, batch loss 0.1919, batch acc 0.7210
13:25:14.521   Training iter 550, batch loss 0.1894, batch acc 0.7230
13:25:15.015   Training iter 600, batch loss 0.1924, batch acc 0.7178
13:25:15.017 Training @ 264 epoch...
13:25:15.521   Training iter 50, batch loss 0.1930, batch acc 0.7190
13:25:16.028   Training iter 100, batch loss 0.1930, batch acc 0.7138
13:25:16.519   Training iter 150, batch loss 0.1944, batch acc 0.7130
13:25:17.011   Training iter 200, batch loss 0.1875, batch acc 0.7260
13:25:17.501   Training iter 250, batch loss 0.1902, batch acc 0.7200
13:25:17.992   Training iter 300, batch loss 0.1879, batch acc 0.7286
13:25:18.495   Training iter 350, batch loss 0.1962, batch acc 0.7088
13:25:18.996   Training iter 400, batch loss 0.1881, batch acc 0.7252
13:25:19.518   Training iter 450, batch loss 0.1873, batch acc 0.7320
13:25:20.036   Training iter 500, batch loss 0.1881, batch acc 0.7274
13:25:20.565   Training iter 550, batch loss 0.1940, batch acc 0.7164
13:25:21.096   Training iter 600, batch loss 0.1977, batch acc 0.7042
13:25:21.097 Training @ 265 epoch...
13:25:21.627   Training iter 50, batch loss 0.1874, batch acc 0.7248
13:25:22.145   Training iter 100, batch loss 0.1925, batch acc 0.7200
13:25:22.684   Training iter 150, batch loss 0.1960, batch acc 0.7140
13:25:23.227   Training iter 200, batch loss 0.1928, batch acc 0.7134
13:25:23.773   Training iter 250, batch loss 0.1867, batch acc 0.7280
13:25:24.313   Training iter 300, batch loss 0.1903, batch acc 0.7154
13:25:24.841   Training iter 350, batch loss 0.1903, batch acc 0.7216
13:25:25.377   Training iter 400, batch loss 0.1918, batch acc 0.7204
13:25:25.883   Training iter 450, batch loss 0.1958, batch acc 0.7140
13:25:26.396   Training iter 500, batch loss 0.1933, batch acc 0.7206
13:25:26.911   Training iter 550, batch loss 0.1897, batch acc 0.7226
13:25:27.434   Training iter 600, batch loss 0.1904, batch acc 0.7192
13:25:27.436 Testing @ 265 epoch...
13:25:27.473     Testing, total mean loss 0.19076, total acc 0.71630
13:25:27.473 Training @ 266 epoch...
13:25:27.984   Training iter 50, batch loss 0.1937, batch acc 0.7148
13:25:28.496   Training iter 100, batch loss 0.1917, batch acc 0.7204
13:25:29.012   Training iter 150, batch loss 0.1871, batch acc 0.7248
13:25:29.496   Training iter 200, batch loss 0.1895, batch acc 0.7234
13:25:29.967   Training iter 250, batch loss 0.1928, batch acc 0.7182
13:25:30.467   Training iter 300, batch loss 0.1943, batch acc 0.7132
13:25:30.955   Training iter 350, batch loss 0.1874, batch acc 0.7336
13:25:31.436   Training iter 400, batch loss 0.1950, batch acc 0.7128
13:25:31.919   Training iter 450, batch loss 0.1925, batch acc 0.7182
13:25:32.397   Training iter 500, batch loss 0.1892, batch acc 0.7210
13:25:32.882   Training iter 550, batch loss 0.1921, batch acc 0.7176
13:25:33.372   Training iter 600, batch loss 0.1916, batch acc 0.7182
13:25:33.373 Training @ 267 epoch...
13:25:33.869   Training iter 50, batch loss 0.1942, batch acc 0.7092
13:25:34.391   Training iter 100, batch loss 0.1901, batch acc 0.7214
13:25:34.907   Training iter 150, batch loss 0.1876, batch acc 0.7264
13:25:35.413   Training iter 200, batch loss 0.1933, batch acc 0.7162
13:25:35.919   Training iter 250, batch loss 0.1942, batch acc 0.7196
13:25:36.423   Training iter 300, batch loss 0.1927, batch acc 0.7192
13:25:36.932   Training iter 350, batch loss 0.1944, batch acc 0.7134
13:25:37.436   Training iter 400, batch loss 0.1885, batch acc 0.7238
13:25:37.935   Training iter 450, batch loss 0.1829, batch acc 0.7344
13:25:38.423   Training iter 500, batch loss 0.1939, batch acc 0.7138
13:25:38.901   Training iter 550, batch loss 0.1894, batch acc 0.7236
13:25:39.390   Training iter 600, batch loss 0.1954, batch acc 0.7144
13:25:39.392 Training @ 268 epoch...
13:25:39.888   Training iter 50, batch loss 0.1914, batch acc 0.7244
13:25:40.389   Training iter 100, batch loss 0.1920, batch acc 0.7198
13:25:40.877   Training iter 150, batch loss 0.1933, batch acc 0.7160
13:25:41.369   Training iter 200, batch loss 0.1923, batch acc 0.7154
13:25:41.872   Training iter 250, batch loss 0.1957, batch acc 0.7104
13:25:42.379   Training iter 300, batch loss 0.1897, batch acc 0.7224
13:25:42.877   Training iter 350, batch loss 0.1865, batch acc 0.7250
13:25:43.374   Training iter 400, batch loss 0.1902, batch acc 0.7250
13:25:43.887   Training iter 450, batch loss 0.1949, batch acc 0.7110
13:25:44.410   Training iter 500, batch loss 0.1893, batch acc 0.7244
13:25:44.933   Training iter 550, batch loss 0.1932, batch acc 0.7144
13:25:45.448   Training iter 600, batch loss 0.1881, batch acc 0.7280
13:25:45.450 Training @ 269 epoch...
13:25:45.965   Training iter 50, batch loss 0.1879, batch acc 0.7288
13:25:46.483   Training iter 100, batch loss 0.1930, batch acc 0.7166
13:25:47.016   Training iter 150, batch loss 0.1913, batch acc 0.7206
13:25:47.532   Training iter 200, batch loss 0.1894, batch acc 0.7198
13:25:48.066   Training iter 250, batch loss 0.1945, batch acc 0.7148
13:25:48.629   Training iter 300, batch loss 0.1884, batch acc 0.7258
13:25:49.158   Training iter 350, batch loss 0.1932, batch acc 0.7148
13:25:49.683   Training iter 400, batch loss 0.1947, batch acc 0.7166
13:25:50.206   Training iter 450, batch loss 0.1912, batch acc 0.7216
13:25:50.745   Training iter 500, batch loss 0.1835, batch acc 0.7348
13:25:51.269   Training iter 550, batch loss 0.1937, batch acc 0.7140
13:25:51.768   Training iter 600, batch loss 0.1954, batch acc 0.7104
13:25:51.770 Training @ 270 epoch...
13:25:52.302   Training iter 50, batch loss 0.1928, batch acc 0.7136
13:25:52.823   Training iter 100, batch loss 0.1932, batch acc 0.7146
13:25:53.355   Training iter 150, batch loss 0.1875, batch acc 0.7266
13:25:53.880   Training iter 200, batch loss 0.1970, batch acc 0.7126
13:25:54.419   Training iter 250, batch loss 0.1888, batch acc 0.7270
13:25:54.953   Training iter 300, batch loss 0.1898, batch acc 0.7244
13:25:55.542   Training iter 350, batch loss 0.1886, batch acc 0.7292
13:25:56.147   Training iter 400, batch loss 0.1920, batch acc 0.7164
13:25:56.735   Training iter 450, batch loss 0.1906, batch acc 0.7170
13:25:57.270   Training iter 500, batch loss 0.1892, batch acc 0.7258
13:25:57.795   Training iter 550, batch loss 0.1963, batch acc 0.7086
13:25:58.353   Training iter 600, batch loss 0.1900, batch acc 0.7208
13:25:58.355 Testing @ 270 epoch...
13:25:58.392     Testing, total mean loss 0.19068, total acc 0.71620
13:25:58.392 Training @ 271 epoch...
13:25:58.938   Training iter 50, batch loss 0.1887, batch acc 0.7232
13:25:59.477   Training iter 100, batch loss 0.1940, batch acc 0.7136
13:26:00.023   Training iter 150, batch loss 0.1910, batch acc 0.7226
13:26:00.562   Training iter 200, batch loss 0.1951, batch acc 0.7142
13:26:01.106   Training iter 250, batch loss 0.1873, batch acc 0.7288
13:26:01.681   Training iter 300, batch loss 0.1899, batch acc 0.7234
13:26:02.229   Training iter 350, batch loss 0.1906, batch acc 0.7202
13:26:02.759   Training iter 400, batch loss 0.1903, batch acc 0.7188
13:26:03.303   Training iter 450, batch loss 0.1922, batch acc 0.7156
13:26:03.849   Training iter 500, batch loss 0.1910, batch acc 0.7196
13:26:04.402   Training iter 550, batch loss 0.1955, batch acc 0.7124
13:26:04.945   Training iter 600, batch loss 0.1900, batch acc 0.7226
13:26:04.946 Training @ 272 epoch...
13:26:05.511   Training iter 50, batch loss 0.1934, batch acc 0.7164
13:26:06.054   Training iter 100, batch loss 0.1896, batch acc 0.7186
13:26:06.630   Training iter 150, batch loss 0.1927, batch acc 0.7196
13:26:07.185   Training iter 200, batch loss 0.1897, batch acc 0.7254
13:26:07.697   Training iter 250, batch loss 0.1870, batch acc 0.7292
13:26:08.186   Training iter 300, batch loss 0.1895, batch acc 0.7194
13:26:08.711   Training iter 350, batch loss 0.1904, batch acc 0.7180
13:26:09.230   Training iter 400, batch loss 0.1945, batch acc 0.7116
13:26:09.752   Training iter 450, batch loss 0.1869, batch acc 0.7310
13:26:10.280   Training iter 500, batch loss 0.1925, batch acc 0.7180
13:26:10.784   Training iter 550, batch loss 0.1919, batch acc 0.7194
13:26:11.292   Training iter 600, batch loss 0.1973, batch acc 0.7098
13:26:11.293 Training @ 273 epoch...
13:26:11.817   Training iter 50, batch loss 0.1971, batch acc 0.7080
13:26:12.354   Training iter 100, batch loss 0.1902, batch acc 0.7242
13:26:12.860   Training iter 150, batch loss 0.1914, batch acc 0.7220
13:26:13.387   Training iter 200, batch loss 0.1864, batch acc 0.7318
13:26:13.938   Training iter 250, batch loss 0.1873, batch acc 0.7272
13:26:14.449   Training iter 300, batch loss 0.1889, batch acc 0.7226
13:26:14.915   Training iter 350, batch loss 0.1911, batch acc 0.7248
13:26:15.397   Training iter 400, batch loss 0.1951, batch acc 0.7134
13:26:15.887   Training iter 450, batch loss 0.1923, batch acc 0.7192
13:26:16.366   Training iter 500, batch loss 0.1906, batch acc 0.7168
13:26:16.858   Training iter 550, batch loss 0.1955, batch acc 0.7088
13:26:17.353   Training iter 600, batch loss 0.1892, batch acc 0.7184
13:26:17.355 Training @ 274 epoch...
13:26:17.876   Training iter 50, batch loss 0.1961, batch acc 0.7086
13:26:18.394   Training iter 100, batch loss 0.1873, batch acc 0.7256
13:26:18.913   Training iter 150, batch loss 0.1909, batch acc 0.7214
13:26:19.427   Training iter 200, batch loss 0.1935, batch acc 0.7142
13:26:19.910   Training iter 250, batch loss 0.1897, batch acc 0.7196
13:26:20.394   Training iter 300, batch loss 0.1943, batch acc 0.7128
13:26:20.862   Training iter 350, batch loss 0.1870, batch acc 0.7328
13:26:21.342   Training iter 400, batch loss 0.1936, batch acc 0.7178
13:26:21.826   Training iter 450, batch loss 0.1900, batch acc 0.7200
13:26:22.307   Training iter 500, batch loss 0.1920, batch acc 0.7192
13:26:22.795   Training iter 550, batch loss 0.1895, batch acc 0.7236
13:26:23.301   Training iter 600, batch loss 0.1911, batch acc 0.7210
13:26:23.303 Training @ 275 epoch...
13:26:23.821   Training iter 50, batch loss 0.1960, batch acc 0.7120
13:26:24.327   Training iter 100, batch loss 0.1945, batch acc 0.7144
13:26:24.840   Training iter 150, batch loss 0.1911, batch acc 0.7208
13:26:25.339   Training iter 200, batch loss 0.1913, batch acc 0.7176
13:26:25.821   Training iter 250, batch loss 0.1915, batch acc 0.7210
13:26:26.308   Training iter 300, batch loss 0.1945, batch acc 0.7114
13:26:26.829   Training iter 350, batch loss 0.1840, batch acc 0.7318
13:26:27.357   Training iter 400, batch loss 0.1946, batch acc 0.7114
13:26:27.863   Training iter 450, batch loss 0.1887, batch acc 0.7242
13:26:28.377   Training iter 500, batch loss 0.1942, batch acc 0.7158
13:26:28.898   Training iter 550, batch loss 0.1892, batch acc 0.7252
13:26:29.423   Training iter 600, batch loss 0.1851, batch acc 0.7318
13:26:29.424 Testing @ 275 epoch...
13:26:29.461     Testing, total mean loss 0.19058, total acc 0.71720
13:26:29.461 Training @ 276 epoch...
13:26:29.987   Training iter 50, batch loss 0.1886, batch acc 0.7302
13:26:30.498   Training iter 100, batch loss 0.1921, batch acc 0.7222
13:26:31.015   Training iter 150, batch loss 0.1918, batch acc 0.7124
13:26:31.501   Training iter 200, batch loss 0.1941, batch acc 0.7140
13:26:32.001   Training iter 250, batch loss 0.1889, batch acc 0.7256
13:26:32.528   Training iter 300, batch loss 0.1935, batch acc 0.7144
13:26:33.066   Training iter 350, batch loss 0.1943, batch acc 0.7100
13:26:33.605   Training iter 400, batch loss 0.1939, batch acc 0.7140
13:26:34.133   Training iter 450, batch loss 0.1885, batch acc 0.7232
13:26:34.658   Training iter 500, batch loss 0.1902, batch acc 0.7230
13:26:35.176   Training iter 550, batch loss 0.1882, batch acc 0.7264
13:26:35.693   Training iter 600, batch loss 0.1904, batch acc 0.7202
13:26:35.694 Training @ 277 epoch...
13:26:36.213   Training iter 50, batch loss 0.1973, batch acc 0.7082
13:26:36.741   Training iter 100, batch loss 0.1919, batch acc 0.7188
13:26:37.248   Training iter 150, batch loss 0.1910, batch acc 0.7246
13:26:37.754   Training iter 200, batch loss 0.1935, batch acc 0.7176
13:26:38.252   Training iter 250, batch loss 0.1871, batch acc 0.7254
13:26:38.749   Training iter 300, batch loss 0.1920, batch acc 0.7182
13:26:39.248   Training iter 350, batch loss 0.1868, batch acc 0.7262
13:26:39.723   Training iter 400, batch loss 0.1906, batch acc 0.7264
13:26:40.200   Training iter 450, batch loss 0.1953, batch acc 0.7128
13:26:40.684   Training iter 500, batch loss 0.1944, batch acc 0.7100
13:26:41.182   Training iter 550, batch loss 0.1907, batch acc 0.7216
13:26:41.687   Training iter 600, batch loss 0.1838, batch acc 0.7294
13:26:41.689 Training @ 278 epoch...
13:26:42.207   Training iter 50, batch loss 0.1940, batch acc 0.7152
13:26:42.727   Training iter 100, batch loss 0.1914, batch acc 0.7190
13:26:43.258   Training iter 150, batch loss 0.1905, batch acc 0.7174
13:26:43.814   Training iter 200, batch loss 0.1884, batch acc 0.7274
13:26:44.366   Training iter 250, batch loss 0.1903, batch acc 0.7216
13:26:44.908   Training iter 300, batch loss 0.1886, batch acc 0.7212
13:26:45.455   Training iter 350, batch loss 0.1923, batch acc 0.7192
13:26:45.997   Training iter 400, batch loss 0.1907, batch acc 0.7198
13:26:46.539   Training iter 450, batch loss 0.1935, batch acc 0.7148
13:26:47.058   Training iter 500, batch loss 0.1849, batch acc 0.7294
13:26:47.558   Training iter 550, batch loss 0.1947, batch acc 0.7184
13:26:48.075   Training iter 600, batch loss 0.1946, batch acc 0.7116
13:26:48.077 Training @ 279 epoch...
13:26:48.602   Training iter 50, batch loss 0.1889, batch acc 0.7242
13:26:49.112   Training iter 100, batch loss 0.1912, batch acc 0.7216
13:26:49.644   Training iter 150, batch loss 0.1887, batch acc 0.7234
13:26:50.161   Training iter 200, batch loss 0.1898, batch acc 0.7224
13:26:50.683   Training iter 250, batch loss 0.1972, batch acc 0.7084
13:26:51.195   Training iter 300, batch loss 0.1893, batch acc 0.7228
13:26:51.711   Training iter 350, batch loss 0.1905, batch acc 0.7228
13:26:52.213   Training iter 400, batch loss 0.1934, batch acc 0.7124
13:26:52.727   Training iter 450, batch loss 0.1946, batch acc 0.7136
13:26:53.239   Training iter 500, batch loss 0.1905, batch acc 0.7244
13:26:53.741   Training iter 550, batch loss 0.1890, batch acc 0.7224
13:26:54.251   Training iter 600, batch loss 0.1906, batch acc 0.7216
13:26:54.253 Training @ 280 epoch...
13:26:54.765   Training iter 50, batch loss 0.1921, batch acc 0.7166
13:26:55.286   Training iter 100, batch loss 0.1954, batch acc 0.7138
13:26:55.776   Training iter 150, batch loss 0.1943, batch acc 0.7132
13:26:56.278   Training iter 200, batch loss 0.1891, batch acc 0.7262
13:26:56.771   Training iter 250, batch loss 0.1901, batch acc 0.7224
13:26:57.277   Training iter 300, batch loss 0.1886, batch acc 0.7210
13:26:57.821   Training iter 350, batch loss 0.1936, batch acc 0.7170
13:26:58.344   Training iter 400, batch loss 0.1914, batch acc 0.7164
13:26:58.863   Training iter 450, batch loss 0.1871, batch acc 0.7284
13:26:59.379   Training iter 500, batch loss 0.1918, batch acc 0.7136
13:26:59.898   Training iter 550, batch loss 0.1943, batch acc 0.7146
13:27:00.410   Training iter 600, batch loss 0.1858, batch acc 0.7346
13:27:00.412 Testing @ 280 epoch...
13:27:00.449     Testing, total mean loss 0.19045, total acc 0.71690
13:27:00.449 Training @ 281 epoch...
13:27:00.964   Training iter 50, batch loss 0.1860, batch acc 0.7314
13:27:01.482   Training iter 100, batch loss 0.1970, batch acc 0.7078
13:27:02.012   Training iter 150, batch loss 0.1990, batch acc 0.7082
13:27:02.542   Training iter 200, batch loss 0.1922, batch acc 0.7190
13:27:03.059   Training iter 250, batch loss 0.1864, batch acc 0.7290
13:27:03.623   Training iter 300, batch loss 0.1872, batch acc 0.7262
13:27:04.193   Training iter 350, batch loss 0.1868, batch acc 0.7288
13:27:04.772   Training iter 400, batch loss 0.1891, batch acc 0.7230
13:27:05.345   Training iter 450, batch loss 0.1898, batch acc 0.7224
13:27:05.919   Training iter 500, batch loss 0.1954, batch acc 0.7084
13:27:06.501   Training iter 550, batch loss 0.1894, batch acc 0.7262
13:27:07.088   Training iter 600, batch loss 0.1950, batch acc 0.7100
13:27:07.089 Training @ 282 epoch...
13:27:07.688   Training iter 50, batch loss 0.1892, batch acc 0.7236
13:27:08.280   Training iter 100, batch loss 0.1963, batch acc 0.7120
13:27:08.875   Training iter 150, batch loss 0.1907, batch acc 0.7188
13:27:09.459   Training iter 200, batch loss 0.1910, batch acc 0.7240
13:27:10.040   Training iter 250, batch loss 0.1937, batch acc 0.7152
13:27:10.626   Training iter 300, batch loss 0.1921, batch acc 0.7168
13:27:11.198   Training iter 350, batch loss 0.1918, batch acc 0.7212
13:27:11.774   Training iter 400, batch loss 0.1897, batch acc 0.7194
13:27:12.351   Training iter 450, batch loss 0.1892, batch acc 0.7204
13:27:12.939   Training iter 500, batch loss 0.1903, batch acc 0.7214
13:27:13.539   Training iter 550, batch loss 0.1870, batch acc 0.7278
13:27:14.158   Training iter 600, batch loss 0.1920, batch acc 0.7186
13:27:14.160 Training @ 283 epoch...
13:27:14.767   Training iter 50, batch loss 0.1921, batch acc 0.7192
13:27:15.372   Training iter 100, batch loss 0.1929, batch acc 0.7188
13:27:15.971   Training iter 150, batch loss 0.1958, batch acc 0.7134
13:27:16.583   Training iter 200, batch loss 0.1933, batch acc 0.7134
13:27:17.191   Training iter 250, batch loss 0.1925, batch acc 0.7154
13:27:17.787   Training iter 300, batch loss 0.1917, batch acc 0.7216
13:27:18.379   Training iter 350, batch loss 0.1888, batch acc 0.7220
13:27:18.959   Training iter 400, batch loss 0.1865, batch acc 0.7298
13:27:19.541   Training iter 450, batch loss 0.1888, batch acc 0.7272
13:27:20.132   Training iter 500, batch loss 0.1913, batch acc 0.7158
13:27:20.729   Training iter 550, batch loss 0.1892, batch acc 0.7232
13:27:21.307   Training iter 600, batch loss 0.1900, batch acc 0.7204
13:27:21.308 Training @ 284 epoch...
13:27:21.887   Training iter 50, batch loss 0.1915, batch acc 0.7186
13:27:22.465   Training iter 100, batch loss 0.1908, batch acc 0.7222
13:27:23.032   Training iter 150, batch loss 0.1895, batch acc 0.7212
13:27:23.577   Training iter 200, batch loss 0.1923, batch acc 0.7202
13:27:24.098   Training iter 250, batch loss 0.1897, batch acc 0.7234
13:27:24.623   Training iter 300, batch loss 0.1878, batch acc 0.7250
13:27:25.154   Training iter 350, batch loss 0.1951, batch acc 0.7088
13:27:25.669   Training iter 400, batch loss 0.1941, batch acc 0.7144
13:27:26.195   Training iter 450, batch loss 0.1923, batch acc 0.7176
13:27:26.697   Training iter 500, batch loss 0.1845, batch acc 0.7354
13:27:27.218   Training iter 550, batch loss 0.1932, batch acc 0.7132
13:27:27.758   Training iter 600, batch loss 0.1920, batch acc 0.7174
13:27:27.760 Training @ 285 epoch...
13:27:28.280   Training iter 50, batch loss 0.1986, batch acc 0.7026
13:27:28.790   Training iter 100, batch loss 0.1961, batch acc 0.7120
13:27:29.335   Training iter 150, batch loss 0.1901, batch acc 0.7222
13:27:29.864   Training iter 200, batch loss 0.1849, batch acc 0.7334
13:27:30.385   Training iter 250, batch loss 0.1937, batch acc 0.7144
13:27:30.911   Training iter 300, batch loss 0.1922, batch acc 0.7166
13:27:31.423   Training iter 350, batch loss 0.1930, batch acc 0.7172
13:27:31.949   Training iter 400, batch loss 0.1884, batch acc 0.7238
13:27:32.471   Training iter 450, batch loss 0.1898, batch acc 0.7232
13:27:32.981   Training iter 500, batch loss 0.1885, batch acc 0.7248
13:27:33.496   Training iter 550, batch loss 0.1892, batch acc 0.7236
13:27:34.028   Training iter 600, batch loss 0.1880, batch acc 0.7286
13:27:34.030 Testing @ 285 epoch...
13:27:34.066     Testing, total mean loss 0.19036, total acc 0.71630
13:27:34.066 Training @ 286 epoch...
13:27:34.593   Training iter 50, batch loss 0.1887, batch acc 0.7254
13:27:35.096   Training iter 100, batch loss 0.1898, batch acc 0.7240
13:27:35.577   Training iter 150, batch loss 0.1877, batch acc 0.7260
13:27:36.052   Training iter 200, batch loss 0.1892, batch acc 0.7210
13:27:36.530   Training iter 250, batch loss 0.1922, batch acc 0.7206
13:27:36.999   Training iter 300, batch loss 0.1925, batch acc 0.7186
13:27:37.472   Training iter 350, batch loss 0.1882, batch acc 0.7266
13:27:37.932   Training iter 400, batch loss 0.1961, batch acc 0.7070
13:27:38.396   Training iter 450, batch loss 0.1940, batch acc 0.7182
13:27:38.857   Training iter 500, batch loss 0.1914, batch acc 0.7182
13:27:39.317   Training iter 550, batch loss 0.1907, batch acc 0.7172
13:27:39.791   Training iter 600, batch loss 0.1918, batch acc 0.7190
13:27:39.793 Training @ 287 epoch...
13:27:40.291   Training iter 50, batch loss 0.1910, batch acc 0.7172
13:27:40.784   Training iter 100, batch loss 0.1919, batch acc 0.7194
13:27:41.282   Training iter 150, batch loss 0.1892, batch acc 0.7230
13:27:41.777   Training iter 200, batch loss 0.1905, batch acc 0.7218
13:27:42.268   Training iter 250, batch loss 0.1866, batch acc 0.7266
13:27:42.757   Training iter 300, batch loss 0.1924, batch acc 0.7178
13:27:43.250   Training iter 350, batch loss 0.1894, batch acc 0.7218
13:27:43.740   Training iter 400, batch loss 0.1909, batch acc 0.7184
13:27:44.236   Training iter 450, batch loss 0.1946, batch acc 0.7144
13:27:44.740   Training iter 500, batch loss 0.1904, batch acc 0.7228
13:27:45.255   Training iter 550, batch loss 0.1936, batch acc 0.7150
13:27:45.789   Training iter 600, batch loss 0.1915, batch acc 0.7222
13:27:45.791 Training @ 288 epoch...
13:27:46.325   Training iter 50, batch loss 0.1895, batch acc 0.7248
13:27:46.858   Training iter 100, batch loss 0.1855, batch acc 0.7272
13:27:47.394   Training iter 150, batch loss 0.1890, batch acc 0.7252
13:27:47.929   Training iter 200, batch loss 0.1911, batch acc 0.7188
13:27:48.475   Training iter 250, batch loss 0.1967, batch acc 0.7058
13:27:49.015   Training iter 300, batch loss 0.1941, batch acc 0.7146
13:27:49.552   Training iter 350, batch loss 0.1928, batch acc 0.7174
13:27:50.099   Training iter 400, batch loss 0.1912, batch acc 0.7226
13:27:50.649   Training iter 450, batch loss 0.1901, batch acc 0.7204
13:27:51.193   Training iter 500, batch loss 0.1916, batch acc 0.7198
13:27:51.738   Training iter 550, batch loss 0.1904, batch acc 0.7240
13:27:52.254   Training iter 600, batch loss 0.1898, batch acc 0.7198
13:27:52.256 Training @ 289 epoch...
13:27:52.778   Training iter 50, batch loss 0.1916, batch acc 0.7198
13:27:53.284   Training iter 100, batch loss 0.1886, batch acc 0.7250
13:27:53.788   Training iter 150, batch loss 0.1900, batch acc 0.7250
13:27:54.296   Training iter 200, batch loss 0.1955, batch acc 0.7090
13:27:54.820   Training iter 250, batch loss 0.1987, batch acc 0.7060
13:27:55.341   Training iter 300, batch loss 0.1887, batch acc 0.7238
13:27:55.860   Training iter 350, batch loss 0.1974, batch acc 0.7048
13:27:56.393   Training iter 400, batch loss 0.1879, batch acc 0.7238
13:27:56.919   Training iter 450, batch loss 0.1839, batch acc 0.7376
13:27:57.438   Training iter 500, batch loss 0.1902, batch acc 0.7220
13:27:57.936   Training iter 550, batch loss 0.1870, batch acc 0.7266
13:27:58.444   Training iter 600, batch loss 0.1921, batch acc 0.7168
13:27:58.446 Training @ 290 epoch...
13:27:58.981   Training iter 50, batch loss 0.1968, batch acc 0.7102
13:27:59.510   Training iter 100, batch loss 0.1920, batch acc 0.7174
13:28:00.027   Training iter 150, batch loss 0.1917, batch acc 0.7192
13:28:00.556   Training iter 200, batch loss 0.1958, batch acc 0.7116
13:28:01.075   Training iter 250, batch loss 0.1911, batch acc 0.7184
13:28:01.635   Training iter 300, batch loss 0.1849, batch acc 0.7332
13:28:02.198   Training iter 350, batch loss 0.1902, batch acc 0.7212
13:28:02.768   Training iter 400, batch loss 0.1923, batch acc 0.7160
13:28:03.330   Training iter 450, batch loss 0.1890, batch acc 0.7254
13:28:03.881   Training iter 500, batch loss 0.1901, batch acc 0.7196
13:28:04.439   Training iter 550, batch loss 0.1901, batch acc 0.7210
13:28:04.988   Training iter 600, batch loss 0.1874, batch acc 0.7282
13:28:04.989 Testing @ 290 epoch...
13:28:05.028     Testing, total mean loss 0.19028, total acc 0.71660
13:28:05.028 Training @ 291 epoch...
13:28:05.587   Training iter 50, batch loss 0.1935, batch acc 0.7108
13:28:06.141   Training iter 100, batch loss 0.1891, batch acc 0.7246
13:28:06.698   Training iter 150, batch loss 0.1928, batch acc 0.7166
13:28:07.267   Training iter 200, batch loss 0.1898, batch acc 0.7232
13:28:07.815   Training iter 250, batch loss 0.1917, batch acc 0.7186
13:28:08.326   Training iter 300, batch loss 0.1923, batch acc 0.7180
13:28:08.822   Training iter 350, batch loss 0.1896, batch acc 0.7242
13:28:09.320   Training iter 400, batch loss 0.1888, batch acc 0.7208
13:28:09.808   Training iter 450, batch loss 0.1932, batch acc 0.7180
13:28:10.321   Training iter 500, batch loss 0.1875, batch acc 0.7254
13:28:10.824   Training iter 550, batch loss 0.1914, batch acc 0.7194
13:28:11.330   Training iter 600, batch loss 0.1916, batch acc 0.7198
13:28:11.332 Training @ 292 epoch...
13:28:11.831   Training iter 50, batch loss 0.1922, batch acc 0.7190
13:28:12.336   Training iter 100, batch loss 0.1920, batch acc 0.7192
13:28:12.842   Training iter 150, batch loss 0.1926, batch acc 0.7148
13:28:13.348   Training iter 200, batch loss 0.1949, batch acc 0.7110
13:28:13.856   Training iter 250, batch loss 0.1835, batch acc 0.7338
13:28:14.385   Training iter 300, batch loss 0.1931, batch acc 0.7154
13:28:14.905   Training iter 350, batch loss 0.1857, batch acc 0.7292
13:28:15.423   Training iter 400, batch loss 0.1914, batch acc 0.7196
13:28:15.951   Training iter 450, batch loss 0.1881, batch acc 0.7274
13:28:16.467   Training iter 500, batch loss 0.1922, batch acc 0.7168
13:28:16.980   Training iter 550, batch loss 0.1924, batch acc 0.7214
13:28:17.499   Training iter 600, batch loss 0.1927, batch acc 0.7140
13:28:17.501 Training @ 293 epoch...
13:28:18.031   Training iter 50, batch loss 0.1853, batch acc 0.7322
13:28:18.576   Training iter 100, batch loss 0.1938, batch acc 0.7204
13:28:19.112   Training iter 150, batch loss 0.1894, batch acc 0.7222
13:28:19.645   Training iter 200, batch loss 0.1908, batch acc 0.7174
13:28:20.183   Training iter 250, batch loss 0.1889, batch acc 0.7238
13:28:20.722   Training iter 300, batch loss 0.1920, batch acc 0.7178
13:28:21.261   Training iter 350, batch loss 0.1960, batch acc 0.7086
13:28:21.805   Training iter 400, batch loss 0.1884, batch acc 0.7236
13:28:22.360   Training iter 450, batch loss 0.1949, batch acc 0.7100
13:28:22.916   Training iter 500, batch loss 0.1883, batch acc 0.7248
13:28:23.455   Training iter 550, batch loss 0.1931, batch acc 0.7188
13:28:23.969   Training iter 600, batch loss 0.1898, batch acc 0.7182
13:28:23.970 Training @ 294 epoch...
13:28:24.468   Training iter 50, batch loss 0.1931, batch acc 0.7138
13:28:24.967   Training iter 100, batch loss 0.1933, batch acc 0.7148
13:28:25.473   Training iter 150, batch loss 0.1906, batch acc 0.7242
13:28:25.960   Training iter 200, batch loss 0.1933, batch acc 0.7172
13:28:26.446   Training iter 250, batch loss 0.1868, batch acc 0.7268
13:28:26.934   Training iter 300, batch loss 0.1890, batch acc 0.7248
13:28:27.431   Training iter 350, batch loss 0.1898, batch acc 0.7202
13:28:27.929   Training iter 400, batch loss 0.1890, batch acc 0.7262
13:28:28.421   Training iter 450, batch loss 0.1895, batch acc 0.7194
13:28:28.904   Training iter 500, batch loss 0.1925, batch acc 0.7172
13:28:29.406   Training iter 550, batch loss 0.1894, batch acc 0.7252
13:28:29.902   Training iter 600, batch loss 0.1942, batch acc 0.7144
13:28:29.904 Training @ 295 epoch...
13:28:30.422   Training iter 50, batch loss 0.1922, batch acc 0.7176
13:28:30.942   Training iter 100, batch loss 0.1869, batch acc 0.7280
13:28:31.456   Training iter 150, batch loss 0.1871, batch acc 0.7254
13:28:31.975   Training iter 200, batch loss 0.1923, batch acc 0.7202
13:28:32.500   Training iter 250, batch loss 0.1944, batch acc 0.7138
13:28:33.034   Training iter 300, batch loss 0.1940, batch acc 0.7166
13:28:33.550   Training iter 350, batch loss 0.1886, batch acc 0.7240
13:28:34.083   Training iter 400, batch loss 0.1927, batch acc 0.7176
13:28:34.633   Training iter 450, batch loss 0.1881, batch acc 0.7226
13:28:35.173   Training iter 500, batch loss 0.1904, batch acc 0.7220
13:28:35.722   Training iter 550, batch loss 0.1934, batch acc 0.7142
13:28:36.281   Training iter 600, batch loss 0.1902, batch acc 0.7216
13:28:36.283 Testing @ 295 epoch...
13:28:36.320     Testing, total mean loss 0.19026, total acc 0.71690
13:28:36.320 Training @ 296 epoch...
13:28:36.860   Training iter 50, batch loss 0.1879, batch acc 0.7286
13:28:37.396   Training iter 100, batch loss 0.1845, batch acc 0.7332
13:28:37.930   Training iter 150, batch loss 0.1899, batch acc 0.7246
13:28:38.477   Training iter 200, batch loss 0.1893, batch acc 0.7206
13:28:39.026   Training iter 250, batch loss 0.1942, batch acc 0.7114
13:28:39.558   Training iter 300, batch loss 0.1859, batch acc 0.7314
13:28:40.071   Training iter 350, batch loss 0.1965, batch acc 0.7108
13:28:40.584   Training iter 400, batch loss 0.1953, batch acc 0.7130
13:28:41.092   Training iter 450, batch loss 0.1917, batch acc 0.7186
13:28:41.590   Training iter 500, batch loss 0.1913, batch acc 0.7188
13:28:42.103   Training iter 550, batch loss 0.1942, batch acc 0.7108
13:28:42.611   Training iter 600, batch loss 0.1894, batch acc 0.7208
13:28:42.612 Training @ 297 epoch...
13:28:43.124   Training iter 50, batch loss 0.1884, batch acc 0.7238
13:28:43.623   Training iter 100, batch loss 0.1923, batch acc 0.7188
13:28:44.128   Training iter 150, batch loss 0.1941, batch acc 0.7082
13:28:44.643   Training iter 200, batch loss 0.1857, batch acc 0.7300
13:28:45.148   Training iter 250, batch loss 0.1940, batch acc 0.7136
13:28:45.655   Training iter 300, batch loss 0.1912, batch acc 0.7196
13:28:46.165   Training iter 350, batch loss 0.1896, batch acc 0.7262
13:28:46.673   Training iter 400, batch loss 0.1898, batch acc 0.7246
13:28:47.199   Training iter 450, batch loss 0.1956, batch acc 0.7126
13:28:47.708   Training iter 500, batch loss 0.1876, batch acc 0.7208
13:28:48.209   Training iter 550, batch loss 0.1884, batch acc 0.7256
13:28:48.724   Training iter 600, batch loss 0.1932, batch acc 0.7170
13:28:48.725 Training @ 298 epoch...
13:28:49.226   Training iter 50, batch loss 0.1916, batch acc 0.7200
13:28:49.696   Training iter 100, batch loss 0.1877, batch acc 0.7266
13:28:50.227   Training iter 150, batch loss 0.1860, batch acc 0.7246
13:28:50.725   Training iter 200, batch loss 0.1959, batch acc 0.7112
13:28:51.241   Training iter 250, batch loss 0.1932, batch acc 0.7174
13:28:51.794   Training iter 300, batch loss 0.1858, batch acc 0.7350
13:28:52.335   Training iter 350, batch loss 0.1895, batch acc 0.7174
13:28:52.857   Training iter 400, batch loss 0.1950, batch acc 0.7094
13:28:53.379   Training iter 450, batch loss 0.1893, batch acc 0.7252
13:28:53.914   Training iter 500, batch loss 0.1910, batch acc 0.7168
13:28:54.498   Training iter 550, batch loss 0.1903, batch acc 0.7210
13:28:55.103   Training iter 600, batch loss 0.1944, batch acc 0.7144
13:28:55.105 Training @ 299 epoch...
13:28:55.684   Training iter 50, batch loss 0.1851, batch acc 0.7310
13:28:56.229   Training iter 100, batch loss 0.1907, batch acc 0.7238
13:28:56.783   Training iter 150, batch loss 0.1894, batch acc 0.7246
13:28:57.316   Training iter 200, batch loss 0.1947, batch acc 0.7110
13:28:57.827   Training iter 250, batch loss 0.1886, batch acc 0.7232
13:28:58.356   Training iter 300, batch loss 0.1901, batch acc 0.7182
13:28:58.855   Training iter 350, batch loss 0.1916, batch acc 0.7186
13:28:59.337   Training iter 400, batch loss 0.1885, batch acc 0.7206
13:28:59.808   Training iter 450, batch loss 0.1903, batch acc 0.7210
13:29:00.277   Training iter 500, batch loss 0.1954, batch acc 0.7106
13:29:00.761   Training iter 550, batch loss 0.1919, batch acc 0.7202
13:29:01.258   Training iter 600, batch loss 0.1931, batch acc 0.7168
13:29:01.260 Training @ 300 epoch...
13:29:01.786   Training iter 50, batch loss 0.1952, batch acc 0.7118
13:29:02.332   Training iter 100, batch loss 0.1949, batch acc 0.7186
13:29:02.877   Training iter 150, batch loss 0.1906, batch acc 0.7164
13:29:03.376   Training iter 200, batch loss 0.1935, batch acc 0.7158
13:29:03.868   Training iter 250, batch loss 0.1931, batch acc 0.7154
13:29:04.372   Training iter 300, batch loss 0.1861, batch acc 0.7310
13:29:04.852   Training iter 350, batch loss 0.1901, batch acc 0.7200
13:29:05.360   Training iter 400, batch loss 0.1888, batch acc 0.7244
13:29:05.851   Training iter 450, batch loss 0.1879, batch acc 0.7222
13:29:06.363   Training iter 500, batch loss 0.1864, batch acc 0.7288
13:29:06.872   Training iter 550, batch loss 0.1855, batch acc 0.7300
13:29:07.388   Training iter 600, batch loss 0.1971, batch acc 0.7074
13:29:07.390 Testing @ 300 epoch...
13:29:07.428     Testing, total mean loss 0.19013, total acc 0.71720
13:29:07.428 Plot @ 300 epoch...
13:29:07.428 Training @ 301 epoch...
13:29:07.916   Training iter 50, batch loss 0.1883, batch acc 0.7250
13:29:08.416   Training iter 100, batch loss 0.1887, batch acc 0.7216
13:29:08.934   Training iter 150, batch loss 0.1875, batch acc 0.7286
13:29:09.446   Training iter 200, batch loss 0.1897, batch acc 0.7222
13:29:09.936   Training iter 250, batch loss 0.1897, batch acc 0.7220
13:29:10.437   Training iter 300, batch loss 0.1892, batch acc 0.7298
13:29:10.944   Training iter 350, batch loss 0.1940, batch acc 0.7158
13:29:11.437   Training iter 400, batch loss 0.1924, batch acc 0.7144
13:29:11.918   Training iter 450, batch loss 0.1928, batch acc 0.7148
13:29:12.369   Training iter 500, batch loss 0.1912, batch acc 0.7180
13:29:12.858   Training iter 550, batch loss 0.1926, batch acc 0.7178
13:29:13.324   Training iter 600, batch loss 0.1930, batch acc 0.7148
13:29:13.326 Training @ 302 epoch...
13:29:13.802   Training iter 50, batch loss 0.1894, batch acc 0.7194
13:29:14.255   Training iter 100, batch loss 0.1906, batch acc 0.7218
13:29:14.729   Training iter 150, batch loss 0.1916, batch acc 0.7198
13:29:15.250   Training iter 200, batch loss 0.1897, batch acc 0.7230
13:29:15.772   Training iter 250, batch loss 0.1906, batch acc 0.7210
13:29:16.297   Training iter 300, batch loss 0.1897, batch acc 0.7238
13:29:16.786   Training iter 350, batch loss 0.1893, batch acc 0.7232
13:29:17.289   Training iter 400, batch loss 0.1929, batch acc 0.7094
13:29:17.796   Training iter 450, batch loss 0.1891, batch acc 0.7252
13:29:18.302   Training iter 500, batch loss 0.1937, batch acc 0.7148
13:29:18.807   Training iter 550, batch loss 0.1889, batch acc 0.7250
13:29:19.300   Training iter 600, batch loss 0.1932, batch acc 0.7188
13:29:19.301 Training @ 303 epoch...
13:29:19.820   Training iter 50, batch loss 0.1911, batch acc 0.7174
13:29:20.329   Training iter 100, batch loss 0.1903, batch acc 0.7194
13:29:20.816   Training iter 150, batch loss 0.1920, batch acc 0.7148
13:29:21.285   Training iter 200, batch loss 0.1900, batch acc 0.7220
13:29:21.755   Training iter 250, batch loss 0.1952, batch acc 0.7126
13:29:22.271   Training iter 300, batch loss 0.1892, batch acc 0.7236
13:29:22.795   Training iter 350, batch loss 0.1898, batch acc 0.7220
13:29:23.321   Training iter 400, batch loss 0.1927, batch acc 0.7174
13:29:23.834   Training iter 450, batch loss 0.1943, batch acc 0.7140
13:29:24.362   Training iter 500, batch loss 0.1886, batch acc 0.7212
13:29:24.885   Training iter 550, batch loss 0.1879, batch acc 0.7272
13:29:25.425   Training iter 600, batch loss 0.1875, batch acc 0.7322
13:29:25.427 Training @ 304 epoch...
13:29:25.954   Training iter 50, batch loss 0.1854, batch acc 0.7312
13:29:26.486   Training iter 100, batch loss 0.1925, batch acc 0.7168
13:29:27.012   Training iter 150, batch loss 0.1923, batch acc 0.7130
13:29:27.544   Training iter 200, batch loss 0.1894, batch acc 0.7220
13:29:28.054   Training iter 250, batch loss 0.1912, batch acc 0.7220
13:29:28.545   Training iter 300, batch loss 0.1941, batch acc 0.7098
13:29:29.037   Training iter 350, batch loss 0.1888, batch acc 0.7254
13:29:29.530   Training iter 400, batch loss 0.1906, batch acc 0.7216
13:29:30.028   Training iter 450, batch loss 0.1894, batch acc 0.7204
13:29:30.555   Training iter 500, batch loss 0.1881, batch acc 0.7256
13:29:31.095   Training iter 550, batch loss 0.1915, batch acc 0.7244
13:29:31.613   Training iter 600, batch loss 0.1952, batch acc 0.7108
13:29:31.614 Training @ 305 epoch...
13:29:32.146   Training iter 50, batch loss 0.1899, batch acc 0.7216
13:29:32.680   Training iter 100, batch loss 0.1903, batch acc 0.7196
13:29:33.226   Training iter 150, batch loss 0.1905, batch acc 0.7202
13:29:33.757   Training iter 200, batch loss 0.1948, batch acc 0.7130
13:29:34.285   Training iter 250, batch loss 0.1938, batch acc 0.7120
13:29:34.809   Training iter 300, batch loss 0.1931, batch acc 0.7178
13:29:35.351   Training iter 350, batch loss 0.1871, batch acc 0.7300
13:29:35.875   Training iter 400, batch loss 0.1942, batch acc 0.7140
13:29:36.399   Training iter 450, batch loss 0.1887, batch acc 0.7216
13:29:36.899   Training iter 500, batch loss 0.1890, batch acc 0.7260
13:29:37.381   Training iter 550, batch loss 0.1901, batch acc 0.7172
13:29:37.856   Training iter 600, batch loss 0.1866, batch acc 0.7314
13:29:37.858 Testing @ 305 epoch...
13:29:37.895     Testing, total mean loss 0.19001, total acc 0.71740
13:29:37.895 Training @ 306 epoch...
13:29:38.385   Training iter 50, batch loss 0.1925, batch acc 0.7180
13:29:38.864   Training iter 100, batch loss 0.1929, batch acc 0.7148
13:29:39.349   Training iter 150, batch loss 0.1905, batch acc 0.7218
13:29:39.820   Training iter 200, batch loss 0.1979, batch acc 0.7040
13:29:40.300   Training iter 250, batch loss 0.1901, batch acc 0.7212
13:29:40.782   Training iter 300, batch loss 0.1865, batch acc 0.7290
13:29:41.266   Training iter 350, batch loss 0.1873, batch acc 0.7282
13:29:41.749   Training iter 400, batch loss 0.1886, batch acc 0.7264
13:29:42.266   Training iter 450, batch loss 0.1896, batch acc 0.7222
13:29:42.756   Training iter 500, batch loss 0.1896, batch acc 0.7222
13:29:43.253   Training iter 550, batch loss 0.1895, batch acc 0.7168
13:29:43.747   Training iter 600, batch loss 0.1928, batch acc 0.7176
13:29:43.749 Training @ 307 epoch...
13:29:44.248   Training iter 50, batch loss 0.1912, batch acc 0.7212
13:29:44.736   Training iter 100, batch loss 0.1910, batch acc 0.7216
13:29:45.228   Training iter 150, batch loss 0.1916, batch acc 0.7190
13:29:45.706   Training iter 200, batch loss 0.1879, batch acc 0.7234
13:29:46.196   Training iter 250, batch loss 0.1914, batch acc 0.7166
13:29:46.680   Training iter 300, batch loss 0.1900, batch acc 0.7214
13:29:47.167   Training iter 350, batch loss 0.1922, batch acc 0.7164
13:29:47.659   Training iter 400, batch loss 0.1891, batch acc 0.7252
13:29:48.125   Training iter 450, batch loss 0.1941, batch acc 0.7118
13:29:48.588   Training iter 500, batch loss 0.1922, batch acc 0.7198
13:29:49.056   Training iter 550, batch loss 0.1905, batch acc 0.7202
13:29:49.530   Training iter 600, batch loss 0.1866, batch acc 0.7288
13:29:49.532 Training @ 308 epoch...
13:29:50.047   Training iter 50, batch loss 0.1935, batch acc 0.7116
13:29:50.558   Training iter 100, batch loss 0.1886, batch acc 0.7244
13:29:51.048   Training iter 150, batch loss 0.1890, batch acc 0.7214
13:29:51.524   Training iter 200, batch loss 0.1920, batch acc 0.7220
13:29:51.982   Training iter 250, batch loss 0.1903, batch acc 0.7174
13:29:52.458   Training iter 300, batch loss 0.1910, batch acc 0.7188
13:29:52.946   Training iter 350, batch loss 0.1909, batch acc 0.7200
13:29:53.443   Training iter 400, batch loss 0.1914, batch acc 0.7204
13:29:53.926   Training iter 450, batch loss 0.1920, batch acc 0.7186
13:29:54.433   Training iter 500, batch loss 0.1886, batch acc 0.7250
13:29:54.946   Training iter 550, batch loss 0.1936, batch acc 0.7152
13:29:55.463   Training iter 600, batch loss 0.1869, batch acc 0.7304
13:29:55.465 Training @ 309 epoch...
13:29:55.968   Training iter 50, batch loss 0.1890, batch acc 0.7232
13:29:56.475   Training iter 100, batch loss 0.1877, batch acc 0.7272
13:29:56.971   Training iter 150, batch loss 0.1922, batch acc 0.7166
13:29:57.496   Training iter 200, batch loss 0.1912, batch acc 0.7196
13:29:58.018   Training iter 250, batch loss 0.1878, batch acc 0.7250
13:29:58.535   Training iter 300, batch loss 0.1919, batch acc 0.7194
13:29:59.060   Training iter 350, batch loss 0.1902, batch acc 0.7210
13:29:59.584   Training iter 400, batch loss 0.1940, batch acc 0.7166
13:30:00.077   Training iter 450, batch loss 0.1921, batch acc 0.7182
13:30:00.585   Training iter 500, batch loss 0.1843, batch acc 0.7302
13:30:01.069   Training iter 550, batch loss 0.1942, batch acc 0.7168
13:30:01.627   Training iter 600, batch loss 0.1928, batch acc 0.7116
13:30:01.629 Training @ 310 epoch...
13:30:02.160   Training iter 50, batch loss 0.1956, batch acc 0.7120
13:30:02.717   Training iter 100, batch loss 0.1913, batch acc 0.7154
13:30:03.261   Training iter 150, batch loss 0.1876, batch acc 0.7282
13:30:03.796   Training iter 200, batch loss 0.1925, batch acc 0.7176
13:30:04.355   Training iter 250, batch loss 0.1869, batch acc 0.7308
13:30:04.882   Training iter 300, batch loss 0.1873, batch acc 0.7258
13:30:05.428   Training iter 350, batch loss 0.1900, batch acc 0.7234
13:30:05.960   Training iter 400, batch loss 0.1961, batch acc 0.7096
13:30:06.504   Training iter 450, batch loss 0.1892, batch acc 0.7250
13:30:07.046   Training iter 500, batch loss 0.1910, batch acc 0.7190
13:30:07.581   Training iter 550, batch loss 0.1913, batch acc 0.7174
13:30:08.107   Training iter 600, batch loss 0.1883, batch acc 0.7212
13:30:08.109 Testing @ 310 epoch...
13:30:08.148     Testing, total mean loss 0.18989, total acc 0.71730
13:30:08.148 Training @ 311 epoch...
13:30:08.680   Training iter 50, batch loss 0.1865, batch acc 0.7292
13:30:09.186   Training iter 100, batch loss 0.1899, batch acc 0.7202
13:30:09.697   Training iter 150, batch loss 0.1914, batch acc 0.7188
13:30:10.222   Training iter 200, batch loss 0.1878, batch acc 0.7246
13:30:10.749   Training iter 250, batch loss 0.1958, batch acc 0.7100
13:30:11.232   Training iter 300, batch loss 0.1863, batch acc 0.7278
13:30:11.771   Training iter 350, batch loss 0.1876, batch acc 0.7282
13:30:12.309   Training iter 400, batch loss 0.1971, batch acc 0.7096
13:30:12.874   Training iter 450, batch loss 0.1908, batch acc 0.7236
13:30:13.435   Training iter 500, batch loss 0.1930, batch acc 0.7102
13:30:13.943   Training iter 550, batch loss 0.1896, batch acc 0.7252
13:30:14.491   Training iter 600, batch loss 0.1914, batch acc 0.7176
13:30:14.492 Training @ 312 epoch...
13:30:15.073   Training iter 50, batch loss 0.1908, batch acc 0.7188
13:30:15.631   Training iter 100, batch loss 0.1935, batch acc 0.7138
13:30:16.171   Training iter 150, batch loss 0.1872, batch acc 0.7280
13:30:16.698   Training iter 200, batch loss 0.1891, batch acc 0.7216
13:30:17.230   Training iter 250, batch loss 0.1852, batch acc 0.7342
13:30:17.745   Training iter 300, batch loss 0.1851, batch acc 0.7304
13:30:18.253   Training iter 350, batch loss 0.1956, batch acc 0.7080
13:30:18.765   Training iter 400, batch loss 0.1936, batch acc 0.7198
13:30:19.285   Training iter 450, batch loss 0.1898, batch acc 0.7194
13:30:19.821   Training iter 500, batch loss 0.1897, batch acc 0.7194
13:30:20.340   Training iter 550, batch loss 0.1953, batch acc 0.7134
13:30:20.846   Training iter 600, batch loss 0.1918, batch acc 0.7200
13:30:20.848 Training @ 313 epoch...
13:30:21.363   Training iter 50, batch loss 0.1878, batch acc 0.7270
13:30:21.875   Training iter 100, batch loss 0.1927, batch acc 0.7158
13:30:22.402   Training iter 150, batch loss 0.1944, batch acc 0.7116
13:30:22.939   Training iter 200, batch loss 0.1838, batch acc 0.7358
13:30:23.446   Training iter 250, batch loss 0.1884, batch acc 0.7254
13:30:23.944   Training iter 300, batch loss 0.1949, batch acc 0.7164
13:30:24.442   Training iter 350, batch loss 0.1899, batch acc 0.7184
13:30:24.964   Training iter 400, batch loss 0.1882, batch acc 0.7218
13:30:25.502   Training iter 450, batch loss 0.1942, batch acc 0.7152
13:30:26.037   Training iter 500, batch loss 0.1907, batch acc 0.7198
13:30:26.579   Training iter 550, batch loss 0.1900, batch acc 0.7238
13:30:27.123   Training iter 600, batch loss 0.1914, batch acc 0.7154
13:30:27.125 Training @ 314 epoch...
13:30:27.699   Training iter 50, batch loss 0.1935, batch acc 0.7142
13:30:28.259   Training iter 100, batch loss 0.1887, batch acc 0.7248
13:30:28.810   Training iter 150, batch loss 0.1943, batch acc 0.7084
13:30:29.370   Training iter 200, batch loss 0.1872, batch acc 0.7272
13:30:29.927   Training iter 250, batch loss 0.1890, batch acc 0.7266
13:30:30.473   Training iter 300, batch loss 0.1873, batch acc 0.7236
13:30:30.999   Training iter 350, batch loss 0.1882, batch acc 0.7244
13:30:31.524   Training iter 400, batch loss 0.1883, batch acc 0.7220
13:30:32.043   Training iter 450, batch loss 0.1944, batch acc 0.7136
13:30:32.550   Training iter 500, batch loss 0.1925, batch acc 0.7220
13:30:33.053   Training iter 550, batch loss 0.1960, batch acc 0.7102
13:30:33.545   Training iter 600, batch loss 0.1869, batch acc 0.7280
13:30:33.546 Training @ 315 epoch...
13:30:34.044   Training iter 50, batch loss 0.1884, batch acc 0.7272
13:30:34.522   Training iter 100, batch loss 0.1903, batch acc 0.7184
13:30:35.024   Training iter 150, batch loss 0.1891, batch acc 0.7216
13:30:35.504   Training iter 200, batch loss 0.1900, batch acc 0.7224
13:30:36.032   Training iter 250, batch loss 0.1919, batch acc 0.7184
13:30:36.555   Training iter 300, batch loss 0.1876, batch acc 0.7234
13:30:37.074   Training iter 350, batch loss 0.1925, batch acc 0.7160
13:30:37.580   Training iter 400, batch loss 0.1932, batch acc 0.7142
13:30:38.095   Training iter 450, batch loss 0.1956, batch acc 0.7146
13:30:38.589   Training iter 500, batch loss 0.1863, batch acc 0.7286
13:30:39.087   Training iter 550, batch loss 0.1882, batch acc 0.7262
13:30:39.602   Training iter 600, batch loss 0.1930, batch acc 0.7158
13:30:39.604 Testing @ 315 epoch...
13:30:39.642     Testing, total mean loss 0.18985, total acc 0.71740
13:30:39.643 Training @ 316 epoch...
13:30:40.173   Training iter 50, batch loss 0.1944, batch acc 0.7124
13:30:40.685   Training iter 100, batch loss 0.1885, batch acc 0.7228
13:30:41.215   Training iter 150, batch loss 0.1887, batch acc 0.7242
13:30:41.733   Training iter 200, batch loss 0.1891, batch acc 0.7274
13:30:42.247   Training iter 250, batch loss 0.1946, batch acc 0.7110
13:30:42.827   Training iter 300, batch loss 0.1935, batch acc 0.7118
13:30:43.382   Training iter 350, batch loss 0.1923, batch acc 0.7188
13:30:43.954   Training iter 400, batch loss 0.1893, batch acc 0.7258
13:30:44.500   Training iter 450, batch loss 0.1856, batch acc 0.7294
13:30:45.062   Training iter 500, batch loss 0.1943, batch acc 0.7138
13:30:45.611   Training iter 550, batch loss 0.1858, batch acc 0.7282
13:30:46.174   Training iter 600, batch loss 0.1897, batch acc 0.7208
13:30:46.176 Training @ 317 epoch...
13:30:46.730   Training iter 50, batch loss 0.1963, batch acc 0.7066
13:30:47.294   Training iter 100, batch loss 0.1924, batch acc 0.7200
13:30:47.847   Training iter 150, batch loss 0.1862, batch acc 0.7348
13:30:48.390   Training iter 200, batch loss 0.1953, batch acc 0.7148
13:30:48.898   Training iter 250, batch loss 0.1881, batch acc 0.7212
13:30:49.393   Training iter 300, batch loss 0.1898, batch acc 0.7194
13:30:49.901   Training iter 350, batch loss 0.1875, batch acc 0.7256
13:30:50.410   Training iter 400, batch loss 0.1903, batch acc 0.7208
13:30:50.913   Training iter 450, batch loss 0.1924, batch acc 0.7164
13:30:51.410   Training iter 500, batch loss 0.1860, batch acc 0.7284
13:30:51.905   Training iter 550, batch loss 0.1901, batch acc 0.7198
13:30:52.397   Training iter 600, batch loss 0.1912, batch acc 0.7190
13:30:52.399 Training @ 318 epoch...
13:30:52.895   Training iter 50, batch loss 0.1854, batch acc 0.7300
13:30:53.394   Training iter 100, batch loss 0.1886, batch acc 0.7234
13:30:53.888   Training iter 150, batch loss 0.1892, batch acc 0.7216
13:30:54.361   Training iter 200, batch loss 0.1899, batch acc 0.7230
13:30:54.835   Training iter 250, batch loss 0.1904, batch acc 0.7268
13:30:55.310   Training iter 300, batch loss 0.1988, batch acc 0.7076
13:30:55.810   Training iter 350, batch loss 0.1918, batch acc 0.7156
13:30:56.308   Training iter 400, batch loss 0.1920, batch acc 0.7160
13:30:56.788   Training iter 450, batch loss 0.1920, batch acc 0.7158
13:30:57.285   Training iter 500, batch loss 0.1872, batch acc 0.7260
13:30:57.770   Training iter 550, batch loss 0.1923, batch acc 0.7204
13:30:58.282   Training iter 600, batch loss 0.1878, batch acc 0.7210
13:30:58.284 Training @ 319 epoch...
13:30:58.816   Training iter 50, batch loss 0.1897, batch acc 0.7240
13:30:59.329   Training iter 100, batch loss 0.1916, batch acc 0.7188
13:30:59.850   Training iter 150, batch loss 0.1869, batch acc 0.7262
13:31:00.375   Training iter 200, batch loss 0.1876, batch acc 0.7304
13:31:00.900   Training iter 250, batch loss 0.1900, batch acc 0.7172
13:31:01.421   Training iter 300, batch loss 0.1882, batch acc 0.7212
13:31:01.958   Training iter 350, batch loss 0.1962, batch acc 0.7110
13:31:02.530   Training iter 400, batch loss 0.1879, batch acc 0.7262
13:31:03.080   Training iter 450, batch loss 0.1906, batch acc 0.7156
13:31:03.607   Training iter 500, batch loss 0.1906, batch acc 0.7252
13:31:04.125   Training iter 550, batch loss 0.1900, batch acc 0.7200
13:31:04.634   Training iter 600, batch loss 0.1960, batch acc 0.7116
13:31:04.636 Training @ 320 epoch...
13:31:05.148   Training iter 50, batch loss 0.1925, batch acc 0.7212
13:31:05.638   Training iter 100, batch loss 0.1906, batch acc 0.7206
13:31:06.119   Training iter 150, batch loss 0.1963, batch acc 0.7066
13:31:06.590   Training iter 200, batch loss 0.1806, batch acc 0.7386
13:31:07.066   Training iter 250, batch loss 0.1911, batch acc 0.7210
13:31:07.542   Training iter 300, batch loss 0.1952, batch acc 0.7130
13:31:08.026   Training iter 350, batch loss 0.1871, batch acc 0.7230
13:31:08.505   Training iter 400, batch loss 0.1941, batch acc 0.7120
13:31:08.967   Training iter 450, batch loss 0.1889, batch acc 0.7262
13:31:09.431   Training iter 500, batch loss 0.1882, batch acc 0.7266
13:31:09.913   Training iter 550, batch loss 0.1895, batch acc 0.7214
13:31:10.407   Training iter 600, batch loss 0.1911, batch acc 0.7182
13:31:10.408 Testing @ 320 epoch...
13:31:10.446     Testing, total mean loss 0.18973, total acc 0.71740
13:31:10.446 Training @ 321 epoch...
13:31:10.939   Training iter 50, batch loss 0.1916, batch acc 0.7162
13:31:11.409   Training iter 100, batch loss 0.1872, batch acc 0.7284
13:31:11.884   Training iter 150, batch loss 0.1898, batch acc 0.7216
13:31:12.412   Training iter 200, batch loss 0.1942, batch acc 0.7154
13:31:12.978   Training iter 250, batch loss 0.1904, batch acc 0.7238
13:31:13.569   Training iter 300, batch loss 0.1881, batch acc 0.7226
13:31:14.107   Training iter 350, batch loss 0.1931, batch acc 0.7132
13:31:14.584   Training iter 400, batch loss 0.1973, batch acc 0.7060
13:31:15.080   Training iter 450, batch loss 0.1888, batch acc 0.7244
13:31:15.589   Training iter 500, batch loss 0.1882, batch acc 0.7278
13:31:16.082   Training iter 550, batch loss 0.1901, batch acc 0.7228
13:31:16.567   Training iter 600, batch loss 0.1861, batch acc 0.7258
13:31:16.569 Training @ 322 epoch...
13:31:17.076   Training iter 50, batch loss 0.1925, batch acc 0.7168
13:31:17.557   Training iter 100, batch loss 0.1914, batch acc 0.7214
13:31:18.046   Training iter 150, batch loss 0.1928, batch acc 0.7160
13:31:18.534   Training iter 200, batch loss 0.1855, batch acc 0.7300
13:31:19.034   Training iter 250, batch loss 0.1951, batch acc 0.7130
13:31:19.507   Training iter 300, batch loss 0.1890, batch acc 0.7214
13:31:19.999   Training iter 350, batch loss 0.1893, batch acc 0.7202
13:31:20.513   Training iter 400, batch loss 0.1891, batch acc 0.7234
13:31:21.005   Training iter 450, batch loss 0.1906, batch acc 0.7238
13:31:21.497   Training iter 500, batch loss 0.1882, batch acc 0.7224
13:31:21.979   Training iter 550, batch loss 0.1880, batch acc 0.7230
13:31:22.490   Training iter 600, batch loss 0.1932, batch acc 0.7170
13:31:22.492 Training @ 323 epoch...
13:31:23.020   Training iter 50, batch loss 0.1864, batch acc 0.7282
13:31:23.552   Training iter 100, batch loss 0.1938, batch acc 0.7126
13:31:24.068   Training iter 150, batch loss 0.1884, batch acc 0.7254
13:31:24.592   Training iter 200, batch loss 0.1941, batch acc 0.7132
13:31:25.143   Training iter 250, batch loss 0.1918, batch acc 0.7178
13:31:25.708   Training iter 300, batch loss 0.1940, batch acc 0.7146
13:31:26.278   Training iter 350, batch loss 0.1906, batch acc 0.7196
13:31:26.830   Training iter 400, batch loss 0.1913, batch acc 0.7194
13:31:27.396   Training iter 450, batch loss 0.1878, batch acc 0.7258
13:31:27.946   Training iter 500, batch loss 0.1897, batch acc 0.7206
13:31:28.503   Training iter 550, batch loss 0.1837, batch acc 0.7346
13:31:29.053   Training iter 600, batch loss 0.1926, batch acc 0.7184
13:31:29.055 Training @ 324 epoch...
13:31:29.598   Training iter 50, batch loss 0.1947, batch acc 0.7154
13:31:30.160   Training iter 100, batch loss 0.1919, batch acc 0.7158
13:31:30.713   Training iter 150, batch loss 0.1888, batch acc 0.7202
13:31:31.235   Training iter 200, batch loss 0.1857, batch acc 0.7304
13:31:31.760   Training iter 250, batch loss 0.1907, batch acc 0.7184
13:31:32.297   Training iter 300, batch loss 0.1872, batch acc 0.7290
13:31:32.828   Training iter 350, batch loss 0.1884, batch acc 0.7236
13:31:33.362   Training iter 400, batch loss 0.1895, batch acc 0.7226
13:31:33.880   Training iter 450, batch loss 0.1955, batch acc 0.7056
13:31:34.395   Training iter 500, batch loss 0.1912, batch acc 0.7258
13:31:34.906   Training iter 550, batch loss 0.1906, batch acc 0.7190
13:31:35.435   Training iter 600, batch loss 0.1899, batch acc 0.7228
13:31:35.436 Training @ 325 epoch...
13:31:35.945   Training iter 50, batch loss 0.1913, batch acc 0.7224
13:31:36.444   Training iter 100, batch loss 0.1923, batch acc 0.7140
13:31:36.948   Training iter 150, batch loss 0.1902, batch acc 0.7232
13:31:37.459   Training iter 200, batch loss 0.1898, batch acc 0.7190
13:31:37.968   Training iter 250, batch loss 0.1906, batch acc 0.7184
13:31:38.478   Training iter 300, batch loss 0.1883, batch acc 0.7258
13:31:38.971   Training iter 350, batch loss 0.1923, batch acc 0.7180
13:31:39.469   Training iter 400, batch loss 0.1942, batch acc 0.7178
13:31:39.973   Training iter 450, batch loss 0.1905, batch acc 0.7188
13:31:40.470   Training iter 500, batch loss 0.1872, batch acc 0.7274
13:31:40.953   Training iter 550, batch loss 0.1895, batch acc 0.7198
13:31:41.468   Training iter 600, batch loss 0.1877, batch acc 0.7236
13:31:41.470 Testing @ 325 epoch...
13:31:41.507     Testing, total mean loss 0.18968, total acc 0.71740
13:31:41.507 Training @ 326 epoch...
13:31:42.040   Training iter 50, batch loss 0.1857, batch acc 0.7294
13:31:42.558   Training iter 100, batch loss 0.1949, batch acc 0.7102
13:31:43.055   Training iter 150, batch loss 0.1902, batch acc 0.7210
13:31:43.543   Training iter 200, batch loss 0.1870, batch acc 0.7250
13:31:44.045   Training iter 250, batch loss 0.1930, batch acc 0.7154
13:31:44.549   Training iter 300, batch loss 0.1903, batch acc 0.7192
13:31:45.055   Training iter 350, batch loss 0.1900, batch acc 0.7218
13:31:45.580   Training iter 400, batch loss 0.1965, batch acc 0.7090
13:31:46.098   Training iter 450, batch loss 0.1918, batch acc 0.7234
13:31:46.610   Training iter 500, batch loss 0.1914, batch acc 0.7150
13:31:47.132   Training iter 550, batch loss 0.1884, batch acc 0.7270
13:31:47.660   Training iter 600, batch loss 0.1846, batch acc 0.7306
13:31:47.662 Training @ 327 epoch...
13:31:48.181   Training iter 50, batch loss 0.1927, batch acc 0.7170
13:31:48.687   Training iter 100, batch loss 0.1894, batch acc 0.7244
13:31:49.196   Training iter 150, batch loss 0.1930, batch acc 0.7184
13:31:49.706   Training iter 200, batch loss 0.1904, batch acc 0.7166
13:31:50.224   Training iter 250, batch loss 0.1908, batch acc 0.7214
13:31:50.744   Training iter 300, batch loss 0.1894, batch acc 0.7236
13:31:51.269   Training iter 350, batch loss 0.1916, batch acc 0.7150
13:31:51.786   Training iter 400, batch loss 0.1954, batch acc 0.7108
13:31:52.316   Training iter 450, batch loss 0.1909, batch acc 0.7206
13:31:52.836   Training iter 500, batch loss 0.1848, batch acc 0.7324
13:31:53.359   Training iter 550, batch loss 0.1867, batch acc 0.7260
13:31:53.879   Training iter 600, batch loss 0.1884, batch acc 0.7214
13:31:53.881 Training @ 328 epoch...
13:31:54.422   Training iter 50, batch loss 0.1875, batch acc 0.7220
13:31:54.952   Training iter 100, batch loss 0.1902, batch acc 0.7252
13:31:55.465   Training iter 150, batch loss 0.1959, batch acc 0.7100
13:31:55.946   Training iter 200, batch loss 0.1920, batch acc 0.7184
13:31:56.438   Training iter 250, batch loss 0.1851, batch acc 0.7286
13:31:56.927   Training iter 300, batch loss 0.1960, batch acc 0.7086
13:31:57.433   Training iter 350, batch loss 0.1905, batch acc 0.7180
13:31:57.935   Training iter 400, batch loss 0.1876, batch acc 0.7318
13:31:58.383   Training iter 450, batch loss 0.1859, batch acc 0.7294
13:31:58.829   Training iter 500, batch loss 0.1950, batch acc 0.7116
13:31:59.281   Training iter 550, batch loss 0.1888, batch acc 0.7242
13:31:59.736   Training iter 600, batch loss 0.1888, batch acc 0.7208
13:31:59.738 Training @ 329 epoch...
13:32:00.195   Training iter 50, batch loss 0.1905, batch acc 0.7220
13:32:00.653   Training iter 100, batch loss 0.1914, batch acc 0.7162
13:32:01.119   Training iter 150, batch loss 0.1896, batch acc 0.7246
13:32:01.641   Training iter 200, batch loss 0.1833, batch acc 0.7354
13:32:02.162   Training iter 250, batch loss 0.1890, batch acc 0.7212
13:32:02.737   Training iter 300, batch loss 0.1863, batch acc 0.7248
13:32:03.297   Training iter 350, batch loss 0.1981, batch acc 0.7086
13:32:03.816   Training iter 400, batch loss 0.1933, batch acc 0.7134
13:32:04.356   Training iter 450, batch loss 0.1878, batch acc 0.7304
13:32:04.868   Training iter 500, batch loss 0.1915, batch acc 0.7188
13:32:05.383   Training iter 550, batch loss 0.1917, batch acc 0.7164
13:32:05.945   Training iter 600, batch loss 0.1905, batch acc 0.7188
13:32:05.947 Training @ 330 epoch...
13:32:06.530   Training iter 50, batch loss 0.1945, batch acc 0.7168
13:32:07.094   Training iter 100, batch loss 0.1893, batch acc 0.7232
13:32:07.623   Training iter 150, batch loss 0.1933, batch acc 0.7150
13:32:08.125   Training iter 200, batch loss 0.1869, batch acc 0.7264
13:32:08.616   Training iter 250, batch loss 0.1894, batch acc 0.7242
13:32:09.116   Training iter 300, batch loss 0.1878, batch acc 0.7182
13:32:09.615   Training iter 350, batch loss 0.1881, batch acc 0.7250
13:32:10.124   Training iter 400, batch loss 0.1930, batch acc 0.7164
13:32:10.626   Training iter 450, batch loss 0.1849, batch acc 0.7288
13:32:11.100   Training iter 500, batch loss 0.1874, batch acc 0.7276
13:32:11.593   Training iter 550, batch loss 0.1914, batch acc 0.7182
13:32:12.097   Training iter 600, batch loss 0.1969, batch acc 0.7080
13:32:12.099 Testing @ 330 epoch...
13:32:12.138     Testing, total mean loss 0.18956, total acc 0.71720
13:32:12.138 Training @ 331 epoch...
13:32:12.650   Training iter 50, batch loss 0.1892, batch acc 0.7270
13:32:13.152   Training iter 100, batch loss 0.1933, batch acc 0.7100
13:32:13.636   Training iter 150, batch loss 0.1975, batch acc 0.7064
13:32:14.125   Training iter 200, batch loss 0.1867, batch acc 0.7274
13:32:14.610   Training iter 250, batch loss 0.1921, batch acc 0.7184
13:32:15.124   Training iter 300, batch loss 0.1910, batch acc 0.7208
13:32:15.641   Training iter 350, batch loss 0.1888, batch acc 0.7218
13:32:16.166   Training iter 400, batch loss 0.1866, batch acc 0.7290
13:32:16.680   Training iter 450, batch loss 0.1897, batch acc 0.7190
13:32:17.190   Training iter 500, batch loss 0.1877, batch acc 0.7246
13:32:17.702   Training iter 550, batch loss 0.1893, batch acc 0.7218
13:32:18.252   Training iter 600, batch loss 0.1908, batch acc 0.7220
13:32:18.254 Training @ 332 epoch...
13:32:18.791   Training iter 50, batch loss 0.1889, batch acc 0.7222
13:32:19.331   Training iter 100, batch loss 0.1939, batch acc 0.7138
13:32:19.883   Training iter 150, batch loss 0.1892, batch acc 0.7230
13:32:20.443   Training iter 200, batch loss 0.1884, batch acc 0.7280
13:32:21.004   Training iter 250, batch loss 0.1875, batch acc 0.7278
13:32:21.552   Training iter 300, batch loss 0.1910, batch acc 0.7194
13:32:22.106   Training iter 350, batch loss 0.1898, batch acc 0.7230
13:32:22.686   Training iter 400, batch loss 0.1932, batch acc 0.7116
13:32:23.226   Training iter 450, batch loss 0.1895, batch acc 0.7208
13:32:23.757   Training iter 500, batch loss 0.1888, batch acc 0.7252
13:32:24.284   Training iter 550, batch loss 0.1914, batch acc 0.7194
13:32:24.806   Training iter 600, batch loss 0.1909, batch acc 0.7150
13:32:24.808 Training @ 333 epoch...
13:32:25.333   Training iter 50, batch loss 0.1883, batch acc 0.7262
13:32:25.854   Training iter 100, batch loss 0.1906, batch acc 0.7200
13:32:26.381   Training iter 150, batch loss 0.1940, batch acc 0.7132
13:32:26.909   Training iter 200, batch loss 0.1952, batch acc 0.7104
13:32:27.441   Training iter 250, batch loss 0.1915, batch acc 0.7184
13:32:27.968   Training iter 300, batch loss 0.1942, batch acc 0.7120
13:32:28.489   Training iter 350, batch loss 0.1856, batch acc 0.7296
13:32:29.020   Training iter 400, batch loss 0.1924, batch acc 0.7190
13:32:29.556   Training iter 450, batch loss 0.1854, batch acc 0.7292
13:32:30.081   Training iter 500, batch loss 0.1855, batch acc 0.7326
13:32:30.588   Training iter 550, batch loss 0.1876, batch acc 0.7212
13:32:31.092   Training iter 600, batch loss 0.1919, batch acc 0.7150
13:32:31.093 Training @ 334 epoch...
13:32:31.586   Training iter 50, batch loss 0.1918, batch acc 0.7188
13:32:32.119   Training iter 100, batch loss 0.1933, batch acc 0.7142
13:32:32.660   Training iter 150, batch loss 0.1879, batch acc 0.7254
13:32:33.209   Training iter 200, batch loss 0.1856, batch acc 0.7302
13:32:33.752   Training iter 250, batch loss 0.1877, batch acc 0.7242
13:32:34.315   Training iter 300, batch loss 0.1899, batch acc 0.7188
13:32:34.869   Training iter 350, batch loss 0.1929, batch acc 0.7174
13:32:35.403   Training iter 400, batch loss 0.1895, batch acc 0.7204
13:32:35.939   Training iter 450, batch loss 0.1904, batch acc 0.7176
13:32:36.485   Training iter 500, batch loss 0.1898, batch acc 0.7254
13:32:37.027   Training iter 550, batch loss 0.1936, batch acc 0.7172
13:32:37.575   Training iter 600, batch loss 0.1896, batch acc 0.7226
13:32:37.577 Training @ 335 epoch...
13:32:38.108   Training iter 50, batch loss 0.1862, batch acc 0.7308
13:32:38.650   Training iter 100, batch loss 0.1894, batch acc 0.7230
13:32:39.196   Training iter 150, batch loss 0.1924, batch acc 0.7154
13:32:39.752   Training iter 200, batch loss 0.1889, batch acc 0.7224
13:32:40.288   Training iter 250, batch loss 0.1893, batch acc 0.7184
13:32:40.790   Training iter 300, batch loss 0.1947, batch acc 0.7102
13:32:41.282   Training iter 350, batch loss 0.1905, batch acc 0.7260
13:32:41.765   Training iter 400, batch loss 0.1893, batch acc 0.7214
13:32:42.278   Training iter 450, batch loss 0.1876, batch acc 0.7264
13:32:42.770   Training iter 500, batch loss 0.1924, batch acc 0.7186
13:32:43.260   Training iter 550, batch loss 0.1877, batch acc 0.7236
13:32:43.753   Training iter 600, batch loss 0.1934, batch acc 0.7132
13:32:43.754 Testing @ 335 epoch...
13:32:43.792     Testing, total mean loss 0.18947, total acc 0.71780
13:32:43.792 Training @ 336 epoch...
13:32:44.315   Training iter 50, batch loss 0.1956, batch acc 0.7096
13:32:44.820   Training iter 100, batch loss 0.1919, batch acc 0.7172
13:32:45.317   Training iter 150, batch loss 0.1812, batch acc 0.7422
13:32:45.817   Training iter 200, batch loss 0.1893, batch acc 0.7258
13:32:46.304   Training iter 250, batch loss 0.1942, batch acc 0.7092
13:32:46.786   Training iter 300, batch loss 0.1922, batch acc 0.7124
13:32:47.273   Training iter 350, batch loss 0.1929, batch acc 0.7140
13:32:47.789   Training iter 400, batch loss 0.1900, batch acc 0.7202
13:32:48.283   Training iter 450, batch loss 0.1894, batch acc 0.7260
13:32:48.771   Training iter 500, batch loss 0.1933, batch acc 0.7164
13:32:49.277   Training iter 550, batch loss 0.1878, batch acc 0.7250
13:32:49.780   Training iter 600, batch loss 0.1841, batch acc 0.7338
13:32:49.781 Training @ 337 epoch...
13:32:50.341   Training iter 50, batch loss 0.1879, batch acc 0.7248
13:32:50.875   Training iter 100, batch loss 0.1921, batch acc 0.7156
13:32:51.405   Training iter 150, batch loss 0.1910, batch acc 0.7218
13:32:51.911   Training iter 200, batch loss 0.1832, batch acc 0.7332
13:32:52.427   Training iter 250, batch loss 0.1861, batch acc 0.7270
13:32:52.956   Training iter 300, batch loss 0.1897, batch acc 0.7232
13:32:53.467   Training iter 350, batch loss 0.1915, batch acc 0.7204
13:32:53.969   Training iter 400, batch loss 0.1900, batch acc 0.7218
13:32:54.476   Training iter 450, batch loss 0.1947, batch acc 0.7104
13:32:54.991   Training iter 500, batch loss 0.1891, batch acc 0.7218
13:32:55.515   Training iter 550, batch loss 0.1920, batch acc 0.7156
13:32:56.032   Training iter 600, batch loss 0.1942, batch acc 0.7156
13:32:56.034 Training @ 338 epoch...
13:32:56.561   Training iter 50, batch loss 0.1887, batch acc 0.7240
13:32:57.074   Training iter 100, batch loss 0.1879, batch acc 0.7256
13:32:57.584   Training iter 150, batch loss 0.1889, batch acc 0.7232
13:32:58.095   Training iter 200, batch loss 0.1920, batch acc 0.7172
13:32:58.612   Training iter 250, batch loss 0.1911, batch acc 0.7146
13:32:59.132   Training iter 300, batch loss 0.1936, batch acc 0.7142
13:32:59.630   Training iter 350, batch loss 0.1920, batch acc 0.7180
13:33:00.125   Training iter 400, batch loss 0.1871, batch acc 0.7278
13:33:00.637   Training iter 450, batch loss 0.1876, batch acc 0.7254
13:33:01.187   Training iter 500, batch loss 0.1880, batch acc 0.7258
13:33:01.747   Training iter 550, batch loss 0.1926, batch acc 0.7170
13:33:02.322   Training iter 600, batch loss 0.1918, batch acc 0.7182
13:33:02.324 Training @ 339 epoch...
13:33:02.905   Training iter 50, batch loss 0.1948, batch acc 0.7108
13:33:03.451   Training iter 100, batch loss 0.1861, batch acc 0.7238
13:33:03.969   Training iter 150, batch loss 0.1880, batch acc 0.7240
13:33:04.502   Training iter 200, batch loss 0.1919, batch acc 0.7184
13:33:05.027   Training iter 250, batch loss 0.1873, batch acc 0.7276
13:33:05.549   Training iter 300, batch loss 0.1904, batch acc 0.7222
13:33:06.066   Training iter 350, batch loss 0.1889, batch acc 0.7220
13:33:06.570   Training iter 400, batch loss 0.1880, batch acc 0.7272
13:33:07.069   Training iter 450, batch loss 0.1943, batch acc 0.7134
13:33:07.571   Training iter 500, batch loss 0.1877, batch acc 0.7252
13:33:08.093   Training iter 550, batch loss 0.1908, batch acc 0.7194
13:33:08.632   Training iter 600, batch loss 0.1929, batch acc 0.7156
13:33:08.634 Training @ 340 epoch...
13:33:09.173   Training iter 50, batch loss 0.1928, batch acc 0.7174
13:33:09.694   Training iter 100, batch loss 0.1860, batch acc 0.7260
13:33:10.215   Training iter 150, batch loss 0.1888, batch acc 0.7250
13:33:10.740   Training iter 200, batch loss 0.1866, batch acc 0.7274
13:33:11.256   Training iter 250, batch loss 0.1872, batch acc 0.7274
13:33:11.751   Training iter 300, batch loss 0.1835, batch acc 0.7322
13:33:12.276   Training iter 350, batch loss 0.1953, batch acc 0.7084
13:33:12.802   Training iter 400, batch loss 0.1910, batch acc 0.7210
13:33:13.317   Training iter 450, batch loss 0.1948, batch acc 0.7100
13:33:13.821   Training iter 500, batch loss 0.1948, batch acc 0.7124
13:33:14.334   Training iter 550, batch loss 0.1877, batch acc 0.7236
13:33:14.834   Training iter 600, batch loss 0.1922, batch acc 0.7178
13:33:14.836 Testing @ 340 epoch...
13:33:14.872     Testing, total mean loss 0.18937, total acc 0.71810
13:33:14.872 Training @ 341 epoch...
13:33:15.397   Training iter 50, batch loss 0.1919, batch acc 0.7196
13:33:15.914   Training iter 100, batch loss 0.1884, batch acc 0.7216
13:33:16.428   Training iter 150, batch loss 0.1898, batch acc 0.7170
13:33:16.945   Training iter 200, batch loss 0.1930, batch acc 0.7140
13:33:17.452   Training iter 250, batch loss 0.1947, batch acc 0.7156
13:33:17.965   Training iter 300, batch loss 0.1839, batch acc 0.7352
13:33:18.507   Training iter 350, batch loss 0.1928, batch acc 0.7152
13:33:19.043   Training iter 400, batch loss 0.1887, batch acc 0.7220
13:33:19.569   Training iter 450, batch loss 0.1884, batch acc 0.7220
13:33:20.096   Training iter 500, batch loss 0.1939, batch acc 0.7136
13:33:20.629   Training iter 550, batch loss 0.1886, batch acc 0.7262
13:33:21.151   Training iter 600, batch loss 0.1866, batch acc 0.7304
13:33:21.152 Training @ 342 epoch...
13:33:21.692   Training iter 50, batch loss 0.1919, batch acc 0.7184
13:33:22.232   Training iter 100, batch loss 0.1884, batch acc 0.7244
13:33:22.789   Training iter 150, batch loss 0.1939, batch acc 0.7126
13:33:23.354   Training iter 200, batch loss 0.1911, batch acc 0.7202
13:33:23.902   Training iter 250, batch loss 0.1889, batch acc 0.7228
13:33:24.448   Training iter 300, batch loss 0.1859, batch acc 0.7282
13:33:24.995   Training iter 350, batch loss 0.1908, batch acc 0.7230
13:33:25.561   Training iter 400, batch loss 0.1871, batch acc 0.7282
13:33:26.110   Training iter 450, batch loss 0.1943, batch acc 0.7090
13:33:26.635   Training iter 500, batch loss 0.1927, batch acc 0.7160
13:33:27.149   Training iter 550, batch loss 0.1878, batch acc 0.7250
13:33:27.668   Training iter 600, batch loss 0.1875, batch acc 0.7252
13:33:27.670 Training @ 343 epoch...
13:33:28.191   Training iter 50, batch loss 0.1902, batch acc 0.7208
13:33:28.669   Training iter 100, batch loss 0.1869, batch acc 0.7278
13:33:29.147   Training iter 150, batch loss 0.1916, batch acc 0.7176
13:33:29.639   Training iter 200, batch loss 0.1955, batch acc 0.7060
13:33:30.147   Training iter 250, batch loss 0.1930, batch acc 0.7134
13:33:30.683   Training iter 300, batch loss 0.1885, batch acc 0.7226
13:33:31.225   Training iter 350, batch loss 0.1874, batch acc 0.7254
13:33:31.776   Training iter 400, batch loss 0.1901, batch acc 0.7180
13:33:32.330   Training iter 450, batch loss 0.1876, batch acc 0.7250
13:33:32.869   Training iter 500, batch loss 0.1926, batch acc 0.7232
13:33:33.400   Training iter 550, batch loss 0.1876, batch acc 0.7262
13:33:33.905   Training iter 600, batch loss 0.1893, batch acc 0.7240
13:33:33.907 Training @ 344 epoch...
13:33:34.413   Training iter 50, batch loss 0.1877, batch acc 0.7286
13:33:34.926   Training iter 100, batch loss 0.1876, batch acc 0.7252
13:33:35.409   Training iter 150, batch loss 0.1905, batch acc 0.7202
13:33:35.860   Training iter 200, batch loss 0.1880, batch acc 0.7216
13:33:36.317   Training iter 250, batch loss 0.1934, batch acc 0.7146
13:33:36.769   Training iter 300, batch loss 0.1906, batch acc 0.7202
13:33:37.249   Training iter 350, batch loss 0.1866, batch acc 0.7306
13:33:37.734   Training iter 400, batch loss 0.1933, batch acc 0.7106
13:33:38.235   Training iter 450, batch loss 0.1916, batch acc 0.7160
13:33:38.765   Training iter 500, batch loss 0.1888, batch acc 0.7226
13:33:39.268   Training iter 550, batch loss 0.1889, batch acc 0.7242
13:33:39.748   Training iter 600, batch loss 0.1933, batch acc 0.7182
13:33:39.750 Training @ 345 epoch...
13:33:40.247   Training iter 50, batch loss 0.1907, batch acc 0.7210
13:33:40.737   Training iter 100, batch loss 0.1922, batch acc 0.7202
13:33:41.231   Training iter 150, batch loss 0.1915, batch acc 0.7132
13:33:41.725   Training iter 200, batch loss 0.1833, batch acc 0.7290
13:33:42.209   Training iter 250, batch loss 0.1957, batch acc 0.7096
13:33:42.719   Training iter 300, batch loss 0.1925, batch acc 0.7186
13:33:43.252   Training iter 350, batch loss 0.1894, batch acc 0.7214
13:33:43.756   Training iter 400, batch loss 0.1913, batch acc 0.7200
13:33:44.264   Training iter 450, batch loss 0.1915, batch acc 0.7216
13:33:44.740   Training iter 500, batch loss 0.1872, batch acc 0.7252
13:33:45.218   Training iter 550, batch loss 0.1875, batch acc 0.7248
13:33:45.686   Training iter 600, batch loss 0.1870, batch acc 0.7292
13:33:45.688 Testing @ 345 epoch...
13:33:45.725     Testing, total mean loss 0.18932, total acc 0.71850
13:33:45.725 Training @ 346 epoch...
13:33:46.197   Training iter 50, batch loss 0.1930, batch acc 0.7152
13:33:46.674   Training iter 100, batch loss 0.1918, batch acc 0.7206
13:33:47.151   Training iter 150, batch loss 0.1884, batch acc 0.7246
13:33:47.629   Training iter 200, batch loss 0.1904, batch acc 0.7166
13:33:48.113   Training iter 250, batch loss 0.1914, batch acc 0.7172
13:33:48.606   Training iter 300, batch loss 0.1873, batch acc 0.7254
13:33:49.096   Training iter 350, batch loss 0.1901, batch acc 0.7224
13:33:49.585   Training iter 400, batch loss 0.1897, batch acc 0.7172
13:33:50.071   Training iter 450, batch loss 0.1920, batch acc 0.7176
13:33:50.565   Training iter 500, batch loss 0.1876, batch acc 0.7272
13:33:51.101   Training iter 550, batch loss 0.1899, batch acc 0.7206
13:33:51.619   Training iter 600, batch loss 0.1881, batch acc 0.7274
13:33:51.621 Training @ 347 epoch...
13:33:52.135   Training iter 50, batch loss 0.1920, batch acc 0.7144
13:33:52.655   Training iter 100, batch loss 0.1939, batch acc 0.7140
13:33:53.167   Training iter 150, batch loss 0.1921, batch acc 0.7174
13:33:53.694   Training iter 200, batch loss 0.1857, batch acc 0.7326
13:33:54.214   Training iter 250, batch loss 0.1910, batch acc 0.7178
13:33:54.756   Training iter 300, batch loss 0.1859, batch acc 0.7304
13:33:55.292   Training iter 350, batch loss 0.1898, batch acc 0.7192
13:33:55.834   Training iter 400, batch loss 0.1884, batch acc 0.7258
13:33:56.365   Training iter 450, batch loss 0.1898, batch acc 0.7176
13:33:56.894   Training iter 500, batch loss 0.1927, batch acc 0.7170
13:33:57.430   Training iter 550, batch loss 0.1858, batch acc 0.7304
13:33:57.963   Training iter 600, batch loss 0.1924, batch acc 0.7166
13:33:57.965 Training @ 348 epoch...
13:33:58.491   Training iter 50, batch loss 0.1913, batch acc 0.7148
13:33:59.009   Training iter 100, batch loss 0.1940, batch acc 0.7196
13:33:59.527   Training iter 150, batch loss 0.1883, batch acc 0.7236
13:34:00.062   Training iter 200, batch loss 0.1840, batch acc 0.7308
13:34:00.597   Training iter 250, batch loss 0.1914, batch acc 0.7192
13:34:01.126   Training iter 300, batch loss 0.1898, batch acc 0.7222
13:34:01.683   Training iter 350, batch loss 0.1909, batch acc 0.7194
13:34:02.234   Training iter 400, batch loss 0.1896, batch acc 0.7210
13:34:02.766   Training iter 450, batch loss 0.1902, batch acc 0.7164
13:34:03.301   Training iter 500, batch loss 0.1930, batch acc 0.7130
13:34:03.835   Training iter 550, batch loss 0.1884, batch acc 0.7260
13:34:04.373   Training iter 600, batch loss 0.1884, batch acc 0.7246
13:34:04.375 Training @ 349 epoch...
13:34:04.924   Training iter 50, batch loss 0.1917, batch acc 0.7164
13:34:05.462   Training iter 100, batch loss 0.1946, batch acc 0.7110
13:34:05.994   Training iter 150, batch loss 0.1947, batch acc 0.7106
13:34:06.508   Training iter 200, batch loss 0.1891, batch acc 0.7218
13:34:07.040   Training iter 250, batch loss 0.1863, batch acc 0.7264
13:34:07.563   Training iter 300, batch loss 0.1884, batch acc 0.7242
13:34:08.063   Training iter 350, batch loss 0.1883, batch acc 0.7282
13:34:08.557   Training iter 400, batch loss 0.1926, batch acc 0.7154
13:34:09.059   Training iter 450, batch loss 0.1912, batch acc 0.7184
13:34:09.562   Training iter 500, batch loss 0.1841, batch acc 0.7308
13:34:10.044   Training iter 550, batch loss 0.1896, batch acc 0.7238
13:34:10.535   Training iter 600, batch loss 0.1884, batch acc 0.7248
13:34:10.537 Training @ 350 epoch...
13:34:11.068   Training iter 50, batch loss 0.1871, batch acc 0.7290
13:34:11.590   Training iter 100, batch loss 0.1870, batch acc 0.7290
13:34:12.120   Training iter 150, batch loss 0.1925, batch acc 0.7164
13:34:12.643   Training iter 200, batch loss 0.1887, batch acc 0.7206
13:34:13.153   Training iter 250, batch loss 0.1896, batch acc 0.7170
13:34:13.660   Training iter 300, batch loss 0.1892, batch acc 0.7202
13:34:14.157   Training iter 350, batch loss 0.1911, batch acc 0.7180
13:34:14.661   Training iter 400, batch loss 0.1862, batch acc 0.7272
13:34:15.164   Training iter 450, batch loss 0.1886, batch acc 0.7230
13:34:15.680   Training iter 500, batch loss 0.1960, batch acc 0.7124
13:34:16.179   Training iter 550, batch loss 0.1887, batch acc 0.7244
13:34:16.645   Training iter 600, batch loss 0.1941, batch acc 0.7176
13:34:16.646 Testing @ 350 epoch...
13:34:16.683     Testing, total mean loss 0.18927, total acc 0.71800
13:34:16.683 Training @ 351 epoch...
13:34:17.135   Training iter 50, batch loss 0.1905, batch acc 0.7224
13:34:17.591   Training iter 100, batch loss 0.1874, batch acc 0.7252
13:34:18.051   Training iter 150, batch loss 0.1884, batch acc 0.7294
13:34:18.526   Training iter 200, batch loss 0.1912, batch acc 0.7208
13:34:18.993   Training iter 250, batch loss 0.1895, batch acc 0.7252
13:34:19.456   Training iter 300, batch loss 0.1941, batch acc 0.7112
13:34:19.913   Training iter 350, batch loss 0.1908, batch acc 0.7204
13:34:20.382   Training iter 400, batch loss 0.1885, batch acc 0.7210
13:34:20.851   Training iter 450, batch loss 0.1898, batch acc 0.7208
13:34:21.327   Training iter 500, batch loss 0.1863, batch acc 0.7232
13:34:21.810   Training iter 550, batch loss 0.1908, batch acc 0.7172
13:34:22.292   Training iter 600, batch loss 0.1916, batch acc 0.7180
13:34:22.293 Training @ 352 epoch...
13:34:22.792   Training iter 50, batch loss 0.1889, batch acc 0.7216
13:34:23.279   Training iter 100, batch loss 0.1867, batch acc 0.7268
13:34:23.765   Training iter 150, batch loss 0.1849, batch acc 0.7298
13:34:24.243   Training iter 200, batch loss 0.1924, batch acc 0.7172
13:34:24.734   Training iter 250, batch loss 0.1879, batch acc 0.7238
13:34:25.206   Training iter 300, batch loss 0.1878, batch acc 0.7250
13:34:25.668   Training iter 350, batch loss 0.1860, batch acc 0.7270
13:34:26.125   Training iter 400, batch loss 0.1926, batch acc 0.7164
13:34:26.592   Training iter 450, batch loss 0.1941, batch acc 0.7136
13:34:27.065   Training iter 500, batch loss 0.1937, batch acc 0.7132
13:34:27.543   Training iter 550, batch loss 0.1869, batch acc 0.7292
13:34:28.023   Training iter 600, batch loss 0.1967, batch acc 0.7092
13:34:28.025 Training @ 353 epoch...
13:34:28.498   Training iter 50, batch loss 0.1885, batch acc 0.7196
13:34:28.964   Training iter 100, batch loss 0.1881, batch acc 0.7232
13:34:29.434   Training iter 150, batch loss 0.1898, batch acc 0.7208
13:34:29.903   Training iter 200, batch loss 0.1878, batch acc 0.7220
13:34:30.389   Training iter 250, batch loss 0.1938, batch acc 0.7178
13:34:30.893   Training iter 300, batch loss 0.1889, batch acc 0.7238
13:34:31.390   Training iter 350, batch loss 0.1893, batch acc 0.7208
13:34:31.894   Training iter 400, batch loss 0.1930, batch acc 0.7198
13:34:32.409   Training iter 450, batch loss 0.1932, batch acc 0.7126
13:34:32.934   Training iter 500, batch loss 0.1869, batch acc 0.7244
13:34:33.423   Training iter 550, batch loss 0.1920, batch acc 0.7196
13:34:33.897   Training iter 600, batch loss 0.1871, batch acc 0.7274
13:34:33.899 Training @ 354 epoch...
13:34:34.364   Training iter 50, batch loss 0.1888, batch acc 0.7226
13:34:34.814   Training iter 100, batch loss 0.1926, batch acc 0.7176
13:34:35.281   Training iter 150, batch loss 0.1848, batch acc 0.7310
13:34:35.767   Training iter 200, batch loss 0.1913, batch acc 0.7174
13:34:36.236   Training iter 250, batch loss 0.1963, batch acc 0.7104
13:34:36.703   Training iter 300, batch loss 0.1886, batch acc 0.7262
13:34:37.164   Training iter 350, batch loss 0.1876, batch acc 0.7248
13:34:37.637   Training iter 400, batch loss 0.1878, batch acc 0.7208
13:34:38.106   Training iter 450, batch loss 0.1874, batch acc 0.7242
13:34:38.575   Training iter 500, batch loss 0.1899, batch acc 0.7236
13:34:39.055   Training iter 550, batch loss 0.1922, batch acc 0.7140
13:34:39.535   Training iter 600, batch loss 0.1909, batch acc 0.7196
13:34:39.537 Training @ 355 epoch...
13:34:40.044   Training iter 50, batch loss 0.1922, batch acc 0.7184
13:34:40.536   Training iter 100, batch loss 0.1883, batch acc 0.7234
13:34:41.044   Training iter 150, batch loss 0.1903, batch acc 0.7176
13:34:41.534   Training iter 200, batch loss 0.1881, batch acc 0.7244
13:34:42.029   Training iter 250, batch loss 0.1912, batch acc 0.7162
13:34:42.520   Training iter 300, batch loss 0.1889, batch acc 0.7216
13:34:43.016   Training iter 350, batch loss 0.1914, batch acc 0.7204
13:34:43.512   Training iter 400, batch loss 0.1903, batch acc 0.7212
13:34:43.996   Training iter 450, batch loss 0.1901, batch acc 0.7220
13:34:44.476   Training iter 500, batch loss 0.1884, batch acc 0.7234
13:34:44.956   Training iter 550, batch loss 0.1865, batch acc 0.7298
13:34:45.443   Training iter 600, batch loss 0.1923, batch acc 0.7160
13:34:45.445 Testing @ 355 epoch...
13:34:45.482     Testing, total mean loss 0.18915, total acc 0.71830
13:34:45.482 Training @ 356 epoch...
13:34:45.989   Training iter 50, batch loss 0.1860, batch acc 0.7324
13:34:46.489   Training iter 100, batch loss 0.1856, batch acc 0.7342
13:34:46.986   Training iter 150, batch loss 0.1954, batch acc 0.7120
13:34:47.480   Training iter 200, batch loss 0.1916, batch acc 0.7138
13:34:47.961   Training iter 250, batch loss 0.1907, batch acc 0.7182
13:34:48.453   Training iter 300, batch loss 0.1906, batch acc 0.7216
13:34:48.917   Training iter 350, batch loss 0.1942, batch acc 0.7126
13:34:49.375   Training iter 400, batch loss 0.1929, batch acc 0.7160
13:34:49.840   Training iter 450, batch loss 0.1920, batch acc 0.7172
13:34:50.307   Training iter 500, batch loss 0.1849, batch acc 0.7272
13:34:50.775   Training iter 550, batch loss 0.1819, batch acc 0.7366
13:34:51.282   Training iter 600, batch loss 0.1920, batch acc 0.7146
13:34:51.284 Training @ 357 epoch...
13:34:51.783   Training iter 50, batch loss 0.1915, batch acc 0.7214
13:34:52.294   Training iter 100, batch loss 0.1910, batch acc 0.7170
13:34:52.790   Training iter 150, batch loss 0.1890, batch acc 0.7232
13:34:53.294   Training iter 200, batch loss 0.1892, batch acc 0.7248
13:34:53.783   Training iter 250, batch loss 0.1898, batch acc 0.7218
13:34:54.296   Training iter 300, batch loss 0.1884, batch acc 0.7232
13:34:54.793   Training iter 350, batch loss 0.1866, batch acc 0.7264
13:34:55.293   Training iter 400, batch loss 0.1921, batch acc 0.7198
13:34:55.764   Training iter 450, batch loss 0.1862, batch acc 0.7258
13:34:56.244   Training iter 500, batch loss 0.1918, batch acc 0.7172
13:34:56.716   Training iter 550, batch loss 0.1922, batch acc 0.7192
13:34:57.183   Training iter 600, batch loss 0.1898, batch acc 0.7204
13:34:57.185 Training @ 358 epoch...
13:34:57.687   Training iter 50, batch loss 0.1874, batch acc 0.7248
13:34:58.186   Training iter 100, batch loss 0.1911, batch acc 0.7206
13:34:58.674   Training iter 150, batch loss 0.1952, batch acc 0.7126
13:34:59.196   Training iter 200, batch loss 0.1883, batch acc 0.7232
13:34:59.713   Training iter 250, batch loss 0.1877, batch acc 0.7228
13:35:00.246   Training iter 300, batch loss 0.1880, batch acc 0.7188
13:35:00.764   Training iter 350, batch loss 0.1883, batch acc 0.7222
13:35:01.282   Training iter 400, batch loss 0.1919, batch acc 0.7196
13:35:01.858   Training iter 450, batch loss 0.1880, batch acc 0.7254
13:35:02.388   Training iter 500, batch loss 0.1883, batch acc 0.7234
13:35:02.940   Training iter 550, batch loss 0.1865, batch acc 0.7306
13:35:03.486   Training iter 600, batch loss 0.1967, batch acc 0.7088
13:35:03.488 Training @ 359 epoch...
13:35:04.045   Training iter 50, batch loss 0.1875, batch acc 0.7266
13:35:04.603   Training iter 100, batch loss 0.1909, batch acc 0.7186
13:35:05.143   Training iter 150, batch loss 0.1924, batch acc 0.7158
13:35:05.698   Training iter 200, batch loss 0.1909, batch acc 0.7208
13:35:06.240   Training iter 250, batch loss 0.1912, batch acc 0.7204
13:35:06.760   Training iter 300, batch loss 0.1895, batch acc 0.7206
13:35:07.296   Training iter 350, batch loss 0.1891, batch acc 0.7206
13:35:07.810   Training iter 400, batch loss 0.1869, batch acc 0.7268
13:35:08.354   Training iter 450, batch loss 0.1878, batch acc 0.7234
13:35:08.855   Training iter 500, batch loss 0.1860, batch acc 0.7278
13:35:09.372   Training iter 550, batch loss 0.1923, batch acc 0.7166
13:35:09.890   Training iter 600, batch loss 0.1927, batch acc 0.7174
13:35:09.892 Training @ 360 epoch...
13:35:10.420   Training iter 50, batch loss 0.1891, batch acc 0.7234
13:35:10.946   Training iter 100, batch loss 0.1903, batch acc 0.7216
13:35:11.468   Training iter 150, batch loss 0.1885, batch acc 0.7214
13:35:12.005   Training iter 200, batch loss 0.1884, batch acc 0.7256
13:35:12.521   Training iter 250, batch loss 0.1926, batch acc 0.7184
13:35:13.056   Training iter 300, batch loss 0.1890, batch acc 0.7210
13:35:13.589   Training iter 350, batch loss 0.1914, batch acc 0.7172
13:35:14.103   Training iter 400, batch loss 0.1839, batch acc 0.7336
13:35:14.615   Training iter 450, batch loss 0.1921, batch acc 0.7114
13:35:15.138   Training iter 500, batch loss 0.1875, batch acc 0.7262
13:35:15.642   Training iter 550, batch loss 0.1888, batch acc 0.7262
13:35:16.158   Training iter 600, batch loss 0.1955, batch acc 0.7084
13:35:16.160 Testing @ 360 epoch...
13:35:16.197     Testing, total mean loss 0.18906, total acc 0.71860
13:35:16.197 Training @ 361 epoch...
13:35:16.721   Training iter 50, batch loss 0.1887, batch acc 0.7216
13:35:17.258   Training iter 100, batch loss 0.1967, batch acc 0.7078
13:35:17.801   Training iter 150, batch loss 0.1880, batch acc 0.7292
13:35:18.353   Training iter 200, batch loss 0.1862, batch acc 0.7260
13:35:18.898   Training iter 250, batch loss 0.1864, batch acc 0.7250
13:35:19.442   Training iter 300, batch loss 0.1860, batch acc 0.7270
13:35:19.987   Training iter 350, batch loss 0.1839, batch acc 0.7302
13:35:20.529   Training iter 400, batch loss 0.1952, batch acc 0.7152
13:35:21.063   Training iter 450, batch loss 0.1929, batch acc 0.7162
13:35:21.574   Training iter 500, batch loss 0.1905, batch acc 0.7188
13:35:22.086   Training iter 550, batch loss 0.1895, batch acc 0.7218
13:35:22.593   Training iter 600, batch loss 0.1929, batch acc 0.7130
13:35:22.595 Training @ 362 epoch...
13:35:23.113   Training iter 50, batch loss 0.1882, batch acc 0.7206
13:35:23.618   Training iter 100, batch loss 0.1878, batch acc 0.7232
13:35:24.126   Training iter 150, batch loss 0.1942, batch acc 0.7132
13:35:24.630   Training iter 200, batch loss 0.1877, batch acc 0.7262
13:35:25.145   Training iter 250, batch loss 0.1919, batch acc 0.7184
13:35:25.652   Training iter 300, batch loss 0.1870, batch acc 0.7284
13:35:26.167   Training iter 350, batch loss 0.1907, batch acc 0.7184
13:35:26.658   Training iter 400, batch loss 0.1934, batch acc 0.7108
13:35:27.162   Training iter 450, batch loss 0.1889, batch acc 0.7226
13:35:27.703   Training iter 500, batch loss 0.1877, batch acc 0.7238
13:35:28.196   Training iter 550, batch loss 0.1877, batch acc 0.7296
13:35:28.665   Training iter 600, batch loss 0.1914, batch acc 0.7192
13:35:28.667 Training @ 363 epoch...
13:35:29.200   Training iter 50, batch loss 0.1906, batch acc 0.7160
13:35:29.760   Training iter 100, batch loss 0.1844, batch acc 0.7310
13:35:30.334   Training iter 150, batch loss 0.1880, batch acc 0.7288
13:35:30.883   Training iter 200, batch loss 0.1937, batch acc 0.7154
13:35:31.384   Training iter 250, batch loss 0.1872, batch acc 0.7260
13:35:31.899   Training iter 300, batch loss 0.1898, batch acc 0.7208
13:35:32.422   Training iter 350, batch loss 0.1908, batch acc 0.7184
13:35:32.909   Training iter 400, batch loss 0.1885, batch acc 0.7204
13:35:33.397   Training iter 450, batch loss 0.1872, batch acc 0.7294
13:35:33.860   Training iter 500, batch loss 0.1938, batch acc 0.7104
13:35:34.315   Training iter 550, batch loss 0.1925, batch acc 0.7166
13:35:34.766   Training iter 600, batch loss 0.1902, batch acc 0.7208
13:35:34.767 Training @ 364 epoch...
13:35:35.227   Training iter 50, batch loss 0.1879, batch acc 0.7248
13:35:35.677   Training iter 100, batch loss 0.1813, batch acc 0.7410
13:35:36.132   Training iter 150, batch loss 0.1889, batch acc 0.7206
13:35:36.586   Training iter 200, batch loss 0.1952, batch acc 0.7104
13:35:37.044   Training iter 250, batch loss 0.1929, batch acc 0.7118
13:35:37.510   Training iter 300, batch loss 0.1928, batch acc 0.7136
13:35:37.997   Training iter 350, batch loss 0.1902, batch acc 0.7204
13:35:38.488   Training iter 400, batch loss 0.1940, batch acc 0.7156
13:35:38.975   Training iter 450, batch loss 0.1884, batch acc 0.7228
13:35:39.456   Training iter 500, batch loss 0.1890, batch acc 0.7206
13:35:39.941   Training iter 550, batch loss 0.1851, batch acc 0.7302
13:35:40.450   Training iter 600, batch loss 0.1906, batch acc 0.7238
13:35:40.452 Training @ 365 epoch...
13:35:40.950   Training iter 50, batch loss 0.1863, batch acc 0.7284
13:35:41.448   Training iter 100, batch loss 0.1948, batch acc 0.7118
13:35:41.937   Training iter 150, batch loss 0.1890, batch acc 0.7210
13:35:42.453   Training iter 200, batch loss 0.1923, batch acc 0.7186
13:35:42.970   Training iter 250, batch loss 0.1934, batch acc 0.7148
13:35:43.469   Training iter 300, batch loss 0.1945, batch acc 0.7110
13:35:43.973   Training iter 350, batch loss 0.1846, batch acc 0.7302
13:35:44.477   Training iter 400, batch loss 0.1856, batch acc 0.7324
13:35:44.985   Training iter 450, batch loss 0.1908, batch acc 0.7178
13:35:45.491   Training iter 500, batch loss 0.1884, batch acc 0.7190
13:35:45.997   Training iter 550, batch loss 0.1878, batch acc 0.7230
13:35:46.510   Training iter 600, batch loss 0.1888, batch acc 0.7278
13:35:46.511 Testing @ 365 epoch...
13:35:46.548     Testing, total mean loss 0.18901, total acc 0.71830
13:35:46.548 Training @ 366 epoch...
13:35:47.075   Training iter 50, batch loss 0.1912, batch acc 0.7188
13:35:47.608   Training iter 100, batch loss 0.1907, batch acc 0.7180
13:35:48.147   Training iter 150, batch loss 0.1837, batch acc 0.7338
13:35:48.675   Training iter 200, batch loss 0.1886, batch acc 0.7244
13:35:49.221   Training iter 250, batch loss 0.1874, batch acc 0.7256
13:35:49.758   Training iter 300, batch loss 0.1935, batch acc 0.7144
13:35:50.281   Training iter 350, batch loss 0.1922, batch acc 0.7180
13:35:50.791   Training iter 400, batch loss 0.1867, batch acc 0.7294
13:35:51.322   Training iter 450, batch loss 0.1910, batch acc 0.7150
13:35:51.868   Training iter 500, batch loss 0.1882, batch acc 0.7242
13:35:52.409   Training iter 550, batch loss 0.1924, batch acc 0.7156
13:35:52.952   Training iter 600, batch loss 0.1905, batch acc 0.7192
13:35:52.954 Training @ 367 epoch...
13:35:53.516   Training iter 50, batch loss 0.1914, batch acc 0.7184
13:35:54.064   Training iter 100, batch loss 0.1881, batch acc 0.7254
13:35:54.599   Training iter 150, batch loss 0.1881, batch acc 0.7236
13:35:55.144   Training iter 200, batch loss 0.1945, batch acc 0.7080
13:35:55.687   Training iter 250, batch loss 0.1866, batch acc 0.7254
13:35:56.202   Training iter 300, batch loss 0.1871, batch acc 0.7278
13:35:56.720   Training iter 350, batch loss 0.1909, batch acc 0.7170
13:35:57.238   Training iter 400, batch loss 0.1834, batch acc 0.7324
13:35:57.752   Training iter 450, batch loss 0.1887, batch acc 0.7242
13:35:58.271   Training iter 500, batch loss 0.1888, batch acc 0.7216
13:35:58.787   Training iter 550, batch loss 0.1904, batch acc 0.7234
13:35:59.295   Training iter 600, batch loss 0.1979, batch acc 0.7084
13:35:59.297 Training @ 368 epoch...
13:35:59.807   Training iter 50, batch loss 0.1832, batch acc 0.7328
13:36:00.337   Training iter 100, batch loss 0.1856, batch acc 0.7282
13:36:00.866   Training iter 150, batch loss 0.1910, batch acc 0.7194
13:36:01.413   Training iter 200, batch loss 0.1856, batch acc 0.7308
13:36:02.019   Training iter 250, batch loss 0.1971, batch acc 0.7066
13:36:02.601   Training iter 300, batch loss 0.1888, batch acc 0.7262
13:36:03.185   Training iter 350, batch loss 0.1878, batch acc 0.7292
13:36:03.756   Training iter 400, batch loss 0.1917, batch acc 0.7154
13:36:04.328   Training iter 450, batch loss 0.1901, batch acc 0.7226
13:36:04.878   Training iter 500, batch loss 0.1862, batch acc 0.7254
13:36:05.421   Training iter 550, batch loss 0.1970, batch acc 0.7054
13:36:05.953   Training iter 600, batch loss 0.1917, batch acc 0.7166
13:36:05.955 Training @ 369 epoch...
13:36:06.475   Training iter 50, batch loss 0.1877, batch acc 0.7262
13:36:07.006   Training iter 100, batch loss 0.1946, batch acc 0.7100
13:36:07.532   Training iter 150, batch loss 0.1840, batch acc 0.7324
13:36:08.017   Training iter 200, batch loss 0.1890, batch acc 0.7204
13:36:08.517   Training iter 250, batch loss 0.1896, batch acc 0.7216
13:36:09.015   Training iter 300, batch loss 0.1899, batch acc 0.7228
13:36:09.511   Training iter 350, batch loss 0.1897, batch acc 0.7196
13:36:10.003   Training iter 400, batch loss 0.1909, batch acc 0.7208
13:36:10.493   Training iter 450, batch loss 0.1908, batch acc 0.7204
13:36:10.971   Training iter 500, batch loss 0.1887, batch acc 0.7216
13:36:11.477   Training iter 550, batch loss 0.1889, batch acc 0.7238
13:36:11.976   Training iter 600, batch loss 0.1917, batch acc 0.7168
13:36:11.978 Training @ 370 epoch...
13:36:12.471   Training iter 50, batch loss 0.1897, batch acc 0.7240
13:36:12.932   Training iter 100, batch loss 0.1900, batch acc 0.7246
13:36:13.411   Training iter 150, batch loss 0.1932, batch acc 0.7116
13:36:14.025   Training iter 200, batch loss 0.1923, batch acc 0.7158
13:36:14.512   Training iter 250, batch loss 0.1866, batch acc 0.7236
13:36:15.048   Training iter 300, batch loss 0.1862, batch acc 0.7268
13:36:15.599   Training iter 350, batch loss 0.1882, batch acc 0.7262
13:36:16.090   Training iter 400, batch loss 0.1912, batch acc 0.7158
13:36:16.558   Training iter 450, batch loss 0.1893, batch acc 0.7184
13:36:17.054   Training iter 500, batch loss 0.1898, batch acc 0.7198
13:36:17.527   Training iter 550, batch loss 0.1869, batch acc 0.7324
13:36:18.038   Training iter 600, batch loss 0.1918, batch acc 0.7182
13:36:18.039 Testing @ 370 epoch...
13:36:18.076     Testing, total mean loss 0.18893, total acc 0.71890
13:36:18.076 Training @ 371 epoch...
13:36:18.649   Training iter 50, batch loss 0.1952, batch acc 0.7102
13:36:19.138   Training iter 100, batch loss 0.1903, batch acc 0.7216
13:36:19.636   Training iter 150, batch loss 0.1922, batch acc 0.7144
13:36:20.247   Training iter 200, batch loss 0.1885, batch acc 0.7246
13:36:20.795   Training iter 250, batch loss 0.1867, batch acc 0.7260
13:36:21.350   Training iter 300, batch loss 0.1912, batch acc 0.7162
13:36:21.903   Training iter 350, batch loss 0.1907, batch acc 0.7216
13:36:22.462   Training iter 400, batch loss 0.1891, batch acc 0.7236
13:36:23.027   Training iter 450, batch loss 0.1888, batch acc 0.7274
13:36:23.571   Training iter 500, batch loss 0.1928, batch acc 0.7140
13:36:24.115   Training iter 550, batch loss 0.1868, batch acc 0.7228
13:36:24.667   Training iter 600, batch loss 0.1829, batch acc 0.7340
13:36:24.669 Training @ 372 epoch...
13:36:25.220   Training iter 50, batch loss 0.1929, batch acc 0.7106
13:36:25.774   Training iter 100, batch loss 0.1896, batch acc 0.7196
13:36:26.334   Training iter 150, batch loss 0.1829, batch acc 0.7350
13:36:26.886   Training iter 200, batch loss 0.1898, batch acc 0.7204
13:36:27.439   Training iter 250, batch loss 0.1891, batch acc 0.7184
13:36:27.988   Training iter 300, batch loss 0.1882, batch acc 0.7254
13:36:28.557   Training iter 350, batch loss 0.1937, batch acc 0.7162
13:36:29.116   Training iter 400, batch loss 0.1902, batch acc 0.7210
13:36:29.675   Training iter 450, batch loss 0.1856, batch acc 0.7320
13:36:30.240   Training iter 500, batch loss 0.1893, batch acc 0.7220
13:36:30.781   Training iter 550, batch loss 0.1913, batch acc 0.7194
13:36:31.300   Training iter 600, batch loss 0.1925, batch acc 0.7156
13:36:31.301 Training @ 373 epoch...
13:36:31.824   Training iter 50, batch loss 0.1902, batch acc 0.7188
13:36:32.385   Training iter 100, batch loss 0.1885, batch acc 0.7252
13:36:32.940   Training iter 150, batch loss 0.1968, batch acc 0.7058
13:36:33.498   Training iter 200, batch loss 0.1868, batch acc 0.7306
13:36:34.053   Training iter 250, batch loss 0.1922, batch acc 0.7200
13:36:34.619   Training iter 300, batch loss 0.1904, batch acc 0.7228
13:36:35.240   Training iter 350, batch loss 0.1806, batch acc 0.7390
13:36:35.834   Training iter 400, batch loss 0.1903, batch acc 0.7140
13:36:36.442   Training iter 450, batch loss 0.1888, batch acc 0.7222
13:36:37.031   Training iter 500, batch loss 0.1868, batch acc 0.7276
13:36:37.633   Training iter 550, batch loss 0.1920, batch acc 0.7136
13:36:38.226   Training iter 600, batch loss 0.1911, batch acc 0.7190
13:36:38.228 Training @ 374 epoch...
13:36:38.831   Training iter 50, batch loss 0.1871, batch acc 0.7262
13:36:39.419   Training iter 100, batch loss 0.1918, batch acc 0.7168
13:36:40.007   Training iter 150, batch loss 0.1871, batch acc 0.7286
13:36:40.596   Training iter 200, batch loss 0.1906, batch acc 0.7186
13:36:41.141   Training iter 250, batch loss 0.1865, batch acc 0.7274
13:36:41.673   Training iter 300, batch loss 0.1895, batch acc 0.7232
13:36:42.227   Training iter 350, batch loss 0.1906, batch acc 0.7188
13:36:42.783   Training iter 400, batch loss 0.1913, batch acc 0.7198
13:36:43.335   Training iter 450, batch loss 0.1921, batch acc 0.7164
13:36:43.859   Training iter 500, batch loss 0.1867, batch acc 0.7284
13:36:44.362   Training iter 550, batch loss 0.1888, batch acc 0.7228
13:36:44.874   Training iter 600, batch loss 0.1925, batch acc 0.7140
13:36:44.876 Training @ 375 epoch...
13:36:45.394   Training iter 50, batch loss 0.1928, batch acc 0.7162
13:36:45.903   Training iter 100, batch loss 0.1879, batch acc 0.7246
13:36:46.408   Training iter 150, batch loss 0.1850, batch acc 0.7320
13:36:46.923   Training iter 200, batch loss 0.1893, batch acc 0.7244
13:36:47.434   Training iter 250, batch loss 0.1896, batch acc 0.7204
13:36:47.952   Training iter 300, batch loss 0.1952, batch acc 0.7078
13:36:48.482   Training iter 350, batch loss 0.1923, batch acc 0.7126
13:36:48.991   Training iter 400, batch loss 0.1865, batch acc 0.7246
13:36:49.527   Training iter 450, batch loss 0.1860, batch acc 0.7276
13:36:50.066   Training iter 500, batch loss 0.1911, batch acc 0.7188
13:36:50.604   Training iter 550, batch loss 0.1876, batch acc 0.7328
13:36:51.162   Training iter 600, batch loss 0.1913, batch acc 0.7168
13:36:51.164 Testing @ 375 epoch...
13:36:51.203     Testing, total mean loss 0.18882, total acc 0.71920
13:36:51.203 Training @ 376 epoch...
13:36:51.754   Training iter 50, batch loss 0.1873, batch acc 0.7214
13:36:52.295   Training iter 100, batch loss 0.1919, batch acc 0.7172
13:36:52.831   Training iter 150, batch loss 0.1912, batch acc 0.7180
13:36:53.374   Training iter 200, batch loss 0.1926, batch acc 0.7176
13:36:53.909   Training iter 250, batch loss 0.1927, batch acc 0.7170
13:36:54.435   Training iter 300, batch loss 0.1856, batch acc 0.7270
13:36:54.937   Training iter 350, batch loss 0.1919, batch acc 0.7136
13:36:55.458   Training iter 400, batch loss 0.1860, batch acc 0.7274
13:36:55.978   Training iter 450, batch loss 0.1927, batch acc 0.7158
13:36:56.509   Training iter 500, batch loss 0.1893, batch acc 0.7274
13:36:57.018   Training iter 550, batch loss 0.1861, batch acc 0.7306
13:36:57.509   Training iter 600, batch loss 0.1868, batch acc 0.7232
13:36:57.510 Training @ 377 epoch...
13:36:57.998   Training iter 50, batch loss 0.1877, batch acc 0.7248
13:36:58.478   Training iter 100, batch loss 0.1906, batch acc 0.7172
13:36:58.971   Training iter 150, batch loss 0.1877, batch acc 0.7212
13:36:59.464   Training iter 200, batch loss 0.1877, batch acc 0.7254
13:36:59.951   Training iter 250, batch loss 0.1881, batch acc 0.7252
13:37:00.438   Training iter 300, batch loss 0.1940, batch acc 0.7116
13:37:00.926   Training iter 350, batch loss 0.1902, batch acc 0.7212
13:37:01.413   Training iter 400, batch loss 0.1909, batch acc 0.7172
13:37:01.900   Training iter 450, batch loss 0.1840, batch acc 0.7330
13:37:02.428   Training iter 500, batch loss 0.1915, batch acc 0.7172
13:37:02.937   Training iter 550, batch loss 0.1927, batch acc 0.7186
13:37:03.446   Training iter 600, batch loss 0.1890, batch acc 0.7264
13:37:03.448 Training @ 378 epoch...
13:37:03.953   Training iter 50, batch loss 0.1899, batch acc 0.7206
13:37:04.460   Training iter 100, batch loss 0.1896, batch acc 0.7234
13:37:04.967   Training iter 150, batch loss 0.1911, batch acc 0.7170
13:37:05.498   Training iter 200, batch loss 0.1886, batch acc 0.7240
13:37:06.029   Training iter 250, batch loss 0.1901, batch acc 0.7178
13:37:06.516   Training iter 300, batch loss 0.1922, batch acc 0.7150
13:37:07.028   Training iter 350, batch loss 0.1858, batch acc 0.7292
13:37:07.559   Training iter 400, batch loss 0.1844, batch acc 0.7306
13:37:08.097   Training iter 450, batch loss 0.1888, batch acc 0.7232
13:37:08.641   Training iter 500, batch loss 0.1892, batch acc 0.7246
13:37:09.200   Training iter 550, batch loss 0.1902, batch acc 0.7212
13:37:09.745   Training iter 600, batch loss 0.1941, batch acc 0.7126
13:37:09.747 Training @ 379 epoch...
13:37:10.304   Training iter 50, batch loss 0.1910, batch acc 0.7194
13:37:10.847   Training iter 100, batch loss 0.1911, batch acc 0.7168
13:37:11.383   Training iter 150, batch loss 0.1852, batch acc 0.7372
13:37:11.926   Training iter 200, batch loss 0.1902, batch acc 0.7218
13:37:12.503   Training iter 250, batch loss 0.1876, batch acc 0.7238
13:37:13.087   Training iter 300, batch loss 0.1945, batch acc 0.7082
13:37:13.619   Training iter 350, batch loss 0.1842, batch acc 0.7334
13:37:14.157   Training iter 400, batch loss 0.1898, batch acc 0.7220
13:37:14.700   Training iter 450, batch loss 0.1895, batch acc 0.7226
13:37:15.266   Training iter 500, batch loss 0.1926, batch acc 0.7102
13:37:15.820   Training iter 550, batch loss 0.1888, batch acc 0.7208
13:37:16.362   Training iter 600, batch loss 0.1893, batch acc 0.7244
13:37:16.364 Training @ 380 epoch...
13:37:16.921   Training iter 50, batch loss 0.1914, batch acc 0.7192
13:37:17.459   Training iter 100, batch loss 0.1889, batch acc 0.7256
13:37:17.968   Training iter 150, batch loss 0.1898, batch acc 0.7156
13:37:18.486   Training iter 200, batch loss 0.1925, batch acc 0.7122
13:37:19.001   Training iter 250, batch loss 0.1879, batch acc 0.7246
13:37:19.509   Training iter 300, batch loss 0.1929, batch acc 0.7136
13:37:20.026   Training iter 350, batch loss 0.1883, batch acc 0.7238
13:37:20.581   Training iter 400, batch loss 0.1877, batch acc 0.7272
13:37:21.172   Training iter 450, batch loss 0.1896, batch acc 0.7248
13:37:21.748   Training iter 500, batch loss 0.1864, batch acc 0.7294
13:37:22.254   Training iter 550, batch loss 0.1891, batch acc 0.7220
13:37:22.885   Training iter 600, batch loss 0.1891, batch acc 0.7194
13:37:22.888 Testing @ 380 epoch...
13:37:22.931     Testing, total mean loss 0.18879, total acc 0.71860
13:37:22.931 Training @ 381 epoch...
13:37:23.561   Training iter 50, batch loss 0.1877, batch acc 0.7300
13:37:24.064   Training iter 100, batch loss 0.1917, batch acc 0.7186
13:37:24.572   Training iter 150, batch loss 0.1920, batch acc 0.7212
13:37:25.063   Training iter 200, batch loss 0.1940, batch acc 0.7126
13:37:25.556   Training iter 250, batch loss 0.1933, batch acc 0.7142
13:37:26.087   Training iter 300, batch loss 0.1875, batch acc 0.7276
13:37:26.574   Training iter 350, batch loss 0.1907, batch acc 0.7200
13:37:27.055   Training iter 400, batch loss 0.1833, batch acc 0.7338
13:37:27.548   Training iter 450, batch loss 0.1907, batch acc 0.7152
13:37:28.047   Training iter 500, batch loss 0.1888, batch acc 0.7216
13:37:28.527   Training iter 550, batch loss 0.1881, batch acc 0.7236
13:37:29.018   Training iter 600, batch loss 0.1858, batch acc 0.7246
13:37:29.020 Training @ 382 epoch...
13:37:29.505   Training iter 50, batch loss 0.1880, batch acc 0.7250
13:37:29.992   Training iter 100, batch loss 0.1909, batch acc 0.7202
13:37:30.481   Training iter 150, batch loss 0.1943, batch acc 0.7128
13:37:30.959   Training iter 200, batch loss 0.1911, batch acc 0.7194
13:37:31.437   Training iter 250, batch loss 0.1859, batch acc 0.7258
13:37:31.900   Training iter 300, batch loss 0.1903, batch acc 0.7196
13:37:32.390   Training iter 350, batch loss 0.1903, batch acc 0.7180
13:37:32.882   Training iter 400, batch loss 0.1903, batch acc 0.7208
13:37:33.368   Training iter 450, batch loss 0.1866, batch acc 0.7246
13:37:33.857   Training iter 500, batch loss 0.1890, batch acc 0.7226
13:37:34.356   Training iter 550, batch loss 0.1857, batch acc 0.7296
13:37:34.847   Training iter 600, batch loss 0.1910, batch acc 0.7196
13:37:34.849 Training @ 383 epoch...
13:37:35.370   Training iter 50, batch loss 0.1874, batch acc 0.7266
13:37:35.880   Training iter 100, batch loss 0.1874, batch acc 0.7292
13:37:36.399   Training iter 150, batch loss 0.1914, batch acc 0.7208
13:37:36.919   Training iter 200, batch loss 0.1877, batch acc 0.7218
13:37:37.439   Training iter 250, batch loss 0.1951, batch acc 0.7096
13:37:37.954   Training iter 300, batch loss 0.1917, batch acc 0.7164
13:37:38.478   Training iter 350, batch loss 0.1872, batch acc 0.7278
13:37:38.993   Training iter 400, batch loss 0.1913, batch acc 0.7178
13:37:39.504   Training iter 450, batch loss 0.1866, batch acc 0.7260
13:37:40.025   Training iter 500, batch loss 0.1860, batch acc 0.7302
13:37:40.569   Training iter 550, batch loss 0.1890, batch acc 0.7220
13:37:41.123   Training iter 600, batch loss 0.1925, batch acc 0.7120
13:37:41.125 Training @ 384 epoch...
13:37:41.672   Training iter 50, batch loss 0.1916, batch acc 0.7206
13:37:42.245   Training iter 100, batch loss 0.1911, batch acc 0.7182
13:37:42.761   Training iter 150, batch loss 0.1879, batch acc 0.7272
13:37:43.296   Training iter 200, batch loss 0.1885, batch acc 0.7216
13:37:43.817   Training iter 250, batch loss 0.1906, batch acc 0.7164
13:37:44.345   Training iter 300, batch loss 0.1861, batch acc 0.7290
13:37:44.860   Training iter 350, batch loss 0.1922, batch acc 0.7154
13:37:45.377   Training iter 400, batch loss 0.1866, batch acc 0.7242
13:37:45.899   Training iter 450, batch loss 0.1960, batch acc 0.7076
13:37:46.412   Training iter 500, batch loss 0.1852, batch acc 0.7320
13:37:46.930   Training iter 550, batch loss 0.1883, batch acc 0.7260
13:37:47.435   Training iter 600, batch loss 0.1889, batch acc 0.7212
13:37:47.436 Training @ 385 epoch...
13:37:47.947   Training iter 50, batch loss 0.1868, batch acc 0.7274
13:37:48.454   Training iter 100, batch loss 0.1921, batch acc 0.7152
13:37:48.956   Training iter 150, batch loss 0.1932, batch acc 0.7146
13:37:49.460   Training iter 200, batch loss 0.1867, batch acc 0.7286
13:37:49.974   Training iter 250, batch loss 0.1887, batch acc 0.7244
13:37:50.485   Training iter 300, batch loss 0.1875, batch acc 0.7226
13:37:50.995   Training iter 350, batch loss 0.1875, batch acc 0.7298
13:37:51.501   Training iter 400, batch loss 0.1894, batch acc 0.7200
13:37:52.007   Training iter 450, batch loss 0.1871, batch acc 0.7264
13:37:52.515   Training iter 500, batch loss 0.1951, batch acc 0.7134
13:37:53.021   Training iter 550, batch loss 0.1889, batch acc 0.7190
13:37:53.532   Training iter 600, batch loss 0.1898, batch acc 0.7186
13:37:53.534 Testing @ 385 epoch...
13:37:53.571     Testing, total mean loss 0.18872, total acc 0.71880
13:37:53.571 Training @ 386 epoch...
13:37:54.106   Training iter 50, batch loss 0.1892, batch acc 0.7216
13:37:54.649   Training iter 100, batch loss 0.1938, batch acc 0.7148
13:37:55.190   Training iter 150, batch loss 0.1941, batch acc 0.7106
13:37:55.716   Training iter 200, batch loss 0.1869, batch acc 0.7248
13:37:56.242   Training iter 250, batch loss 0.1823, batch acc 0.7346
13:37:56.792   Training iter 300, batch loss 0.1942, batch acc 0.7176
13:37:57.324   Training iter 350, batch loss 0.1889, batch acc 0.7248
13:37:57.865   Training iter 400, batch loss 0.1871, batch acc 0.7238
13:37:58.412   Training iter 450, batch loss 0.1894, batch acc 0.7248
13:37:58.958   Training iter 500, batch loss 0.1844, batch acc 0.7304
13:37:59.489   Training iter 550, batch loss 0.1907, batch acc 0.7184
13:38:00.011   Training iter 600, batch loss 0.1916, batch acc 0.7148
13:38:00.012 Training @ 387 epoch...
13:38:00.555   Training iter 50, batch loss 0.1886, batch acc 0.7204
13:38:01.087   Training iter 100, batch loss 0.1854, batch acc 0.7336
13:38:01.620   Training iter 150, batch loss 0.1911, batch acc 0.7150
13:38:02.179   Training iter 200, batch loss 0.1919, batch acc 0.7170
13:38:02.731   Training iter 250, batch loss 0.1869, batch acc 0.7250
13:38:03.278   Training iter 300, batch loss 0.1901, batch acc 0.7172
13:38:03.826   Training iter 350, batch loss 0.1882, batch acc 0.7252
13:38:04.370   Training iter 400, batch loss 0.1909, batch acc 0.7164
13:38:04.922   Training iter 450, batch loss 0.1915, batch acc 0.7154
13:38:05.480   Training iter 500, batch loss 0.1897, batch acc 0.7240
13:38:05.964   Training iter 550, batch loss 0.1867, batch acc 0.7332
13:38:06.482   Training iter 600, batch loss 0.1916, batch acc 0.7184
13:38:06.484 Training @ 388 epoch...
13:38:07.013   Training iter 50, batch loss 0.1892, batch acc 0.7196
13:38:07.504   Training iter 100, batch loss 0.1918, batch acc 0.7216
13:38:07.992   Training iter 150, batch loss 0.1913, batch acc 0.7168
13:38:08.493   Training iter 200, batch loss 0.1887, batch acc 0.7236
13:38:08.981   Training iter 250, batch loss 0.1910, batch acc 0.7194
13:38:09.474   Training iter 300, batch loss 0.1907, batch acc 0.7148
13:38:09.990   Training iter 350, batch loss 0.1884, batch acc 0.7186
13:38:10.550   Training iter 400, batch loss 0.1870, batch acc 0.7310
13:38:11.084   Training iter 450, batch loss 0.1855, batch acc 0.7260
13:38:11.647   Training iter 500, batch loss 0.1866, batch acc 0.7284
13:38:12.236   Training iter 550, batch loss 0.1927, batch acc 0.7196
13:38:12.829   Training iter 600, batch loss 0.1897, batch acc 0.7190
13:38:12.831 Training @ 389 epoch...
13:38:13.428   Training iter 50, batch loss 0.1897, batch acc 0.7230
13:38:14.014   Training iter 100, batch loss 0.1931, batch acc 0.7148
13:38:14.604   Training iter 150, batch loss 0.1915, batch acc 0.7180
13:38:15.220   Training iter 200, batch loss 0.1892, batch acc 0.7234
13:38:15.816   Training iter 250, batch loss 0.1940, batch acc 0.7142
13:38:16.468   Training iter 300, batch loss 0.1921, batch acc 0.7120
13:38:17.065   Training iter 350, batch loss 0.1845, batch acc 0.7278
13:38:17.689   Training iter 400, batch loss 0.1869, batch acc 0.7252
13:38:18.284   Training iter 450, batch loss 0.1899, batch acc 0.7204
13:38:18.847   Training iter 500, batch loss 0.1837, batch acc 0.7332
13:38:19.421   Training iter 550, batch loss 0.1886, batch acc 0.7222
13:38:19.993   Training iter 600, batch loss 0.1890, batch acc 0.7244
13:38:19.995 Training @ 390 epoch...
13:38:20.597   Training iter 50, batch loss 0.1913, batch acc 0.7174
13:38:21.178   Training iter 100, batch loss 0.1929, batch acc 0.7096
13:38:21.742   Training iter 150, batch loss 0.1928, batch acc 0.7146
13:38:22.304   Training iter 200, batch loss 0.1911, batch acc 0.7160
13:38:22.869   Training iter 250, batch loss 0.1881, batch acc 0.7252
13:38:23.439   Training iter 300, batch loss 0.1903, batch acc 0.7232
13:38:24.008   Training iter 350, batch loss 0.1865, batch acc 0.7280
13:38:24.585   Training iter 400, batch loss 0.1893, batch acc 0.7194
13:38:25.170   Training iter 450, batch loss 0.1857, batch acc 0.7290
13:38:25.755   Training iter 500, batch loss 0.1903, batch acc 0.7240
13:38:26.362   Training iter 550, batch loss 0.1872, batch acc 0.7288
13:38:26.954   Training iter 600, batch loss 0.1864, batch acc 0.7258
13:38:26.956 Testing @ 390 epoch...
13:38:26.998     Testing, total mean loss 0.18862, total acc 0.71880
13:38:26.999 Training @ 391 epoch...
13:38:27.601   Training iter 50, batch loss 0.1938, batch acc 0.7134
13:38:28.197   Training iter 100, batch loss 0.1891, batch acc 0.7210
13:38:28.781   Training iter 150, batch loss 0.1925, batch acc 0.7128
13:38:29.387   Training iter 200, batch loss 0.1860, batch acc 0.7256
13:38:29.985   Training iter 250, batch loss 0.1890, batch acc 0.7234
13:38:30.587   Training iter 300, batch loss 0.1860, batch acc 0.7256
13:38:31.191   Training iter 350, batch loss 0.1887, batch acc 0.7234
13:38:31.794   Training iter 400, batch loss 0.1890, batch acc 0.7242
13:38:32.388   Training iter 450, batch loss 0.1910, batch acc 0.7204
13:38:32.957   Training iter 500, batch loss 0.1902, batch acc 0.7190
13:38:33.527   Training iter 550, batch loss 0.1864, batch acc 0.7304
13:38:34.097   Training iter 600, batch loss 0.1904, batch acc 0.7208
13:38:34.099 Training @ 392 epoch...
13:38:34.678   Training iter 50, batch loss 0.1933, batch acc 0.7130
13:38:35.250   Training iter 100, batch loss 0.1913, batch acc 0.7188
13:38:35.816   Training iter 150, batch loss 0.1921, batch acc 0.7192
13:38:36.391   Training iter 200, batch loss 0.1862, batch acc 0.7268
13:38:36.971   Training iter 250, batch loss 0.1873, batch acc 0.7266
13:38:37.556   Training iter 300, batch loss 0.1897, batch acc 0.7196
13:38:38.149   Training iter 350, batch loss 0.1864, batch acc 0.7296
13:38:38.737   Training iter 400, batch loss 0.1909, batch acc 0.7154
13:38:39.318   Training iter 450, batch loss 0.1871, batch acc 0.7250
13:38:39.888   Training iter 500, batch loss 0.1890, batch acc 0.7200
13:38:40.432   Training iter 550, batch loss 0.1876, batch acc 0.7234
13:38:40.917   Training iter 600, batch loss 0.1909, batch acc 0.7214
13:38:40.919 Training @ 393 epoch...
13:38:41.402   Training iter 50, batch loss 0.1872, batch acc 0.7258
13:38:41.877   Training iter 100, batch loss 0.1890, batch acc 0.7234
13:38:42.359   Training iter 150, batch loss 0.1909, batch acc 0.7204
13:38:42.878   Training iter 200, batch loss 0.1959, batch acc 0.7066
13:38:43.390   Training iter 250, batch loss 0.1880, batch acc 0.7228
13:38:43.896   Training iter 300, batch loss 0.1866, batch acc 0.7260
13:38:44.430   Training iter 350, batch loss 0.1875, batch acc 0.7250
13:38:44.945   Training iter 400, batch loss 0.1919, batch acc 0.7166
13:38:45.471   Training iter 450, batch loss 0.1917, batch acc 0.7164
13:38:45.992   Training iter 500, batch loss 0.1911, batch acc 0.7186
13:38:46.522   Training iter 550, batch loss 0.1871, batch acc 0.7276
13:38:47.042   Training iter 600, batch loss 0.1847, batch acc 0.7298
13:38:47.044 Training @ 394 epoch...
13:38:47.588   Training iter 50, batch loss 0.1925, batch acc 0.7152
13:38:48.106   Training iter 100, batch loss 0.1872, batch acc 0.7194
13:38:48.612   Training iter 150, batch loss 0.1890, batch acc 0.7234
13:38:49.097   Training iter 200, batch loss 0.1967, batch acc 0.7110
13:38:49.592   Training iter 250, batch loss 0.1885, batch acc 0.7244
13:38:50.152   Training iter 300, batch loss 0.1870, batch acc 0.7264
13:38:50.715   Training iter 350, batch loss 0.1907, batch acc 0.7174
13:38:51.277   Training iter 400, batch loss 0.1816, batch acc 0.7366
13:38:51.783   Training iter 450, batch loss 0.1874, batch acc 0.7298
13:38:52.290   Training iter 500, batch loss 0.1892, batch acc 0.7220
13:38:52.814   Training iter 550, batch loss 0.1908, batch acc 0.7168
13:38:53.330   Training iter 600, batch loss 0.1909, batch acc 0.7176
13:38:53.332 Training @ 395 epoch...
13:38:53.845   Training iter 50, batch loss 0.1894, batch acc 0.7250
13:38:54.362   Training iter 100, batch loss 0.1872, batch acc 0.7270
13:38:54.881   Training iter 150, batch loss 0.1877, batch acc 0.7200
13:38:55.397   Training iter 200, batch loss 0.1885, batch acc 0.7238
13:38:55.890   Training iter 250, batch loss 0.1901, batch acc 0.7200
13:38:56.387   Training iter 300, batch loss 0.1885, batch acc 0.7262
13:38:56.872   Training iter 350, batch loss 0.1906, batch acc 0.7174
13:38:57.374   Training iter 400, batch loss 0.1964, batch acc 0.7056
13:38:57.891   Training iter 450, batch loss 0.1899, batch acc 0.7164
13:38:58.392   Training iter 500, batch loss 0.1886, batch acc 0.7206
13:38:58.895   Training iter 550, batch loss 0.1871, batch acc 0.7282
13:38:59.392   Training iter 600, batch loss 0.1873, batch acc 0.7276
13:38:59.393 Testing @ 395 epoch...
13:38:59.430     Testing, total mean loss 0.18857, total acc 0.71910
13:38:59.430 Training @ 396 epoch...
13:38:59.944   Training iter 50, batch loss 0.1890, batch acc 0.7226
13:39:00.461   Training iter 100, batch loss 0.1912, batch acc 0.7154
13:39:00.947   Training iter 150, batch loss 0.1895, batch acc 0.7228
13:39:01.469   Training iter 200, batch loss 0.1915, batch acc 0.7172
13:39:02.013   Training iter 250, batch loss 0.1854, batch acc 0.7282
13:39:02.560   Training iter 300, batch loss 0.1910, batch acc 0.7168
13:39:03.099   Training iter 350, batch loss 0.1893, batch acc 0.7222
13:39:03.632   Training iter 400, batch loss 0.1903, batch acc 0.7218
13:39:04.163   Training iter 450, batch loss 0.1872, batch acc 0.7248
13:39:04.678   Training iter 500, batch loss 0.1869, batch acc 0.7260
13:39:05.208   Training iter 550, batch loss 0.1894, batch acc 0.7230
13:39:05.717   Training iter 600, batch loss 0.1907, batch acc 0.7204
13:39:05.718 Training @ 397 epoch...
13:39:06.217   Training iter 50, batch loss 0.1873, batch acc 0.7268
13:39:06.727   Training iter 100, batch loss 0.1907, batch acc 0.7132
13:39:07.201   Training iter 150, batch loss 0.1929, batch acc 0.7136
13:39:07.655   Training iter 200, batch loss 0.1856, batch acc 0.7306
13:39:08.109   Training iter 250, batch loss 0.1935, batch acc 0.7168
13:39:08.564   Training iter 300, batch loss 0.1878, batch acc 0.7202
13:39:09.029   Training iter 350, batch loss 0.1870, batch acc 0.7308
13:39:09.498   Training iter 400, batch loss 0.1906, batch acc 0.7184
13:39:09.966   Training iter 450, batch loss 0.1902, batch acc 0.7200
13:39:10.458   Training iter 500, batch loss 0.1835, batch acc 0.7354
13:39:10.923   Training iter 550, batch loss 0.1893, batch acc 0.7218
13:39:11.374   Training iter 600, batch loss 0.1929, batch acc 0.7122
13:39:11.375 Training @ 398 epoch...
13:39:11.814   Training iter 50, batch loss 0.1854, batch acc 0.7294
13:39:12.271   Training iter 100, batch loss 0.1888, batch acc 0.7234
13:39:12.731   Training iter 150, batch loss 0.1835, batch acc 0.7296
13:39:13.209   Training iter 200, batch loss 0.1913, batch acc 0.7174
13:39:13.674   Training iter 250, batch loss 0.1874, batch acc 0.7282
13:39:14.137   Training iter 300, batch loss 0.1890, batch acc 0.7244
13:39:14.633   Training iter 350, batch loss 0.1837, batch acc 0.7328
13:39:15.158   Training iter 400, batch loss 0.1978, batch acc 0.7030
13:39:15.671   Training iter 450, batch loss 0.1925, batch acc 0.7142
13:39:16.161   Training iter 500, batch loss 0.1960, batch acc 0.7074
13:39:16.648   Training iter 550, batch loss 0.1861, batch acc 0.7290
13:39:17.136   Training iter 600, batch loss 0.1895, batch acc 0.7216
13:39:17.138 Training @ 399 epoch...
13:39:17.640   Training iter 50, batch loss 0.1902, batch acc 0.7206
13:39:18.154   Training iter 100, batch loss 0.1909, batch acc 0.7190
13:39:18.660   Training iter 150, batch loss 0.1805, batch acc 0.7424
13:39:19.163   Training iter 200, batch loss 0.1913, batch acc 0.7192
13:39:19.670   Training iter 250, batch loss 0.1913, batch acc 0.7176
13:39:20.189   Training iter 300, batch loss 0.1935, batch acc 0.7126
13:39:20.663   Training iter 350, batch loss 0.1912, batch acc 0.7170
13:39:21.138   Training iter 400, batch loss 0.1884, batch acc 0.7208
13:39:21.625   Training iter 450, batch loss 0.1885, batch acc 0.7238
13:39:22.102   Training iter 500, batch loss 0.1870, batch acc 0.7214
13:39:22.581   Training iter 550, batch loss 0.1871, batch acc 0.7242
13:39:23.076   Training iter 600, batch loss 0.1908, batch acc 0.7208
13:39:23.078 Training @ 400 epoch...
13:39:23.587   Training iter 50, batch loss 0.1947, batch acc 0.7102
13:39:24.068   Training iter 100, batch loss 0.1919, batch acc 0.7136
13:39:24.553   Training iter 150, batch loss 0.1909, batch acc 0.7204
13:39:25.071   Training iter 200, batch loss 0.1819, batch acc 0.7344
13:39:25.560   Training iter 250, batch loss 0.1878, batch acc 0.7274
13:39:26.029   Training iter 300, batch loss 0.1879, batch acc 0.7254
13:39:26.489   Training iter 350, batch loss 0.1848, batch acc 0.7314
13:39:26.946   Training iter 400, batch loss 0.1908, batch acc 0.7214
13:39:27.417   Training iter 450, batch loss 0.1878, batch acc 0.7272
13:39:27.894   Training iter 500, batch loss 0.1964, batch acc 0.7074
13:39:28.377   Training iter 550, batch loss 0.1847, batch acc 0.7298
13:39:28.857   Training iter 600, batch loss 0.1910, batch acc 0.7146
13:39:28.859 Testing @ 400 epoch...
13:39:28.895     Testing, total mean loss 0.18853, total acc 0.71920
13:39:28.896 Plot @ 400 epoch...
13:39:28.896 Training @ 401 epoch...
13:39:29.363   Training iter 50, batch loss 0.1867, batch acc 0.7310
13:39:29.846   Training iter 100, batch loss 0.1887, batch acc 0.7214
13:39:30.364   Training iter 150, batch loss 0.1886, batch acc 0.7226
13:39:30.886   Training iter 200, batch loss 0.1864, batch acc 0.7256
13:39:31.352   Training iter 250, batch loss 0.1940, batch acc 0.7106
13:39:31.814   Training iter 300, batch loss 0.1877, batch acc 0.7230
13:39:32.281   Training iter 350, batch loss 0.1930, batch acc 0.7180
13:39:32.754   Training iter 400, batch loss 0.1917, batch acc 0.7196
13:39:33.236   Training iter 450, batch loss 0.1903, batch acc 0.7148
13:39:33.717   Training iter 500, batch loss 0.1874, batch acc 0.7240
13:39:34.192   Training iter 550, batch loss 0.1852, batch acc 0.7292
13:39:34.663   Training iter 600, batch loss 0.1908, batch acc 0.7202
13:39:34.665 Training @ 402 epoch...
13:39:35.133   Training iter 50, batch loss 0.1873, batch acc 0.7296
13:39:35.620   Training iter 100, batch loss 0.1900, batch acc 0.7244
13:39:36.094   Training iter 150, batch loss 0.1917, batch acc 0.7136
13:39:36.566   Training iter 200, batch loss 0.1835, batch acc 0.7320
13:39:37.040   Training iter 250, batch loss 0.1883, batch acc 0.7246
13:39:37.518   Training iter 300, batch loss 0.1899, batch acc 0.7144
13:39:37.987   Training iter 350, batch loss 0.1886, batch acc 0.7258
13:39:38.461   Training iter 400, batch loss 0.1875, batch acc 0.7252
13:39:38.925   Training iter 450, batch loss 0.1912, batch acc 0.7150
13:39:39.420   Training iter 500, batch loss 0.1926, batch acc 0.7134
13:39:39.907   Training iter 550, batch loss 0.1894, batch acc 0.7226
13:39:40.395   Training iter 600, batch loss 0.1905, batch acc 0.7198
13:39:40.396 Training @ 403 epoch...
13:39:40.872   Training iter 50, batch loss 0.1866, batch acc 0.7254
13:39:41.335   Training iter 100, batch loss 0.1874, batch acc 0.7226
13:39:41.794   Training iter 150, batch loss 0.1910, batch acc 0.7174
13:39:42.250   Training iter 200, batch loss 0.1881, batch acc 0.7226
13:39:42.717   Training iter 250, batch loss 0.1934, batch acc 0.7104
13:39:43.185   Training iter 300, batch loss 0.1885, batch acc 0.7232
13:39:43.665   Training iter 350, batch loss 0.1940, batch acc 0.7160
13:39:44.127   Training iter 400, batch loss 0.1886, batch acc 0.7282
13:39:44.593   Training iter 450, batch loss 0.1959, batch acc 0.7116
13:39:45.057   Training iter 500, batch loss 0.1878, batch acc 0.7230
13:39:45.523   Training iter 550, batch loss 0.1850, batch acc 0.7272
13:39:45.984   Training iter 600, batch loss 0.1840, batch acc 0.7350
13:39:45.986 Training @ 404 epoch...
13:39:46.471   Training iter 50, batch loss 0.1839, batch acc 0.7332
13:39:46.958   Training iter 100, batch loss 0.1865, batch acc 0.7302
13:39:47.432   Training iter 150, batch loss 0.1915, batch acc 0.7150
13:39:47.905   Training iter 200, batch loss 0.1848, batch acc 0.7316
13:39:48.381   Training iter 250, batch loss 0.1888, batch acc 0.7214
13:39:48.847   Training iter 300, batch loss 0.1929, batch acc 0.7120
13:39:49.311   Training iter 350, batch loss 0.1889, batch acc 0.7204
13:39:49.784   Training iter 400, batch loss 0.1890, batch acc 0.7228
13:39:50.267   Training iter 450, batch loss 0.1940, batch acc 0.7134
13:39:50.747   Training iter 500, batch loss 0.1877, batch acc 0.7222
13:39:51.220   Training iter 550, batch loss 0.1925, batch acc 0.7162
13:39:51.712   Training iter 600, batch loss 0.1895, batch acc 0.7252
13:39:51.713 Training @ 405 epoch...
13:39:52.186   Training iter 50, batch loss 0.1880, batch acc 0.7254
13:39:52.636   Training iter 100, batch loss 0.1937, batch acc 0.7102
13:39:53.095   Training iter 150, batch loss 0.1959, batch acc 0.7090
13:39:53.562   Training iter 200, batch loss 0.1876, batch acc 0.7230
13:39:54.028   Training iter 250, batch loss 0.1832, batch acc 0.7334
13:39:54.494   Training iter 300, batch loss 0.1876, batch acc 0.7268
13:39:54.956   Training iter 350, batch loss 0.1903, batch acc 0.7194
13:39:55.439   Training iter 400, batch loss 0.1926, batch acc 0.7148
13:39:55.915   Training iter 450, batch loss 0.1873, batch acc 0.7252
13:39:56.381   Training iter 500, batch loss 0.1851, batch acc 0.7260
13:39:56.851   Training iter 550, batch loss 0.1868, batch acc 0.7254
13:39:57.317   Training iter 600, batch loss 0.1918, batch acc 0.7204
13:39:57.319 Testing @ 405 epoch...
13:39:57.355     Testing, total mean loss 0.18847, total acc 0.71950
13:39:57.355 Training @ 406 epoch...
13:39:57.840   Training iter 50, batch loss 0.1888, batch acc 0.7206
13:39:58.316   Training iter 100, batch loss 0.1868, batch acc 0.7242
13:39:58.794   Training iter 150, batch loss 0.1882, batch acc 0.7226
13:39:59.264   Training iter 200, batch loss 0.1934, batch acc 0.7134
13:39:59.740   Training iter 250, batch loss 0.1898, batch acc 0.7216
13:40:00.240   Training iter 300, batch loss 0.1855, batch acc 0.7336
13:40:00.735   Training iter 350, batch loss 0.1882, batch acc 0.7244
13:40:01.228   Training iter 400, batch loss 0.1889, batch acc 0.7240
13:40:01.745   Training iter 450, batch loss 0.1875, batch acc 0.7246
13:40:02.288   Training iter 500, batch loss 0.1846, batch acc 0.7302
13:40:02.844   Training iter 550, batch loss 0.1937, batch acc 0.7126
13:40:03.401   Training iter 600, batch loss 0.1946, batch acc 0.7112
13:40:03.403 Training @ 407 epoch...
13:40:03.921   Training iter 50, batch loss 0.1871, batch acc 0.7260
13:40:04.426   Training iter 100, batch loss 0.1866, batch acc 0.7264
13:40:04.938   Training iter 150, batch loss 0.1925, batch acc 0.7168
13:40:05.448   Training iter 200, batch loss 0.1927, batch acc 0.7122
13:40:05.962   Training iter 250, batch loss 0.1925, batch acc 0.7176
13:40:06.475   Training iter 300, batch loss 0.1850, batch acc 0.7298
13:40:06.984   Training iter 350, batch loss 0.1859, batch acc 0.7300
13:40:07.487   Training iter 400, batch loss 0.1915, batch acc 0.7134
13:40:07.982   Training iter 450, batch loss 0.1904, batch acc 0.7218
13:40:08.482   Training iter 500, batch loss 0.1850, batch acc 0.7292
13:40:08.976   Training iter 550, batch loss 0.1919, batch acc 0.7168
13:40:09.467   Training iter 600, batch loss 0.1886, batch acc 0.7212
13:40:09.469 Training @ 408 epoch...
13:40:09.966   Training iter 50, batch loss 0.1880, batch acc 0.7226
13:40:10.442   Training iter 100, batch loss 0.1853, batch acc 0.7256
13:40:10.906   Training iter 150, batch loss 0.1871, batch acc 0.7280
13:40:11.378   Training iter 200, batch loss 0.1933, batch acc 0.7120
13:40:11.841   Training iter 250, batch loss 0.1940, batch acc 0.7118
13:40:12.302   Training iter 300, batch loss 0.1848, batch acc 0.7286
13:40:12.772   Training iter 350, batch loss 0.1896, batch acc 0.7272
13:40:13.254   Training iter 400, batch loss 0.1892, batch acc 0.7226
13:40:13.745   Training iter 450, batch loss 0.1883, batch acc 0.7262
13:40:14.251   Training iter 500, batch loss 0.1915, batch acc 0.7164
13:40:14.740   Training iter 550, batch loss 0.1903, batch acc 0.7170
13:40:15.240   Training iter 600, batch loss 0.1883, batch acc 0.7234
13:40:15.242 Training @ 409 epoch...
13:40:15.781   Training iter 50, batch loss 0.1881, batch acc 0.7240
13:40:16.317   Training iter 100, batch loss 0.1915, batch acc 0.7198
13:40:16.864   Training iter 150, batch loss 0.1893, batch acc 0.7248
13:40:17.402   Training iter 200, batch loss 0.1911, batch acc 0.7154
13:40:17.941   Training iter 250, batch loss 0.1885, batch acc 0.7228
13:40:18.496   Training iter 300, batch loss 0.1893, batch acc 0.7204
13:40:19.063   Training iter 350, batch loss 0.1904, batch acc 0.7186
13:40:19.623   Training iter 400, batch loss 0.1854, batch acc 0.7276
13:40:20.182   Training iter 450, batch loss 0.1965, batch acc 0.7072
13:40:20.728   Training iter 500, batch loss 0.1910, batch acc 0.7182
13:40:21.286   Training iter 550, batch loss 0.1850, batch acc 0.7274
13:40:21.843   Training iter 600, batch loss 0.1832, batch acc 0.7328
13:40:21.845 Training @ 410 epoch...
13:40:22.404   Training iter 50, batch loss 0.1813, batch acc 0.7356
13:40:22.942   Training iter 100, batch loss 0.1926, batch acc 0.7164
13:40:23.489   Training iter 150, batch loss 0.1870, batch acc 0.7234
13:40:24.011   Training iter 200, batch loss 0.1913, batch acc 0.7138
13:40:24.519   Training iter 250, batch loss 0.1839, batch acc 0.7294
13:40:25.021   Training iter 300, batch loss 0.1903, batch acc 0.7212
13:40:25.543   Training iter 350, batch loss 0.1902, batch acc 0.7226
13:40:26.039   Training iter 400, batch loss 0.1920, batch acc 0.7182
13:40:26.526   Training iter 450, batch loss 0.1842, batch acc 0.7284
13:40:27.013   Training iter 500, batch loss 0.1910, batch acc 0.7208
13:40:27.513   Training iter 550, batch loss 0.1922, batch acc 0.7180
13:40:28.020   Training iter 600, batch loss 0.1934, batch acc 0.7148
13:40:28.021 Testing @ 410 epoch...
13:40:28.058     Testing, total mean loss 0.18839, total acc 0.71960
13:40:28.058 Training @ 411 epoch...
13:40:28.562   Training iter 50, batch loss 0.1885, batch acc 0.7214
13:40:29.071   Training iter 100, batch loss 0.1884, batch acc 0.7268
13:40:29.603   Training iter 150, batch loss 0.1872, batch acc 0.7254
13:40:30.138   Training iter 200, batch loss 0.1874, batch acc 0.7190
13:40:30.659   Training iter 250, batch loss 0.1903, batch acc 0.7200
13:40:31.156   Training iter 300, batch loss 0.1927, batch acc 0.7160
13:40:31.661   Training iter 350, batch loss 0.1912, batch acc 0.7198
13:40:32.162   Training iter 400, batch loss 0.1938, batch acc 0.7144
13:40:32.657   Training iter 450, batch loss 0.1883, batch acc 0.7234
13:40:33.176   Training iter 500, batch loss 0.1925, batch acc 0.7140
13:40:33.694   Training iter 550, batch loss 0.1838, batch acc 0.7298
13:40:34.203   Training iter 600, batch loss 0.1852, batch acc 0.7304
13:40:34.205 Training @ 412 epoch...
13:40:34.717   Training iter 50, batch loss 0.1945, batch acc 0.7118
13:40:35.245   Training iter 100, batch loss 0.1865, batch acc 0.7254
13:40:35.793   Training iter 150, batch loss 0.1915, batch acc 0.7208
13:40:36.338   Training iter 200, batch loss 0.1866, batch acc 0.7266
13:40:36.894   Training iter 250, batch loss 0.1916, batch acc 0.7186
13:40:37.448   Training iter 300, batch loss 0.1949, batch acc 0.7098
13:40:38.007   Training iter 350, batch loss 0.1813, batch acc 0.7352
13:40:38.543   Training iter 400, batch loss 0.1927, batch acc 0.7180
13:40:39.064   Training iter 450, batch loss 0.1869, batch acc 0.7248
13:40:39.571   Training iter 500, batch loss 0.1862, batch acc 0.7218
13:40:40.069   Training iter 550, batch loss 0.1886, batch acc 0.7242
13:40:40.599   Training iter 600, batch loss 0.1878, batch acc 0.7254
13:40:40.601 Training @ 413 epoch...
13:40:41.127   Training iter 50, batch loss 0.1837, batch acc 0.7310
13:40:41.638   Training iter 100, batch loss 0.1878, batch acc 0.7258
13:40:42.127   Training iter 150, batch loss 0.1884, batch acc 0.7188
13:40:42.619   Training iter 200, batch loss 0.1909, batch acc 0.7186
13:40:43.185   Training iter 250, batch loss 0.1898, batch acc 0.7190
13:40:43.749   Training iter 300, batch loss 0.1872, batch acc 0.7250
13:40:44.310   Training iter 350, batch loss 0.1937, batch acc 0.7178
13:40:44.832   Training iter 400, batch loss 0.1867, batch acc 0.7264
13:40:45.313   Training iter 450, batch loss 0.1928, batch acc 0.7136
13:40:45.806   Training iter 500, batch loss 0.1907, batch acc 0.7200
13:40:46.291   Training iter 550, batch loss 0.1866, batch acc 0.7282
13:40:46.808   Training iter 600, batch loss 0.1909, batch acc 0.7158
13:40:46.810 Training @ 414 epoch...
13:40:47.319   Training iter 50, batch loss 0.1919, batch acc 0.7184
13:40:47.825   Training iter 100, batch loss 0.1901, batch acc 0.7192
13:40:48.335   Training iter 150, batch loss 0.1889, batch acc 0.7238
13:40:48.831   Training iter 200, batch loss 0.1904, batch acc 0.7182
13:40:49.317   Training iter 250, batch loss 0.1891, batch acc 0.7204
13:40:49.814   Training iter 300, batch loss 0.1882, batch acc 0.7216
13:40:50.314   Training iter 350, batch loss 0.1866, batch acc 0.7260
13:40:50.835   Training iter 400, batch loss 0.1901, batch acc 0.7176
13:40:51.351   Training iter 450, batch loss 0.1839, batch acc 0.7330
13:40:51.870   Training iter 500, batch loss 0.1903, batch acc 0.7202
13:40:52.389   Training iter 550, batch loss 0.1879, batch acc 0.7248
13:40:52.916   Training iter 600, batch loss 0.1917, batch acc 0.7180
13:40:52.918 Training @ 415 epoch...
13:40:53.447   Training iter 50, batch loss 0.1925, batch acc 0.7168
13:40:53.973   Training iter 100, batch loss 0.1871, batch acc 0.7254
13:40:54.506   Training iter 150, batch loss 0.1898, batch acc 0.7194
13:40:55.054   Training iter 200, batch loss 0.1873, batch acc 0.7272
13:40:55.589   Training iter 250, batch loss 0.1863, batch acc 0.7282
13:40:56.108   Training iter 300, batch loss 0.1877, batch acc 0.7228
13:40:56.613   Training iter 350, batch loss 0.1898, batch acc 0.7172
13:40:57.105   Training iter 400, batch loss 0.1844, batch acc 0.7312
13:40:57.596   Training iter 450, batch loss 0.1909, batch acc 0.7196
13:40:58.086   Training iter 500, batch loss 0.1890, batch acc 0.7236
13:40:58.584   Training iter 550, batch loss 0.1911, batch acc 0.7186
13:40:59.084   Training iter 600, batch loss 0.1928, batch acc 0.7132
13:40:59.085 Testing @ 415 epoch...
13:40:59.123     Testing, total mean loss 0.18836, total acc 0.71960
13:40:59.123 Training @ 416 epoch...
13:40:59.634   Training iter 50, batch loss 0.1958, batch acc 0.7064
13:41:00.164   Training iter 100, batch loss 0.1871, batch acc 0.7266
13:41:00.696   Training iter 150, batch loss 0.1889, batch acc 0.7218
13:41:01.192   Training iter 200, batch loss 0.1904, batch acc 0.7204
13:41:01.715   Training iter 250, batch loss 0.1871, batch acc 0.7268
13:41:02.258   Training iter 300, batch loss 0.1853, batch acc 0.7284
13:41:02.800   Training iter 350, batch loss 0.1876, batch acc 0.7248
13:41:03.338   Training iter 400, batch loss 0.1898, batch acc 0.7216
13:41:03.870   Training iter 450, batch loss 0.1850, batch acc 0.7322
13:41:04.411   Training iter 500, batch loss 0.1924, batch acc 0.7106
13:41:04.936   Training iter 550, batch loss 0.1906, batch acc 0.7196
13:41:05.478   Training iter 600, batch loss 0.1885, batch acc 0.7236
13:41:05.480 Training @ 417 epoch...
13:41:06.011   Training iter 50, batch loss 0.1871, batch acc 0.7258
13:41:06.534   Training iter 100, batch loss 0.1896, batch acc 0.7208
13:41:07.047   Training iter 150, batch loss 0.1953, batch acc 0.7120
13:41:07.546   Training iter 200, batch loss 0.1888, batch acc 0.7218
13:41:08.057   Training iter 250, batch loss 0.1907, batch acc 0.7174
13:41:08.578   Training iter 300, batch loss 0.1809, batch acc 0.7382
13:41:09.109   Training iter 350, batch loss 0.1859, batch acc 0.7294
13:41:09.640   Training iter 400, batch loss 0.1931, batch acc 0.7150
13:41:10.178   Training iter 450, batch loss 0.1877, batch acc 0.7214
13:41:10.718   Training iter 500, batch loss 0.1853, batch acc 0.7248
13:41:11.263   Training iter 550, batch loss 0.1940, batch acc 0.7168
13:41:11.808   Training iter 600, batch loss 0.1902, batch acc 0.7192
13:41:11.810 Training @ 418 epoch...
13:41:12.350   Training iter 50, batch loss 0.1870, batch acc 0.7240
13:41:12.861   Training iter 100, batch loss 0.1859, batch acc 0.7288
13:41:13.377   Training iter 150, batch loss 0.1898, batch acc 0.7190
13:41:13.879   Training iter 200, batch loss 0.1883, batch acc 0.7226
13:41:14.366   Training iter 250, batch loss 0.1887, batch acc 0.7240
13:41:14.852   Training iter 300, batch loss 0.1878, batch acc 0.7236
13:41:15.349   Training iter 350, batch loss 0.1941, batch acc 0.7128
13:41:15.868   Training iter 400, batch loss 0.1890, batch acc 0.7216
13:41:16.388   Training iter 450, batch loss 0.1918, batch acc 0.7176
13:41:16.907   Training iter 500, batch loss 0.1911, batch acc 0.7186
13:41:17.429   Training iter 550, batch loss 0.1903, batch acc 0.7180
13:41:17.944   Training iter 600, batch loss 0.1845, batch acc 0.7328
13:41:17.946 Training @ 419 epoch...
13:41:18.475   Training iter 50, batch loss 0.1896, batch acc 0.7206
13:41:19.003   Training iter 100, batch loss 0.1959, batch acc 0.7090
13:41:19.522   Training iter 150, batch loss 0.1916, batch acc 0.7170
13:41:20.062   Training iter 200, batch loss 0.1891, batch acc 0.7250
13:41:20.612   Training iter 250, batch loss 0.1891, batch acc 0.7206
13:41:21.157   Training iter 300, batch loss 0.1850, batch acc 0.7260
13:41:21.701   Training iter 350, batch loss 0.1859, batch acc 0.7336
13:41:22.255   Training iter 400, batch loss 0.1871, batch acc 0.7236
13:41:22.818   Training iter 450, batch loss 0.1909, batch acc 0.7194
13:41:23.389   Training iter 500, batch loss 0.1918, batch acc 0.7134
13:41:23.947   Training iter 550, batch loss 0.1885, batch acc 0.7228
13:41:24.517   Training iter 600, batch loss 0.1839, batch acc 0.7306
13:41:24.519 Training @ 420 epoch...
13:41:25.099   Training iter 50, batch loss 0.1874, batch acc 0.7230
13:41:25.668   Training iter 100, batch loss 0.1927, batch acc 0.7164
13:41:26.228   Training iter 150, batch loss 0.1863, batch acc 0.7292
13:41:26.784   Training iter 200, batch loss 0.1885, batch acc 0.7208
13:41:27.351   Training iter 250, batch loss 0.1944, batch acc 0.7132
13:41:27.926   Training iter 300, batch loss 0.1906, batch acc 0.7154
13:41:28.499   Training iter 350, batch loss 0.1903, batch acc 0.7200
13:41:29.062   Training iter 400, batch loss 0.1857, batch acc 0.7332
13:41:29.610   Training iter 450, batch loss 0.1903, batch acc 0.7210
13:41:30.176   Training iter 500, batch loss 0.1904, batch acc 0.7186
13:41:30.721   Training iter 550, batch loss 0.1838, batch acc 0.7326
13:41:31.254   Training iter 600, batch loss 0.1877, batch acc 0.7218
13:41:31.256 Testing @ 420 epoch...
13:41:31.296     Testing, total mean loss 0.18832, total acc 0.72020
13:41:31.296 Training @ 421 epoch...
13:41:31.834   Training iter 50, batch loss 0.1886, batch acc 0.7248
13:41:32.381   Training iter 100, batch loss 0.1878, batch acc 0.7284
13:41:32.919   Training iter 150, batch loss 0.1895, batch acc 0.7160
13:41:33.458   Training iter 200, batch loss 0.1872, batch acc 0.7272
13:41:34.002   Training iter 250, batch loss 0.1866, batch acc 0.7256
13:41:34.546   Training iter 300, batch loss 0.1918, batch acc 0.7126
13:41:35.082   Training iter 350, batch loss 0.1888, batch acc 0.7240
13:41:35.653   Training iter 400, batch loss 0.1869, batch acc 0.7264
13:41:36.171   Training iter 450, batch loss 0.1919, batch acc 0.7168
13:41:36.674   Training iter 500, batch loss 0.1922, batch acc 0.7126
13:41:37.173   Training iter 550, batch loss 0.1908, batch acc 0.7194
13:41:37.643   Training iter 600, batch loss 0.1860, batch acc 0.7288
13:41:37.644 Training @ 422 epoch...
13:41:38.191   Training iter 50, batch loss 0.1852, batch acc 0.7252
13:41:38.750   Training iter 100, batch loss 0.1875, batch acc 0.7294
13:41:39.275   Training iter 150, batch loss 0.1954, batch acc 0.7118
13:41:39.858   Training iter 200, batch loss 0.1913, batch acc 0.7174
13:41:40.519   Training iter 250, batch loss 0.1873, batch acc 0.7270
13:41:41.094   Training iter 300, batch loss 0.1881, batch acc 0.7236
13:41:41.613   Training iter 350, batch loss 0.1839, batch acc 0.7302
13:41:42.117   Training iter 400, batch loss 0.1925, batch acc 0.7152
13:41:42.643   Training iter 450, batch loss 0.1861, batch acc 0.7262
13:41:43.220   Training iter 500, batch loss 0.1919, batch acc 0.7148
13:41:43.765   Training iter 550, batch loss 0.1890, batch acc 0.7216
13:41:44.299   Training iter 600, batch loss 0.1897, batch acc 0.7218
13:41:44.301 Training @ 423 epoch...
13:41:44.814   Training iter 50, batch loss 0.1830, batch acc 0.7330
13:41:45.336   Training iter 100, batch loss 0.1911, batch acc 0.7164
13:41:45.842   Training iter 150, batch loss 0.1839, batch acc 0.7308
13:41:46.344   Training iter 200, batch loss 0.1870, batch acc 0.7314
13:41:46.847   Training iter 250, batch loss 0.1877, batch acc 0.7296
13:41:47.359   Training iter 300, batch loss 0.1927, batch acc 0.7134
13:41:47.887   Training iter 350, batch loss 0.1944, batch acc 0.7136
13:41:48.417   Training iter 400, batch loss 0.1888, batch acc 0.7194
13:41:48.945   Training iter 450, batch loss 0.1907, batch acc 0.7202
13:41:49.470   Training iter 500, batch loss 0.1907, batch acc 0.7152
13:41:49.936   Training iter 550, batch loss 0.1908, batch acc 0.7178
13:41:50.432   Training iter 600, batch loss 0.1870, batch acc 0.7212
13:41:50.433 Training @ 424 epoch...
13:41:50.947   Training iter 50, batch loss 0.1900, batch acc 0.7194
13:41:51.439   Training iter 100, batch loss 0.1892, batch acc 0.7246
13:41:51.908   Training iter 150, batch loss 0.1862, batch acc 0.7276
13:41:52.391   Training iter 200, batch loss 0.1902, batch acc 0.7204
13:41:52.885   Training iter 250, batch loss 0.1884, batch acc 0.7244
13:41:53.379   Training iter 300, batch loss 0.1931, batch acc 0.7124
13:41:53.876   Training iter 350, batch loss 0.1878, batch acc 0.7240
13:41:54.373   Training iter 400, batch loss 0.1846, batch acc 0.7294
13:41:54.868   Training iter 450, batch loss 0.1921, batch acc 0.7166
13:41:55.357   Training iter 500, batch loss 0.1893, batch acc 0.7204
13:41:55.860   Training iter 550, batch loss 0.1898, batch acc 0.7204
13:41:56.373   Training iter 600, batch loss 0.1870, batch acc 0.7256
13:41:56.375 Training @ 425 epoch...
13:41:56.884   Training iter 50, batch loss 0.1908, batch acc 0.7220
13:41:57.403   Training iter 100, batch loss 0.1871, batch acc 0.7244
13:41:57.920   Training iter 150, batch loss 0.1844, batch acc 0.7290
13:41:58.432   Training iter 200, batch loss 0.1901, batch acc 0.7204
13:41:58.935   Training iter 250, batch loss 0.1955, batch acc 0.7078
13:41:59.446   Training iter 300, batch loss 0.1864, batch acc 0.7272
13:41:59.952   Training iter 350, batch loss 0.1816, batch acc 0.7344
13:42:00.464   Training iter 400, batch loss 0.1951, batch acc 0.7098
13:42:00.994   Training iter 450, batch loss 0.1905, batch acc 0.7158
13:42:01.528   Training iter 500, batch loss 0.1885, batch acc 0.7234
13:42:02.088   Training iter 550, batch loss 0.1882, batch acc 0.7192
13:42:02.640   Training iter 600, batch loss 0.1891, batch acc 0.7272
13:42:02.642 Testing @ 425 epoch...
13:42:02.679     Testing, total mean loss 0.18825, total acc 0.71970
13:42:02.679 Training @ 426 epoch...
13:42:03.222   Training iter 50, batch loss 0.1930, batch acc 0.7178
13:42:03.729   Training iter 100, batch loss 0.1886, batch acc 0.7234
13:42:04.240   Training iter 150, batch loss 0.1938, batch acc 0.7100
13:42:04.748   Training iter 200, batch loss 0.1831, batch acc 0.7354
13:42:05.258   Training iter 250, batch loss 0.1852, batch acc 0.7304
13:42:05.767   Training iter 300, batch loss 0.1862, batch acc 0.7268
13:42:06.271   Training iter 350, batch loss 0.1884, batch acc 0.7230
13:42:06.785   Training iter 400, batch loss 0.1912, batch acc 0.7172
13:42:07.296   Training iter 450, batch loss 0.1932, batch acc 0.7142
13:42:07.798   Training iter 500, batch loss 0.1882, batch acc 0.7200
13:42:08.300   Training iter 550, batch loss 0.1900, batch acc 0.7202
13:42:08.805   Training iter 600, batch loss 0.1866, batch acc 0.7262
13:42:08.807 Training @ 427 epoch...
13:42:09.326   Training iter 50, batch loss 0.1898, batch acc 0.7224
13:42:09.837   Training iter 100, batch loss 0.1912, batch acc 0.7136
13:42:10.360   Training iter 150, batch loss 0.1930, batch acc 0.7154
13:42:10.871   Training iter 200, batch loss 0.1888, batch acc 0.7196
13:42:11.387   Training iter 250, batch loss 0.1904, batch acc 0.7182
13:42:11.897   Training iter 300, batch loss 0.1811, batch acc 0.7350
13:42:12.418   Training iter 350, batch loss 0.1885, batch acc 0.7266
13:42:12.926   Training iter 400, batch loss 0.1915, batch acc 0.7188
13:42:13.447   Training iter 450, batch loss 0.1860, batch acc 0.7300
13:42:13.995   Training iter 500, batch loss 0.1934, batch acc 0.7138
13:42:14.538   Training iter 550, batch loss 0.1850, batch acc 0.7298
13:42:15.060   Training iter 600, batch loss 0.1888, batch acc 0.7208
13:42:15.062 Training @ 428 epoch...
13:42:15.600   Training iter 50, batch loss 0.1888, batch acc 0.7204
13:42:16.127   Training iter 100, batch loss 0.1897, batch acc 0.7206
13:42:16.639   Training iter 150, batch loss 0.1853, batch acc 0.7262
13:42:17.146   Training iter 200, batch loss 0.1883, batch acc 0.7254
13:42:17.671   Training iter 250, batch loss 0.1885, batch acc 0.7218
13:42:18.155   Training iter 300, batch loss 0.1892, batch acc 0.7234
13:42:18.632   Training iter 350, batch loss 0.1897, batch acc 0.7214
13:42:19.123   Training iter 400, batch loss 0.1904, batch acc 0.7194
13:42:19.619   Training iter 450, batch loss 0.1897, batch acc 0.7180
13:42:20.108   Training iter 500, batch loss 0.1907, batch acc 0.7166
13:42:20.601   Training iter 550, batch loss 0.1875, batch acc 0.7238
13:42:21.081   Training iter 600, batch loss 0.1895, batch acc 0.7254
13:42:21.083 Training @ 429 epoch...
13:42:21.576   Training iter 50, batch loss 0.1830, batch acc 0.7316
13:42:22.059   Training iter 100, batch loss 0.1871, batch acc 0.7238
13:42:22.549   Training iter 150, batch loss 0.1905, batch acc 0.7196
13:42:23.037   Training iter 200, batch loss 0.1903, batch acc 0.7190
13:42:23.521   Training iter 250, batch loss 0.1936, batch acc 0.7152
13:42:24.029   Training iter 300, batch loss 0.1871, batch acc 0.7260
13:42:24.535   Training iter 350, batch loss 0.1879, batch acc 0.7236
13:42:25.050   Training iter 400, batch loss 0.1901, batch acc 0.7196
13:42:25.561   Training iter 450, batch loss 0.1890, batch acc 0.7210
13:42:26.034   Training iter 500, batch loss 0.1915, batch acc 0.7206
13:42:26.518   Training iter 550, batch loss 0.1853, batch acc 0.7280
13:42:26.982   Training iter 600, batch loss 0.1919, batch acc 0.7186
13:42:26.984 Training @ 430 epoch...
13:42:27.480   Training iter 50, batch loss 0.1888, batch acc 0.7236
13:42:28.026   Training iter 100, batch loss 0.1936, batch acc 0.7160
13:42:28.541   Training iter 150, batch loss 0.1907, batch acc 0.7206
13:42:29.062   Training iter 200, batch loss 0.1914, batch acc 0.7174
13:42:29.572   Training iter 250, batch loss 0.1959, batch acc 0.7076
13:42:30.109   Training iter 300, batch loss 0.1818, batch acc 0.7338
13:42:30.655   Training iter 350, batch loss 0.1827, batch acc 0.7336
13:42:31.211   Training iter 400, batch loss 0.1894, batch acc 0.7210
13:42:31.756   Training iter 450, batch loss 0.1937, batch acc 0.7146
13:42:32.295   Training iter 500, batch loss 0.1858, batch acc 0.7240
13:42:32.841   Training iter 550, batch loss 0.1856, batch acc 0.7284
13:42:33.405   Training iter 600, batch loss 0.1876, batch acc 0.7244
13:42:33.407 Testing @ 430 epoch...
13:42:33.444     Testing, total mean loss 0.18827, total acc 0.72020
13:42:33.444 Training @ 431 epoch...
13:42:34.021   Training iter 50, batch loss 0.1869, batch acc 0.7274
13:42:34.590   Training iter 100, batch loss 0.1895, batch acc 0.7214
13:42:35.137   Training iter 150, batch loss 0.1929, batch acc 0.7172
13:42:35.638   Training iter 200, batch loss 0.1892, batch acc 0.7210
13:42:36.154   Training iter 250, batch loss 0.1921, batch acc 0.7180
13:42:36.668   Training iter 300, batch loss 0.1910, batch acc 0.7146
13:42:37.164   Training iter 350, batch loss 0.1839, batch acc 0.7314
13:42:37.665   Training iter 400, batch loss 0.1882, batch acc 0.7230
13:42:38.185   Training iter 450, batch loss 0.1905, batch acc 0.7196
13:42:38.691   Training iter 500, batch loss 0.1886, batch acc 0.7188
13:42:39.175   Training iter 550, batch loss 0.1854, batch acc 0.7294
13:42:39.640   Training iter 600, batch loss 0.1887, batch acc 0.7198
13:42:39.642 Training @ 432 epoch...
13:42:40.117   Training iter 50, batch loss 0.1886, batch acc 0.7206
13:42:40.611   Training iter 100, batch loss 0.1881, batch acc 0.7226
13:42:41.121   Training iter 150, batch loss 0.1851, batch acc 0.7310
13:42:41.617   Training iter 200, batch loss 0.1878, batch acc 0.7224
13:42:42.100   Training iter 250, batch loss 0.1900, batch acc 0.7210
13:42:42.585   Training iter 300, batch loss 0.1906, batch acc 0.7204
13:42:43.092   Training iter 350, batch loss 0.1905, batch acc 0.7186
13:42:43.623   Training iter 400, batch loss 0.1860, batch acc 0.7284
13:42:44.153   Training iter 450, batch loss 0.1920, batch acc 0.7150
13:42:44.710   Training iter 500, batch loss 0.1863, batch acc 0.7290
13:42:45.269   Training iter 550, batch loss 0.1926, batch acc 0.7154
13:42:45.825   Training iter 600, batch loss 0.1892, batch acc 0.7216
13:42:45.827 Training @ 433 epoch...
13:42:46.366   Training iter 50, batch loss 0.1883, batch acc 0.7222
13:42:46.887   Training iter 100, batch loss 0.1838, batch acc 0.7296
13:42:47.400   Training iter 150, batch loss 0.1940, batch acc 0.7124
13:42:47.915   Training iter 200, batch loss 0.1861, batch acc 0.7270
13:42:48.446   Training iter 250, batch loss 0.1858, batch acc 0.7262
13:42:48.977   Training iter 300, batch loss 0.1889, batch acc 0.7248
13:42:49.493   Training iter 350, batch loss 0.1867, batch acc 0.7220
13:42:49.985   Training iter 400, batch loss 0.1925, batch acc 0.7164
13:42:50.461   Training iter 450, batch loss 0.1872, batch acc 0.7288
13:42:50.938   Training iter 500, batch loss 0.1886, batch acc 0.7234
13:42:51.400   Training iter 550, batch loss 0.1904, batch acc 0.7198
13:42:51.853   Training iter 600, batch loss 0.1945, batch acc 0.7112
13:42:51.855 Training @ 434 epoch...
13:42:52.314   Training iter 50, batch loss 0.1924, batch acc 0.7142
13:42:52.778   Training iter 100, batch loss 0.1805, batch acc 0.7332
13:42:53.247   Training iter 150, batch loss 0.1873, batch acc 0.7240
13:42:53.751   Training iter 200, batch loss 0.1918, batch acc 0.7206
13:42:54.258   Training iter 250, batch loss 0.1857, batch acc 0.7272
13:42:54.768   Training iter 300, batch loss 0.1831, batch acc 0.7328
13:42:55.285   Training iter 350, batch loss 0.1951, batch acc 0.7092
13:42:55.809   Training iter 400, batch loss 0.1894, batch acc 0.7212
13:42:56.319   Training iter 450, batch loss 0.1912, batch acc 0.7222
13:42:56.818   Training iter 500, batch loss 0.1928, batch acc 0.7148
13:42:57.319   Training iter 550, batch loss 0.1892, batch acc 0.7198
13:42:57.843   Training iter 600, batch loss 0.1883, batch acc 0.7248
13:42:57.845 Training @ 435 epoch...
13:42:58.357   Training iter 50, batch loss 0.1894, batch acc 0.7198
13:42:58.859   Training iter 100, batch loss 0.1898, batch acc 0.7252
13:42:59.375   Training iter 150, batch loss 0.1929, batch acc 0.7096
13:42:59.875   Training iter 200, batch loss 0.1873, batch acc 0.7244
13:43:00.373   Training iter 250, batch loss 0.1921, batch acc 0.7156
13:43:00.847   Training iter 300, batch loss 0.1891, batch acc 0.7220
13:43:01.356   Training iter 350, batch loss 0.1838, batch acc 0.7312
13:43:01.893   Training iter 400, batch loss 0.1899, batch acc 0.7174
13:43:02.446   Training iter 450, batch loss 0.1925, batch acc 0.7160
13:43:02.942   Training iter 500, batch loss 0.1888, batch acc 0.7266
13:43:03.438   Training iter 550, batch loss 0.1848, batch acc 0.7296
13:43:03.943   Training iter 600, batch loss 0.1860, batch acc 0.7274
13:43:03.944 Testing @ 435 epoch...
13:43:03.981     Testing, total mean loss 0.18819, total acc 0.72020
13:43:03.981 Training @ 436 epoch...
13:43:04.509   Training iter 50, batch loss 0.1853, batch acc 0.7256
13:43:05.029   Training iter 100, batch loss 0.1887, batch acc 0.7224
13:43:05.509   Training iter 150, batch loss 0.1871, batch acc 0.7286
13:43:05.996   Training iter 200, batch loss 0.1896, batch acc 0.7182
13:43:06.487   Training iter 250, batch loss 0.1946, batch acc 0.7088
13:43:06.983   Training iter 300, batch loss 0.1896, batch acc 0.7242
13:43:07.454   Training iter 350, batch loss 0.1900, batch acc 0.7226
13:43:07.920   Training iter 400, batch loss 0.1863, batch acc 0.7250
13:43:08.389   Training iter 450, batch loss 0.1879, batch acc 0.7224
13:43:08.833   Training iter 500, batch loss 0.1924, batch acc 0.7206
13:43:09.294   Training iter 550, batch loss 0.1896, batch acc 0.7194
13:43:09.781   Training iter 600, batch loss 0.1854, batch acc 0.7264
13:43:09.782 Training @ 437 epoch...
13:43:10.270   Training iter 50, batch loss 0.1886, batch acc 0.7252
13:43:10.731   Training iter 100, batch loss 0.1950, batch acc 0.7150
13:43:11.206   Training iter 150, batch loss 0.1876, batch acc 0.7236
13:43:11.703   Training iter 200, batch loss 0.1895, batch acc 0.7212
13:43:12.206   Training iter 250, batch loss 0.1920, batch acc 0.7128
13:43:12.686   Training iter 300, batch loss 0.1909, batch acc 0.7150
13:43:13.205   Training iter 350, batch loss 0.1871, batch acc 0.7238
13:43:13.694   Training iter 400, batch loss 0.1892, batch acc 0.7242
13:43:14.178   Training iter 450, batch loss 0.1887, batch acc 0.7222
13:43:14.642   Training iter 500, batch loss 0.1888, batch acc 0.7198
13:43:15.100   Training iter 550, batch loss 0.1837, batch acc 0.7300
13:43:15.593   Training iter 600, batch loss 0.1851, batch acc 0.7306
13:43:15.594 Training @ 438 epoch...
13:43:16.110   Training iter 50, batch loss 0.1857, batch acc 0.7292
13:43:16.631   Training iter 100, batch loss 0.1884, batch acc 0.7230
13:43:17.139   Training iter 150, batch loss 0.1855, batch acc 0.7262
13:43:17.642   Training iter 200, batch loss 0.1930, batch acc 0.7140
13:43:18.160   Training iter 250, batch loss 0.1889, batch acc 0.7244
13:43:18.667   Training iter 300, batch loss 0.1899, batch acc 0.7246
13:43:19.176   Training iter 350, batch loss 0.1926, batch acc 0.7134
13:43:19.677   Training iter 400, batch loss 0.1832, batch acc 0.7326
13:43:20.183   Training iter 450, batch loss 0.1947, batch acc 0.7100
13:43:20.694   Training iter 500, batch loss 0.1908, batch acc 0.7172
13:43:21.213   Training iter 550, batch loss 0.1911, batch acc 0.7158
13:43:21.745   Training iter 600, batch loss 0.1822, batch acc 0.7334
13:43:21.747 Training @ 439 epoch...
13:43:22.253   Training iter 50, batch loss 0.1909, batch acc 0.7162
13:43:22.756   Training iter 100, batch loss 0.1855, batch acc 0.7280
13:43:23.247   Training iter 150, batch loss 0.1913, batch acc 0.7168
13:43:23.751   Training iter 200, batch loss 0.1885, batch acc 0.7244
13:43:24.253   Training iter 250, batch loss 0.1862, batch acc 0.7260
13:43:24.734   Training iter 300, batch loss 0.1896, batch acc 0.7216
13:43:25.224   Training iter 350, batch loss 0.1881, batch acc 0.7250
13:43:25.714   Training iter 400, batch loss 0.1876, batch acc 0.7224
13:43:26.218   Training iter 450, batch loss 0.1898, batch acc 0.7206
13:43:26.704   Training iter 500, batch loss 0.1915, batch acc 0.7178
13:43:27.195   Training iter 550, batch loss 0.1911, batch acc 0.7180
13:43:27.688   Training iter 600, batch loss 0.1860, batch acc 0.7264
13:43:27.690 Training @ 440 epoch...
13:43:28.187   Training iter 50, batch loss 0.1893, batch acc 0.7182
13:43:28.691   Training iter 100, batch loss 0.1943, batch acc 0.7134
13:43:29.189   Training iter 150, batch loss 0.1911, batch acc 0.7162
13:43:29.687   Training iter 200, batch loss 0.1889, batch acc 0.7216
13:43:30.190   Training iter 250, batch loss 0.1879, batch acc 0.7282
13:43:30.698   Training iter 300, batch loss 0.1879, batch acc 0.7222
13:43:31.198   Training iter 350, batch loss 0.1883, batch acc 0.7228
13:43:31.707   Training iter 400, batch loss 0.1943, batch acc 0.7090
13:43:32.218   Training iter 450, batch loss 0.1888, batch acc 0.7230
13:43:32.718   Training iter 500, batch loss 0.1861, batch acc 0.7248
13:43:33.209   Training iter 550, batch loss 0.1840, batch acc 0.7330
13:43:33.718   Training iter 600, batch loss 0.1852, batch acc 0.7322
13:43:33.720 Testing @ 440 epoch...
13:43:33.757     Testing, total mean loss 0.18813, total acc 0.71990
13:43:33.757 Training @ 441 epoch...
13:43:34.263   Training iter 50, batch loss 0.1910, batch acc 0.7180
13:43:34.756   Training iter 100, batch loss 0.1885, batch acc 0.7234
13:43:35.236   Training iter 150, batch loss 0.1862, batch acc 0.7280
13:43:35.718   Training iter 200, batch loss 0.1879, batch acc 0.7216
13:43:36.209   Training iter 250, batch loss 0.1938, batch acc 0.7146
13:43:36.691   Training iter 300, batch loss 0.1882, batch acc 0.7214
13:43:37.170   Training iter 350, batch loss 0.1923, batch acc 0.7158
13:43:37.651   Training iter 400, batch loss 0.1859, batch acc 0.7272
13:43:38.133   Training iter 450, batch loss 0.1901, batch acc 0.7174
13:43:38.623   Training iter 500, batch loss 0.1866, batch acc 0.7286
13:43:39.121   Training iter 550, batch loss 0.1897, batch acc 0.7202
13:43:39.613   Training iter 600, batch loss 0.1857, batch acc 0.7288
13:43:39.614 Training @ 442 epoch...
13:43:40.110   Training iter 50, batch loss 0.1857, batch acc 0.7270
13:43:40.597   Training iter 100, batch loss 0.1915, batch acc 0.7182
13:43:41.088   Training iter 150, batch loss 0.1836, batch acc 0.7316
13:43:41.567   Training iter 200, batch loss 0.1864, batch acc 0.7272
13:43:42.047   Training iter 250, batch loss 0.1922, batch acc 0.7148
13:43:42.527   Training iter 300, batch loss 0.1842, batch acc 0.7300
13:43:43.008   Training iter 350, batch loss 0.1916, batch acc 0.7184
13:43:43.517   Training iter 400, batch loss 0.1880, batch acc 0.7220
13:43:44.029   Training iter 450, batch loss 0.1908, batch acc 0.7216
13:43:44.537   Training iter 500, batch loss 0.1871, batch acc 0.7266
13:43:45.046   Training iter 550, batch loss 0.1919, batch acc 0.7174
13:43:45.541   Training iter 600, batch loss 0.1929, batch acc 0.7116
13:43:45.543 Training @ 443 epoch...
13:43:46.051   Training iter 50, batch loss 0.1877, batch acc 0.7264
13:43:46.545   Training iter 100, batch loss 0.1879, batch acc 0.7254
13:43:47.053   Training iter 150, batch loss 0.1914, batch acc 0.7124
13:43:47.566   Training iter 200, batch loss 0.1892, batch acc 0.7190
13:43:48.087   Training iter 250, batch loss 0.1919, batch acc 0.7150
13:43:48.594   Training iter 300, batch loss 0.1848, batch acc 0.7312
13:43:49.096   Training iter 350, batch loss 0.1900, batch acc 0.7192
13:43:49.606   Training iter 400, batch loss 0.1884, batch acc 0.7204
13:43:50.106   Training iter 450, batch loss 0.1861, batch acc 0.7276
13:43:50.612   Training iter 500, batch loss 0.1865, batch acc 0.7264
13:43:51.098   Training iter 550, batch loss 0.1890, batch acc 0.7242
13:43:51.612   Training iter 600, batch loss 0.1927, batch acc 0.7176
13:43:51.613 Training @ 444 epoch...
13:43:52.112   Training iter 50, batch loss 0.1935, batch acc 0.7140
13:43:52.596   Training iter 100, batch loss 0.1933, batch acc 0.7150
13:43:53.085   Training iter 150, batch loss 0.1880, batch acc 0.7202
13:43:53.589   Training iter 200, batch loss 0.1856, batch acc 0.7300
13:43:54.077   Training iter 250, batch loss 0.1862, batch acc 0.7284
13:43:54.566   Training iter 300, batch loss 0.1864, batch acc 0.7220
13:43:55.070   Training iter 350, batch loss 0.1910, batch acc 0.7174
13:43:55.594   Training iter 400, batch loss 0.1830, batch acc 0.7320
13:43:56.096   Training iter 450, batch loss 0.1846, batch acc 0.7312
13:43:56.578   Training iter 500, batch loss 0.1931, batch acc 0.7126
13:43:57.067   Training iter 550, batch loss 0.1901, batch acc 0.7226
13:43:57.572   Training iter 600, batch loss 0.1908, batch acc 0.7190
13:43:57.573 Training @ 445 epoch...
13:43:58.063   Training iter 50, batch loss 0.1853, batch acc 0.7272
13:43:58.540   Training iter 100, batch loss 0.1827, batch acc 0.7338
13:43:59.037   Training iter 150, batch loss 0.1882, batch acc 0.7234
13:43:59.550   Training iter 200, batch loss 0.1861, batch acc 0.7264
13:44:00.062   Training iter 250, batch loss 0.1931, batch acc 0.7158
13:44:00.598   Training iter 300, batch loss 0.1917, batch acc 0.7174
13:44:01.128   Training iter 350, batch loss 0.1905, batch acc 0.7152
13:44:01.634   Training iter 400, batch loss 0.1889, batch acc 0.7228
13:44:02.178   Training iter 450, batch loss 0.1931, batch acc 0.7156
13:44:02.714   Training iter 500, batch loss 0.1923, batch acc 0.7130
13:44:03.263   Training iter 550, batch loss 0.1836, batch acc 0.7348
13:44:03.862   Training iter 600, batch loss 0.1900, batch acc 0.7188
13:44:03.864 Testing @ 445 epoch...
13:44:03.907     Testing, total mean loss 0.18807, total acc 0.72030
13:44:03.907 Training @ 446 epoch...
13:44:04.511   Training iter 50, batch loss 0.1883, batch acc 0.7162
13:44:05.103   Training iter 100, batch loss 0.1888, batch acc 0.7236
13:44:05.668   Training iter 150, batch loss 0.1869, batch acc 0.7276
13:44:06.245   Training iter 200, batch loss 0.1856, batch acc 0.7286
13:44:06.824   Training iter 250, batch loss 0.1935, batch acc 0.7144
13:44:07.400   Training iter 300, batch loss 0.1918, batch acc 0.7150
13:44:07.956   Training iter 350, batch loss 0.1880, batch acc 0.7256
13:44:08.509   Training iter 400, batch loss 0.1837, batch acc 0.7320
13:44:09.030   Training iter 450, batch loss 0.1900, batch acc 0.7190
13:44:09.545   Training iter 500, batch loss 0.1843, batch acc 0.7320
13:44:10.045   Training iter 550, batch loss 0.1919, batch acc 0.7186
13:44:10.582   Training iter 600, batch loss 0.1925, batch acc 0.7148
13:44:10.584 Training @ 447 epoch...
13:44:11.126   Training iter 50, batch loss 0.1870, batch acc 0.7268
13:44:11.637   Training iter 100, batch loss 0.1928, batch acc 0.7132
13:44:12.150   Training iter 150, batch loss 0.1884, batch acc 0.7204
13:44:12.666   Training iter 200, batch loss 0.1863, batch acc 0.7286
13:44:13.165   Training iter 250, batch loss 0.1911, batch acc 0.7176
13:44:13.652   Training iter 300, batch loss 0.1893, batch acc 0.7208
13:44:14.137   Training iter 350, batch loss 0.1884, batch acc 0.7232
13:44:14.603   Training iter 400, batch loss 0.1862, batch acc 0.7288
13:44:15.078   Training iter 450, batch loss 0.1936, batch acc 0.7144
13:44:15.624   Training iter 500, batch loss 0.1834, batch acc 0.7326
13:44:16.202   Training iter 550, batch loss 0.1891, batch acc 0.7188
13:44:16.785   Training iter 600, batch loss 0.1896, batch acc 0.7226
13:44:16.787 Training @ 448 epoch...
13:44:17.321   Training iter 50, batch loss 0.1913, batch acc 0.7200
13:44:17.824   Training iter 100, batch loss 0.1886, batch acc 0.7218
13:44:18.341   Training iter 150, batch loss 0.1928, batch acc 0.7134
13:44:18.860   Training iter 200, batch loss 0.1872, batch acc 0.7214
13:44:19.363   Training iter 250, batch loss 0.1863, batch acc 0.7230
13:44:19.893   Training iter 300, batch loss 0.1895, batch acc 0.7190
13:44:20.426   Training iter 350, batch loss 0.1856, batch acc 0.7296
13:44:20.965   Training iter 400, batch loss 0.1907, batch acc 0.7226
13:44:21.515   Training iter 450, batch loss 0.1910, batch acc 0.7204
13:44:22.069   Training iter 500, batch loss 0.1851, batch acc 0.7304
13:44:22.629   Training iter 550, batch loss 0.1869, batch acc 0.7268
13:44:23.194   Training iter 600, batch loss 0.1900, batch acc 0.7198
13:44:23.196 Training @ 449 epoch...
13:44:23.760   Training iter 50, batch loss 0.1848, batch acc 0.7274
13:44:24.313   Training iter 100, batch loss 0.1894, batch acc 0.7180
13:44:24.870   Training iter 150, batch loss 0.1905, batch acc 0.7164
13:44:25.458   Training iter 200, batch loss 0.1913, batch acc 0.7182
13:44:26.015   Training iter 250, batch loss 0.1867, batch acc 0.7262
13:44:26.555   Training iter 300, batch loss 0.1876, batch acc 0.7274
13:44:27.081   Training iter 350, batch loss 0.1889, batch acc 0.7188
13:44:27.619   Training iter 400, batch loss 0.1852, batch acc 0.7306
13:44:28.219   Training iter 450, batch loss 0.1898, batch acc 0.7252
13:44:28.773   Training iter 500, batch loss 0.1952, batch acc 0.7102
13:44:29.320   Training iter 550, batch loss 0.1827, batch acc 0.7314
13:44:29.858   Training iter 600, batch loss 0.1932, batch acc 0.7132
13:44:29.860 Training @ 450 epoch...
13:44:30.408   Training iter 50, batch loss 0.1886, batch acc 0.7230
13:44:30.935   Training iter 100, batch loss 0.1845, batch acc 0.7308
13:44:31.463   Training iter 150, batch loss 0.1921, batch acc 0.7152
13:44:31.979   Training iter 200, batch loss 0.1909, batch acc 0.7182
13:44:32.500   Training iter 250, batch loss 0.1871, batch acc 0.7250
13:44:33.039   Training iter 300, batch loss 0.1896, batch acc 0.7212
13:44:33.576   Training iter 350, batch loss 0.1918, batch acc 0.7172
13:44:34.096   Training iter 400, batch loss 0.1900, batch acc 0.7226
13:44:34.612   Training iter 450, batch loss 0.1864, batch acc 0.7250
13:44:35.126   Training iter 500, batch loss 0.1876, batch acc 0.7224
13:44:35.648   Training iter 550, batch loss 0.1900, batch acc 0.7194
13:44:36.193   Training iter 600, batch loss 0.1865, batch acc 0.7264
13:44:36.195 Testing @ 450 epoch...
13:44:36.235     Testing, total mean loss 0.18808, total acc 0.72030
13:44:36.235 Training @ 451 epoch...
13:44:36.781   Training iter 50, batch loss 0.1856, batch acc 0.7292
13:44:37.327   Training iter 100, batch loss 0.1874, batch acc 0.7266
13:44:37.919   Training iter 150, batch loss 0.1841, batch acc 0.7292
13:44:38.519   Training iter 200, batch loss 0.1865, batch acc 0.7246
13:44:39.080   Training iter 250, batch loss 0.1947, batch acc 0.7086
13:44:39.633   Training iter 300, batch loss 0.1893, batch acc 0.7186
13:44:40.191   Training iter 350, batch loss 0.1909, batch acc 0.7198
13:44:40.727   Training iter 400, batch loss 0.1866, batch acc 0.7240
13:44:41.249   Training iter 450, batch loss 0.1922, batch acc 0.7190
13:44:41.762   Training iter 500, batch loss 0.1922, batch acc 0.7148
13:44:42.282   Training iter 550, batch loss 0.1885, batch acc 0.7250
13:44:42.808   Training iter 600, batch loss 0.1868, batch acc 0.7252
13:44:42.810 Training @ 452 epoch...
13:44:43.348   Training iter 50, batch loss 0.1905, batch acc 0.7240
13:44:43.855   Training iter 100, batch loss 0.1918, batch acc 0.7164
13:44:44.352   Training iter 150, batch loss 0.1864, batch acc 0.7260
13:44:44.857   Training iter 200, batch loss 0.1871, batch acc 0.7228
13:44:45.370   Training iter 250, batch loss 0.1860, batch acc 0.7266
13:44:45.909   Training iter 300, batch loss 0.1898, batch acc 0.7168
13:44:46.457   Training iter 350, batch loss 0.1909, batch acc 0.7188
13:44:46.995   Training iter 400, batch loss 0.1917, batch acc 0.7162
13:44:47.541   Training iter 450, batch loss 0.1870, batch acc 0.7256
13:44:48.075   Training iter 500, batch loss 0.1876, batch acc 0.7272
13:44:48.636   Training iter 550, batch loss 0.1894, batch acc 0.7188
13:44:49.182   Training iter 600, batch loss 0.1864, batch acc 0.7284
13:44:49.184 Training @ 453 epoch...
13:44:49.771   Training iter 50, batch loss 0.1876, batch acc 0.7220
13:44:50.331   Training iter 100, batch loss 0.1909, batch acc 0.7232
13:44:50.895   Training iter 150, batch loss 0.1884, batch acc 0.7268
13:44:51.466   Training iter 200, batch loss 0.1881, batch acc 0.7240
13:44:52.020   Training iter 250, batch loss 0.1848, batch acc 0.7306
13:44:52.595   Training iter 300, batch loss 0.1875, batch acc 0.7234
13:44:53.168   Training iter 350, batch loss 0.1898, batch acc 0.7220
13:44:53.757   Training iter 400, batch loss 0.1914, batch acc 0.7150
13:44:54.499   Training iter 450, batch loss 0.1896, batch acc 0.7182
13:44:55.167   Training iter 500, batch loss 0.1890, batch acc 0.7200
13:44:55.729   Training iter 550, batch loss 0.1899, batch acc 0.7204
13:44:56.293   Training iter 600, batch loss 0.1878, batch acc 0.7204
13:44:56.295 Training @ 454 epoch...
13:44:56.860   Training iter 50, batch loss 0.1866, batch acc 0.7262
13:44:57.422   Training iter 100, batch loss 0.1906, batch acc 0.7194
13:44:57.982   Training iter 150, batch loss 0.1906, batch acc 0.7174
13:44:58.546   Training iter 200, batch loss 0.1887, batch acc 0.7204
13:44:59.135   Training iter 250, batch loss 0.1903, batch acc 0.7202
13:44:59.739   Training iter 300, batch loss 0.1874, batch acc 0.7238
13:45:00.346   Training iter 350, batch loss 0.1878, batch acc 0.7262
13:45:00.911   Training iter 400, batch loss 0.1907, batch acc 0.7162
13:45:01.466   Training iter 450, batch loss 0.1910, batch acc 0.7170
13:45:02.019   Training iter 500, batch loss 0.1875, batch acc 0.7252
13:45:02.563   Training iter 550, batch loss 0.1826, batch acc 0.7308
13:45:03.082   Training iter 600, batch loss 0.1907, batch acc 0.7226
13:45:03.084 Training @ 455 epoch...
13:45:03.598   Training iter 50, batch loss 0.1906, batch acc 0.7198
13:45:04.071   Training iter 100, batch loss 0.1848, batch acc 0.7284
13:45:04.556   Training iter 150, batch loss 0.1876, batch acc 0.7270
13:45:05.041   Training iter 200, batch loss 0.1889, batch acc 0.7162
13:45:05.538   Training iter 250, batch loss 0.1954, batch acc 0.7086
13:45:06.073   Training iter 300, batch loss 0.1873, batch acc 0.7238
13:45:06.605   Training iter 350, batch loss 0.1865, batch acc 0.7288
13:45:07.115   Training iter 400, batch loss 0.1878, batch acc 0.7266
13:45:07.626   Training iter 450, batch loss 0.1883, batch acc 0.7198
13:45:08.141   Training iter 500, batch loss 0.1916, batch acc 0.7174
13:45:08.672   Training iter 550, batch loss 0.1871, batch acc 0.7266
13:45:09.217   Training iter 600, batch loss 0.1886, batch acc 0.7244
13:45:09.219 Testing @ 455 epoch...
13:45:09.259     Testing, total mean loss 0.18799, total acc 0.72030
13:45:09.259 Training @ 456 epoch...
13:45:09.824   Training iter 50, batch loss 0.1880, batch acc 0.7194
13:45:10.396   Training iter 100, batch loss 0.1916, batch acc 0.7186
13:45:10.947   Training iter 150, batch loss 0.1908, batch acc 0.7208
13:45:11.500   Training iter 200, batch loss 0.1852, batch acc 0.7284
13:45:12.056   Training iter 250, batch loss 0.1939, batch acc 0.7112
13:45:12.614   Training iter 300, batch loss 0.1820, batch acc 0.7334
13:45:13.178   Training iter 350, batch loss 0.1858, batch acc 0.7318
13:45:13.703   Training iter 400, batch loss 0.1881, batch acc 0.7216
13:45:14.231   Training iter 450, batch loss 0.1911, batch acc 0.7174
13:45:14.765   Training iter 500, batch loss 0.1851, batch acc 0.7302
13:45:15.287   Training iter 550, batch loss 0.1943, batch acc 0.7152
13:45:15.813   Training iter 600, batch loss 0.1885, batch acc 0.7204
13:45:15.815 Training @ 457 epoch...
13:45:16.338   Training iter 50, batch loss 0.1961, batch acc 0.7090
13:45:16.849   Training iter 100, batch loss 0.1922, batch acc 0.7118
13:45:17.368   Training iter 150, batch loss 0.1801, batch acc 0.7414
13:45:17.887   Training iter 200, batch loss 0.1969, batch acc 0.7044
13:45:18.402   Training iter 250, batch loss 0.1873, batch acc 0.7248
13:45:18.926   Training iter 300, batch loss 0.1884, batch acc 0.7188
13:45:19.436   Training iter 350, batch loss 0.1867, batch acc 0.7306
13:45:19.948   Training iter 400, batch loss 0.1893, batch acc 0.7234
13:45:20.467   Training iter 450, batch loss 0.1928, batch acc 0.7170
13:45:20.980   Training iter 500, batch loss 0.1817, batch acc 0.7352
13:45:21.507   Training iter 550, batch loss 0.1870, batch acc 0.7242
13:45:22.040   Training iter 600, batch loss 0.1859, batch acc 0.7240
13:45:22.041 Training @ 458 epoch...
13:45:22.667   Training iter 50, batch loss 0.1877, batch acc 0.7252
13:45:23.361   Training iter 100, batch loss 0.1937, batch acc 0.7134
13:45:24.050   Training iter 150, batch loss 0.1887, batch acc 0.7200
13:45:24.577   Training iter 200, batch loss 0.1888, batch acc 0.7230
13:45:25.104   Training iter 250, batch loss 0.1912, batch acc 0.7164
13:45:25.619   Training iter 300, batch loss 0.1925, batch acc 0.7144
13:45:26.134   Training iter 350, batch loss 0.1885, batch acc 0.7258
13:45:26.644   Training iter 400, batch loss 0.1841, batch acc 0.7322
13:45:27.183   Training iter 450, batch loss 0.1868, batch acc 0.7226
13:45:27.739   Training iter 500, batch loss 0.1819, batch acc 0.7360
13:45:28.306   Training iter 550, batch loss 0.1878, batch acc 0.7238
13:45:28.831   Training iter 600, batch loss 0.1925, batch acc 0.7132
13:45:28.833 Training @ 459 epoch...
13:45:29.359   Training iter 50, batch loss 0.1880, batch acc 0.7234
13:45:29.888   Training iter 100, batch loss 0.1888, batch acc 0.7236
13:45:30.413   Training iter 150, batch loss 0.1901, batch acc 0.7174
13:45:30.923   Training iter 200, batch loss 0.1917, batch acc 0.7184
13:45:31.431   Training iter 250, batch loss 0.1882, batch acc 0.7218
13:45:31.944   Training iter 300, batch loss 0.1861, batch acc 0.7244
13:45:32.447   Training iter 350, batch loss 0.1873, batch acc 0.7230
13:45:32.984   Training iter 400, batch loss 0.1885, batch acc 0.7228
13:45:33.526   Training iter 450, batch loss 0.1906, batch acc 0.7174
13:45:34.065   Training iter 500, batch loss 0.1916, batch acc 0.7170
13:45:34.608   Training iter 550, batch loss 0.1862, batch acc 0.7296
13:45:35.170   Training iter 600, batch loss 0.1872, batch acc 0.7266
13:45:35.171 Training @ 460 epoch...
13:45:35.721   Training iter 50, batch loss 0.1882, batch acc 0.7254
13:45:36.257   Training iter 100, batch loss 0.1853, batch acc 0.7326
13:45:36.778   Training iter 150, batch loss 0.1903, batch acc 0.7196
13:45:37.267   Training iter 200, batch loss 0.1908, batch acc 0.7160
13:45:37.760   Training iter 250, batch loss 0.1855, batch acc 0.7264
13:45:38.259   Training iter 300, batch loss 0.1893, batch acc 0.7216
13:45:38.751   Training iter 350, batch loss 0.1926, batch acc 0.7142
13:45:39.227   Training iter 400, batch loss 0.1827, batch acc 0.7304
13:45:39.705   Training iter 450, batch loss 0.1854, batch acc 0.7300
13:45:40.199   Training iter 500, batch loss 0.1923, batch acc 0.7156
13:45:40.688   Training iter 550, batch loss 0.1957, batch acc 0.7104
13:45:41.166   Training iter 600, batch loss 0.1858, batch acc 0.7266
13:45:41.168 Testing @ 460 epoch...
13:45:41.207     Testing, total mean loss 0.18796, total acc 0.72020
13:45:41.207 Training @ 461 epoch...
13:45:41.692   Training iter 50, batch loss 0.1927, batch acc 0.7122
13:45:42.197   Training iter 100, batch loss 0.1900, batch acc 0.7214
13:45:42.697   Training iter 150, batch loss 0.1868, batch acc 0.7268
13:45:43.205   Training iter 200, batch loss 0.1887, batch acc 0.7240
13:45:43.714   Training iter 250, batch loss 0.1877, batch acc 0.7236
13:45:44.236   Training iter 300, batch loss 0.1854, batch acc 0.7270
13:45:44.794   Training iter 350, batch loss 0.1866, batch acc 0.7244
13:45:45.339   Training iter 400, batch loss 0.1883, batch acc 0.7232
13:45:45.916   Training iter 450, batch loss 0.1902, batch acc 0.7192
13:45:46.485   Training iter 500, batch loss 0.1899, batch acc 0.7186
13:45:47.022   Training iter 550, batch loss 0.1862, batch acc 0.7274
13:45:47.577   Training iter 600, batch loss 0.1913, batch acc 0.7200
13:45:47.578 Training @ 462 epoch...
13:45:48.125   Training iter 50, batch loss 0.1910, batch acc 0.7160
13:45:48.623   Training iter 100, batch loss 0.1880, batch acc 0.7198
13:45:49.131   Training iter 150, batch loss 0.1928, batch acc 0.7126
13:45:49.628   Training iter 200, batch loss 0.1892, batch acc 0.7216
13:45:50.128   Training iter 250, batch loss 0.1838, batch acc 0.7320
13:45:50.633   Training iter 300, batch loss 0.1879, batch acc 0.7230
13:45:51.143   Training iter 350, batch loss 0.1911, batch acc 0.7206
13:45:51.660   Training iter 400, batch loss 0.1963, batch acc 0.7078
13:45:52.188   Training iter 450, batch loss 0.1799, batch acc 0.7416
13:45:52.723   Training iter 500, batch loss 0.1867, batch acc 0.7236
13:45:53.260   Training iter 550, batch loss 0.1835, batch acc 0.7346
13:45:53.793   Training iter 600, batch loss 0.1936, batch acc 0.7116
13:45:53.795 Training @ 463 epoch...
13:45:54.331   Training iter 50, batch loss 0.1935, batch acc 0.7154
13:45:54.864   Training iter 100, batch loss 0.1896, batch acc 0.7254
13:45:55.411   Training iter 150, batch loss 0.1843, batch acc 0.7274
13:45:55.945   Training iter 200, batch loss 0.1898, batch acc 0.7190
13:45:56.491   Training iter 250, batch loss 0.1876, batch acc 0.7258
13:45:57.032   Training iter 300, batch loss 0.1855, batch acc 0.7280
13:45:57.577   Training iter 350, batch loss 0.1905, batch acc 0.7196
13:45:58.120   Training iter 400, batch loss 0.1851, batch acc 0.7292
13:45:58.658   Training iter 450, batch loss 0.1964, batch acc 0.7088
13:45:59.168   Training iter 500, batch loss 0.1869, batch acc 0.7258
13:45:59.670   Training iter 550, batch loss 0.1889, batch acc 0.7176
13:46:00.185   Training iter 600, batch loss 0.1857, batch acc 0.7274
13:46:00.186 Training @ 464 epoch...
13:46:00.713   Training iter 50, batch loss 0.1843, batch acc 0.7292
13:46:01.250   Training iter 100, batch loss 0.1873, batch acc 0.7264
13:46:01.793   Training iter 150, batch loss 0.1896, batch acc 0.7228
13:46:02.324   Training iter 200, batch loss 0.1880, batch acc 0.7246
13:46:02.869   Training iter 250, batch loss 0.1900, batch acc 0.7198
13:46:03.408   Training iter 300, batch loss 0.1898, batch acc 0.7192
13:46:03.951   Training iter 350, batch loss 0.1856, batch acc 0.7286
13:46:04.495   Training iter 400, batch loss 0.1886, batch acc 0.7230
13:46:05.040   Training iter 450, batch loss 0.1898, batch acc 0.7180
13:46:05.580   Training iter 500, batch loss 0.1907, batch acc 0.7158
13:46:06.119   Training iter 550, batch loss 0.1889, batch acc 0.7228
13:46:06.660   Training iter 600, batch loss 0.1912, batch acc 0.7180
13:46:06.662 Training @ 465 epoch...
13:46:07.201   Training iter 50, batch loss 0.1917, batch acc 0.7154
13:46:07.736   Training iter 100, batch loss 0.1875, batch acc 0.7270
13:46:08.266   Training iter 150, batch loss 0.1890, batch acc 0.7178
13:46:08.788   Training iter 200, batch loss 0.1889, batch acc 0.7194
13:46:09.307   Training iter 250, batch loss 0.1863, batch acc 0.7248
13:46:09.846   Training iter 300, batch loss 0.1854, batch acc 0.7308
13:46:10.408   Training iter 350, batch loss 0.1900, batch acc 0.7206
13:46:10.952   Training iter 400, batch loss 0.1907, batch acc 0.7174
13:46:11.499   Training iter 450, batch loss 0.1869, batch acc 0.7272
13:46:12.052   Training iter 500, batch loss 0.1893, batch acc 0.7224
13:46:12.648   Training iter 550, batch loss 0.1892, batch acc 0.7230
13:46:13.242   Training iter 600, batch loss 0.1887, batch acc 0.7234
13:46:13.244 Testing @ 465 epoch...
13:46:13.285     Testing, total mean loss 0.18789, total acc 0.72040
13:46:13.286 Training @ 466 epoch...
13:46:13.880   Training iter 50, batch loss 0.1901, batch acc 0.7178
13:46:14.456   Training iter 100, batch loss 0.1895, batch acc 0.7216
13:46:15.041   Training iter 150, batch loss 0.1872, batch acc 0.7292
13:46:15.627   Training iter 200, batch loss 0.1876, batch acc 0.7212
13:46:16.195   Training iter 250, batch loss 0.1915, batch acc 0.7186
13:46:16.763   Training iter 300, batch loss 0.1884, batch acc 0.7228
13:46:17.327   Training iter 350, batch loss 0.1933, batch acc 0.7148
13:46:17.887   Training iter 400, batch loss 0.1875, batch acc 0.7266
13:46:18.452   Training iter 450, batch loss 0.1917, batch acc 0.7140
13:46:18.988   Training iter 500, batch loss 0.1838, batch acc 0.7340
13:46:19.522   Training iter 550, batch loss 0.1886, batch acc 0.7198
13:46:20.066   Training iter 600, batch loss 0.1845, batch acc 0.7278
13:46:20.068 Training @ 467 epoch...
13:46:20.604   Training iter 50, batch loss 0.1920, batch acc 0.7150
13:46:21.138   Training iter 100, batch loss 0.1900, batch acc 0.7206
13:46:21.666   Training iter 150, batch loss 0.1847, batch acc 0.7334
13:46:22.212   Training iter 200, batch loss 0.1857, batch acc 0.7280
13:46:22.759   Training iter 250, batch loss 0.1888, batch acc 0.7228
13:46:23.295   Training iter 300, batch loss 0.1878, batch acc 0.7196
13:46:23.833   Training iter 350, batch loss 0.1948, batch acc 0.7094
13:46:24.371   Training iter 400, batch loss 0.1885, batch acc 0.7232
13:46:24.910   Training iter 450, batch loss 0.1900, batch acc 0.7198
13:46:25.453   Training iter 500, batch loss 0.1904, batch acc 0.7158
13:46:25.988   Training iter 550, batch loss 0.1876, batch acc 0.7254
13:46:26.530   Training iter 600, batch loss 0.1830, batch acc 0.7334
13:46:26.532 Training @ 468 epoch...
13:46:27.074   Training iter 50, batch loss 0.1861, batch acc 0.7270
13:46:27.633   Training iter 100, batch loss 0.1854, batch acc 0.7248
13:46:28.181   Training iter 150, batch loss 0.1837, batch acc 0.7314
13:46:28.698   Training iter 200, batch loss 0.1891, batch acc 0.7192
13:46:29.236   Training iter 250, batch loss 0.1884, batch acc 0.7200
13:46:29.779   Training iter 300, batch loss 0.1870, batch acc 0.7268
13:46:30.326   Training iter 350, batch loss 0.1896, batch acc 0.7184
13:46:30.860   Training iter 400, batch loss 0.1923, batch acc 0.7122
13:46:31.395   Training iter 450, batch loss 0.1932, batch acc 0.7150
13:46:31.947   Training iter 500, batch loss 0.1831, batch acc 0.7360
13:46:32.506   Training iter 550, batch loss 0.1944, batch acc 0.7134
13:46:33.066   Training iter 600, batch loss 0.1910, batch acc 0.7220
13:46:33.068 Training @ 469 epoch...
13:46:33.622   Training iter 50, batch loss 0.1929, batch acc 0.7162
13:46:34.162   Training iter 100, batch loss 0.1847, batch acc 0.7320
13:46:34.709   Training iter 150, batch loss 0.1910, batch acc 0.7168
13:46:35.251   Training iter 200, batch loss 0.1875, batch acc 0.7238
13:46:35.785   Training iter 250, batch loss 0.1853, batch acc 0.7280
13:46:36.326   Training iter 300, batch loss 0.1886, batch acc 0.7204
13:46:36.864   Training iter 350, batch loss 0.1873, batch acc 0.7258
13:46:37.415   Training iter 400, batch loss 0.1933, batch acc 0.7114
13:46:37.984   Training iter 450, batch loss 0.1884, batch acc 0.7220
13:46:38.546   Training iter 500, batch loss 0.1865, batch acc 0.7264
13:46:39.086   Training iter 550, batch loss 0.1854, batch acc 0.7326
13:46:39.646   Training iter 600, batch loss 0.1925, batch acc 0.7130
13:46:39.648 Training @ 470 epoch...
13:46:40.211   Training iter 50, batch loss 0.1964, batch acc 0.7064
13:46:40.740   Training iter 100, batch loss 0.1828, batch acc 0.7326
13:46:41.269   Training iter 150, batch loss 0.1880, batch acc 0.7234
13:46:41.948   Training iter 200, batch loss 0.1885, batch acc 0.7250
13:46:42.679   Training iter 250, batch loss 0.1852, batch acc 0.7276
13:46:43.255   Training iter 300, batch loss 0.1853, batch acc 0.7272
13:46:43.791   Training iter 350, batch loss 0.1927, batch acc 0.7158
13:46:44.313   Training iter 400, batch loss 0.1856, batch acc 0.7296
13:46:44.832   Training iter 450, batch loss 0.1878, batch acc 0.7236
13:46:45.347   Training iter 500, batch loss 0.1892, batch acc 0.7218
13:46:45.857   Training iter 550, batch loss 0.1920, batch acc 0.7142
13:46:46.372   Training iter 600, batch loss 0.1896, batch acc 0.7214
13:46:46.374 Testing @ 470 epoch...
13:46:46.413     Testing, total mean loss 0.18790, total acc 0.72060
13:46:46.413 Training @ 471 epoch...
13:46:46.931   Training iter 50, batch loss 0.1885, batch acc 0.7236
13:46:47.457   Training iter 100, batch loss 0.1934, batch acc 0.7114
13:46:47.983   Training iter 150, batch loss 0.1854, batch acc 0.7288
13:46:48.494   Training iter 200, batch loss 0.1967, batch acc 0.7056
13:46:48.998   Training iter 250, batch loss 0.1859, batch acc 0.7288
13:46:49.507   Training iter 300, batch loss 0.1880, batch acc 0.7216
13:46:50.017   Training iter 350, batch loss 0.1911, batch acc 0.7172
13:46:50.495   Training iter 400, batch loss 0.1867, batch acc 0.7276
13:46:51.004   Training iter 450, batch loss 0.1906, batch acc 0.7192
13:46:51.510   Training iter 500, batch loss 0.1857, batch acc 0.7280
13:46:52.012   Training iter 550, batch loss 0.1839, batch acc 0.7316
13:46:52.528   Training iter 600, batch loss 0.1873, batch acc 0.7244
13:46:52.530 Training @ 472 epoch...
13:46:53.034   Training iter 50, batch loss 0.1886, batch acc 0.7246
13:46:53.549   Training iter 100, batch loss 0.1857, batch acc 0.7298
13:46:54.061   Training iter 150, batch loss 0.1916, batch acc 0.7164
13:46:54.577   Training iter 200, batch loss 0.1917, batch acc 0.7136
13:46:55.100   Training iter 250, batch loss 0.1856, batch acc 0.7296
13:46:55.629   Training iter 300, batch loss 0.1912, batch acc 0.7160
13:46:56.142   Training iter 350, batch loss 0.1863, batch acc 0.7230
13:46:56.643   Training iter 400, batch loss 0.1897, batch acc 0.7184
13:46:57.151   Training iter 450, batch loss 0.1904, batch acc 0.7226
13:46:57.689   Training iter 500, batch loss 0.1868, batch acc 0.7264
13:46:58.236   Training iter 550, batch loss 0.1905, batch acc 0.7182
13:46:58.769   Training iter 600, batch loss 0.1850, batch acc 0.7298
13:46:58.771 Training @ 473 epoch...
13:46:59.316   Training iter 50, batch loss 0.1884, batch acc 0.7206
13:46:59.849   Training iter 100, batch loss 0.1907, batch acc 0.7174
13:47:00.390   Training iter 150, batch loss 0.1874, batch acc 0.7276
13:47:00.954   Training iter 200, batch loss 0.1863, batch acc 0.7308
13:47:01.504   Training iter 250, batch loss 0.1883, batch acc 0.7210
13:47:02.078   Training iter 300, batch loss 0.1924, batch acc 0.7164
13:47:02.630   Training iter 350, batch loss 0.1887, batch acc 0.7206
13:47:03.174   Training iter 400, batch loss 0.1909, batch acc 0.7174
13:47:03.729   Training iter 450, batch loss 0.1901, batch acc 0.7184
13:47:04.286   Training iter 500, batch loss 0.1849, batch acc 0.7312
13:47:04.824   Training iter 550, batch loss 0.1864, batch acc 0.7240
13:47:05.344   Training iter 600, batch loss 0.1884, batch acc 0.7214
13:47:05.346 Training @ 474 epoch...
13:47:05.881   Training iter 50, batch loss 0.1896, batch acc 0.7224
13:47:06.432   Training iter 100, batch loss 0.1853, batch acc 0.7282
13:47:06.979   Training iter 150, batch loss 0.1841, batch acc 0.7296
13:47:07.540   Training iter 200, batch loss 0.1874, batch acc 0.7220
13:47:08.089   Training iter 250, batch loss 0.1917, batch acc 0.7172
13:47:08.639   Training iter 300, batch loss 0.1879, batch acc 0.7230
13:47:09.185   Training iter 350, batch loss 0.1951, batch acc 0.7130
13:47:09.747   Training iter 400, batch loss 0.1854, batch acc 0.7284
13:47:10.319   Training iter 450, batch loss 0.1947, batch acc 0.7118
13:47:10.853   Training iter 500, batch loss 0.1876, batch acc 0.7216
13:47:11.395   Training iter 550, batch loss 0.1868, batch acc 0.7256
13:47:11.939   Training iter 600, batch loss 0.1875, batch acc 0.7250
13:47:11.941 Training @ 475 epoch...
13:47:12.496   Training iter 50, batch loss 0.1907, batch acc 0.7174
13:47:13.021   Training iter 100, batch loss 0.1834, batch acc 0.7344
13:47:13.551   Training iter 150, batch loss 0.1848, batch acc 0.7348
13:47:14.086   Training iter 200, batch loss 0.1964, batch acc 0.7062
13:47:14.613   Training iter 250, batch loss 0.1888, batch acc 0.7178
13:47:15.143   Training iter 300, batch loss 0.1879, batch acc 0.7274
13:47:15.670   Training iter 350, batch loss 0.1900, batch acc 0.7220
13:47:16.192   Training iter 400, batch loss 0.1868, batch acc 0.7232
13:47:16.715   Training iter 450, batch loss 0.1865, batch acc 0.7272
13:47:17.264   Training iter 500, batch loss 0.1912, batch acc 0.7154
13:47:17.812   Training iter 550, batch loss 0.1903, batch acc 0.7160
13:47:18.375   Training iter 600, batch loss 0.1860, batch acc 0.7272
13:47:18.377 Testing @ 475 epoch...
13:47:18.416     Testing, total mean loss 0.18786, total acc 0.72010
13:47:18.416 Training @ 476 epoch...
13:47:18.970   Training iter 50, batch loss 0.1882, batch acc 0.7198
13:47:19.515   Training iter 100, batch loss 0.1887, batch acc 0.7208
13:47:20.074   Training iter 150, batch loss 0.1946, batch acc 0.7102
13:47:20.626   Training iter 200, batch loss 0.1905, batch acc 0.7180
13:47:21.182   Training iter 250, batch loss 0.1966, batch acc 0.7076
13:47:21.750   Training iter 300, batch loss 0.1871, batch acc 0.7276
13:47:22.296   Training iter 350, batch loss 0.1845, batch acc 0.7300
13:47:22.815   Training iter 400, batch loss 0.1841, batch acc 0.7346
13:47:23.339   Training iter 450, batch loss 0.1879, batch acc 0.7252
13:47:23.859   Training iter 500, batch loss 0.1910, batch acc 0.7174
13:47:24.385   Training iter 550, batch loss 0.1865, batch acc 0.7250
13:47:24.916   Training iter 600, batch loss 0.1831, batch acc 0.7322
13:47:24.918 Training @ 477 epoch...
13:47:25.468   Training iter 50, batch loss 0.1949, batch acc 0.7074
13:47:25.996   Training iter 100, batch loss 0.1850, batch acc 0.7292
13:47:26.525   Training iter 150, batch loss 0.1878, batch acc 0.7242
13:47:27.046   Training iter 200, batch loss 0.1857, batch acc 0.7294
13:47:27.587   Training iter 250, batch loss 0.1893, batch acc 0.7218
13:47:28.117   Training iter 300, batch loss 0.1880, batch acc 0.7242
13:47:28.638   Training iter 350, batch loss 0.1890, batch acc 0.7216
13:47:29.156   Training iter 400, batch loss 0.1842, batch acc 0.7294
13:47:29.676   Training iter 450, batch loss 0.1861, batch acc 0.7286
13:47:30.210   Training iter 500, batch loss 0.1938, batch acc 0.7100
13:47:30.750   Training iter 550, batch loss 0.1852, batch acc 0.7292
13:47:31.272   Training iter 600, batch loss 0.1938, batch acc 0.7126
13:47:31.274 Training @ 478 epoch...
13:47:31.788   Training iter 50, batch loss 0.1925, batch acc 0.7162
13:47:32.313   Training iter 100, batch loss 0.1851, batch acc 0.7294
13:47:32.841   Training iter 150, batch loss 0.1906, batch acc 0.7214
13:47:33.360   Training iter 200, batch loss 0.1863, batch acc 0.7252
13:47:33.872   Training iter 250, batch loss 0.1892, batch acc 0.7178
13:47:34.382   Training iter 300, batch loss 0.1873, batch acc 0.7236
13:47:34.884   Training iter 350, batch loss 0.1844, batch acc 0.7312
13:47:35.375   Training iter 400, batch loss 0.1914, batch acc 0.7188
13:47:35.889   Training iter 450, batch loss 0.1884, batch acc 0.7270
13:47:36.400   Training iter 500, batch loss 0.1872, batch acc 0.7244
13:47:36.903   Training iter 550, batch loss 0.1910, batch acc 0.7142
13:47:37.416   Training iter 600, batch loss 0.1894, batch acc 0.7214
13:47:37.418 Training @ 479 epoch...
13:47:37.935   Training iter 50, batch loss 0.1933, batch acc 0.7132
13:47:38.446   Training iter 100, batch loss 0.1938, batch acc 0.7108
13:47:38.942   Training iter 150, batch loss 0.1840, batch acc 0.7318
13:47:39.481   Training iter 200, batch loss 0.1884, batch acc 0.7194
13:47:40.058   Training iter 250, batch loss 0.1900, batch acc 0.7216
13:47:40.638   Training iter 300, batch loss 0.1919, batch acc 0.7170
13:47:41.187   Training iter 350, batch loss 0.1850, batch acc 0.7336
13:47:41.722   Training iter 400, batch loss 0.1859, batch acc 0.7266
13:47:42.280   Training iter 450, batch loss 0.1859, batch acc 0.7262
13:47:42.845   Training iter 500, batch loss 0.1812, batch acc 0.7364
13:47:43.407   Training iter 550, batch loss 0.1921, batch acc 0.7158
13:47:43.982   Training iter 600, batch loss 0.1910, batch acc 0.7148
13:47:43.984 Training @ 480 epoch...
13:47:44.542   Training iter 50, batch loss 0.1861, batch acc 0.7258
13:47:45.094   Training iter 100, batch loss 0.1884, batch acc 0.7204
13:47:45.646   Training iter 150, batch loss 0.1863, batch acc 0.7266
13:47:46.199   Training iter 200, batch loss 0.1890, batch acc 0.7256
13:47:46.758   Training iter 250, batch loss 0.1835, batch acc 0.7330
13:47:47.302   Training iter 300, batch loss 0.1912, batch acc 0.7166
13:47:47.857   Training iter 350, batch loss 0.1869, batch acc 0.7212
13:47:48.423   Training iter 400, batch loss 0.1891, batch acc 0.7204
13:47:49.003   Training iter 450, batch loss 0.1885, batch acc 0.7240
13:47:49.587   Training iter 500, batch loss 0.1895, batch acc 0.7234
13:47:50.179   Training iter 550, batch loss 0.1926, batch acc 0.7170
13:47:50.750   Training iter 600, batch loss 0.1914, batch acc 0.7166
13:47:50.752 Testing @ 480 epoch...
13:47:50.791     Testing, total mean loss 0.18780, total acc 0.72080
13:47:50.791 Training @ 481 epoch...
13:47:51.360   Training iter 50, batch loss 0.1905, batch acc 0.7170
13:47:51.924   Training iter 100, batch loss 0.1883, batch acc 0.7226
13:47:52.485   Training iter 150, batch loss 0.1879, batch acc 0.7260
13:47:53.045   Training iter 200, batch loss 0.1825, batch acc 0.7332
13:47:53.609   Training iter 250, batch loss 0.1834, batch acc 0.7382
13:47:54.172   Training iter 300, batch loss 0.1915, batch acc 0.7166
13:47:54.730   Training iter 350, batch loss 0.1912, batch acc 0.7150
13:47:55.280   Training iter 400, batch loss 0.1937, batch acc 0.7118
13:47:55.822   Training iter 450, batch loss 0.1887, batch acc 0.7238
13:47:56.376   Training iter 500, batch loss 0.1855, batch acc 0.7246
13:47:56.928   Training iter 550, batch loss 0.1888, batch acc 0.7256
13:47:57.483   Training iter 600, batch loss 0.1904, batch acc 0.7180
13:47:57.485 Training @ 482 epoch...
13:47:58.034   Training iter 50, batch loss 0.1839, batch acc 0.7322
13:47:58.570   Training iter 100, batch loss 0.1820, batch acc 0.7386
13:47:59.110   Training iter 150, batch loss 0.1852, batch acc 0.7278
13:47:59.641   Training iter 200, batch loss 0.1907, batch acc 0.7174
13:48:00.215   Training iter 250, batch loss 0.1961, batch acc 0.7064
13:48:00.777   Training iter 300, batch loss 0.1877, batch acc 0.7296
13:48:01.349   Training iter 350, batch loss 0.1867, batch acc 0.7226
13:48:01.939   Training iter 400, batch loss 0.1825, batch acc 0.7316
13:48:02.526   Training iter 450, batch loss 0.1921, batch acc 0.7152
13:48:03.098   Training iter 500, batch loss 0.1921, batch acc 0.7174
13:48:03.662   Training iter 550, batch loss 0.1916, batch acc 0.7148
13:48:04.238   Training iter 600, batch loss 0.1917, batch acc 0.7166
13:48:04.240 Training @ 483 epoch...
13:48:04.830   Training iter 50, batch loss 0.1881, batch acc 0.7210
13:48:05.434   Training iter 100, batch loss 0.1940, batch acc 0.7106
13:48:06.008   Training iter 150, batch loss 0.1877, batch acc 0.7238
13:48:06.543   Training iter 200, batch loss 0.1941, batch acc 0.7106
13:48:07.108   Training iter 250, batch loss 0.1844, batch acc 0.7278
13:48:07.670   Training iter 300, batch loss 0.1876, batch acc 0.7248
13:48:08.220   Training iter 350, batch loss 0.1870, batch acc 0.7280
13:48:08.744   Training iter 400, batch loss 0.1861, batch acc 0.7326
13:48:09.277   Training iter 450, batch loss 0.1929, batch acc 0.7158
13:48:09.817   Training iter 500, batch loss 0.1843, batch acc 0.7324
13:48:10.360   Training iter 550, batch loss 0.1900, batch acc 0.7156
13:48:10.850   Training iter 600, batch loss 0.1860, batch acc 0.7250
13:48:10.851 Training @ 484 epoch...
13:48:11.350   Training iter 50, batch loss 0.1889, batch acc 0.7188
13:48:11.846   Training iter 100, batch loss 0.1913, batch acc 0.7176
13:48:12.350   Training iter 150, batch loss 0.1892, batch acc 0.7200
13:48:12.854   Training iter 200, batch loss 0.1863, batch acc 0.7284
13:48:13.357   Training iter 250, batch loss 0.1961, batch acc 0.7076
13:48:13.856   Training iter 300, batch loss 0.1876, batch acc 0.7232
13:48:14.372   Training iter 350, batch loss 0.1867, batch acc 0.7254
13:48:14.890   Training iter 400, batch loss 0.1896, batch acc 0.7232
13:48:15.393   Training iter 450, batch loss 0.1896, batch acc 0.7210
13:48:15.902   Training iter 500, batch loss 0.1896, batch acc 0.7230
13:48:16.443   Training iter 550, batch loss 0.1791, batch acc 0.7412
13:48:16.921   Training iter 600, batch loss 0.1882, batch acc 0.7204
13:48:16.922 Training @ 485 epoch...
13:48:17.380   Training iter 50, batch loss 0.1871, batch acc 0.7238
13:48:17.834   Training iter 100, batch loss 0.1887, batch acc 0.7208
13:48:18.301   Training iter 150, batch loss 0.1891, batch acc 0.7242
13:48:18.765   Training iter 200, batch loss 0.1884, batch acc 0.7214
13:48:19.230   Training iter 250, batch loss 0.1865, batch acc 0.7244
13:48:19.700   Training iter 300, batch loss 0.1888, batch acc 0.7220
13:48:20.183   Training iter 350, batch loss 0.1909, batch acc 0.7170
13:48:20.700   Training iter 400, batch loss 0.1911, batch acc 0.7194
13:48:21.204   Training iter 450, batch loss 0.1898, batch acc 0.7160
13:48:21.711   Training iter 500, batch loss 0.1939, batch acc 0.7140
13:48:22.222   Training iter 550, batch loss 0.1873, batch acc 0.7298
13:48:22.748   Training iter 600, batch loss 0.1804, batch acc 0.7382
13:48:22.749 Testing @ 485 epoch...
13:48:22.787     Testing, total mean loss 0.18780, total acc 0.72050
13:48:22.787 Training @ 486 epoch...
13:48:23.342   Training iter 50, batch loss 0.1889, batch acc 0.7226
13:48:23.871   Training iter 100, batch loss 0.1940, batch acc 0.7074
13:48:24.430   Training iter 150, batch loss 0.1951, batch acc 0.7108
13:48:24.967   Training iter 200, batch loss 0.1892, batch acc 0.7222
13:48:25.513   Training iter 250, batch loss 0.1884, batch acc 0.7238
13:48:26.056   Training iter 300, batch loss 0.1852, batch acc 0.7290
13:48:26.559   Training iter 350, batch loss 0.1841, batch acc 0.7318
13:48:27.039   Training iter 400, batch loss 0.1879, batch acc 0.7212
13:48:27.557   Training iter 450, batch loss 0.1877, batch acc 0.7254
13:48:28.070   Training iter 500, batch loss 0.1893, batch acc 0.7202
13:48:28.574   Training iter 550, batch loss 0.1894, batch acc 0.7234
13:48:29.080   Training iter 600, batch loss 0.1829, batch acc 0.7332
13:48:29.082 Training @ 487 epoch...
13:48:29.604   Training iter 50, batch loss 0.1858, batch acc 0.7296
13:48:30.114   Training iter 100, batch loss 0.1877, batch acc 0.7250
13:48:30.614   Training iter 150, batch loss 0.1930, batch acc 0.7128
13:48:31.130   Training iter 200, batch loss 0.1887, batch acc 0.7252
13:48:31.686   Training iter 250, batch loss 0.1878, batch acc 0.7260
13:48:32.278   Training iter 300, batch loss 0.1894, batch acc 0.7160
13:48:32.845   Training iter 350, batch loss 0.1869, batch acc 0.7258
13:48:33.388   Training iter 400, batch loss 0.1910, batch acc 0.7180
13:48:33.867   Training iter 450, batch loss 0.1875, batch acc 0.7252
13:48:34.351   Training iter 500, batch loss 0.1932, batch acc 0.7148
13:48:34.861   Training iter 550, batch loss 0.1854, batch acc 0.7248
13:48:35.359   Training iter 600, batch loss 0.1854, batch acc 0.7260
13:48:35.361 Training @ 488 epoch...
13:48:35.865   Training iter 50, batch loss 0.1875, batch acc 0.7256
13:48:36.371   Training iter 100, batch loss 0.1842, batch acc 0.7282
13:48:36.909   Training iter 150, batch loss 0.1911, batch acc 0.7182
13:48:37.443   Training iter 200, batch loss 0.1919, batch acc 0.7190
13:48:37.978   Training iter 250, batch loss 0.1933, batch acc 0.7116
13:48:38.516   Training iter 300, batch loss 0.1878, batch acc 0.7240
13:48:39.048   Training iter 350, batch loss 0.1879, batch acc 0.7216
13:48:39.569   Training iter 400, batch loss 0.1872, batch acc 0.7268
13:48:40.104   Training iter 450, batch loss 0.1828, batch acc 0.7322
13:48:40.648   Training iter 500, batch loss 0.1925, batch acc 0.7152
13:48:41.182   Training iter 550, batch loss 0.1851, batch acc 0.7282
13:48:41.722   Training iter 600, batch loss 0.1904, batch acc 0.7176
13:48:41.724 Training @ 489 epoch...
13:48:42.275   Training iter 50, batch loss 0.1879, batch acc 0.7274
13:48:42.772   Training iter 100, batch loss 0.1857, batch acc 0.7258
13:48:43.265   Training iter 150, batch loss 0.1911, batch acc 0.7174
13:48:43.752   Training iter 200, batch loss 0.1867, batch acc 0.7250
13:48:44.260   Training iter 250, batch loss 0.1867, batch acc 0.7262
13:48:44.760   Training iter 300, batch loss 0.1882, batch acc 0.7238
13:48:45.260   Training iter 350, batch loss 0.1934, batch acc 0.7134
13:48:45.760   Training iter 400, batch loss 0.1877, batch acc 0.7260
13:48:46.244   Training iter 450, batch loss 0.1873, batch acc 0.7230
13:48:46.696   Training iter 500, batch loss 0.1883, batch acc 0.7190
13:48:47.154   Training iter 550, batch loss 0.1912, batch acc 0.7198
13:48:47.609   Training iter 600, batch loss 0.1876, batch acc 0.7208
13:48:47.611 Training @ 490 epoch...
13:48:48.069   Training iter 50, batch loss 0.1893, batch acc 0.7198
13:48:48.528   Training iter 100, batch loss 0.1910, batch acc 0.7230
13:48:48.995   Training iter 150, batch loss 0.1841, batch acc 0.7320
13:48:49.482   Training iter 200, batch loss 0.1856, batch acc 0.7294
13:48:49.958   Training iter 250, batch loss 0.1877, batch acc 0.7216
13:48:50.432   Training iter 300, batch loss 0.1924, batch acc 0.7224
13:48:50.903   Training iter 350, batch loss 0.1863, batch acc 0.7254
13:48:51.376   Training iter 400, batch loss 0.1876, batch acc 0.7224
13:48:51.848   Training iter 450, batch loss 0.1917, batch acc 0.7144
13:48:52.326   Training iter 500, batch loss 0.1850, batch acc 0.7292
13:48:52.832   Training iter 550, batch loss 0.1899, batch acc 0.7200
13:48:53.353   Training iter 600, batch loss 0.1911, batch acc 0.7126
13:48:53.354 Testing @ 490 epoch...
13:48:53.391     Testing, total mean loss 0.18776, total acc 0.72040
13:48:53.391 Training @ 491 epoch...
13:48:53.907   Training iter 50, batch loss 0.1916, batch acc 0.7190
13:48:54.416   Training iter 100, batch loss 0.1877, batch acc 0.7230
13:48:54.915   Training iter 150, batch loss 0.1892, batch acc 0.7220
13:48:55.437   Training iter 200, batch loss 0.1867, batch acc 0.7316
13:48:55.947   Training iter 250, batch loss 0.1844, batch acc 0.7298
13:48:56.493   Training iter 300, batch loss 0.1865, batch acc 0.7250
13:48:57.038   Training iter 350, batch loss 0.1846, batch acc 0.7312
13:48:57.579   Training iter 400, batch loss 0.1934, batch acc 0.7128
13:48:58.117   Training iter 450, batch loss 0.1934, batch acc 0.7120
13:48:58.630   Training iter 500, batch loss 0.1871, batch acc 0.7256
13:48:59.141   Training iter 550, batch loss 0.1919, batch acc 0.7136
13:48:59.655   Training iter 600, batch loss 0.1852, batch acc 0.7252
13:48:59.657 Training @ 492 epoch...
13:49:00.180   Training iter 50, batch loss 0.1825, batch acc 0.7356
13:49:00.690   Training iter 100, batch loss 0.1840, batch acc 0.7300
13:49:01.188   Training iter 150, batch loss 0.1877, batch acc 0.7246
13:49:01.709   Training iter 200, batch loss 0.1869, batch acc 0.7248
13:49:02.234   Training iter 250, batch loss 0.1913, batch acc 0.7166
13:49:02.771   Training iter 300, batch loss 0.1946, batch acc 0.7066
13:49:03.300   Training iter 350, batch loss 0.1862, batch acc 0.7276
13:49:03.825   Training iter 400, batch loss 0.1848, batch acc 0.7284
13:49:04.351   Training iter 450, batch loss 0.1930, batch acc 0.7136
13:49:04.875   Training iter 500, batch loss 0.1887, batch acc 0.7216
13:49:05.402   Training iter 550, batch loss 0.1902, batch acc 0.7192
13:49:05.928   Training iter 600, batch loss 0.1917, batch acc 0.7206
13:49:05.930 Training @ 493 epoch...
13:49:06.462   Training iter 50, batch loss 0.1923, batch acc 0.7156
13:49:06.970   Training iter 100, batch loss 0.1895, batch acc 0.7178
13:49:07.487   Training iter 150, batch loss 0.1858, batch acc 0.7268
13:49:07.996   Training iter 200, batch loss 0.1894, batch acc 0.7220
13:49:08.523   Training iter 250, batch loss 0.1868, batch acc 0.7242
13:49:09.069   Training iter 300, batch loss 0.1857, batch acc 0.7238
13:49:09.614   Training iter 350, batch loss 0.1911, batch acc 0.7176
13:49:10.179   Training iter 400, batch loss 0.1887, batch acc 0.7278
13:49:10.734   Training iter 450, batch loss 0.1903, batch acc 0.7208
13:49:11.297   Training iter 500, batch loss 0.1859, batch acc 0.7294
13:49:11.851   Training iter 550, batch loss 0.1838, batch acc 0.7314
13:49:12.403   Training iter 600, batch loss 0.1923, batch acc 0.7122
13:49:12.405 Training @ 494 epoch...
13:49:12.954   Training iter 50, batch loss 0.1897, batch acc 0.7180
13:49:13.509   Training iter 100, batch loss 0.1852, batch acc 0.7278
13:49:14.069   Training iter 150, batch loss 0.1873, batch acc 0.7204
13:49:14.620   Training iter 200, batch loss 0.1905, batch acc 0.7156
13:49:15.141   Training iter 250, batch loss 0.1920, batch acc 0.7186
13:49:15.687   Training iter 300, batch loss 0.1865, batch acc 0.7266
13:49:16.235   Training iter 350, batch loss 0.1938, batch acc 0.7144
13:49:16.779   Training iter 400, batch loss 0.1880, batch acc 0.7260
13:49:17.301   Training iter 450, batch loss 0.1823, batch acc 0.7356
13:49:17.828   Training iter 500, batch loss 0.1879, batch acc 0.7224
13:49:18.343   Training iter 550, batch loss 0.1926, batch acc 0.7128
13:49:18.876   Training iter 600, batch loss 0.1856, batch acc 0.7320
13:49:18.878 Training @ 495 epoch...
13:49:19.420   Training iter 50, batch loss 0.1880, batch acc 0.7188
13:49:19.933   Training iter 100, batch loss 0.1900, batch acc 0.7212
13:49:20.440   Training iter 150, batch loss 0.1885, batch acc 0.7228
13:49:20.941   Training iter 200, batch loss 0.1886, batch acc 0.7238
13:49:21.444   Training iter 250, batch loss 0.1931, batch acc 0.7132
13:49:21.952   Training iter 300, batch loss 0.1849, batch acc 0.7268
13:49:22.496   Training iter 350, batch loss 0.1877, batch acc 0.7250
13:49:23.027   Training iter 400, batch loss 0.1879, batch acc 0.7228
13:49:23.552   Training iter 450, batch loss 0.1921, batch acc 0.7158
13:49:24.073   Training iter 500, batch loss 0.1870, batch acc 0.7292
13:49:24.591   Training iter 550, batch loss 0.1844, batch acc 0.7292
13:49:25.121   Training iter 600, batch loss 0.1893, batch acc 0.7202
13:49:25.122 Testing @ 495 epoch...
13:49:25.160     Testing, total mean loss 0.18775, total acc 0.72070
13:49:25.160 Training @ 496 epoch...
13:49:25.690   Training iter 50, batch loss 0.1896, batch acc 0.7232
13:49:26.228   Training iter 100, batch loss 0.1872, batch acc 0.7218
13:49:26.763   Training iter 150, batch loss 0.1876, batch acc 0.7226
13:49:27.293   Training iter 200, batch loss 0.1875, batch acc 0.7204
13:49:27.845   Training iter 250, batch loss 0.1918, batch acc 0.7160
13:49:28.371   Training iter 300, batch loss 0.1857, batch acc 0.7298
13:49:28.893   Training iter 350, batch loss 0.1849, batch acc 0.7302
13:49:29.419   Training iter 400, batch loss 0.1896, batch acc 0.7226
13:49:29.929   Training iter 450, batch loss 0.1895, batch acc 0.7200
13:49:30.439   Training iter 500, batch loss 0.1892, batch acc 0.7216
13:49:30.963   Training iter 550, batch loss 0.1911, batch acc 0.7214
13:49:31.471   Training iter 600, batch loss 0.1876, batch acc 0.7206
13:49:31.473 Training @ 497 epoch...
13:49:31.981   Training iter 50, batch loss 0.1884, batch acc 0.7234
13:49:32.481   Training iter 100, batch loss 0.1861, batch acc 0.7294
13:49:32.976   Training iter 150, batch loss 0.1930, batch acc 0.7140
13:49:33.475   Training iter 200, batch loss 0.1890, batch acc 0.7220
13:49:33.969   Training iter 250, batch loss 0.1907, batch acc 0.7168
13:49:34.466   Training iter 300, batch loss 0.1922, batch acc 0.7150
13:49:34.966   Training iter 350, batch loss 0.1888, batch acc 0.7224
13:49:35.445   Training iter 400, batch loss 0.1823, batch acc 0.7348
13:49:35.930   Training iter 450, batch loss 0.1851, batch acc 0.7258
13:49:36.409   Training iter 500, batch loss 0.1872, batch acc 0.7230
13:49:36.887   Training iter 550, batch loss 0.1901, batch acc 0.7222
13:49:37.370   Training iter 600, batch loss 0.1884, batch acc 0.7226
13:49:37.372 Training @ 498 epoch...
13:49:37.863   Training iter 50, batch loss 0.1882, batch acc 0.7212
13:49:38.358   Training iter 100, batch loss 0.1883, batch acc 0.7202
13:49:38.844   Training iter 150, batch loss 0.1865, batch acc 0.7292
13:49:39.341   Training iter 200, batch loss 0.1872, batch acc 0.7246
13:49:39.836   Training iter 250, batch loss 0.1887, batch acc 0.7224
13:49:40.332   Training iter 300, batch loss 0.1933, batch acc 0.7132
13:49:40.816   Training iter 350, batch loss 0.1865, batch acc 0.7286
13:49:41.309   Training iter 400, batch loss 0.1896, batch acc 0.7194
13:49:41.818   Training iter 450, batch loss 0.1909, batch acc 0.7216
13:49:42.353   Training iter 500, batch loss 0.1903, batch acc 0.7196
13:49:42.887   Training iter 550, batch loss 0.1874, batch acc 0.7236
13:49:43.413   Training iter 600, batch loss 0.1844, batch acc 0.7276
13:49:43.415 Training @ 499 epoch...
13:49:43.935   Training iter 50, batch loss 0.1926, batch acc 0.7164
13:49:44.478   Training iter 100, batch loss 0.1902, batch acc 0.7136
13:49:45.012   Training iter 150, batch loss 0.1866, batch acc 0.7230
13:49:45.536   Training iter 200, batch loss 0.1845, batch acc 0.7334
13:49:46.057   Training iter 250, batch loss 0.1910, batch acc 0.7184
13:49:46.582   Training iter 300, batch loss 0.1884, batch acc 0.7228
13:49:47.093   Training iter 350, batch loss 0.1835, batch acc 0.7312
13:49:47.613   Training iter 400, batch loss 0.1849, batch acc 0.7324
13:49:48.133   Training iter 450, batch loss 0.1878, batch acc 0.7248
13:49:48.648   Training iter 500, batch loss 0.1899, batch acc 0.7220
13:49:49.159   Training iter 550, batch loss 0.1908, batch acc 0.7170
13:49:49.664   Training iter 600, batch loss 0.1911, batch acc 0.7152
======================================================
13:49:49.666 Testing @ final epoch...
13:49:49.703     Testing, total mean loss 0.18772, total acc 0.72040
training time: 3090 seconds
