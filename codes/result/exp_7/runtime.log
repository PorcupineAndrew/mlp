======================================================
learning_rate: 0.1
weight_decay: 0.0001
momentum: 0.1
batch_size: 100
max_epoch: 500
disp_freq: 50
test_epoch: 5
plot_epoch: 100
network: Lin-784-10 Relu Lin-10-10 Relu
loss: Softmax
result dir: ./result/exp_7
======================================================
14:42:13.099 Training @ 0 epoch...
14:42:13.591   Training iter 50, batch loss 2.2968, batch acc 0.1302
14:42:14.050   Training iter 100, batch loss 2.1709, batch acc 0.1822
14:42:14.516   Training iter 150, batch loss 1.9143, batch acc 0.3478
14:42:14.995   Training iter 200, batch loss 1.6142, batch acc 0.4958
14:42:15.485   Training iter 250, batch loss 1.4227, batch acc 0.5300
14:42:15.969   Training iter 300, batch loss 1.3133, batch acc 0.5524
14:42:16.453   Training iter 350, batch loss 1.2805, batch acc 0.5722
14:42:16.972   Training iter 400, batch loss 1.2321, batch acc 0.5846
14:42:17.507   Training iter 450, batch loss 1.2319, batch acc 0.5920
14:42:18.024   Training iter 500, batch loss 1.1932, batch acc 0.6150
14:42:18.568   Training iter 550, batch loss 1.2012, batch acc 0.6180
14:42:19.120   Training iter 600, batch loss 1.1892, batch acc 0.6200
14:42:19.122 Testing @ 0 epoch...
14:42:19.165     Testing, total mean loss 1.16538, total acc 0.62350
14:42:19.165 Plot @ 0 epoch...
14:42:19.165 Training @ 1 epoch...
14:42:19.722   Training iter 50, batch loss 1.1663, batch acc 0.6324
14:42:20.257   Training iter 100, batch loss 1.1618, batch acc 0.6302
14:42:20.784   Training iter 150, batch loss 1.1813, batch acc 0.6284
14:42:21.326   Training iter 200, batch loss 1.1752, batch acc 0.6270
14:42:21.835   Training iter 250, batch loss 1.1580, batch acc 0.6452
14:42:22.336   Training iter 300, batch loss 1.1337, batch acc 0.6414
14:42:22.830   Training iter 350, batch loss 1.1431, batch acc 0.6358
14:42:23.298   Training iter 400, batch loss 1.0594, batch acc 0.6614
14:42:23.769   Training iter 450, batch loss 1.0474, batch acc 0.6834
14:42:24.240   Training iter 500, batch loss 0.9826, batch acc 0.7284
14:42:24.713   Training iter 550, batch loss 1.0131, batch acc 0.7222
14:42:25.193   Training iter 600, batch loss 0.9869, batch acc 0.7368
14:42:25.195 Training @ 2 epoch...
14:42:25.677   Training iter 50, batch loss 0.9765, batch acc 0.7340
14:42:26.175   Training iter 100, batch loss 0.9598, batch acc 0.7402
14:42:26.651   Training iter 150, batch loss 0.9495, batch acc 0.7438
14:42:27.151   Training iter 200, batch loss 0.9362, batch acc 0.7486
14:42:27.644   Training iter 250, batch loss 0.9594, batch acc 0.7398
14:42:28.134   Training iter 300, batch loss 0.9512, batch acc 0.7392
14:42:28.612   Training iter 350, batch loss 0.8786, batch acc 0.7500
14:42:29.091   Training iter 400, batch loss 0.7416, batch acc 0.7748
14:42:29.570   Training iter 450, batch loss 0.6124, batch acc 0.8192
14:42:30.061   Training iter 500, batch loss 0.5847, batch acc 0.8218
14:42:30.547   Training iter 550, batch loss 0.5628, batch acc 0.8242
14:42:31.036   Training iter 600, batch loss 0.5836, batch acc 0.8188
14:42:31.038 Training @ 3 epoch...
14:42:31.524   Training iter 50, batch loss 0.5472, batch acc 0.8272
14:42:32.017   Training iter 100, batch loss 0.5386, batch acc 0.8262
14:42:32.495   Training iter 150, batch loss 0.5374, batch acc 0.8288
14:42:32.979   Training iter 200, batch loss 0.5514, batch acc 0.8272
14:42:33.488   Training iter 250, batch loss 0.5487, batch acc 0.8292
14:42:33.981   Training iter 300, batch loss 0.5236, batch acc 0.8342
14:42:34.483   Training iter 350, batch loss 0.5184, batch acc 0.8370
14:42:34.967   Training iter 400, batch loss 0.5158, batch acc 0.8358
14:42:35.473   Training iter 450, batch loss 0.5205, batch acc 0.8334
14:42:35.962   Training iter 500, batch loss 0.5109, batch acc 0.8356
14:42:36.459   Training iter 550, batch loss 0.5238, batch acc 0.8348
14:42:36.946   Training iter 600, batch loss 0.4941, batch acc 0.8428
14:42:36.948 Training @ 4 epoch...
14:42:37.430   Training iter 50, batch loss 0.4934, batch acc 0.8446
14:42:37.930   Training iter 100, batch loss 0.4855, batch acc 0.8428
14:42:38.442   Training iter 150, batch loss 0.4834, batch acc 0.8454
14:42:38.937   Training iter 200, batch loss 0.4991, batch acc 0.8368
14:42:39.431   Training iter 250, batch loss 0.5017, batch acc 0.8426
14:42:39.912   Training iter 300, batch loss 0.4875, batch acc 0.8450
14:42:40.428   Training iter 350, batch loss 0.5149, batch acc 0.8354
14:42:40.909   Training iter 400, batch loss 0.5200, batch acc 0.8334
14:42:41.403   Training iter 450, batch loss 0.4844, batch acc 0.8418
14:42:41.920   Training iter 500, batch loss 0.4721, batch acc 0.8490
14:42:42.437   Training iter 550, batch loss 0.4953, batch acc 0.8386
14:42:42.951   Training iter 600, batch loss 0.4856, batch acc 0.8396
14:42:42.952 Training @ 5 epoch...
14:42:43.483   Training iter 50, batch loss 0.4844, batch acc 0.8394
14:42:43.960   Training iter 100, batch loss 0.4746, batch acc 0.8442
14:42:44.460   Training iter 150, batch loss 0.4970, batch acc 0.8392
14:42:44.955   Training iter 200, batch loss 0.3606, batch acc 0.9022
14:42:45.460   Training iter 250, batch loss 0.2869, batch acc 0.9224
14:42:45.993   Training iter 300, batch loss 0.3063, batch acc 0.9156
14:42:46.537   Training iter 350, batch loss 0.3124, batch acc 0.9128
14:42:47.106   Training iter 400, batch loss 0.3144, batch acc 0.9106
14:42:47.668   Training iter 450, batch loss 0.2998, batch acc 0.9134
14:42:48.206   Training iter 500, batch loss 0.2918, batch acc 0.9174
14:42:48.728   Training iter 550, batch loss 0.2980, batch acc 0.9148
14:42:49.217   Training iter 600, batch loss 0.2937, batch acc 0.9144
14:42:49.218 Testing @ 5 epoch...
14:42:49.263     Testing, total mean loss 0.27521, total acc 0.92320
14:42:49.263 Training @ 6 epoch...
14:42:49.784   Training iter 50, batch loss 0.2752, batch acc 0.9250
14:42:50.270   Training iter 100, batch loss 0.2745, batch acc 0.9154
14:42:50.733   Training iter 150, batch loss 0.2918, batch acc 0.9126
14:42:51.202   Training iter 200, batch loss 0.2933, batch acc 0.9176
14:42:51.662   Training iter 250, batch loss 0.2748, batch acc 0.9228
14:42:52.134   Training iter 300, batch loss 0.2885, batch acc 0.9202
14:42:52.597   Training iter 350, batch loss 0.2811, batch acc 0.9176
14:42:53.074   Training iter 400, batch loss 0.2915, batch acc 0.9184
14:42:53.548   Training iter 450, batch loss 0.2811, batch acc 0.9210
14:42:54.023   Training iter 500, batch loss 0.2921, batch acc 0.9174
14:42:54.506   Training iter 550, batch loss 0.2859, batch acc 0.9196
14:42:54.976   Training iter 600, batch loss 0.2729, batch acc 0.9214
14:42:54.978 Training @ 7 epoch...
14:42:55.477   Training iter 50, batch loss 0.2778, batch acc 0.9166
14:42:55.951   Training iter 100, batch loss 0.2587, batch acc 0.9248
14:42:56.436   Training iter 150, batch loss 0.2735, batch acc 0.9216
14:42:56.919   Training iter 200, batch loss 0.2749, batch acc 0.9204
14:42:57.411   Training iter 250, batch loss 0.2701, batch acc 0.9226
14:42:57.904   Training iter 300, batch loss 0.2613, batch acc 0.9220
14:42:58.426   Training iter 350, batch loss 0.2714, batch acc 0.9266
14:42:58.939   Training iter 400, batch loss 0.2872, batch acc 0.9158
14:42:59.448   Training iter 450, batch loss 0.2900, batch acc 0.9168
14:42:59.959   Training iter 500, batch loss 0.2739, batch acc 0.9222
14:43:00.493   Training iter 550, batch loss 0.2567, batch acc 0.9256
14:43:01.012   Training iter 600, batch loss 0.2576, batch acc 0.9254
14:43:01.014 Training @ 8 epoch...
14:43:01.556   Training iter 50, batch loss 0.2593, batch acc 0.9260
14:43:02.119   Training iter 100, batch loss 0.2572, batch acc 0.9228
14:43:02.692   Training iter 150, batch loss 0.2634, batch acc 0.9266
14:43:03.270   Training iter 200, batch loss 0.2785, batch acc 0.9218
14:43:03.798   Training iter 250, batch loss 0.2511, batch acc 0.9256
14:43:04.323   Training iter 300, batch loss 0.2583, batch acc 0.9278
14:43:04.861   Training iter 350, batch loss 0.2604, batch acc 0.9238
14:43:05.398   Training iter 400, batch loss 0.2758, batch acc 0.9204
14:43:05.949   Training iter 450, batch loss 0.2515, batch acc 0.9266
14:43:06.488   Training iter 500, batch loss 0.2495, batch acc 0.9310
14:43:07.038   Training iter 550, batch loss 0.2580, batch acc 0.9190
14:43:07.569   Training iter 600, batch loss 0.2637, batch acc 0.9240
14:43:07.571 Training @ 9 epoch...
14:43:08.105   Training iter 50, batch loss 0.2477, batch acc 0.9306
14:43:08.600   Training iter 100, batch loss 0.2747, batch acc 0.9174
14:43:09.104   Training iter 150, batch loss 0.2492, batch acc 0.9254
14:43:09.610   Training iter 200, batch loss 0.2677, batch acc 0.9194
14:43:10.122   Training iter 250, batch loss 0.2465, batch acc 0.9276
14:43:10.630   Training iter 300, batch loss 0.2592, batch acc 0.9264
14:43:11.128   Training iter 350, batch loss 0.2516, batch acc 0.9262
14:43:11.631   Training iter 400, batch loss 0.2677, batch acc 0.9228
14:43:12.139   Training iter 450, batch loss 0.2276, batch acc 0.9312
14:43:12.644   Training iter 500, batch loss 0.2553, batch acc 0.9256
14:43:13.152   Training iter 550, batch loss 0.2358, batch acc 0.9298
14:43:13.658   Training iter 600, batch loss 0.2621, batch acc 0.9244
14:43:13.660 Training @ 10 epoch...
14:43:14.170   Training iter 50, batch loss 0.2419, batch acc 0.9314
14:43:14.663   Training iter 100, batch loss 0.2444, batch acc 0.9248
14:43:15.161   Training iter 150, batch loss 0.2483, batch acc 0.9264
14:43:15.662   Training iter 200, batch loss 0.2579, batch acc 0.9256
14:43:16.162   Training iter 250, batch loss 0.2280, batch acc 0.9352
14:43:16.657   Training iter 300, batch loss 0.2613, batch acc 0.9218
14:43:17.155   Training iter 350, batch loss 0.2672, batch acc 0.9184
14:43:17.645   Training iter 400, batch loss 0.2630, batch acc 0.9226
14:43:18.133   Training iter 450, batch loss 0.2482, batch acc 0.9284
14:43:18.632   Training iter 500, batch loss 0.2451, batch acc 0.9282
14:43:19.138   Training iter 550, batch loss 0.2387, batch acc 0.9318
14:43:19.633   Training iter 600, batch loss 0.2660, batch acc 0.9224
14:43:19.635 Testing @ 10 epoch...
14:43:19.679     Testing, total mean loss 0.28009, total acc 0.91320
14:43:19.679 Training @ 11 epoch...
14:43:20.186   Training iter 50, batch loss 0.2464, batch acc 0.9284
14:43:20.705   Training iter 100, batch loss 0.2326, batch acc 0.9332
14:43:21.247   Training iter 150, batch loss 0.2653, batch acc 0.9220
14:43:21.779   Training iter 200, batch loss 0.2425, batch acc 0.9266
14:43:22.330   Training iter 250, batch loss 0.2428, batch acc 0.9266
14:43:22.881   Training iter 300, batch loss 0.2522, batch acc 0.9306
14:43:23.451   Training iter 350, batch loss 0.2484, batch acc 0.9260
14:43:24.027   Training iter 400, batch loss 0.2452, batch acc 0.9274
14:43:24.605   Training iter 450, batch loss 0.2259, batch acc 0.9326
14:43:25.171   Training iter 500, batch loss 0.2492, batch acc 0.9270
14:43:25.687   Training iter 550, batch loss 0.2544, batch acc 0.9292
14:43:26.194   Training iter 600, batch loss 0.2317, batch acc 0.9358
14:43:26.196 Training @ 12 epoch...
14:43:26.679   Training iter 50, batch loss 0.2467, batch acc 0.9314
14:43:27.134   Training iter 100, batch loss 0.2353, batch acc 0.9306
14:43:27.581   Training iter 150, batch loss 0.2360, batch acc 0.9316
14:43:28.075   Training iter 200, batch loss 0.2229, batch acc 0.9304
14:43:28.577   Training iter 250, batch loss 0.2470, batch acc 0.9320
14:43:29.050   Training iter 300, batch loss 0.2495, batch acc 0.9230
14:43:29.522   Training iter 350, batch loss 0.2418, batch acc 0.9272
14:43:29.990   Training iter 400, batch loss 0.2497, batch acc 0.9252
14:43:30.478   Training iter 450, batch loss 0.2480, batch acc 0.9282
14:43:30.983   Training iter 500, batch loss 0.2216, batch acc 0.9330
14:43:31.477   Training iter 550, batch loss 0.2413, batch acc 0.9246
14:43:31.993   Training iter 600, batch loss 0.2379, batch acc 0.9310
14:43:31.995 Training @ 13 epoch...
14:43:32.501   Training iter 50, batch loss 0.2560, batch acc 0.9246
14:43:33.003   Training iter 100, batch loss 0.2177, batch acc 0.9314
14:43:33.494   Training iter 150, batch loss 0.2319, batch acc 0.9348
14:43:33.988   Training iter 200, batch loss 0.2412, batch acc 0.9296
14:43:34.471   Training iter 250, batch loss 0.2317, batch acc 0.9346
14:43:34.952   Training iter 300, batch loss 0.2160, batch acc 0.9368
14:43:35.443   Training iter 350, batch loss 0.2407, batch acc 0.9326
14:43:35.930   Training iter 400, batch loss 0.2303, batch acc 0.9342
14:43:36.422   Training iter 450, batch loss 0.2555, batch acc 0.9266
14:43:36.922   Training iter 500, batch loss 0.2261, batch acc 0.9308
14:43:37.441   Training iter 550, batch loss 0.2582, batch acc 0.9230
14:43:37.975   Training iter 600, batch loss 0.2463, batch acc 0.9262
14:43:37.977 Training @ 14 epoch...
14:43:38.546   Training iter 50, batch loss 0.2309, batch acc 0.9304
14:43:39.081   Training iter 100, batch loss 0.2443, batch acc 0.9302
14:43:39.603   Training iter 150, batch loss 0.2282, batch acc 0.9314
14:43:40.130   Training iter 200, batch loss 0.2227, batch acc 0.9320
14:43:40.669   Training iter 250, batch loss 0.2441, batch acc 0.9294
14:43:41.201   Training iter 300, batch loss 0.2291, batch acc 0.9312
14:43:41.720   Training iter 350, batch loss 0.2136, batch acc 0.9394
14:43:42.255   Training iter 400, batch loss 0.2569, batch acc 0.9256
14:43:42.792   Training iter 450, batch loss 0.2403, batch acc 0.9322
14:43:43.295   Training iter 500, batch loss 0.2472, batch acc 0.9276
14:43:43.788   Training iter 550, batch loss 0.2078, batch acc 0.9362
14:43:44.273   Training iter 600, batch loss 0.2443, batch acc 0.9282
14:43:44.274 Training @ 15 epoch...
14:43:44.768   Training iter 50, batch loss 0.2159, batch acc 0.9370
14:43:45.269   Training iter 100, batch loss 0.2245, batch acc 0.9350
14:43:45.773   Training iter 150, batch loss 0.2249, batch acc 0.9374
14:43:46.259   Training iter 200, batch loss 0.2382, batch acc 0.9270
14:43:46.744   Training iter 250, batch loss 0.2196, batch acc 0.9326
14:43:47.234   Training iter 300, batch loss 0.2288, batch acc 0.9310
14:43:47.722   Training iter 350, batch loss 0.2261, batch acc 0.9360
14:43:48.233   Training iter 400, batch loss 0.2349, batch acc 0.9264
14:43:48.732   Training iter 450, batch loss 0.2560, batch acc 0.9240
14:43:49.246   Training iter 500, batch loss 0.2379, batch acc 0.9294
14:43:49.742   Training iter 550, batch loss 0.2365, batch acc 0.9352
14:43:50.272   Training iter 600, batch loss 0.2307, batch acc 0.9314
14:43:50.273 Testing @ 15 epoch...
14:43:50.320     Testing, total mean loss 0.23299, total acc 0.93020
14:43:50.320 Training @ 16 epoch...
14:43:50.862   Training iter 50, batch loss 0.2410, batch acc 0.9314
14:43:51.394   Training iter 100, batch loss 0.2400, batch acc 0.9294
14:43:51.930   Training iter 150, batch loss 0.2222, batch acc 0.9290
14:43:52.461   Training iter 200, batch loss 0.2201, batch acc 0.9398
14:43:52.999   Training iter 250, batch loss 0.2263, batch acc 0.9374
14:43:53.574   Training iter 300, batch loss 0.2128, batch acc 0.9370
14:43:54.131   Training iter 350, batch loss 0.2198, batch acc 0.9368
14:43:54.678   Training iter 400, batch loss 0.2161, batch acc 0.9364
14:43:55.238   Training iter 450, batch loss 0.2399, batch acc 0.9270
14:43:55.795   Training iter 500, batch loss 0.2300, batch acc 0.9360
14:43:56.364   Training iter 550, batch loss 0.2458, batch acc 0.9300
14:43:56.919   Training iter 600, batch loss 0.2300, batch acc 0.9334
14:43:56.921 Training @ 17 epoch...
14:43:57.480   Training iter 50, batch loss 0.2154, batch acc 0.9364
14:43:58.038   Training iter 100, batch loss 0.2316, batch acc 0.9336
14:43:58.599   Training iter 150, batch loss 0.2351, batch acc 0.9330
14:43:59.129   Training iter 200, batch loss 0.2276, batch acc 0.9328
14:43:59.646   Training iter 250, batch loss 0.2232, batch acc 0.9350
14:44:00.197   Training iter 300, batch loss 0.2341, batch acc 0.9336
14:44:00.770   Training iter 350, batch loss 0.2170, batch acc 0.9364
14:44:01.325   Training iter 400, batch loss 0.2242, batch acc 0.9340
14:44:01.898   Training iter 450, batch loss 0.2130, batch acc 0.9342
14:44:02.487   Training iter 500, batch loss 0.2329, batch acc 0.9340
14:44:03.099   Training iter 550, batch loss 0.2244, batch acc 0.9338
14:44:03.697   Training iter 600, batch loss 0.2276, batch acc 0.9380
14:44:03.698 Training @ 18 epoch...
14:44:04.270   Training iter 50, batch loss 0.2245, batch acc 0.9302
14:44:04.829   Training iter 100, batch loss 0.2120, batch acc 0.9416
14:44:05.379   Training iter 150, batch loss 0.2360, batch acc 0.9324
14:44:05.921   Training iter 200, batch loss 0.2107, batch acc 0.9360
14:44:06.474   Training iter 250, batch loss 0.2317, batch acc 0.9332
14:44:06.978   Training iter 300, batch loss 0.2209, batch acc 0.9336
14:44:07.471   Training iter 350, batch loss 0.2155, batch acc 0.9376
14:44:07.971   Training iter 400, batch loss 0.2333, batch acc 0.9320
14:44:08.472   Training iter 450, batch loss 0.2321, batch acc 0.9336
14:44:08.973   Training iter 500, batch loss 0.2166, batch acc 0.9402
14:44:09.503   Training iter 550, batch loss 0.2203, batch acc 0.9340
14:44:10.029   Training iter 600, batch loss 0.2301, batch acc 0.9310
14:44:10.031 Training @ 19 epoch...
14:44:10.572   Training iter 50, batch loss 0.2284, batch acc 0.9346
14:44:11.114   Training iter 100, batch loss 0.2165, batch acc 0.9394
14:44:11.630   Training iter 150, batch loss 0.2240, batch acc 0.9368
14:44:12.133   Training iter 200, batch loss 0.2214, batch acc 0.9334
14:44:12.689   Training iter 250, batch loss 0.2091, batch acc 0.9388
14:44:13.287   Training iter 300, batch loss 0.2314, batch acc 0.9328
14:44:13.870   Training iter 350, batch loss 0.2410, batch acc 0.9278
14:44:14.458   Training iter 400, batch loss 0.1974, batch acc 0.9398
14:44:14.978   Training iter 450, batch loss 0.2276, batch acc 0.9346
14:44:15.494   Training iter 500, batch loss 0.2089, batch acc 0.9414
14:44:15.962   Training iter 550, batch loss 0.2311, batch acc 0.9346
14:44:16.425   Training iter 600, batch loss 0.2287, batch acc 0.9340
14:44:16.427 Training @ 20 epoch...
14:44:16.925   Training iter 50, batch loss 0.2054, batch acc 0.9420
14:44:17.446   Training iter 100, batch loss 0.2225, batch acc 0.9354
14:44:17.949   Training iter 150, batch loss 0.2118, batch acc 0.9370
14:44:18.465   Training iter 200, batch loss 0.1963, batch acc 0.9422
14:44:18.972   Training iter 250, batch loss 0.2126, batch acc 0.9350
14:44:19.481   Training iter 300, batch loss 0.2164, batch acc 0.9348
14:44:20.021   Training iter 350, batch loss 0.2197, batch acc 0.9372
14:44:20.562   Training iter 400, batch loss 0.2301, batch acc 0.9344
14:44:21.095   Training iter 450, batch loss 0.2213, batch acc 0.9400
14:44:21.581   Training iter 500, batch loss 0.2350, batch acc 0.9294
14:44:22.092   Training iter 550, batch loss 0.2243, batch acc 0.9378
14:44:22.622   Training iter 600, batch loss 0.2157, batch acc 0.9374
14:44:22.624 Testing @ 20 epoch...
14:44:22.668     Testing, total mean loss 0.24884, total acc 0.92740
14:44:22.669 Training @ 21 epoch...
14:44:23.182   Training iter 50, batch loss 0.2153, batch acc 0.9346
14:44:23.674   Training iter 100, batch loss 0.2038, batch acc 0.9386
14:44:24.169   Training iter 150, batch loss 0.2260, batch acc 0.9332
14:44:24.673   Training iter 200, batch loss 0.2230, batch acc 0.9334
14:44:25.180   Training iter 250, batch loss 0.2253, batch acc 0.9368
14:44:25.697   Training iter 300, batch loss 0.2174, batch acc 0.9396
14:44:26.219   Training iter 350, batch loss 0.2178, batch acc 0.9342
14:44:26.733   Training iter 400, batch loss 0.2137, batch acc 0.9384
14:44:27.248   Training iter 450, batch loss 0.2068, batch acc 0.9394
14:44:27.763   Training iter 500, batch loss 0.2142, batch acc 0.9384
14:44:28.301   Training iter 550, batch loss 0.2125, batch acc 0.9358
14:44:28.839   Training iter 600, batch loss 0.2305, batch acc 0.9346
14:44:28.840 Training @ 22 epoch...
14:44:29.369   Training iter 50, batch loss 0.2071, batch acc 0.9392
14:44:29.909   Training iter 100, batch loss 0.2030, batch acc 0.9396
14:44:30.460   Training iter 150, batch loss 0.2316, batch acc 0.9342
14:44:31.023   Training iter 200, batch loss 0.2068, batch acc 0.9402
14:44:31.554   Training iter 250, batch loss 0.2276, batch acc 0.9366
14:44:32.050   Training iter 300, batch loss 0.2238, batch acc 0.9356
14:44:32.533   Training iter 350, batch loss 0.1929, batch acc 0.9404
14:44:33.058   Training iter 400, batch loss 0.2117, batch acc 0.9396
14:44:33.538   Training iter 450, batch loss 0.2305, batch acc 0.9342
14:44:34.014   Training iter 500, batch loss 0.2338, batch acc 0.9308
14:44:34.483   Training iter 550, batch loss 0.2310, batch acc 0.9366
14:44:34.976   Training iter 600, batch loss 0.2085, batch acc 0.9372
14:44:34.978 Training @ 23 epoch...
14:44:35.501   Training iter 50, batch loss 0.2068, batch acc 0.9362
14:44:36.049   Training iter 100, batch loss 0.2086, batch acc 0.9408
14:44:36.548   Training iter 150, batch loss 0.2134, batch acc 0.9358
14:44:37.058   Training iter 200, batch loss 0.2167, batch acc 0.9368
14:44:37.562   Training iter 250, batch loss 0.2066, batch acc 0.9410
14:44:38.069   Training iter 300, batch loss 0.2264, batch acc 0.9298
14:44:38.572   Training iter 350, batch loss 0.2297, batch acc 0.9338
14:44:39.072   Training iter 400, batch loss 0.2095, batch acc 0.9332
14:44:39.573   Training iter 450, batch loss 0.2071, batch acc 0.9388
14:44:40.087   Training iter 500, batch loss 0.2073, batch acc 0.9398
14:44:40.587   Training iter 550, batch loss 0.2292, batch acc 0.9316
14:44:41.087   Training iter 600, batch loss 0.2251, batch acc 0.9314
14:44:41.089 Training @ 24 epoch...
14:44:41.592   Training iter 50, batch loss 0.1952, batch acc 0.9422
14:44:42.134   Training iter 100, batch loss 0.2217, batch acc 0.9402
14:44:42.668   Training iter 150, batch loss 0.2247, batch acc 0.9352
14:44:43.208   Training iter 200, batch loss 0.2313, batch acc 0.9322
14:44:43.738   Training iter 250, batch loss 0.2063, batch acc 0.9398
14:44:44.289   Training iter 300, batch loss 0.2171, batch acc 0.9396
14:44:44.815   Training iter 350, batch loss 0.2141, batch acc 0.9320
14:44:45.357   Training iter 400, batch loss 0.2078, batch acc 0.9372
14:44:45.885   Training iter 450, batch loss 0.2133, batch acc 0.9362
14:44:46.413   Training iter 500, batch loss 0.2115, batch acc 0.9376
14:44:46.939   Training iter 550, batch loss 0.2121, batch acc 0.9340
14:44:47.471   Training iter 600, batch loss 0.2056, batch acc 0.9398
14:44:47.473 Training @ 25 epoch...
14:44:47.998   Training iter 50, batch loss 0.2079, batch acc 0.9380
14:44:48.486   Training iter 100, batch loss 0.1995, batch acc 0.9384
14:44:48.979   Training iter 150, batch loss 0.2038, batch acc 0.9386
14:44:49.469   Training iter 200, batch loss 0.2191, batch acc 0.9364
14:44:49.962   Training iter 250, batch loss 0.2082, batch acc 0.9392
14:44:50.471   Training iter 300, batch loss 0.2189, batch acc 0.9356
14:44:50.960   Training iter 350, batch loss 0.2219, batch acc 0.9368
14:44:51.427   Training iter 400, batch loss 0.2071, batch acc 0.9382
14:44:51.895   Training iter 450, batch loss 0.1967, batch acc 0.9410
14:44:52.397   Training iter 500, batch loss 0.1998, batch acc 0.9408
14:44:52.908   Training iter 550, batch loss 0.2449, batch acc 0.9292
14:44:53.424   Training iter 600, batch loss 0.2197, batch acc 0.9358
14:44:53.426 Testing @ 25 epoch...
14:44:53.470     Testing, total mean loss 0.22360, total acc 0.93320
14:44:53.470 Training @ 26 epoch...
14:44:53.983   Training iter 50, batch loss 0.2140, batch acc 0.9390
14:44:54.464   Training iter 100, batch loss 0.2004, batch acc 0.9406
14:44:54.932   Training iter 150, batch loss 0.1982, batch acc 0.9360
14:44:55.417   Training iter 200, batch loss 0.2082, batch acc 0.9386
14:44:55.928   Training iter 250, batch loss 0.2226, batch acc 0.9352
14:44:56.421   Training iter 300, batch loss 0.1947, batch acc 0.9452
14:44:56.907   Training iter 350, batch loss 0.2052, batch acc 0.9374
14:44:57.397   Training iter 400, batch loss 0.2064, batch acc 0.9384
14:44:57.896   Training iter 450, batch loss 0.2077, batch acc 0.9424
14:44:58.431   Training iter 500, batch loss 0.2158, batch acc 0.9380
14:44:58.939   Training iter 550, batch loss 0.2184, batch acc 0.9346
14:44:59.437   Training iter 600, batch loss 0.2342, batch acc 0.9328
14:44:59.439 Training @ 27 epoch...
14:44:59.940   Training iter 50, batch loss 0.2184, batch acc 0.9348
14:45:00.475   Training iter 100, batch loss 0.2142, batch acc 0.9370
14:45:00.990   Training iter 150, batch loss 0.2072, batch acc 0.9358
14:45:01.541   Training iter 200, batch loss 0.2299, batch acc 0.9356
14:45:02.099   Training iter 250, batch loss 0.2081, batch acc 0.9402
14:45:02.640   Training iter 300, batch loss 0.2005, batch acc 0.9394
14:45:03.203   Training iter 350, batch loss 0.1914, batch acc 0.9458
14:45:03.776   Training iter 400, batch loss 0.2035, batch acc 0.9410
14:45:04.318   Training iter 450, batch loss 0.2146, batch acc 0.9328
14:45:04.877   Training iter 500, batch loss 0.2043, batch acc 0.9366
14:45:05.417   Training iter 550, batch loss 0.2081, batch acc 0.9402
14:45:05.928   Training iter 600, batch loss 0.2105, batch acc 0.9354
14:45:05.930 Training @ 28 epoch...
14:45:06.437   Training iter 50, batch loss 0.2076, batch acc 0.9374
14:45:06.954   Training iter 100, batch loss 0.1926, batch acc 0.9484
14:45:07.483   Training iter 150, batch loss 0.2150, batch acc 0.9334
14:45:07.987   Training iter 200, batch loss 0.2286, batch acc 0.9392
14:45:08.468   Training iter 250, batch loss 0.2169, batch acc 0.9352
14:45:08.958   Training iter 300, batch loss 0.2148, batch acc 0.9372
14:45:09.426   Training iter 350, batch loss 0.2104, batch acc 0.9328
14:45:09.885   Training iter 400, batch loss 0.1848, batch acc 0.9448
14:45:10.365   Training iter 450, batch loss 0.1966, batch acc 0.9438
14:45:10.825   Training iter 500, batch loss 0.2145, batch acc 0.9384
14:45:11.297   Training iter 550, batch loss 0.2022, batch acc 0.9382
14:45:11.780   Training iter 600, batch loss 0.2117, batch acc 0.9366
14:45:11.782 Training @ 29 epoch...
14:45:12.292   Training iter 50, batch loss 0.1990, batch acc 0.9394
14:45:12.808   Training iter 100, batch loss 0.2054, batch acc 0.9382
14:45:13.338   Training iter 150, batch loss 0.1842, batch acc 0.9424
14:45:13.850   Training iter 200, batch loss 0.2149, batch acc 0.9392
14:45:14.352   Training iter 250, batch loss 0.2054, batch acc 0.9432
14:45:14.871   Training iter 300, batch loss 0.2245, batch acc 0.9328
14:45:15.401   Training iter 350, batch loss 0.2026, batch acc 0.9420
14:45:15.932   Training iter 400, batch loss 0.2086, batch acc 0.9426
14:45:16.465   Training iter 450, batch loss 0.1962, batch acc 0.9418
14:45:17.003   Training iter 500, batch loss 0.2193, batch acc 0.9388
14:45:17.501   Training iter 550, batch loss 0.1986, batch acc 0.9392
14:45:18.019   Training iter 600, batch loss 0.2233, batch acc 0.9344
14:45:18.021 Training @ 30 epoch...
14:45:18.547   Training iter 50, batch loss 0.2163, batch acc 0.9390
14:45:19.096   Training iter 100, batch loss 0.2151, batch acc 0.9390
14:45:19.641   Training iter 150, batch loss 0.1883, batch acc 0.9476
14:45:20.185   Training iter 200, batch loss 0.2226, batch acc 0.9340
14:45:20.732   Training iter 250, batch loss 0.2036, batch acc 0.9394
14:45:21.276   Training iter 300, batch loss 0.1952, batch acc 0.9428
14:45:21.811   Training iter 350, batch loss 0.2026, batch acc 0.9354
14:45:22.348   Training iter 400, batch loss 0.2037, batch acc 0.9378
14:45:22.884   Training iter 450, batch loss 0.1960, batch acc 0.9418
14:45:23.427   Training iter 500, batch loss 0.1933, batch acc 0.9418
14:45:23.961   Training iter 550, batch loss 0.2223, batch acc 0.9368
14:45:24.493   Training iter 600, batch loss 0.2123, batch acc 0.9354
14:45:24.495 Testing @ 30 epoch...
14:45:24.539     Testing, total mean loss 0.23713, total acc 0.92900
14:45:24.539 Training @ 31 epoch...
14:45:25.067   Training iter 50, batch loss 0.1866, batch acc 0.9472
14:45:25.581   Training iter 100, batch loss 0.2035, batch acc 0.9410
14:45:26.120   Training iter 150, batch loss 0.2133, batch acc 0.9386
14:45:26.666   Training iter 200, batch loss 0.2139, batch acc 0.9384
14:45:27.217   Training iter 250, batch loss 0.1908, batch acc 0.9426
14:45:27.786   Training iter 300, batch loss 0.2127, batch acc 0.9352
14:45:28.359   Training iter 350, batch loss 0.2084, batch acc 0.9390
14:45:28.935   Training iter 400, batch loss 0.2053, batch acc 0.9390
14:45:29.497   Training iter 450, batch loss 0.2036, batch acc 0.9392
14:45:30.056   Training iter 500, batch loss 0.2122, batch acc 0.9364
14:45:30.617   Training iter 550, batch loss 0.2143, batch acc 0.9348
14:45:31.172   Training iter 600, batch loss 0.1900, batch acc 0.9442
14:45:31.174 Training @ 32 epoch...
14:45:31.681   Training iter 50, batch loss 0.1798, batch acc 0.9438
14:45:32.194   Training iter 100, batch loss 0.2008, batch acc 0.9416
14:45:32.739   Training iter 150, batch loss 0.2088, batch acc 0.9376
14:45:33.353   Training iter 200, batch loss 0.2157, batch acc 0.9342
14:45:33.870   Training iter 250, batch loss 0.2103, batch acc 0.9416
14:45:34.390   Training iter 300, batch loss 0.1914, batch acc 0.9450
14:45:34.982   Training iter 350, batch loss 0.2230, batch acc 0.9318
14:45:35.553   Training iter 400, batch loss 0.2398, batch acc 0.9324
14:45:36.088   Training iter 450, batch loss 0.2020, batch acc 0.9406
14:45:36.631   Training iter 500, batch loss 0.2015, batch acc 0.9418
14:45:37.209   Training iter 550, batch loss 0.1903, batch acc 0.9422
14:45:37.818   Training iter 600, batch loss 0.1984, batch acc 0.9416
14:45:37.820 Training @ 33 epoch...
14:45:38.441   Training iter 50, batch loss 0.1987, batch acc 0.9434
14:45:38.995   Training iter 100, batch loss 0.1843, batch acc 0.9462
14:45:39.546   Training iter 150, batch loss 0.2064, batch acc 0.9354
14:45:40.083   Training iter 200, batch loss 0.2122, batch acc 0.9422
14:45:40.616   Training iter 250, batch loss 0.2009, batch acc 0.9402
14:45:41.131   Training iter 300, batch loss 0.2154, batch acc 0.9348
14:45:41.654   Training iter 350, batch loss 0.1959, batch acc 0.9428
14:45:42.197   Training iter 400, batch loss 0.1969, batch acc 0.9404
14:45:42.733   Training iter 450, batch loss 0.1941, batch acc 0.9424
14:45:43.276   Training iter 500, batch loss 0.2137, batch acc 0.9358
14:45:43.804   Training iter 550, batch loss 0.2150, batch acc 0.9362
14:45:44.355   Training iter 600, batch loss 0.1944, batch acc 0.9436
14:45:44.356 Training @ 34 epoch...
14:45:44.925   Training iter 50, batch loss 0.1858, batch acc 0.9434
14:45:45.495   Training iter 100, batch loss 0.2217, batch acc 0.9366
14:45:46.065   Training iter 150, batch loss 0.1993, batch acc 0.9430
14:45:46.643   Training iter 200, batch loss 0.1994, batch acc 0.9386
14:45:47.213   Training iter 250, batch loss 0.2021, batch acc 0.9412
14:45:47.775   Training iter 300, batch loss 0.2143, batch acc 0.9374
14:45:48.342   Training iter 350, batch loss 0.2117, batch acc 0.9368
14:45:48.889   Training iter 400, batch loss 0.2007, batch acc 0.9402
14:45:49.448   Training iter 450, batch loss 0.1944, batch acc 0.9426
14:45:50.018   Training iter 500, batch loss 0.2082, batch acc 0.9400
14:45:50.576   Training iter 550, batch loss 0.1858, batch acc 0.9448
14:45:51.133   Training iter 600, batch loss 0.2055, batch acc 0.9418
14:45:51.135 Training @ 35 epoch...
14:45:51.683   Training iter 50, batch loss 0.1968, batch acc 0.9440
14:45:52.233   Training iter 100, batch loss 0.1990, batch acc 0.9376
14:45:52.750   Training iter 150, batch loss 0.1989, batch acc 0.9422
14:45:53.258   Training iter 200, batch loss 0.1924, batch acc 0.9432
14:45:53.765   Training iter 250, batch loss 0.2060, batch acc 0.9404
14:45:54.274   Training iter 300, batch loss 0.1967, batch acc 0.9430
14:45:54.793   Training iter 350, batch loss 0.1857, batch acc 0.9452
14:45:55.313   Training iter 400, batch loss 0.2172, batch acc 0.9332
14:45:55.832   Training iter 450, batch loss 0.2222, batch acc 0.9348
14:45:56.360   Training iter 500, batch loss 0.2083, batch acc 0.9400
14:45:56.874   Training iter 550, batch loss 0.1818, batch acc 0.9464
14:45:57.399   Training iter 600, batch loss 0.2121, batch acc 0.9356
14:45:57.401 Testing @ 35 epoch...
14:45:57.445     Testing, total mean loss 0.22396, total acc 0.93300
14:45:57.445 Training @ 36 epoch...
14:45:57.967   Training iter 50, batch loss 0.2087, batch acc 0.9426
14:45:58.489   Training iter 100, batch loss 0.1878, batch acc 0.9454
14:45:59.008   Training iter 150, batch loss 0.2004, batch acc 0.9396
14:45:59.547   Training iter 200, batch loss 0.1808, batch acc 0.9460
14:46:00.111   Training iter 250, batch loss 0.1891, batch acc 0.9442
14:46:00.678   Training iter 300, batch loss 0.1969, batch acc 0.9382
14:46:01.217   Training iter 350, batch loss 0.1944, batch acc 0.9456
14:46:01.787   Training iter 400, batch loss 0.2091, batch acc 0.9382
14:46:02.367   Training iter 450, batch loss 0.2089, batch acc 0.9400
14:46:02.948   Training iter 500, batch loss 0.2189, batch acc 0.9364
14:46:03.527   Training iter 550, batch loss 0.2123, batch acc 0.9424
14:46:04.110   Training iter 600, batch loss 0.1989, batch acc 0.9408
14:46:04.112 Training @ 37 epoch...
14:46:04.692   Training iter 50, batch loss 0.2073, batch acc 0.9380
14:46:05.267   Training iter 100, batch loss 0.2218, batch acc 0.9356
14:46:05.834   Training iter 150, batch loss 0.1945, batch acc 0.9416
14:46:06.392   Training iter 200, batch loss 0.1986, batch acc 0.9428
14:46:06.961   Training iter 250, batch loss 0.1998, batch acc 0.9420
14:46:07.515   Training iter 300, batch loss 0.1813, batch acc 0.9462
14:46:08.054   Training iter 350, batch loss 0.1994, batch acc 0.9446
14:46:08.561   Training iter 400, batch loss 0.1965, batch acc 0.9408
14:46:09.028   Training iter 450, batch loss 0.2168, batch acc 0.9344
14:46:09.492   Training iter 500, batch loss 0.1994, batch acc 0.9410
14:46:09.960   Training iter 550, batch loss 0.1992, batch acc 0.9428
14:46:10.483   Training iter 600, batch loss 0.1764, batch acc 0.9512
14:46:10.485 Training @ 38 epoch...
14:46:11.014   Training iter 50, batch loss 0.1798, batch acc 0.9444
14:46:11.517   Training iter 100, batch loss 0.1779, batch acc 0.9442
14:46:12.010   Training iter 150, batch loss 0.1991, batch acc 0.9412
14:46:12.514   Training iter 200, batch loss 0.1910, batch acc 0.9434
14:46:13.045   Training iter 250, batch loss 0.2147, batch acc 0.9368
14:46:13.580   Training iter 300, batch loss 0.1971, batch acc 0.9396
14:46:14.104   Training iter 350, batch loss 0.1919, batch acc 0.9424
14:46:14.624   Training iter 400, batch loss 0.2157, batch acc 0.9338
14:46:15.144   Training iter 450, batch loss 0.1864, batch acc 0.9440
14:46:15.661   Training iter 500, batch loss 0.1965, batch acc 0.9470
14:46:16.181   Training iter 550, batch loss 0.2222, batch acc 0.9366
14:46:16.692   Training iter 600, batch loss 0.2118, batch acc 0.9382
14:46:16.694 Training @ 39 epoch...
14:46:17.217   Training iter 50, batch loss 0.1855, batch acc 0.9442
14:46:17.739   Training iter 100, batch loss 0.2050, batch acc 0.9420
14:46:18.270   Training iter 150, batch loss 0.1898, batch acc 0.9442
14:46:18.799   Training iter 200, batch loss 0.1954, batch acc 0.9404
14:46:19.333   Training iter 250, batch loss 0.1949, batch acc 0.9420
14:46:19.860   Training iter 300, batch loss 0.2099, batch acc 0.9384
14:46:20.392   Training iter 350, batch loss 0.1953, batch acc 0.9420
14:46:20.907   Training iter 400, batch loss 0.1934, batch acc 0.9460
14:46:21.397   Training iter 450, batch loss 0.2052, batch acc 0.9342
14:46:21.892   Training iter 500, batch loss 0.2043, batch acc 0.9390
14:46:22.393   Training iter 550, batch loss 0.2012, batch acc 0.9396
14:46:22.901   Training iter 600, batch loss 0.2001, batch acc 0.9412
14:46:22.903 Training @ 40 epoch...
14:46:23.404   Training iter 50, batch loss 0.1935, batch acc 0.9434
14:46:23.905   Training iter 100, batch loss 0.1983, batch acc 0.9400
14:46:24.413   Training iter 150, batch loss 0.2018, batch acc 0.9390
14:46:24.925   Training iter 200, batch loss 0.2077, batch acc 0.9410
14:46:25.439   Training iter 250, batch loss 0.2005, batch acc 0.9422
14:46:25.948   Training iter 300, batch loss 0.2040, batch acc 0.9438
14:46:26.483   Training iter 350, batch loss 0.1965, batch acc 0.9434
14:46:27.013   Training iter 400, batch loss 0.1877, batch acc 0.9436
14:46:27.548   Training iter 450, batch loss 0.1839, batch acc 0.9440
14:46:28.076   Training iter 500, batch loss 0.2024, batch acc 0.9428
14:46:28.604   Training iter 550, batch loss 0.1947, batch acc 0.9414
14:46:29.143   Training iter 600, batch loss 0.2051, batch acc 0.9420
14:46:29.145 Testing @ 40 epoch...
14:46:29.188     Testing, total mean loss 0.23200, total acc 0.93010
14:46:29.188 Training @ 41 epoch...
14:46:29.712   Training iter 50, batch loss 0.1994, batch acc 0.9428
14:46:30.234   Training iter 100, batch loss 0.1881, batch acc 0.9428
14:46:30.747   Training iter 150, batch loss 0.1953, batch acc 0.9458
14:46:31.277   Training iter 200, batch loss 0.2106, batch acc 0.9386
14:46:31.803   Training iter 250, batch loss 0.2053, batch acc 0.9374
14:46:32.336   Training iter 300, batch loss 0.1914, batch acc 0.9436
14:46:32.858   Training iter 350, batch loss 0.1992, batch acc 0.9400
14:46:33.387   Training iter 400, batch loss 0.1941, batch acc 0.9404
14:46:33.898   Training iter 450, batch loss 0.2025, batch acc 0.9350
14:46:34.397   Training iter 500, batch loss 0.2048, batch acc 0.9408
14:46:34.920   Training iter 550, batch loss 0.2010, batch acc 0.9412
14:46:35.433   Training iter 600, batch loss 0.1889, batch acc 0.9456
14:46:35.434 Training @ 42 epoch...
14:46:35.945   Training iter 50, batch loss 0.1953, batch acc 0.9436
14:46:36.469   Training iter 100, batch loss 0.1805, batch acc 0.9496
14:46:36.997   Training iter 150, batch loss 0.2142, batch acc 0.9384
14:46:37.515   Training iter 200, batch loss 0.1890, batch acc 0.9394
14:46:38.033   Training iter 250, batch loss 0.1886, batch acc 0.9404
14:46:38.561   Training iter 300, batch loss 0.2102, batch acc 0.9360
14:46:39.084   Training iter 350, batch loss 0.1844, batch acc 0.9440
14:46:39.621   Training iter 400, batch loss 0.2040, batch acc 0.9344
14:46:40.161   Training iter 450, batch loss 0.1975, batch acc 0.9430
14:46:40.693   Training iter 500, batch loss 0.2036, batch acc 0.9430
14:46:41.221   Training iter 550, batch loss 0.1925, batch acc 0.9438
14:46:41.741   Training iter 600, batch loss 0.1844, batch acc 0.9444
14:46:41.743 Training @ 43 epoch...
14:46:42.272   Training iter 50, batch loss 0.1961, batch acc 0.9418
14:46:42.807   Training iter 100, batch loss 0.1967, batch acc 0.9398
14:46:43.350   Training iter 150, batch loss 0.1944, batch acc 0.9412
14:46:43.868   Training iter 200, batch loss 0.1818, batch acc 0.9462
14:46:44.399   Training iter 250, batch loss 0.2056, batch acc 0.9388
14:46:44.935   Training iter 300, batch loss 0.1885, batch acc 0.9424
14:46:45.467   Training iter 350, batch loss 0.1936, batch acc 0.9468
14:46:45.984   Training iter 400, batch loss 0.1843, batch acc 0.9442
14:46:46.525   Training iter 450, batch loss 0.2086, batch acc 0.9406
14:46:47.061   Training iter 500, batch loss 0.2070, batch acc 0.9404
14:46:47.582   Training iter 550, batch loss 0.1942, batch acc 0.9408
14:46:48.109   Training iter 600, batch loss 0.1914, batch acc 0.9442
14:46:48.110 Training @ 44 epoch...
14:46:48.626   Training iter 50, batch loss 0.2044, batch acc 0.9392
14:46:49.100   Training iter 100, batch loss 0.1928, batch acc 0.9440
14:46:49.582   Training iter 150, batch loss 0.1943, batch acc 0.9420
14:46:50.091   Training iter 200, batch loss 0.1938, batch acc 0.9416
14:46:50.620   Training iter 250, batch loss 0.2246, batch acc 0.9328
14:46:51.147   Training iter 300, batch loss 0.1735, batch acc 0.9468
14:46:51.680   Training iter 350, batch loss 0.1878, batch acc 0.9432
14:46:52.203   Training iter 400, batch loss 0.1869, batch acc 0.9456
14:46:52.719   Training iter 450, batch loss 0.1760, batch acc 0.9510
14:46:53.245   Training iter 500, batch loss 0.2033, batch acc 0.9438
14:46:53.776   Training iter 550, batch loss 0.1881, batch acc 0.9418
14:46:54.307   Training iter 600, batch loss 0.2098, batch acc 0.9418
14:46:54.309 Training @ 45 epoch...
14:46:54.831   Training iter 50, batch loss 0.2020, batch acc 0.9378
14:46:55.340   Training iter 100, batch loss 0.1997, batch acc 0.9412
14:46:55.860   Training iter 150, batch loss 0.1732, batch acc 0.9478
14:46:56.372   Training iter 200, batch loss 0.1837, batch acc 0.9466
14:46:56.880   Training iter 250, batch loss 0.1928, batch acc 0.9428
14:46:57.388   Training iter 300, batch loss 0.1979, batch acc 0.9424
14:46:57.917   Training iter 350, batch loss 0.1846, batch acc 0.9452
14:46:58.456   Training iter 400, batch loss 0.1931, batch acc 0.9430
14:46:58.974   Training iter 450, batch loss 0.2186, batch acc 0.9322
14:46:59.498   Training iter 500, batch loss 0.1945, batch acc 0.9422
14:47:00.021   Training iter 550, batch loss 0.1827, batch acc 0.9456
14:47:00.549   Training iter 600, batch loss 0.1927, batch acc 0.9404
14:47:00.550 Testing @ 45 epoch...
14:47:00.595     Testing, total mean loss 0.22137, total acc 0.93470
14:47:00.595 Training @ 46 epoch...
14:47:01.121   Training iter 50, batch loss 0.1814, batch acc 0.9462
14:47:01.653   Training iter 100, batch loss 0.1940, batch acc 0.9410
14:47:02.228   Training iter 150, batch loss 0.1834, batch acc 0.9484
14:47:02.782   Training iter 200, batch loss 0.1799, batch acc 0.9490
14:47:03.344   Training iter 250, batch loss 0.1976, batch acc 0.9400
14:47:03.901   Training iter 300, batch loss 0.2081, batch acc 0.9390
14:47:04.460   Training iter 350, batch loss 0.1995, batch acc 0.9430
14:47:05.021   Training iter 400, batch loss 0.1813, batch acc 0.9462
14:47:05.555   Training iter 450, batch loss 0.1962, batch acc 0.9436
14:47:06.087   Training iter 500, batch loss 0.2073, batch acc 0.9404
14:47:06.636   Training iter 550, batch loss 0.1952, batch acc 0.9416
14:47:07.159   Training iter 600, batch loss 0.1974, batch acc 0.9426
14:47:07.160 Training @ 47 epoch...
14:47:07.702   Training iter 50, batch loss 0.1891, batch acc 0.9428
14:47:08.199   Training iter 100, batch loss 0.1848, batch acc 0.9422
14:47:08.708   Training iter 150, batch loss 0.1832, batch acc 0.9468
14:47:09.200   Training iter 200, batch loss 0.1963, batch acc 0.9400
14:47:09.689   Training iter 250, batch loss 0.2194, batch acc 0.9398
14:47:10.196   Training iter 300, batch loss 0.2089, batch acc 0.9416
14:47:10.706   Training iter 350, batch loss 0.1875, batch acc 0.9424
14:47:11.213   Training iter 400, batch loss 0.1866, batch acc 0.9488
14:47:11.688   Training iter 450, batch loss 0.1883, batch acc 0.9428
14:47:12.180   Training iter 500, batch loss 0.1888, batch acc 0.9384
14:47:12.679   Training iter 550, batch loss 0.1975, batch acc 0.9408
14:47:13.184   Training iter 600, batch loss 0.1829, batch acc 0.9460
14:47:13.186 Training @ 48 epoch...
14:47:13.660   Training iter 50, batch loss 0.1901, batch acc 0.9416
14:47:14.122   Training iter 100, batch loss 0.1892, batch acc 0.9444
14:47:14.583   Training iter 150, batch loss 0.1838, batch acc 0.9450
14:47:15.048   Training iter 200, batch loss 0.1731, batch acc 0.9498
14:47:15.507   Training iter 250, batch loss 0.1894, batch acc 0.9414
14:47:15.962   Training iter 300, batch loss 0.2079, batch acc 0.9424
14:47:16.419   Training iter 350, batch loss 0.1722, batch acc 0.9474
14:47:16.890   Training iter 400, batch loss 0.2063, batch acc 0.9410
14:47:17.356   Training iter 450, batch loss 0.1974, batch acc 0.9428
14:47:17.814   Training iter 500, batch loss 0.1881, batch acc 0.9438
14:47:18.288   Training iter 550, batch loss 0.2049, batch acc 0.9414
14:47:18.759   Training iter 600, batch loss 0.2078, batch acc 0.9400
14:47:18.761 Training @ 49 epoch...
14:47:19.242   Training iter 50, batch loss 0.2014, batch acc 0.9374
14:47:19.714   Training iter 100, batch loss 0.1873, batch acc 0.9456
14:47:20.216   Training iter 150, batch loss 0.1959, batch acc 0.9452
14:47:20.720   Training iter 200, batch loss 0.1958, batch acc 0.9422
14:47:21.221   Training iter 250, batch loss 0.1865, batch acc 0.9462
14:47:21.731   Training iter 300, batch loss 0.1870, batch acc 0.9462
14:47:22.254   Training iter 350, batch loss 0.1675, batch acc 0.9468
14:47:22.776   Training iter 400, batch loss 0.1822, batch acc 0.9484
14:47:23.307   Training iter 450, batch loss 0.1899, batch acc 0.9430
14:47:23.824   Training iter 500, batch loss 0.1994, batch acc 0.9412
14:47:24.329   Training iter 550, batch loss 0.1999, batch acc 0.9406
14:47:24.825   Training iter 600, batch loss 0.2138, batch acc 0.9368
14:47:24.827 Training @ 50 epoch...
14:47:25.317   Training iter 50, batch loss 0.1870, batch acc 0.9468
14:47:25.814   Training iter 100, batch loss 0.1877, batch acc 0.9462
14:47:26.332   Training iter 150, batch loss 0.2015, batch acc 0.9398
14:47:26.829   Training iter 200, batch loss 0.1852, batch acc 0.9438
14:47:27.335   Training iter 250, batch loss 0.1834, batch acc 0.9470
14:47:27.849   Training iter 300, batch loss 0.1837, batch acc 0.9458
14:47:28.369   Training iter 350, batch loss 0.1862, batch acc 0.9434
14:47:28.875   Training iter 400, batch loss 0.1840, batch acc 0.9490
14:47:29.378   Training iter 450, batch loss 0.2079, batch acc 0.9370
14:47:29.889   Training iter 500, batch loss 0.1873, batch acc 0.9438
14:47:30.403   Training iter 550, batch loss 0.2011, batch acc 0.9406
14:47:30.895   Training iter 600, batch loss 0.1991, batch acc 0.9406
14:47:30.897 Testing @ 50 epoch...
14:47:30.941     Testing, total mean loss 0.21461, total acc 0.93560
14:47:30.941 Training @ 51 epoch...
14:47:31.435   Training iter 50, batch loss 0.1879, batch acc 0.9458
14:47:31.919   Training iter 100, batch loss 0.1896, batch acc 0.9410
14:47:32.413   Training iter 150, batch loss 0.1884, batch acc 0.9448
14:47:32.906   Training iter 200, batch loss 0.2069, batch acc 0.9392
14:47:33.408   Training iter 250, batch loss 0.1872, batch acc 0.9484
14:47:33.897   Training iter 300, batch loss 0.1835, batch acc 0.9476
14:47:34.395   Training iter 350, batch loss 0.1840, batch acc 0.9460
14:47:34.888   Training iter 400, batch loss 0.1855, batch acc 0.9450
14:47:35.384   Training iter 450, batch loss 0.1972, batch acc 0.9418
14:47:35.870   Training iter 500, batch loss 0.1870, batch acc 0.9458
14:47:36.366   Training iter 550, batch loss 0.1961, batch acc 0.9446
14:47:36.854   Training iter 600, batch loss 0.1991, batch acc 0.9414
14:47:36.856 Training @ 52 epoch...
14:47:37.340   Training iter 50, batch loss 0.1887, batch acc 0.9436
14:47:37.814   Training iter 100, batch loss 0.1830, batch acc 0.9470
14:47:38.295   Training iter 150, batch loss 0.1917, batch acc 0.9428
14:47:38.770   Training iter 200, batch loss 0.1926, batch acc 0.9456
14:47:39.264   Training iter 250, batch loss 0.1803, batch acc 0.9454
14:47:39.741   Training iter 300, batch loss 0.1960, batch acc 0.9456
14:47:40.259   Training iter 350, batch loss 0.1741, batch acc 0.9488
14:47:40.771   Training iter 400, batch loss 0.1966, batch acc 0.9436
14:47:41.278   Training iter 450, batch loss 0.1958, batch acc 0.9476
14:47:41.783   Training iter 500, batch loss 0.1791, batch acc 0.9434
14:47:42.269   Training iter 550, batch loss 0.1960, batch acc 0.9406
14:47:42.724   Training iter 600, batch loss 0.2022, batch acc 0.9410
14:47:42.725 Training @ 53 epoch...
14:47:43.232   Training iter 50, batch loss 0.1762, batch acc 0.9524
14:47:43.721   Training iter 100, batch loss 0.1867, batch acc 0.9456
14:47:44.210   Training iter 150, batch loss 0.1847, batch acc 0.9458
14:47:44.712   Training iter 200, batch loss 0.1971, batch acc 0.9406
14:47:45.203   Training iter 250, batch loss 0.1851, batch acc 0.9460
14:47:45.707   Training iter 300, batch loss 0.1966, batch acc 0.9380
14:47:46.221   Training iter 350, batch loss 0.2123, batch acc 0.9380
14:47:46.729   Training iter 400, batch loss 0.1892, batch acc 0.9440
14:47:47.240   Training iter 450, batch loss 0.1812, batch acc 0.9490
14:47:47.749   Training iter 500, batch loss 0.1994, batch acc 0.9358
14:47:48.257   Training iter 550, batch loss 0.1833, batch acc 0.9458
14:47:48.772   Training iter 600, batch loss 0.1842, batch acc 0.9470
14:47:48.774 Training @ 54 epoch...
14:47:49.286   Training iter 50, batch loss 0.1958, batch acc 0.9442
14:47:49.827   Training iter 100, batch loss 0.1959, batch acc 0.9408
14:47:50.405   Training iter 150, batch loss 0.1751, batch acc 0.9498
14:47:50.982   Training iter 200, batch loss 0.2024, batch acc 0.9414
14:47:51.507   Training iter 250, batch loss 0.1906, batch acc 0.9436
14:47:51.971   Training iter 300, batch loss 0.1679, batch acc 0.9488
14:47:52.456   Training iter 350, batch loss 0.1917, batch acc 0.9422
14:47:52.964   Training iter 400, batch loss 0.1996, batch acc 0.9432
14:47:53.512   Training iter 450, batch loss 0.1876, batch acc 0.9494
14:47:54.056   Training iter 500, batch loss 0.1711, batch acc 0.9474
14:47:54.602   Training iter 550, batch loss 0.1946, batch acc 0.9404
14:47:55.136   Training iter 600, batch loss 0.1827, batch acc 0.9446
14:47:55.138 Training @ 55 epoch...
14:47:55.684   Training iter 50, batch loss 0.1763, batch acc 0.9514
14:47:56.232   Training iter 100, batch loss 0.1844, batch acc 0.9460
14:47:56.773   Training iter 150, batch loss 0.1871, batch acc 0.9444
14:47:57.325   Training iter 200, batch loss 0.1900, batch acc 0.9444
14:47:57.881   Training iter 250, batch loss 0.1906, batch acc 0.9456
14:47:58.438   Training iter 300, batch loss 0.1810, batch acc 0.9418
14:47:58.983   Training iter 350, batch loss 0.1827, batch acc 0.9440
14:47:59.521   Training iter 400, batch loss 0.1811, batch acc 0.9474
14:48:00.053   Training iter 450, batch loss 0.1932, batch acc 0.9410
14:48:00.587   Training iter 500, batch loss 0.1890, batch acc 0.9424
14:48:01.122   Training iter 550, batch loss 0.1989, batch acc 0.9422
14:48:01.679   Training iter 600, batch loss 0.2041, batch acc 0.9400
14:48:01.681 Testing @ 55 epoch...
14:48:01.725     Testing, total mean loss 0.21372, total acc 0.93720
14:48:01.725 Training @ 56 epoch...
14:48:02.294   Training iter 50, batch loss 0.1862, batch acc 0.9484
14:48:02.827   Training iter 100, batch loss 0.1890, batch acc 0.9442
14:48:03.392   Training iter 150, batch loss 0.1902, batch acc 0.9418
14:48:03.949   Training iter 200, batch loss 0.1918, batch acc 0.9440
14:48:04.506   Training iter 250, batch loss 0.1902, batch acc 0.9460
14:48:05.069   Training iter 300, batch loss 0.1761, batch acc 0.9458
14:48:05.599   Training iter 350, batch loss 0.2005, batch acc 0.9388
14:48:06.117   Training iter 400, batch loss 0.2047, batch acc 0.9394
14:48:06.684   Training iter 450, batch loss 0.1839, batch acc 0.9464
14:48:07.262   Training iter 500, batch loss 0.1860, batch acc 0.9454
14:48:07.798   Training iter 550, batch loss 0.1819, batch acc 0.9458
14:48:08.325   Training iter 600, batch loss 0.1912, batch acc 0.9452
14:48:08.326 Training @ 57 epoch...
14:48:08.842   Training iter 50, batch loss 0.1693, batch acc 0.9476
14:48:09.420   Training iter 100, batch loss 0.1914, batch acc 0.9454
14:48:09.968   Training iter 150, batch loss 0.1933, batch acc 0.9446
14:48:10.526   Training iter 200, batch loss 0.1655, batch acc 0.9494
14:48:11.099   Training iter 250, batch loss 0.1764, batch acc 0.9486
14:48:11.626   Training iter 300, batch loss 0.1753, batch acc 0.9490
14:48:12.154   Training iter 350, batch loss 0.1842, batch acc 0.9444
14:48:12.636   Training iter 400, batch loss 0.2101, batch acc 0.9378
14:48:13.143   Training iter 450, batch loss 0.1896, batch acc 0.9452
14:48:13.650   Training iter 500, batch loss 0.1986, batch acc 0.9394
14:48:14.128   Training iter 550, batch loss 0.1942, batch acc 0.9414
14:48:14.606   Training iter 600, batch loss 0.1975, batch acc 0.9464
14:48:14.608 Training @ 58 epoch...
14:48:15.143   Training iter 50, batch loss 0.1832, batch acc 0.9466
14:48:15.677   Training iter 100, batch loss 0.1784, batch acc 0.9456
14:48:16.210   Training iter 150, batch loss 0.1936, batch acc 0.9428
14:48:16.738   Training iter 200, batch loss 0.1998, batch acc 0.9412
14:48:17.249   Training iter 250, batch loss 0.1914, batch acc 0.9444
14:48:17.753   Training iter 300, batch loss 0.1901, batch acc 0.9460
14:48:18.260   Training iter 350, batch loss 0.1771, batch acc 0.9468
14:48:18.775   Training iter 400, batch loss 0.1959, batch acc 0.9428
14:48:19.300   Training iter 450, batch loss 0.1980, batch acc 0.9396
14:48:19.798   Training iter 500, batch loss 0.1802, batch acc 0.9416
14:48:20.301   Training iter 550, batch loss 0.1879, batch acc 0.9442
14:48:20.792   Training iter 600, batch loss 0.1884, batch acc 0.9426
14:48:20.794 Training @ 59 epoch...
14:48:21.306   Training iter 50, batch loss 0.1787, batch acc 0.9482
14:48:21.824   Training iter 100, batch loss 0.1795, batch acc 0.9468
14:48:22.357   Training iter 150, batch loss 0.1750, batch acc 0.9480
14:48:22.888   Training iter 200, batch loss 0.1940, batch acc 0.9448
14:48:23.417   Training iter 250, batch loss 0.1719, batch acc 0.9468
14:48:23.939   Training iter 300, batch loss 0.1655, batch acc 0.9506
14:48:24.476   Training iter 350, batch loss 0.1830, batch acc 0.9434
14:48:25.019   Training iter 400, batch loss 0.1965, batch acc 0.9414
14:48:25.613   Training iter 450, batch loss 0.2079, batch acc 0.9396
14:48:26.201   Training iter 500, batch loss 0.1852, batch acc 0.9420
14:48:26.778   Training iter 550, batch loss 0.2007, batch acc 0.9420
14:48:27.350   Training iter 600, batch loss 0.1851, batch acc 0.9478
14:48:27.351 Training @ 60 epoch...
14:48:27.933   Training iter 50, batch loss 0.1846, batch acc 0.9502
14:48:28.521   Training iter 100, batch loss 0.1814, batch acc 0.9458
14:48:29.082   Training iter 150, batch loss 0.1868, batch acc 0.9456
14:48:29.631   Training iter 200, batch loss 0.1753, batch acc 0.9476
14:48:30.168   Training iter 250, batch loss 0.1797, batch acc 0.9434
14:48:30.704   Training iter 300, batch loss 0.1702, batch acc 0.9516
14:48:31.204   Training iter 350, batch loss 0.1690, batch acc 0.9504
14:48:31.697   Training iter 400, batch loss 0.1946, batch acc 0.9392
14:48:32.190   Training iter 450, batch loss 0.1873, batch acc 0.9464
14:48:32.694   Training iter 500, batch loss 0.1856, batch acc 0.9482
14:48:33.245   Training iter 550, batch loss 0.2009, batch acc 0.9388
14:48:33.748   Training iter 600, batch loss 0.2119, batch acc 0.9400
14:48:33.749 Testing @ 60 epoch...
14:48:33.793     Testing, total mean loss 0.21194, total acc 0.93750
14:48:33.793 Training @ 61 epoch...
14:48:34.306   Training iter 50, batch loss 0.1731, batch acc 0.9494
14:48:34.840   Training iter 100, batch loss 0.1749, batch acc 0.9484
14:48:35.394   Training iter 150, batch loss 0.1960, batch acc 0.9434
14:48:35.929   Training iter 200, batch loss 0.1885, batch acc 0.9442
14:48:36.469   Training iter 250, batch loss 0.1727, batch acc 0.9442
14:48:36.984   Training iter 300, batch loss 0.1807, batch acc 0.9476
14:48:37.518   Training iter 350, batch loss 0.1830, batch acc 0.9498
14:48:38.056   Training iter 400, batch loss 0.1835, batch acc 0.9424
14:48:38.581   Training iter 450, batch loss 0.1731, batch acc 0.9464
14:48:39.109   Training iter 500, batch loss 0.2095, batch acc 0.9402
14:48:39.635   Training iter 550, batch loss 0.1836, batch acc 0.9436
14:48:40.165   Training iter 600, batch loss 0.1997, batch acc 0.9432
14:48:40.167 Training @ 62 epoch...
14:48:40.674   Training iter 50, batch loss 0.1785, batch acc 0.9450
14:48:41.180   Training iter 100, batch loss 0.1743, batch acc 0.9488
14:48:41.687   Training iter 150, batch loss 0.1968, batch acc 0.9404
14:48:42.198   Training iter 200, batch loss 0.1932, batch acc 0.9428
14:48:42.706   Training iter 250, batch loss 0.2077, batch acc 0.9384
14:48:43.228   Training iter 300, batch loss 0.1716, batch acc 0.9494
14:48:43.730   Training iter 350, batch loss 0.1660, batch acc 0.9504
14:48:44.241   Training iter 400, batch loss 0.1953, batch acc 0.9402
14:48:44.783   Training iter 450, batch loss 0.1818, batch acc 0.9428
14:48:45.326   Training iter 500, batch loss 0.1929, batch acc 0.9400
14:48:45.843   Training iter 550, batch loss 0.1826, batch acc 0.9430
14:48:46.370   Training iter 600, batch loss 0.1822, batch acc 0.9470
14:48:46.372 Training @ 63 epoch...
14:48:46.891   Training iter 50, batch loss 0.1809, batch acc 0.9432
14:48:47.395   Training iter 100, batch loss 0.1784, batch acc 0.9462
14:48:47.911   Training iter 150, batch loss 0.1729, batch acc 0.9492
14:48:48.425   Training iter 200, batch loss 0.1943, batch acc 0.9388
14:48:48.912   Training iter 250, batch loss 0.1874, batch acc 0.9444
14:48:49.411   Training iter 300, batch loss 0.1718, batch acc 0.9458
14:48:49.896   Training iter 350, batch loss 0.2046, batch acc 0.9410
14:48:50.390   Training iter 400, batch loss 0.1958, batch acc 0.9444
14:48:50.895   Training iter 450, batch loss 0.1767, batch acc 0.9484
14:48:51.434   Training iter 500, batch loss 0.1938, batch acc 0.9416
14:48:51.975   Training iter 550, batch loss 0.2039, batch acc 0.9382
14:48:52.534   Training iter 600, batch loss 0.1757, batch acc 0.9498
14:48:52.536 Training @ 64 epoch...
14:48:53.092   Training iter 50, batch loss 0.1765, batch acc 0.9454
14:48:53.601   Training iter 100, batch loss 0.1833, batch acc 0.9452
14:48:54.118   Training iter 150, batch loss 0.1766, batch acc 0.9494
14:48:54.661   Training iter 200, batch loss 0.1935, batch acc 0.9422
14:48:55.186   Training iter 250, batch loss 0.1767, batch acc 0.9462
14:48:55.701   Training iter 300, batch loss 0.1978, batch acc 0.9436
14:48:56.215   Training iter 350, batch loss 0.1942, batch acc 0.9486
14:48:56.731   Training iter 400, batch loss 0.1752, batch acc 0.9474
14:48:57.236   Training iter 450, batch loss 0.1906, batch acc 0.9450
14:48:57.759   Training iter 500, batch loss 0.1792, batch acc 0.9452
14:48:58.282   Training iter 550, batch loss 0.1878, batch acc 0.9436
14:48:58.794   Training iter 600, batch loss 0.1755, batch acc 0.9478
14:48:58.796 Training @ 65 epoch...
14:48:59.307   Training iter 50, batch loss 0.1890, batch acc 0.9428
14:48:59.818   Training iter 100, batch loss 0.1749, batch acc 0.9496
14:49:00.342   Training iter 150, batch loss 0.1698, batch acc 0.9512
14:49:00.859   Training iter 200, batch loss 0.1990, batch acc 0.9430
14:49:01.382   Training iter 250, batch loss 0.1729, batch acc 0.9486
14:49:01.917   Training iter 300, batch loss 0.1946, batch acc 0.9398
14:49:02.445   Training iter 350, batch loss 0.1741, batch acc 0.9474
14:49:02.957   Training iter 400, batch loss 0.1932, batch acc 0.9396
14:49:03.463   Training iter 450, batch loss 0.1990, batch acc 0.9408
14:49:03.966   Training iter 500, batch loss 0.1750, batch acc 0.9488
14:49:04.489   Training iter 550, batch loss 0.1821, batch acc 0.9456
14:49:05.017   Training iter 600, batch loss 0.1856, batch acc 0.9484
14:49:05.018 Testing @ 65 epoch...
14:49:05.062     Testing, total mean loss 0.21161, total acc 0.93760
14:49:05.062 Training @ 66 epoch...
14:49:05.596   Training iter 50, batch loss 0.1763, batch acc 0.9478
14:49:06.119   Training iter 100, batch loss 0.1729, batch acc 0.9490
14:49:06.636   Training iter 150, batch loss 0.2087, batch acc 0.9404
14:49:07.154   Training iter 200, batch loss 0.1785, batch acc 0.9476
14:49:07.659   Training iter 250, batch loss 0.1675, batch acc 0.9454
14:49:08.164   Training iter 300, batch loss 0.1910, batch acc 0.9454
14:49:08.677   Training iter 350, batch loss 0.1654, batch acc 0.9500
14:49:09.179   Training iter 400, batch loss 0.1846, batch acc 0.9476
14:49:09.685   Training iter 450, batch loss 0.1977, batch acc 0.9390
14:49:10.197   Training iter 500, batch loss 0.1868, batch acc 0.9442
14:49:10.695   Training iter 550, batch loss 0.1762, batch acc 0.9488
14:49:11.199   Training iter 600, batch loss 0.1953, batch acc 0.9458
14:49:11.200 Training @ 67 epoch...
14:49:11.708   Training iter 50, batch loss 0.1973, batch acc 0.9390
14:49:12.218   Training iter 100, batch loss 0.1810, batch acc 0.9450
14:49:12.728   Training iter 150, batch loss 0.1855, batch acc 0.9444
14:49:13.250   Training iter 200, batch loss 0.1853, batch acc 0.9486
14:49:13.768   Training iter 250, batch loss 0.1605, batch acc 0.9540
14:49:14.301   Training iter 300, batch loss 0.1757, batch acc 0.9494
14:49:14.825   Training iter 350, batch loss 0.1822, batch acc 0.9450
14:49:15.343   Training iter 400, batch loss 0.1837, batch acc 0.9468
14:49:15.891   Training iter 450, batch loss 0.1714, batch acc 0.9480
14:49:16.483   Training iter 500, batch loss 0.1802, batch acc 0.9466
14:49:17.062   Training iter 550, batch loss 0.2052, batch acc 0.9388
14:49:17.627   Training iter 600, batch loss 0.1823, batch acc 0.9462
14:49:17.629 Training @ 68 epoch...
14:49:18.150   Training iter 50, batch loss 0.1770, batch acc 0.9458
14:49:18.675   Training iter 100, batch loss 0.1893, batch acc 0.9444
14:49:19.206   Training iter 150, batch loss 0.1785, batch acc 0.9484
14:49:19.740   Training iter 200, batch loss 0.1654, batch acc 0.9482
14:49:20.278   Training iter 250, batch loss 0.1828, batch acc 0.9462
14:49:20.806   Training iter 300, batch loss 0.1793, batch acc 0.9454
14:49:21.320   Training iter 350, batch loss 0.1775, batch acc 0.9488
14:49:21.821   Training iter 400, batch loss 0.1720, batch acc 0.9462
14:49:22.334   Training iter 450, batch loss 0.1985, batch acc 0.9420
14:49:22.831   Training iter 500, batch loss 0.1860, batch acc 0.9448
14:49:23.324   Training iter 550, batch loss 0.1932, batch acc 0.9424
14:49:23.817   Training iter 600, batch loss 0.1852, batch acc 0.9442
14:49:23.819 Training @ 69 epoch...
14:49:24.311   Training iter 50, batch loss 0.1660, batch acc 0.9480
14:49:24.812   Training iter 100, batch loss 0.1800, batch acc 0.9452
14:49:25.314   Training iter 150, batch loss 0.1749, batch acc 0.9476
14:49:25.767   Training iter 200, batch loss 0.1862, batch acc 0.9490
14:49:26.242   Training iter 250, batch loss 0.1998, batch acc 0.9416
14:49:26.729   Training iter 300, batch loss 0.1894, batch acc 0.9444
14:49:27.270   Training iter 350, batch loss 0.1866, batch acc 0.9414
14:49:27.801   Training iter 400, batch loss 0.1743, batch acc 0.9476
14:49:28.309   Training iter 450, batch loss 0.1923, batch acc 0.9436
14:49:28.820   Training iter 500, batch loss 0.1757, batch acc 0.9462
14:49:29.362   Training iter 550, batch loss 0.1952, batch acc 0.9408
14:49:29.863   Training iter 600, batch loss 0.1649, batch acc 0.9498
14:49:29.865 Training @ 70 epoch...
14:49:30.406   Training iter 50, batch loss 0.1731, batch acc 0.9492
14:49:30.935   Training iter 100, batch loss 0.1913, batch acc 0.9404
14:49:31.420   Training iter 150, batch loss 0.1968, batch acc 0.9426
14:49:31.911   Training iter 200, batch loss 0.1735, batch acc 0.9466
14:49:32.398   Training iter 250, batch loss 0.1842, batch acc 0.9408
14:49:32.888   Training iter 300, batch loss 0.1597, batch acc 0.9512
14:49:33.401   Training iter 350, batch loss 0.2015, batch acc 0.9394
14:49:33.913   Training iter 400, batch loss 0.1780, batch acc 0.9446
14:49:34.421   Training iter 450, batch loss 0.1725, batch acc 0.9466
14:49:34.912   Training iter 500, batch loss 0.1882, batch acc 0.9482
14:49:35.414   Training iter 550, batch loss 0.2040, batch acc 0.9392
14:49:35.904   Training iter 600, batch loss 0.1810, batch acc 0.9484
14:49:35.906 Testing @ 70 epoch...
14:49:35.950     Testing, total mean loss 0.20569, total acc 0.93910
14:49:35.950 Training @ 71 epoch...
14:49:36.445   Training iter 50, batch loss 0.1654, batch acc 0.9480
14:49:36.934   Training iter 100, batch loss 0.2044, batch acc 0.9388
14:49:37.428   Training iter 150, batch loss 0.2036, batch acc 0.9390
14:49:37.918   Training iter 200, batch loss 0.1749, batch acc 0.9482
14:49:38.413   Training iter 250, batch loss 0.1843, batch acc 0.9464
14:49:38.911   Training iter 300, batch loss 0.1722, batch acc 0.9488
14:49:39.410   Training iter 350, batch loss 0.1705, batch acc 0.9496
14:49:39.904   Training iter 400, batch loss 0.1606, batch acc 0.9514
14:49:40.416   Training iter 450, batch loss 0.2010, batch acc 0.9410
14:49:40.911   Training iter 500, batch loss 0.1829, batch acc 0.9484
14:49:41.419   Training iter 550, batch loss 0.1758, batch acc 0.9500
14:49:41.913   Training iter 600, batch loss 0.1839, batch acc 0.9490
14:49:41.915 Training @ 72 epoch...
14:49:42.437   Training iter 50, batch loss 0.1772, batch acc 0.9444
14:49:42.950   Training iter 100, batch loss 0.1763, batch acc 0.9446
14:49:43.460   Training iter 150, batch loss 0.1822, batch acc 0.9444
14:49:43.962   Training iter 200, batch loss 0.1936, batch acc 0.9438
14:49:44.498   Training iter 250, batch loss 0.2006, batch acc 0.9418
14:49:45.040   Training iter 300, batch loss 0.1865, batch acc 0.9428
14:49:45.581   Training iter 350, batch loss 0.1797, batch acc 0.9456
14:49:46.129   Training iter 400, batch loss 0.1662, batch acc 0.9506
14:49:46.669   Training iter 450, batch loss 0.1941, batch acc 0.9424
14:49:47.205   Training iter 500, batch loss 0.1895, batch acc 0.9436
14:49:47.737   Training iter 550, batch loss 0.1649, batch acc 0.9536
14:49:48.275   Training iter 600, batch loss 0.1710, batch acc 0.9484
14:49:48.277 Training @ 73 epoch...
14:49:48.822   Training iter 50, batch loss 0.1645, batch acc 0.9480
14:49:49.378   Training iter 100, batch loss 0.1712, batch acc 0.9466
14:49:49.926   Training iter 150, batch loss 0.2181, batch acc 0.9356
14:49:50.461   Training iter 200, batch loss 0.1804, batch acc 0.9446
14:49:50.976   Training iter 250, batch loss 0.1896, batch acc 0.9426
14:49:51.499   Training iter 300, batch loss 0.1685, batch acc 0.9504
14:49:52.034   Training iter 350, batch loss 0.1765, batch acc 0.9486
14:49:52.562   Training iter 400, batch loss 0.1836, batch acc 0.9472
14:49:53.073   Training iter 450, batch loss 0.1813, batch acc 0.9484
14:49:53.571   Training iter 500, batch loss 0.1884, batch acc 0.9432
14:49:54.073   Training iter 550, batch loss 0.1686, batch acc 0.9516
14:49:54.571   Training iter 600, batch loss 0.1820, batch acc 0.9458
14:49:54.572 Training @ 74 epoch...
14:49:55.087   Training iter 50, batch loss 0.1836, batch acc 0.9450
14:49:55.591   Training iter 100, batch loss 0.1706, batch acc 0.9512
14:49:56.096   Training iter 150, batch loss 0.1690, batch acc 0.9476
14:49:56.601   Training iter 200, batch loss 0.1826, batch acc 0.9472
14:49:57.101   Training iter 250, batch loss 0.1932, batch acc 0.9422
14:49:57.605   Training iter 300, batch loss 0.1823, batch acc 0.9438
14:49:58.112   Training iter 350, batch loss 0.1779, batch acc 0.9436
14:49:58.624   Training iter 400, batch loss 0.1801, batch acc 0.9450
14:49:59.138   Training iter 450, batch loss 0.1824, batch acc 0.9476
14:49:59.661   Training iter 500, batch loss 0.1696, batch acc 0.9482
14:50:00.202   Training iter 550, batch loss 0.1917, batch acc 0.9436
14:50:00.765   Training iter 600, batch loss 0.1917, batch acc 0.9452
14:50:00.766 Training @ 75 epoch...
14:50:01.331   Training iter 50, batch loss 0.1687, batch acc 0.9490
14:50:01.916   Training iter 100, batch loss 0.1935, batch acc 0.9428
14:50:02.452   Training iter 150, batch loss 0.1828, batch acc 0.9442
14:50:02.975   Training iter 200, batch loss 0.1878, batch acc 0.9416
14:50:03.528   Training iter 250, batch loss 0.1725, batch acc 0.9496
14:50:04.077   Training iter 300, batch loss 0.1802, batch acc 0.9470
14:50:04.634   Training iter 350, batch loss 0.1687, batch acc 0.9480
14:50:05.194   Training iter 400, batch loss 0.2031, batch acc 0.9384
14:50:05.757   Training iter 450, batch loss 0.1816, batch acc 0.9440
14:50:06.318   Training iter 500, batch loss 0.1669, batch acc 0.9504
14:50:06.863   Training iter 550, batch loss 0.1893, batch acc 0.9434
14:50:07.425   Training iter 600, batch loss 0.1795, batch acc 0.9508
14:50:07.426 Testing @ 75 epoch...
14:50:07.473     Testing, total mean loss 0.21227, total acc 0.93770
14:50:07.473 Training @ 76 epoch...
14:50:08.036   Training iter 50, batch loss 0.1683, batch acc 0.9470
14:50:08.600   Training iter 100, batch loss 0.1951, batch acc 0.9414
14:50:09.144   Training iter 150, batch loss 0.1683, batch acc 0.9496
14:50:09.688   Training iter 200, batch loss 0.1691, batch acc 0.9532
14:50:10.251   Training iter 250, batch loss 0.1874, batch acc 0.9444
14:50:10.781   Training iter 300, batch loss 0.1832, batch acc 0.9454
14:50:11.281   Training iter 350, batch loss 0.1701, batch acc 0.9486
14:50:11.758   Training iter 400, batch loss 0.1787, batch acc 0.9452
14:50:12.240   Training iter 450, batch loss 0.1584, batch acc 0.9532
14:50:12.794   Training iter 500, batch loss 0.1869, batch acc 0.9422
14:50:13.364   Training iter 550, batch loss 0.2130, batch acc 0.9402
14:50:13.934   Training iter 600, batch loss 0.1792, batch acc 0.9484
14:50:13.936 Training @ 77 epoch...
14:50:14.429   Training iter 50, batch loss 0.1815, batch acc 0.9430
14:50:14.903   Training iter 100, batch loss 0.1773, batch acc 0.9472
14:50:15.405   Training iter 150, batch loss 0.1880, batch acc 0.9440
14:50:15.910   Training iter 200, batch loss 0.1984, batch acc 0.9430
14:50:16.431   Training iter 250, batch loss 0.1754, batch acc 0.9512
14:50:16.970   Training iter 300, batch loss 0.1880, batch acc 0.9418
14:50:17.488   Training iter 350, batch loss 0.1732, batch acc 0.9510
14:50:17.992   Training iter 400, batch loss 0.1624, batch acc 0.9520
14:50:18.500   Training iter 450, batch loss 0.1796, batch acc 0.9450
14:50:19.009   Training iter 500, batch loss 0.1945, batch acc 0.9436
14:50:19.506   Training iter 550, batch loss 0.1740, batch acc 0.9474
14:50:20.004   Training iter 600, batch loss 0.1782, batch acc 0.9434
14:50:20.006 Training @ 78 epoch...
14:50:20.539   Training iter 50, batch loss 0.1754, batch acc 0.9480
14:50:21.086   Training iter 100, batch loss 0.1726, batch acc 0.9486
14:50:21.624   Training iter 150, batch loss 0.1727, batch acc 0.9478
14:50:22.212   Training iter 200, batch loss 0.1753, batch acc 0.9462
14:50:22.752   Training iter 250, batch loss 0.1799, batch acc 0.9470
14:50:23.289   Training iter 300, batch loss 0.1655, batch acc 0.9534
14:50:23.774   Training iter 350, batch loss 0.2022, batch acc 0.9420
14:50:24.254   Training iter 400, batch loss 0.1912, batch acc 0.9428
14:50:24.753   Training iter 450, batch loss 0.1785, batch acc 0.9468
14:50:25.263   Training iter 500, batch loss 0.1907, batch acc 0.9414
14:50:25.766   Training iter 550, batch loss 0.1626, batch acc 0.9518
14:50:26.265   Training iter 600, batch loss 0.1934, batch acc 0.9390
14:50:26.267 Training @ 79 epoch...
14:50:26.780   Training iter 50, batch loss 0.1895, batch acc 0.9414
14:50:27.342   Training iter 100, batch loss 0.1557, batch acc 0.9528
14:50:27.929   Training iter 150, batch loss 0.1621, batch acc 0.9536
14:50:28.502   Training iter 200, batch loss 0.1907, batch acc 0.9424
14:50:29.069   Training iter 250, batch loss 0.1736, batch acc 0.9478
14:50:29.618   Training iter 300, batch loss 0.1984, batch acc 0.9404
14:50:30.168   Training iter 350, batch loss 0.1781, batch acc 0.9492
14:50:30.754   Training iter 400, batch loss 0.1936, batch acc 0.9458
14:50:31.310   Training iter 450, batch loss 0.1749, batch acc 0.9468
14:50:31.859   Training iter 500, batch loss 0.1798, batch acc 0.9438
14:50:32.383   Training iter 550, batch loss 0.1760, batch acc 0.9468
14:50:32.895   Training iter 600, batch loss 0.1792, batch acc 0.9484
14:50:32.897 Training @ 80 epoch...
14:50:33.429   Training iter 50, batch loss 0.1745, batch acc 0.9484
14:50:33.946   Training iter 100, batch loss 0.1753, batch acc 0.9482
14:50:34.462   Training iter 150, batch loss 0.1859, batch acc 0.9454
14:50:34.982   Training iter 200, batch loss 0.1941, batch acc 0.9416
14:50:35.506   Training iter 250, batch loss 0.1816, batch acc 0.9462
14:50:36.025   Training iter 300, batch loss 0.1690, batch acc 0.9492
14:50:36.534   Training iter 350, batch loss 0.1679, batch acc 0.9512
14:50:37.055   Training iter 400, batch loss 0.1810, batch acc 0.9458
14:50:37.591   Training iter 450, batch loss 0.1605, batch acc 0.9536
14:50:38.111   Training iter 500, batch loss 0.1985, batch acc 0.9446
14:50:38.618   Training iter 550, batch loss 0.1842, batch acc 0.9424
14:50:39.120   Training iter 600, batch loss 0.1839, batch acc 0.9460
14:50:39.122 Testing @ 80 epoch...
14:50:39.166     Testing, total mean loss 0.21365, total acc 0.93710
14:50:39.166 Training @ 81 epoch...
14:50:39.683   Training iter 50, batch loss 0.1678, batch acc 0.9482
14:50:40.198   Training iter 100, batch loss 0.1723, batch acc 0.9492
14:50:40.716   Training iter 150, batch loss 0.1739, batch acc 0.9518
14:50:41.223   Training iter 200, batch loss 0.1743, batch acc 0.9494
14:50:41.712   Training iter 250, batch loss 0.1944, batch acc 0.9406
14:50:42.220   Training iter 300, batch loss 0.1718, batch acc 0.9478
14:50:42.720   Training iter 350, batch loss 0.1713, batch acc 0.9474
14:50:43.205   Training iter 400, batch loss 0.1730, batch acc 0.9496
14:50:43.673   Training iter 450, batch loss 0.1815, batch acc 0.9508
14:50:44.136   Training iter 500, batch loss 0.1913, batch acc 0.9446
14:50:44.601   Training iter 550, batch loss 0.1814, batch acc 0.9464
14:50:45.072   Training iter 600, batch loss 0.1787, batch acc 0.9446
14:50:45.074 Training @ 82 epoch...
14:50:45.557   Training iter 50, batch loss 0.1655, batch acc 0.9470
14:50:46.024   Training iter 100, batch loss 0.1710, batch acc 0.9498
14:50:46.483   Training iter 150, batch loss 0.1696, batch acc 0.9484
14:50:46.947   Training iter 200, batch loss 0.1723, batch acc 0.9462
14:50:47.424   Training iter 250, batch loss 0.1817, batch acc 0.9464
14:50:47.884   Training iter 300, batch loss 0.1869, batch acc 0.9460
14:50:48.364   Training iter 350, batch loss 0.1769, batch acc 0.9450
14:50:48.825   Training iter 400, batch loss 0.1760, batch acc 0.9462
14:50:49.304   Training iter 450, batch loss 0.1899, batch acc 0.9428
14:50:49.779   Training iter 500, batch loss 0.1869, batch acc 0.9460
14:50:50.298   Training iter 550, batch loss 0.2000, batch acc 0.9416
14:50:50.814   Training iter 600, batch loss 0.1826, batch acc 0.9472
14:50:50.815 Training @ 83 epoch...
14:50:51.314   Training iter 50, batch loss 0.1722, batch acc 0.9490
14:50:51.798   Training iter 100, batch loss 0.1753, batch acc 0.9504
14:50:52.306   Training iter 150, batch loss 0.1841, batch acc 0.9452
14:50:52.830   Training iter 200, batch loss 0.1874, batch acc 0.9458
14:50:53.345   Training iter 250, batch loss 0.1867, batch acc 0.9414
14:50:53.854   Training iter 300, batch loss 0.1654, batch acc 0.9482
14:50:54.363   Training iter 350, batch loss 0.1731, batch acc 0.9494
14:50:54.895   Training iter 400, batch loss 0.1648, batch acc 0.9488
14:50:55.427   Training iter 450, batch loss 0.1728, batch acc 0.9478
14:50:55.952   Training iter 500, batch loss 0.1734, batch acc 0.9504
14:50:56.488   Training iter 550, batch loss 0.1929, batch acc 0.9388
14:50:57.025   Training iter 600, batch loss 0.1867, batch acc 0.9444
14:50:57.027 Training @ 84 epoch...
14:50:57.585   Training iter 50, batch loss 0.1559, batch acc 0.9504
14:50:58.105   Training iter 100, batch loss 0.1638, batch acc 0.9526
14:50:58.634   Training iter 150, batch loss 0.1602, batch acc 0.9522
14:50:59.159   Training iter 200, batch loss 0.1688, batch acc 0.9488
14:50:59.689   Training iter 250, batch loss 0.2056, batch acc 0.9430
14:51:00.262   Training iter 300, batch loss 0.1912, batch acc 0.9420
14:51:00.819   Training iter 350, batch loss 0.1875, batch acc 0.9460
14:51:01.393   Training iter 400, batch loss 0.1874, batch acc 0.9434
14:51:01.964   Training iter 450, batch loss 0.1778, batch acc 0.9452
14:51:02.523   Training iter 500, batch loss 0.1774, batch acc 0.9498
14:51:03.073   Training iter 550, batch loss 0.1873, batch acc 0.9428
14:51:03.640   Training iter 600, batch loss 0.1872, batch acc 0.9470
14:51:03.642 Training @ 85 epoch...
14:51:04.194   Training iter 50, batch loss 0.1737, batch acc 0.9502
14:51:04.723   Training iter 100, batch loss 0.1933, batch acc 0.9458
14:51:05.271   Training iter 150, batch loss 0.1934, batch acc 0.9416
14:51:05.846   Training iter 200, batch loss 0.1890, batch acc 0.9418
14:51:06.394   Training iter 250, batch loss 0.1865, batch acc 0.9422
14:51:06.934   Training iter 300, batch loss 0.1752, batch acc 0.9482
14:51:07.495   Training iter 350, batch loss 0.1760, batch acc 0.9428
14:51:08.033   Training iter 400, batch loss 0.1857, batch acc 0.9436
14:51:08.522   Training iter 450, batch loss 0.1711, batch acc 0.9474
14:51:09.007   Training iter 500, batch loss 0.1682, batch acc 0.9486
14:51:09.526   Training iter 550, batch loss 0.1662, batch acc 0.9508
14:51:10.051   Training iter 600, batch loss 0.1841, batch acc 0.9446
14:51:10.053 Testing @ 85 epoch...
14:51:10.097     Testing, total mean loss 0.24358, total acc 0.93000
14:51:10.097 Training @ 86 epoch...
14:51:10.629   Training iter 50, batch loss 0.1722, batch acc 0.9468
14:51:11.166   Training iter 100, batch loss 0.1842, batch acc 0.9476
14:51:11.713   Training iter 150, batch loss 0.1818, batch acc 0.9456
14:51:12.219   Training iter 200, batch loss 0.1751, batch acc 0.9434
14:51:12.691   Training iter 250, batch loss 0.1742, batch acc 0.9462
14:51:13.186   Training iter 300, batch loss 0.1808, batch acc 0.9448
14:51:13.668   Training iter 350, batch loss 0.1808, batch acc 0.9466
14:51:14.151   Training iter 400, batch loss 0.1649, batch acc 0.9508
14:51:14.707   Training iter 450, batch loss 0.1930, batch acc 0.9440
14:51:15.208   Training iter 500, batch loss 0.1773, batch acc 0.9432
14:51:15.681   Training iter 550, batch loss 0.1804, batch acc 0.9456
14:51:16.185   Training iter 600, batch loss 0.1686, batch acc 0.9526
14:51:16.187 Training @ 87 epoch...
14:51:16.688   Training iter 50, batch loss 0.1860, batch acc 0.9472
14:51:17.196   Training iter 100, batch loss 0.1729, batch acc 0.9502
14:51:17.736   Training iter 150, batch loss 0.1818, batch acc 0.9486
14:51:18.267   Training iter 200, batch loss 0.1756, batch acc 0.9492
14:51:18.802   Training iter 250, batch loss 0.1684, batch acc 0.9474
14:51:19.324   Training iter 300, batch loss 0.1674, batch acc 0.9488
14:51:19.844   Training iter 350, batch loss 0.1774, batch acc 0.9478
14:51:20.368   Training iter 400, batch loss 0.1762, batch acc 0.9456
14:51:21.013   Training iter 450, batch loss 0.1886, batch acc 0.9436
14:51:21.587   Training iter 500, batch loss 0.1897, batch acc 0.9416
14:51:22.143   Training iter 550, batch loss 0.1761, batch acc 0.9476
14:51:22.703   Training iter 600, batch loss 0.1817, batch acc 0.9484
14:51:22.705 Training @ 88 epoch...
14:51:23.311   Training iter 50, batch loss 0.1606, batch acc 0.9522
14:51:23.901   Training iter 100, batch loss 0.1587, batch acc 0.9524
14:51:24.503   Training iter 150, batch loss 0.1887, batch acc 0.9446
14:51:25.099   Training iter 200, batch loss 0.1773, batch acc 0.9474
14:51:25.642   Training iter 250, batch loss 0.1734, batch acc 0.9504
14:51:26.174   Training iter 300, batch loss 0.1856, batch acc 0.9470
14:51:26.659   Training iter 350, batch loss 0.1905, batch acc 0.9400
14:51:27.177   Training iter 400, batch loss 0.1625, batch acc 0.9486
14:51:27.718   Training iter 450, batch loss 0.1769, batch acc 0.9446
14:51:28.272   Training iter 500, batch loss 0.1780, batch acc 0.9468
14:51:28.806   Training iter 550, batch loss 0.1832, batch acc 0.9428
14:51:29.346   Training iter 600, batch loss 0.2035, batch acc 0.9416
14:51:29.348 Training @ 89 epoch...
14:51:29.881   Training iter 50, batch loss 0.1779, batch acc 0.9470
14:51:30.413   Training iter 100, batch loss 0.1760, batch acc 0.9492
14:51:30.935   Training iter 150, batch loss 0.1718, batch acc 0.9502
14:51:31.469   Training iter 200, batch loss 0.1669, batch acc 0.9480
14:51:31.988   Training iter 250, batch loss 0.2114, batch acc 0.9372
14:51:32.512   Training iter 300, batch loss 0.1634, batch acc 0.9520
14:51:33.040   Training iter 350, batch loss 0.1755, batch acc 0.9438
14:51:33.563   Training iter 400, batch loss 0.1752, batch acc 0.9480
14:51:34.071   Training iter 450, batch loss 0.1770, batch acc 0.9476
14:51:34.592   Training iter 500, batch loss 0.1907, batch acc 0.9464
14:51:35.110   Training iter 550, batch loss 0.1739, batch acc 0.9434
14:51:35.605   Training iter 600, batch loss 0.1649, batch acc 0.9532
14:51:35.606 Training @ 90 epoch...
14:51:36.111   Training iter 50, batch loss 0.1554, batch acc 0.9524
14:51:36.641   Training iter 100, batch loss 0.1540, batch acc 0.9506
14:51:37.182   Training iter 150, batch loss 0.1688, batch acc 0.9526
14:51:37.730   Training iter 200, batch loss 0.1800, batch acc 0.9460
14:51:38.266   Training iter 250, batch loss 0.1767, batch acc 0.9452
14:51:38.777   Training iter 300, batch loss 0.1797, batch acc 0.9432
14:51:39.303   Training iter 350, batch loss 0.1754, batch acc 0.9494
14:51:39.835   Training iter 400, batch loss 0.1678, batch acc 0.9500
14:51:40.367   Training iter 450, batch loss 0.1979, batch acc 0.9446
14:51:40.888   Training iter 500, batch loss 0.1721, batch acc 0.9454
14:51:41.415   Training iter 550, batch loss 0.2015, batch acc 0.9418
14:51:41.944   Training iter 600, batch loss 0.1873, batch acc 0.9422
14:51:41.946 Testing @ 90 epoch...
14:51:41.990     Testing, total mean loss 0.23352, total acc 0.93260
14:51:41.990 Training @ 91 epoch...
14:51:42.533   Training iter 50, batch loss 0.1957, batch acc 0.9432
14:51:43.036   Training iter 100, batch loss 0.1678, batch acc 0.9500
14:51:43.537   Training iter 150, batch loss 0.1788, batch acc 0.9474
14:51:44.038   Training iter 200, batch loss 0.1817, batch acc 0.9444
14:51:44.541   Training iter 250, batch loss 0.1619, batch acc 0.9556
14:51:45.052   Training iter 300, batch loss 0.1692, batch acc 0.9446
14:51:45.555   Training iter 350, batch loss 0.1784, batch acc 0.9460
14:51:46.050   Training iter 400, batch loss 0.1815, batch acc 0.9454
14:51:46.543   Training iter 450, batch loss 0.1866, batch acc 0.9436
14:51:47.045   Training iter 500, batch loss 0.1793, batch acc 0.9444
14:51:47.559   Training iter 550, batch loss 0.1716, batch acc 0.9460
14:51:48.043   Training iter 600, batch loss 0.1831, batch acc 0.9480
14:51:48.044 Training @ 92 epoch...
14:51:48.514   Training iter 50, batch loss 0.1917, batch acc 0.9424
14:51:48.979   Training iter 100, batch loss 0.1553, batch acc 0.9508
14:51:49.462   Training iter 150, batch loss 0.1762, batch acc 0.9428
14:51:49.959   Training iter 200, batch loss 0.1781, batch acc 0.9482
14:51:50.461   Training iter 250, batch loss 0.1738, batch acc 0.9508
14:51:50.953   Training iter 300, batch loss 0.1804, batch acc 0.9466
14:51:51.469   Training iter 350, batch loss 0.1803, batch acc 0.9482
14:51:51.953   Training iter 400, batch loss 0.1685, batch acc 0.9450
14:51:52.459   Training iter 450, batch loss 0.1926, batch acc 0.9452
14:51:52.951   Training iter 500, batch loss 0.1635, batch acc 0.9484
14:51:53.471   Training iter 550, batch loss 0.1750, batch acc 0.9480
14:51:53.960   Training iter 600, batch loss 0.1855, batch acc 0.9454
14:51:53.962 Training @ 93 epoch...
14:51:54.475   Training iter 50, batch loss 0.1730, batch acc 0.9500
14:51:54.999   Training iter 100, batch loss 0.1771, batch acc 0.9450
14:51:55.521   Training iter 150, batch loss 0.1756, batch acc 0.9466
14:51:56.029   Training iter 200, batch loss 0.1892, batch acc 0.9418
14:51:56.530   Training iter 250, batch loss 0.1727, batch acc 0.9482
14:51:57.028   Training iter 300, batch loss 0.1646, batch acc 0.9522
14:51:57.557   Training iter 350, batch loss 0.1622, batch acc 0.9524
14:51:58.068   Training iter 400, batch loss 0.1753, batch acc 0.9440
14:51:58.545   Training iter 450, batch loss 0.1830, batch acc 0.9472
14:51:59.012   Training iter 500, batch loss 0.1986, batch acc 0.9404
14:51:59.494   Training iter 550, batch loss 0.1944, batch acc 0.9408
14:51:59.983   Training iter 600, batch loss 0.1701, batch acc 0.9504
14:51:59.985 Training @ 94 epoch...
14:52:00.533   Training iter 50, batch loss 0.1701, batch acc 0.9482
14:52:01.086   Training iter 100, batch loss 0.1779, batch acc 0.9484
14:52:01.673   Training iter 150, batch loss 0.1841, batch acc 0.9422
14:52:02.267   Training iter 200, batch loss 0.1776, batch acc 0.9474
14:52:02.844   Training iter 250, batch loss 0.1666, batch acc 0.9496
14:52:03.399   Training iter 300, batch loss 0.1734, batch acc 0.9516
14:52:03.974   Training iter 350, batch loss 0.1859, batch acc 0.9426
14:52:04.549   Training iter 400, batch loss 0.1764, batch acc 0.9476
14:52:05.116   Training iter 450, batch loss 0.1807, batch acc 0.9444
14:52:05.705   Training iter 500, batch loss 0.1665, batch acc 0.9520
14:52:06.285   Training iter 550, batch loss 0.1871, batch acc 0.9474
14:52:06.790   Training iter 600, batch loss 0.1744, batch acc 0.9498
14:52:06.792 Training @ 95 epoch...
14:52:07.279   Training iter 50, batch loss 0.1889, batch acc 0.9458
14:52:07.783   Training iter 100, batch loss 0.1580, batch acc 0.9536
14:52:08.282   Training iter 150, batch loss 0.1955, batch acc 0.9406
14:52:08.793   Training iter 200, batch loss 0.1797, batch acc 0.9460
14:52:09.311   Training iter 250, batch loss 0.1752, batch acc 0.9424
14:52:09.837   Training iter 300, batch loss 0.1655, batch acc 0.9502
14:52:10.382   Training iter 350, batch loss 0.1647, batch acc 0.9524
14:52:10.925   Training iter 400, batch loss 0.1739, batch acc 0.9462
14:52:11.460   Training iter 450, batch loss 0.1732, batch acc 0.9504
14:52:11.984   Training iter 500, batch loss 0.1940, batch acc 0.9426
14:52:12.527   Training iter 550, batch loss 0.1645, batch acc 0.9502
14:52:13.055   Training iter 600, batch loss 0.1733, batch acc 0.9492
14:52:13.057 Testing @ 95 epoch...
14:52:13.102     Testing, total mean loss 0.21393, total acc 0.93650
14:52:13.102 Training @ 96 epoch...
14:52:13.623   Training iter 50, batch loss 0.1628, batch acc 0.9528
14:52:14.153   Training iter 100, batch loss 0.1559, batch acc 0.9558
14:52:14.703   Training iter 150, batch loss 0.1799, batch acc 0.9458
14:52:15.257   Training iter 200, batch loss 0.1719, batch acc 0.9498
14:52:15.820   Training iter 250, batch loss 0.1829, batch acc 0.9454
14:52:16.368   Training iter 300, batch loss 0.1816, batch acc 0.9410
14:52:16.921   Training iter 350, batch loss 0.1678, batch acc 0.9468
14:52:17.478   Training iter 400, batch loss 0.1764, batch acc 0.9474
14:52:18.031   Training iter 450, batch loss 0.1613, batch acc 0.9480
14:52:18.575   Training iter 500, batch loss 0.1965, batch acc 0.9416
14:52:19.135   Training iter 550, batch loss 0.1789, batch acc 0.9458
14:52:19.690   Training iter 600, batch loss 0.1896, batch acc 0.9450
14:52:19.692 Training @ 97 epoch...
14:52:20.266   Training iter 50, batch loss 0.1739, batch acc 0.9478
14:52:20.816   Training iter 100, batch loss 0.1899, batch acc 0.9448
14:52:21.362   Training iter 150, batch loss 0.1631, batch acc 0.9502
14:52:21.923   Training iter 200, batch loss 0.1803, batch acc 0.9510
14:52:22.493   Training iter 250, batch loss 0.1946, batch acc 0.9414
14:52:23.075   Training iter 300, batch loss 0.1836, batch acc 0.9418
14:52:23.645   Training iter 350, batch loss 0.1745, batch acc 0.9472
14:52:24.213   Training iter 400, batch loss 0.1889, batch acc 0.9454
14:52:24.787   Training iter 450, batch loss 0.1752, batch acc 0.9488
14:52:25.368   Training iter 500, batch loss 0.1559, batch acc 0.9514
14:52:25.936   Training iter 550, batch loss 0.1667, batch acc 0.9516
14:52:26.507   Training iter 600, batch loss 0.1708, batch acc 0.9464
14:52:26.509 Training @ 98 epoch...
14:52:27.055   Training iter 50, batch loss 0.1551, batch acc 0.9560
14:52:27.662   Training iter 100, batch loss 0.1642, batch acc 0.9474
14:52:28.263   Training iter 150, batch loss 0.1574, batch acc 0.9520
14:52:28.826   Training iter 200, batch loss 0.1947, batch acc 0.9444
14:52:29.390   Training iter 250, batch loss 0.1845, batch acc 0.9468
14:52:29.954   Training iter 300, batch loss 0.1825, batch acc 0.9482
14:52:30.535   Training iter 350, batch loss 0.1723, batch acc 0.9480
14:52:31.127   Training iter 400, batch loss 0.1700, batch acc 0.9488
14:52:31.684   Training iter 450, batch loss 0.1670, batch acc 0.9510
14:52:32.199   Training iter 500, batch loss 0.1872, batch acc 0.9428
14:52:32.773   Training iter 550, batch loss 0.1802, batch acc 0.9482
14:52:33.327   Training iter 600, batch loss 0.1883, batch acc 0.9444
14:52:33.328 Training @ 99 epoch...
14:52:33.849   Training iter 50, batch loss 0.1718, batch acc 0.9486
14:52:34.363   Training iter 100, batch loss 0.1785, batch acc 0.9454
14:52:34.876   Training iter 150, batch loss 0.1904, batch acc 0.9442
14:52:35.368   Training iter 200, batch loss 0.1853, batch acc 0.9456
14:52:35.863   Training iter 250, batch loss 0.1773, batch acc 0.9460
14:52:36.348   Training iter 300, batch loss 0.1635, batch acc 0.9514
14:52:36.845   Training iter 350, batch loss 0.1823, batch acc 0.9514
14:52:37.373   Training iter 400, batch loss 0.1661, batch acc 0.9496
14:52:37.911   Training iter 450, batch loss 0.1709, batch acc 0.9466
14:52:38.444   Training iter 500, batch loss 0.1744, batch acc 0.9498
14:52:38.989   Training iter 550, batch loss 0.1774, batch acc 0.9456
14:52:39.532   Training iter 600, batch loss 0.1769, batch acc 0.9468
14:52:39.534 Training @ 100 epoch...
14:52:40.083   Training iter 50, batch loss 0.1603, batch acc 0.9510
14:52:40.642   Training iter 100, batch loss 0.1716, batch acc 0.9450
14:52:41.197   Training iter 150, batch loss 0.1656, batch acc 0.9502
14:52:41.741   Training iter 200, batch loss 0.1871, batch acc 0.9458
14:52:42.267   Training iter 250, batch loss 0.1788, batch acc 0.9468
14:52:42.796   Training iter 300, batch loss 0.1603, batch acc 0.9540
14:52:43.323   Training iter 350, batch loss 0.1740, batch acc 0.9464
14:52:43.845   Training iter 400, batch loss 0.1790, batch acc 0.9486
14:52:44.377   Training iter 450, batch loss 0.2016, batch acc 0.9390
14:52:44.913   Training iter 500, batch loss 0.1780, batch acc 0.9462
14:52:45.446   Training iter 550, batch loss 0.1597, batch acc 0.9530
14:52:45.973   Training iter 600, batch loss 0.1721, batch acc 0.9496
14:52:45.975 Testing @ 100 epoch...
14:52:46.023     Testing, total mean loss 0.21683, total acc 0.93640
14:52:46.023 Plot @ 100 epoch...
14:52:46.023 Training @ 101 epoch...
14:52:46.503   Training iter 50, batch loss 0.1736, batch acc 0.9468
14:52:46.971   Training iter 100, batch loss 0.1631, batch acc 0.9522
14:52:47.447   Training iter 150, batch loss 0.1778, batch acc 0.9486
14:52:47.906   Training iter 200, batch loss 0.1865, batch acc 0.9450
14:52:48.367   Training iter 250, batch loss 0.1827, batch acc 0.9494
14:52:48.832   Training iter 300, batch loss 0.1736, batch acc 0.9444
14:52:49.318   Training iter 350, batch loss 0.1738, batch acc 0.9466
14:52:49.836   Training iter 400, batch loss 0.1678, batch acc 0.9458
14:52:50.342   Training iter 450, batch loss 0.1672, batch acc 0.9492
14:52:50.850   Training iter 500, batch loss 0.1828, batch acc 0.9444
14:52:51.353   Training iter 550, batch loss 0.1719, batch acc 0.9474
14:52:51.855   Training iter 600, batch loss 0.1819, batch acc 0.9482
14:52:51.857 Training @ 102 epoch...
14:52:52.399   Training iter 50, batch loss 0.1694, batch acc 0.9490
14:52:52.936   Training iter 100, batch loss 0.1560, batch acc 0.9532
14:52:53.483   Training iter 150, batch loss 0.1775, batch acc 0.9476
14:52:54.025   Training iter 200, batch loss 0.1587, batch acc 0.9514
14:52:54.569   Training iter 250, batch loss 0.1775, batch acc 0.9480
14:52:55.101   Training iter 300, batch loss 0.1677, batch acc 0.9494
14:52:55.707   Training iter 350, batch loss 0.1888, batch acc 0.9458
14:52:56.317   Training iter 400, batch loss 0.1700, batch acc 0.9496
14:52:56.921   Training iter 450, batch loss 0.1930, batch acc 0.9440
14:52:57.456   Training iter 500, batch loss 0.1760, batch acc 0.9474
14:52:57.978   Training iter 550, batch loss 0.2009, batch acc 0.9414
14:52:58.499   Training iter 600, batch loss 0.1671, batch acc 0.9494
14:52:58.501 Training @ 103 epoch...
14:52:59.040   Training iter 50, batch loss 0.1527, batch acc 0.9530
14:52:59.565   Training iter 100, batch loss 0.1664, batch acc 0.9480
14:53:00.096   Training iter 150, batch loss 0.1814, batch acc 0.9442
14:53:00.613   Training iter 200, batch loss 0.1692, batch acc 0.9502
14:53:01.136   Training iter 250, batch loss 0.1777, batch acc 0.9460
14:53:01.693   Training iter 300, batch loss 0.1741, batch acc 0.9510
14:53:02.250   Training iter 350, batch loss 0.1836, batch acc 0.9472
14:53:02.793   Training iter 400, batch loss 0.1632, batch acc 0.9514
14:53:03.320   Training iter 450, batch loss 0.1613, batch acc 0.9550
14:53:03.854   Training iter 500, batch loss 0.1955, batch acc 0.9418
14:53:04.379   Training iter 550, batch loss 0.1948, batch acc 0.9404
14:53:04.914   Training iter 600, batch loss 0.1764, batch acc 0.9452
14:53:04.916 Training @ 104 epoch...
14:53:05.476   Training iter 50, batch loss 0.1563, batch acc 0.9502
14:53:06.038   Training iter 100, batch loss 0.1794, batch acc 0.9474
14:53:06.584   Training iter 150, batch loss 0.1655, batch acc 0.9502
14:53:07.115   Training iter 200, batch loss 0.1668, batch acc 0.9508
14:53:07.643   Training iter 250, batch loss 0.1670, batch acc 0.9510
14:53:08.145   Training iter 300, batch loss 0.1795, batch acc 0.9480
14:53:08.640   Training iter 350, batch loss 0.1679, batch acc 0.9492
14:53:09.137   Training iter 400, batch loss 0.1839, batch acc 0.9438
14:53:09.638   Training iter 450, batch loss 0.1690, batch acc 0.9518
14:53:10.160   Training iter 500, batch loss 0.1802, batch acc 0.9462
14:53:10.678   Training iter 550, batch loss 0.1861, batch acc 0.9440
14:53:11.182   Training iter 600, batch loss 0.1960, batch acc 0.9440
14:53:11.184 Training @ 105 epoch...
14:53:11.678   Training iter 50, batch loss 0.1898, batch acc 0.9486
14:53:12.173   Training iter 100, batch loss 0.1830, batch acc 0.9484
14:53:12.695   Training iter 150, batch loss 0.1610, batch acc 0.9534
14:53:13.244   Training iter 200, batch loss 0.1843, batch acc 0.9506
14:53:13.791   Training iter 250, batch loss 0.1586, batch acc 0.9504
14:53:14.347   Training iter 300, batch loss 0.1785, batch acc 0.9420
14:53:14.901   Training iter 350, batch loss 0.1705, batch acc 0.9492
14:53:15.452   Training iter 400, batch loss 0.1792, batch acc 0.9452
14:53:15.986   Training iter 450, batch loss 0.1799, batch acc 0.9452
14:53:16.531   Training iter 500, batch loss 0.1625, batch acc 0.9496
14:53:17.079   Training iter 550, batch loss 0.1863, batch acc 0.9450
14:53:17.637   Training iter 600, batch loss 0.1422, batch acc 0.9558
14:53:17.638 Testing @ 105 epoch...
14:53:17.685     Testing, total mean loss 0.21026, total acc 0.93720
14:53:17.685 Training @ 106 epoch...
14:53:18.228   Training iter 50, batch loss 0.1796, batch acc 0.9488
14:53:18.749   Training iter 100, batch loss 0.1682, batch acc 0.9492
14:53:19.284   Training iter 150, batch loss 0.1621, batch acc 0.9520
14:53:19.817   Training iter 200, batch loss 0.1751, batch acc 0.9496
14:53:20.358   Training iter 250, batch loss 0.1660, batch acc 0.9490
14:53:20.883   Training iter 300, batch loss 0.1723, batch acc 0.9480
14:53:21.417   Training iter 350, batch loss 0.1817, batch acc 0.9450
14:53:21.967   Training iter 400, batch loss 0.1783, batch acc 0.9464
14:53:22.520   Training iter 450, batch loss 0.1726, batch acc 0.9454
14:53:23.057   Training iter 500, batch loss 0.1675, batch acc 0.9508
14:53:23.611   Training iter 550, batch loss 0.1667, batch acc 0.9470
14:53:24.144   Training iter 600, batch loss 0.1796, batch acc 0.9476
14:53:24.146 Training @ 107 epoch...
14:53:24.711   Training iter 50, batch loss 0.1868, batch acc 0.9466
14:53:25.330   Training iter 100, batch loss 0.1773, batch acc 0.9464
14:53:25.995   Training iter 150, batch loss 0.1650, batch acc 0.9516
14:53:26.616   Training iter 200, batch loss 0.1656, batch acc 0.9496
14:53:27.260   Training iter 250, batch loss 0.1574, batch acc 0.9512
14:53:27.930   Training iter 300, batch loss 0.1692, batch acc 0.9476
14:53:28.615   Training iter 350, batch loss 0.1876, batch acc 0.9456
14:53:29.289   Training iter 400, batch loss 0.1846, batch acc 0.9476
14:53:29.912   Training iter 450, batch loss 0.1698, batch acc 0.9502
14:53:30.502   Training iter 500, batch loss 0.1634, batch acc 0.9518
14:53:31.046   Training iter 550, batch loss 0.1812, batch acc 0.9462
14:53:31.621   Training iter 600, batch loss 0.1731, batch acc 0.9486
14:53:31.624 Training @ 108 epoch...
14:53:32.245   Training iter 50, batch loss 0.1504, batch acc 0.9514
14:53:32.915   Training iter 100, batch loss 0.1883, batch acc 0.9464
14:53:33.494   Training iter 150, batch loss 0.1768, batch acc 0.9502
14:53:34.073   Training iter 200, batch loss 0.1643, batch acc 0.9492
14:53:34.633   Training iter 250, batch loss 0.1687, batch acc 0.9440
14:53:35.150   Training iter 300, batch loss 0.1693, batch acc 0.9478
14:53:35.656   Training iter 350, batch loss 0.1818, batch acc 0.9454
14:53:36.186   Training iter 400, batch loss 0.1933, batch acc 0.9462
14:53:36.747   Training iter 450, batch loss 0.1591, batch acc 0.9496
14:53:37.309   Training iter 500, batch loss 0.1654, batch acc 0.9490
14:53:37.859   Training iter 550, batch loss 0.1817, batch acc 0.9492
14:53:38.352   Training iter 600, batch loss 0.1899, batch acc 0.9450
14:53:38.354 Training @ 109 epoch...
14:53:38.861   Training iter 50, batch loss 0.1759, batch acc 0.9472
14:53:39.391   Training iter 100, batch loss 0.1690, batch acc 0.9514
14:53:39.904   Training iter 150, batch loss 0.1859, batch acc 0.9462
14:53:40.410   Training iter 200, batch loss 0.1795, batch acc 0.9450
14:53:40.899   Training iter 250, batch loss 0.1840, batch acc 0.9432
14:53:41.404   Training iter 300, batch loss 0.1748, batch acc 0.9450
14:53:41.901   Training iter 350, batch loss 0.1836, batch acc 0.9480
14:53:42.394   Training iter 400, batch loss 0.1792, batch acc 0.9444
14:53:42.877   Training iter 450, batch loss 0.1680, batch acc 0.9480
14:53:43.348   Training iter 500, batch loss 0.1608, batch acc 0.9530
14:53:43.832   Training iter 550, batch loss 0.1854, batch acc 0.9430
14:53:44.385   Training iter 600, batch loss 0.1613, batch acc 0.9546
14:53:44.387 Training @ 110 epoch...
14:53:44.920   Training iter 50, batch loss 0.1568, batch acc 0.9554
14:53:45.454   Training iter 100, batch loss 0.1593, batch acc 0.9482
14:53:45.950   Training iter 150, batch loss 0.1811, batch acc 0.9438
14:53:46.428   Training iter 200, batch loss 0.1661, batch acc 0.9472
14:53:46.913   Training iter 250, batch loss 0.1630, batch acc 0.9506
14:53:47.409   Training iter 300, batch loss 0.1720, batch acc 0.9452
14:53:47.894   Training iter 350, batch loss 0.1711, batch acc 0.9490
14:53:48.394   Training iter 400, batch loss 0.1889, batch acc 0.9452
14:53:48.882   Training iter 450, batch loss 0.1811, batch acc 0.9464
14:53:49.371   Training iter 500, batch loss 0.1885, batch acc 0.9448
14:53:49.856   Training iter 550, batch loss 0.1856, batch acc 0.9456
14:53:50.331   Training iter 600, batch loss 0.1709, batch acc 0.9460
14:53:50.332 Testing @ 110 epoch...
14:53:50.376     Testing, total mean loss 0.20939, total acc 0.93790
14:53:50.376 Training @ 111 epoch...
14:53:50.864   Training iter 50, batch loss 0.1610, batch acc 0.9516
14:53:51.348   Training iter 100, batch loss 0.1897, batch acc 0.9456
14:53:51.842   Training iter 150, batch loss 0.1732, batch acc 0.9482
14:53:52.327   Training iter 200, batch loss 0.1792, batch acc 0.9490
14:53:52.803   Training iter 250, batch loss 0.1662, batch acc 0.9486
14:53:53.318   Training iter 300, batch loss 0.1826, batch acc 0.9452
14:53:53.838   Training iter 350, batch loss 0.1908, batch acc 0.9444
14:53:54.358   Training iter 400, batch loss 0.1713, batch acc 0.9500
14:53:54.879   Training iter 450, batch loss 0.1504, batch acc 0.9530
14:53:55.403   Training iter 500, batch loss 0.1711, batch acc 0.9504
14:53:55.912   Training iter 550, batch loss 0.1999, batch acc 0.9422
14:53:56.435   Training iter 600, batch loss 0.1522, batch acc 0.9544
14:53:56.437 Training @ 112 epoch...
14:53:56.961   Training iter 50, batch loss 0.1678, batch acc 0.9518
14:53:57.483   Training iter 100, batch loss 0.1716, batch acc 0.9486
14:53:58.001   Training iter 150, batch loss 0.1763, batch acc 0.9468
14:53:58.521   Training iter 200, batch loss 0.1744, batch acc 0.9490
14:53:59.040   Training iter 250, batch loss 0.1657, batch acc 0.9510
14:53:59.568   Training iter 300, batch loss 0.1641, batch acc 0.9492
14:54:00.100   Training iter 350, batch loss 0.1670, batch acc 0.9502
14:54:00.667   Training iter 400, batch loss 0.1805, batch acc 0.9456
14:54:01.239   Training iter 450, batch loss 0.1935, batch acc 0.9414
14:54:01.806   Training iter 500, batch loss 0.1783, batch acc 0.9456
14:54:02.369   Training iter 550, batch loss 0.1562, batch acc 0.9548
14:54:02.937   Training iter 600, batch loss 0.1693, batch acc 0.9528
14:54:02.939 Training @ 113 epoch...
14:54:03.520   Training iter 50, batch loss 0.1740, batch acc 0.9506
14:54:04.085   Training iter 100, batch loss 0.1680, batch acc 0.9500
14:54:04.648   Training iter 150, batch loss 0.1580, batch acc 0.9498
14:54:05.216   Training iter 200, batch loss 0.1625, batch acc 0.9544
14:54:05.777   Training iter 250, batch loss 0.1767, batch acc 0.9452
14:54:06.330   Training iter 300, batch loss 0.1737, batch acc 0.9480
14:54:06.875   Training iter 350, batch loss 0.1795, batch acc 0.9468
14:54:07.397   Training iter 400, batch loss 0.1677, batch acc 0.9508
14:54:07.901   Training iter 450, batch loss 0.1819, batch acc 0.9434
14:54:08.383   Training iter 500, batch loss 0.1927, batch acc 0.9448
14:54:08.879   Training iter 550, batch loss 0.1845, batch acc 0.9438
14:54:09.380   Training iter 600, batch loss 0.1791, batch acc 0.9448
14:54:09.382 Training @ 114 epoch...
14:54:09.884   Training iter 50, batch loss 0.1635, batch acc 0.9514
14:54:10.413   Training iter 100, batch loss 0.1715, batch acc 0.9506
14:54:10.930   Training iter 150, batch loss 0.1554, batch acc 0.9516
14:54:11.449   Training iter 200, batch loss 0.1739, batch acc 0.9460
14:54:11.973   Training iter 250, batch loss 0.1837, batch acc 0.9416
14:54:12.487   Training iter 300, batch loss 0.1698, batch acc 0.9524
14:54:13.002   Training iter 350, batch loss 0.1600, batch acc 0.9536
14:54:13.507   Training iter 400, batch loss 0.1839, batch acc 0.9478
14:54:14.032   Training iter 450, batch loss 0.1847, batch acc 0.9454
14:54:14.559   Training iter 500, batch loss 0.1817, batch acc 0.9426
14:54:15.085   Training iter 550, batch loss 0.1750, batch acc 0.9480
14:54:15.622   Training iter 600, batch loss 0.1776, batch acc 0.9454
14:54:15.624 Training @ 115 epoch...
14:54:16.161   Training iter 50, batch loss 0.1700, batch acc 0.9474
14:54:16.688   Training iter 100, batch loss 0.1605, batch acc 0.9530
14:54:17.241   Training iter 150, batch loss 0.1717, batch acc 0.9498
14:54:17.798   Training iter 200, batch loss 0.1917, batch acc 0.9470
14:54:18.362   Training iter 250, batch loss 0.1819, batch acc 0.9458
14:54:18.920   Training iter 300, batch loss 0.1711, batch acc 0.9488
14:54:19.484   Training iter 350, batch loss 0.1762, batch acc 0.9480
14:54:20.047   Training iter 400, batch loss 0.1839, batch acc 0.9402
14:54:20.595   Training iter 450, batch loss 0.1665, batch acc 0.9538
14:54:21.148   Training iter 500, batch loss 0.1736, batch acc 0.9492
14:54:21.699   Training iter 550, batch loss 0.1666, batch acc 0.9460
14:54:22.257   Training iter 600, batch loss 0.1793, batch acc 0.9466
14:54:22.258 Testing @ 115 epoch...
14:54:22.302     Testing, total mean loss 0.21395, total acc 0.93790
14:54:22.303 Training @ 116 epoch...
14:54:22.859   Training iter 50, batch loss 0.1617, batch acc 0.9530
14:54:23.391   Training iter 100, batch loss 0.1548, batch acc 0.9492
14:54:23.916   Training iter 150, batch loss 0.1645, batch acc 0.9496
14:54:24.464   Training iter 200, batch loss 0.1861, batch acc 0.9462
14:54:25.050   Training iter 250, batch loss 0.1785, batch acc 0.9476
14:54:25.635   Training iter 300, batch loss 0.1734, batch acc 0.9464
14:54:26.208   Training iter 350, batch loss 0.1698, batch acc 0.9494
14:54:26.730   Training iter 400, batch loss 0.1760, batch acc 0.9472
14:54:27.262   Training iter 450, batch loss 0.1622, batch acc 0.9520
14:54:27.796   Training iter 500, batch loss 0.1809, batch acc 0.9456
14:54:28.332   Training iter 550, batch loss 0.1758, batch acc 0.9486
14:54:28.874   Training iter 600, batch loss 0.1755, batch acc 0.9476
14:54:28.875 Training @ 117 epoch...
14:54:29.418   Training iter 50, batch loss 0.1547, batch acc 0.9544
14:54:29.929   Training iter 100, batch loss 0.1711, batch acc 0.9494
14:54:30.440   Training iter 150, batch loss 0.1813, batch acc 0.9480
14:54:30.943   Training iter 200, batch loss 0.1667, batch acc 0.9504
14:54:31.456   Training iter 250, batch loss 0.1822, batch acc 0.9432
14:54:31.966   Training iter 300, batch loss 0.1744, batch acc 0.9512
14:54:32.476   Training iter 350, batch loss 0.1698, batch acc 0.9476
14:54:32.976   Training iter 400, batch loss 0.1705, batch acc 0.9484
14:54:33.489   Training iter 450, batch loss 0.1538, batch acc 0.9520
14:54:34.014   Training iter 500, batch loss 0.1662, batch acc 0.9506
14:54:34.544   Training iter 550, batch loss 0.1870, batch acc 0.9454
14:54:35.062   Training iter 600, batch loss 0.1944, batch acc 0.9376
14:54:35.064 Training @ 118 epoch...
14:54:35.602   Training iter 50, batch loss 0.1694, batch acc 0.9500
14:54:36.139   Training iter 100, batch loss 0.1681, batch acc 0.9498
14:54:36.686   Training iter 150, batch loss 0.1881, batch acc 0.9472
14:54:37.234   Training iter 200, batch loss 0.1676, batch acc 0.9476
14:54:37.785   Training iter 250, batch loss 0.1695, batch acc 0.9504
14:54:38.338   Training iter 300, batch loss 0.1588, batch acc 0.9504
14:54:38.889   Training iter 350, batch loss 0.1708, batch acc 0.9472
14:54:39.433   Training iter 400, batch loss 0.1848, batch acc 0.9454
14:54:39.971   Training iter 450, batch loss 0.1789, batch acc 0.9446
14:54:40.512   Training iter 500, batch loss 0.1813, batch acc 0.9440
14:54:41.036   Training iter 550, batch loss 0.1800, batch acc 0.9484
14:54:41.559   Training iter 600, batch loss 0.1788, batch acc 0.9468
14:54:41.561 Training @ 119 epoch...
14:54:42.078   Training iter 50, batch loss 0.1462, batch acc 0.9562
14:54:42.580   Training iter 100, batch loss 0.1651, batch acc 0.9514
14:54:43.084   Training iter 150, batch loss 0.1629, batch acc 0.9516
14:54:43.581   Training iter 200, batch loss 0.1795, batch acc 0.9488
14:54:44.060   Training iter 250, batch loss 0.1531, batch acc 0.9534
14:54:44.526   Training iter 300, batch loss 0.1808, batch acc 0.9476
14:54:44.982   Training iter 350, batch loss 0.1633, batch acc 0.9508
14:54:45.440   Training iter 400, batch loss 0.1837, batch acc 0.9404
14:54:45.893   Training iter 450, batch loss 0.2037, batch acc 0.9402
14:54:46.362   Training iter 500, batch loss 0.1665, batch acc 0.9500
14:54:46.829   Training iter 550, batch loss 0.1930, batch acc 0.9466
14:54:47.293   Training iter 600, batch loss 0.1683, batch acc 0.9488
14:54:47.295 Training @ 120 epoch...
14:54:47.782   Training iter 50, batch loss 0.1648, batch acc 0.9538
14:54:48.291   Training iter 100, batch loss 0.1659, batch acc 0.9490
14:54:48.795   Training iter 150, batch loss 0.1625, batch acc 0.9540
14:54:49.331   Training iter 200, batch loss 0.1737, batch acc 0.9470
14:54:49.874   Training iter 250, batch loss 0.1909, batch acc 0.9408
14:54:50.405   Training iter 300, batch loss 0.1779, batch acc 0.9504
14:54:50.926   Training iter 350, batch loss 0.1627, batch acc 0.9526
14:54:51.451   Training iter 400, batch loss 0.1626, batch acc 0.9502
14:54:51.975   Training iter 450, batch loss 0.1773, batch acc 0.9466
14:54:52.514   Training iter 500, batch loss 0.1758, batch acc 0.9464
14:54:53.053   Training iter 550, batch loss 0.1729, batch acc 0.9486
14:54:53.592   Training iter 600, batch loss 0.1741, batch acc 0.9484
14:54:53.594 Testing @ 120 epoch...
14:54:53.638     Testing, total mean loss 0.22245, total acc 0.93290
14:54:53.638 Training @ 121 epoch...
14:54:54.195   Training iter 50, batch loss 0.1894, batch acc 0.9428
14:54:54.748   Training iter 100, batch loss 0.1746, batch acc 0.9468
14:54:55.295   Training iter 150, batch loss 0.1809, batch acc 0.9464
14:54:55.802   Training iter 200, batch loss 0.1762, batch acc 0.9452
14:54:56.319   Training iter 250, batch loss 0.1515, batch acc 0.9524
14:54:56.830   Training iter 300, batch loss 0.1574, batch acc 0.9522
14:54:57.381   Training iter 350, batch loss 0.1570, batch acc 0.9550
14:54:57.926   Training iter 400, batch loss 0.1912, batch acc 0.9412
14:54:58.441   Training iter 450, batch loss 0.1604, batch acc 0.9530
14:54:58.947   Training iter 500, batch loss 0.1629, batch acc 0.9512
14:54:59.465   Training iter 550, batch loss 0.1836, batch acc 0.9484
14:54:59.985   Training iter 600, batch loss 0.1774, batch acc 0.9468
14:54:59.986 Training @ 122 epoch...
14:55:00.506   Training iter 50, batch loss 0.1793, batch acc 0.9484
14:55:01.022   Training iter 100, batch loss 0.1651, batch acc 0.9508
14:55:01.581   Training iter 150, batch loss 0.1709, batch acc 0.9482
14:55:02.165   Training iter 200, batch loss 0.1605, batch acc 0.9508
14:55:02.724   Training iter 250, batch loss 0.1719, batch acc 0.9480
14:55:03.264   Training iter 300, batch loss 0.1750, batch acc 0.9470
14:55:03.803   Training iter 350, batch loss 0.1694, batch acc 0.9496
14:55:04.353   Training iter 400, batch loss 0.1707, batch acc 0.9476
14:55:04.886   Training iter 450, batch loss 0.1698, batch acc 0.9482
14:55:05.418   Training iter 500, batch loss 0.1693, batch acc 0.9490
14:55:05.960   Training iter 550, batch loss 0.1586, batch acc 0.9530
14:55:06.518   Training iter 600, batch loss 0.1925, batch acc 0.9480
14:55:06.520 Training @ 123 epoch...
14:55:07.084   Training iter 50, batch loss 0.1607, batch acc 0.9532
14:55:07.644   Training iter 100, batch loss 0.1546, batch acc 0.9550
14:55:08.173   Training iter 150, batch loss 0.1627, batch acc 0.9500
14:55:08.676   Training iter 200, batch loss 0.1881, batch acc 0.9412
14:55:09.201   Training iter 250, batch loss 0.1570, batch acc 0.9532
14:55:09.733   Training iter 300, batch loss 0.1778, batch acc 0.9482
14:55:10.291   Training iter 350, batch loss 0.1724, batch acc 0.9494
14:55:10.835   Training iter 400, batch loss 0.1832, batch acc 0.9486
14:55:11.380   Training iter 450, batch loss 0.1746, batch acc 0.9480
14:55:11.926   Training iter 500, batch loss 0.1695, batch acc 0.9502
14:55:12.473   Training iter 550, batch loss 0.1721, batch acc 0.9470
14:55:13.019   Training iter 600, batch loss 0.1603, batch acc 0.9504
14:55:13.021 Training @ 124 epoch...
14:55:13.582   Training iter 50, batch loss 0.1837, batch acc 0.9458
14:55:14.128   Training iter 100, batch loss 0.1791, batch acc 0.9478
14:55:14.677   Training iter 150, batch loss 0.1628, batch acc 0.9478
14:55:15.223   Training iter 200, batch loss 0.1661, batch acc 0.9486
14:55:15.772   Training iter 250, batch loss 0.1693, batch acc 0.9484
14:55:16.370   Training iter 300, batch loss 0.1624, batch acc 0.9524
14:55:16.938   Training iter 350, batch loss 0.1616, batch acc 0.9476
14:55:17.524   Training iter 400, batch loss 0.1614, batch acc 0.9542
14:55:18.026   Training iter 450, batch loss 0.1809, batch acc 0.9492
14:55:18.526   Training iter 500, batch loss 0.1856, batch acc 0.9446
14:55:19.019   Training iter 550, batch loss 0.1693, batch acc 0.9490
14:55:19.567   Training iter 600, batch loss 0.1736, batch acc 0.9490
14:55:19.568 Training @ 125 epoch...
14:55:20.119   Training iter 50, batch loss 0.1675, batch acc 0.9476
14:55:20.713   Training iter 100, batch loss 0.1735, batch acc 0.9420
14:55:21.222   Training iter 150, batch loss 0.1718, batch acc 0.9466
14:55:21.742   Training iter 200, batch loss 0.1537, batch acc 0.9554
14:55:22.259   Training iter 250, batch loss 0.1678, batch acc 0.9500
14:55:22.790   Training iter 300, batch loss 0.1606, batch acc 0.9572
14:55:23.329   Training iter 350, batch loss 0.1781, batch acc 0.9468
14:55:23.868   Training iter 400, batch loss 0.1782, batch acc 0.9456
14:55:24.402   Training iter 450, batch loss 0.1654, batch acc 0.9532
14:55:24.922   Training iter 500, batch loss 0.1850, batch acc 0.9482
14:55:25.462   Training iter 550, batch loss 0.1761, batch acc 0.9492
14:55:25.981   Training iter 600, batch loss 0.1626, batch acc 0.9496
14:55:25.982 Testing @ 125 epoch...
14:55:26.030     Testing, total mean loss 0.20772, total acc 0.93890
14:55:26.030 Training @ 126 epoch...
14:55:26.568   Training iter 50, batch loss 0.1683, batch acc 0.9514
14:55:27.103   Training iter 100, batch loss 0.1659, batch acc 0.9526
14:55:27.640   Training iter 150, batch loss 0.1582, batch acc 0.9516
14:55:28.185   Training iter 200, batch loss 0.1700, batch acc 0.9470
14:55:28.713   Training iter 250, batch loss 0.1826, batch acc 0.9496
14:55:29.254   Training iter 300, batch loss 0.1658, batch acc 0.9462
14:55:29.782   Training iter 350, batch loss 0.1610, batch acc 0.9524
14:55:30.315   Training iter 400, batch loss 0.1789, batch acc 0.9486
14:55:30.834   Training iter 450, batch loss 0.1654, batch acc 0.9494
14:55:31.356   Training iter 500, batch loss 0.1630, batch acc 0.9526
14:55:31.872   Training iter 550, batch loss 0.1860, batch acc 0.9462
14:55:32.387   Training iter 600, batch loss 0.1882, batch acc 0.9416
14:55:32.389 Training @ 127 epoch...
14:55:32.901   Training iter 50, batch loss 0.1727, batch acc 0.9506
14:55:33.391   Training iter 100, batch loss 0.1742, batch acc 0.9470
14:55:33.874   Training iter 150, batch loss 0.1805, batch acc 0.9466
14:55:34.366   Training iter 200, batch loss 0.1680, batch acc 0.9492
14:55:34.865   Training iter 250, batch loss 0.1667, batch acc 0.9528
14:55:35.343   Training iter 300, batch loss 0.1813, batch acc 0.9434
14:55:35.828   Training iter 350, batch loss 0.1740, batch acc 0.9512
14:55:36.311   Training iter 400, batch loss 0.1758, batch acc 0.9418
14:55:36.822   Training iter 450, batch loss 0.1671, batch acc 0.9494
14:55:37.357   Training iter 500, batch loss 0.1643, batch acc 0.9498
14:55:37.884   Training iter 550, batch loss 0.1691, batch acc 0.9486
14:55:38.413   Training iter 600, batch loss 0.1721, batch acc 0.9482
14:55:38.415 Training @ 128 epoch...
14:55:38.955   Training iter 50, batch loss 0.1698, batch acc 0.9468
14:55:39.514   Training iter 100, batch loss 0.1829, batch acc 0.9460
14:55:40.051   Training iter 150, batch loss 0.1712, batch acc 0.9484
14:55:40.598   Training iter 200, batch loss 0.1554, batch acc 0.9558
14:55:41.124   Training iter 250, batch loss 0.1684, batch acc 0.9482
14:55:41.655   Training iter 300, batch loss 0.1596, batch acc 0.9530
14:55:42.196   Training iter 350, batch loss 0.1812, batch acc 0.9426
14:55:42.720   Training iter 400, batch loss 0.1610, batch acc 0.9496
14:55:43.233   Training iter 450, batch loss 0.1695, batch acc 0.9490
14:55:43.753   Training iter 500, batch loss 0.1589, batch acc 0.9530
14:55:44.280   Training iter 550, batch loss 0.1826, batch acc 0.9480
14:55:44.794   Training iter 600, batch loss 0.1833, batch acc 0.9432
14:55:44.796 Training @ 129 epoch...
14:55:45.308   Training iter 50, batch loss 0.1711, batch acc 0.9496
14:55:45.823   Training iter 100, batch loss 0.1752, batch acc 0.9458
14:55:46.342   Training iter 150, batch loss 0.1599, batch acc 0.9516
14:55:46.870   Training iter 200, batch loss 0.1472, batch acc 0.9540
14:55:47.391   Training iter 250, batch loss 0.1862, batch acc 0.9434
14:55:47.920   Training iter 300, batch loss 0.1704, batch acc 0.9506
14:55:48.442   Training iter 350, batch loss 0.1695, batch acc 0.9506
14:55:48.964   Training iter 400, batch loss 0.1628, batch acc 0.9514
14:55:49.494   Training iter 450, batch loss 0.1710, batch acc 0.9488
14:55:50.035   Training iter 500, batch loss 0.1838, batch acc 0.9408
14:55:50.570   Training iter 550, batch loss 0.1831, batch acc 0.9452
14:55:51.091   Training iter 600, batch loss 0.1593, batch acc 0.9520
14:55:51.092 Training @ 130 epoch...
14:55:51.613   Training iter 50, batch loss 0.1833, batch acc 0.9472
14:55:52.146   Training iter 100, batch loss 0.1672, batch acc 0.9448
14:55:52.685   Training iter 150, batch loss 0.1450, batch acc 0.9566
14:55:53.240   Training iter 200, batch loss 0.1719, batch acc 0.9436
14:55:53.781   Training iter 250, batch loss 0.1712, batch acc 0.9482
14:55:54.319   Training iter 300, batch loss 0.1933, batch acc 0.9470
14:55:54.868   Training iter 350, batch loss 0.1843, batch acc 0.9470
14:55:55.422   Training iter 400, batch loss 0.1478, batch acc 0.9560
14:55:55.972   Training iter 450, batch loss 0.1754, batch acc 0.9496
14:55:56.489   Training iter 500, batch loss 0.1812, batch acc 0.9462
14:55:57.015   Training iter 550, batch loss 0.1711, batch acc 0.9470
14:55:57.556   Training iter 600, batch loss 0.1541, batch acc 0.9528
14:55:57.557 Testing @ 130 epoch...
14:55:57.601     Testing, total mean loss 0.21123, total acc 0.93820
14:55:57.601 Training @ 131 epoch...
14:55:58.130   Training iter 50, batch loss 0.1646, batch acc 0.9502
14:55:58.658   Training iter 100, batch loss 0.1525, batch acc 0.9540
14:55:59.182   Training iter 150, batch loss 0.1704, batch acc 0.9514
14:55:59.690   Training iter 200, batch loss 0.1750, batch acc 0.9448
14:56:00.193   Training iter 250, batch loss 0.1686, batch acc 0.9510
14:56:00.698   Training iter 300, batch loss 0.1740, batch acc 0.9484
14:56:01.209   Training iter 350, batch loss 0.1703, batch acc 0.9488
14:56:01.727   Training iter 400, batch loss 0.1742, batch acc 0.9490
14:56:02.286   Training iter 450, batch loss 0.1663, batch acc 0.9544
14:56:02.851   Training iter 500, batch loss 0.1691, batch acc 0.9510
14:56:03.370   Training iter 550, batch loss 0.1640, batch acc 0.9486
14:56:03.870   Training iter 600, batch loss 0.2001, batch acc 0.9364
14:56:03.872 Training @ 132 epoch...
14:56:04.361   Training iter 50, batch loss 0.1650, batch acc 0.9468
14:56:04.843   Training iter 100, batch loss 0.1782, batch acc 0.9470
14:56:05.334   Training iter 150, batch loss 0.1701, batch acc 0.9476
14:56:05.831   Training iter 200, batch loss 0.1765, batch acc 0.9464
14:56:06.360   Training iter 250, batch loss 0.1569, batch acc 0.9546
14:56:06.889   Training iter 300, batch loss 0.1673, batch acc 0.9494
14:56:07.402   Training iter 350, batch loss 0.1718, batch acc 0.9468
14:56:07.906   Training iter 400, batch loss 0.1809, batch acc 0.9468
14:56:08.431   Training iter 450, batch loss 0.1665, batch acc 0.9488
14:56:08.991   Training iter 500, batch loss 0.1628, batch acc 0.9514
14:56:09.568   Training iter 550, batch loss 0.1855, batch acc 0.9432
14:56:10.183   Training iter 600, batch loss 0.1779, batch acc 0.9500
14:56:10.185 Training @ 133 epoch...
14:56:10.771   Training iter 50, batch loss 0.1576, batch acc 0.9506
14:56:11.337   Training iter 100, batch loss 0.1693, batch acc 0.9480
14:56:11.897   Training iter 150, batch loss 0.1679, batch acc 0.9496
14:56:12.565   Training iter 200, batch loss 0.1723, batch acc 0.9508
14:56:13.145   Training iter 250, batch loss 0.1822, batch acc 0.9488
14:56:13.746   Training iter 300, batch loss 0.1634, batch acc 0.9488
14:56:14.350   Training iter 350, batch loss 0.1799, batch acc 0.9488
14:56:14.941   Training iter 400, batch loss 0.1608, batch acc 0.9522
14:56:15.492   Training iter 450, batch loss 0.1558, batch acc 0.9520
14:56:15.993   Training iter 500, batch loss 0.1735, batch acc 0.9502
14:56:16.505   Training iter 550, batch loss 0.1720, batch acc 0.9454
14:56:17.005   Training iter 600, batch loss 0.1628, batch acc 0.9502
14:56:17.007 Training @ 134 epoch...
14:56:17.545   Training iter 50, batch loss 0.1515, batch acc 0.9534
14:56:18.083   Training iter 100, batch loss 0.1662, batch acc 0.9512
14:56:18.620   Training iter 150, batch loss 0.1729, batch acc 0.9464
14:56:19.159   Training iter 200, batch loss 0.1771, batch acc 0.9470
14:56:19.682   Training iter 250, batch loss 0.1564, batch acc 0.9500
14:56:20.194   Training iter 300, batch loss 0.1647, batch acc 0.9532
14:56:20.686   Training iter 350, batch loss 0.1700, batch acc 0.9514
14:56:21.180   Training iter 400, batch loss 0.1723, batch acc 0.9494
14:56:21.680   Training iter 450, batch loss 0.1829, batch acc 0.9472
14:56:22.172   Training iter 500, batch loss 0.1653, batch acc 0.9484
14:56:22.657   Training iter 550, batch loss 0.1855, batch acc 0.9434
14:56:23.143   Training iter 600, batch loss 0.1822, batch acc 0.9468
14:56:23.145 Training @ 135 epoch...
14:56:23.640   Training iter 50, batch loss 0.1570, batch acc 0.9548
14:56:24.145   Training iter 100, batch loss 0.1621, batch acc 0.9530
14:56:24.667   Training iter 150, batch loss 0.1877, batch acc 0.9464
14:56:25.150   Training iter 200, batch loss 0.1608, batch acc 0.9554
14:56:25.617   Training iter 250, batch loss 0.1605, batch acc 0.9538
14:56:26.088   Training iter 300, batch loss 0.1797, batch acc 0.9476
14:56:26.551   Training iter 350, batch loss 0.1723, batch acc 0.9478
14:56:27.026   Training iter 400, batch loss 0.1782, batch acc 0.9456
14:56:27.505   Training iter 450, batch loss 0.1762, batch acc 0.9442
14:56:27.997   Training iter 500, batch loss 0.1541, batch acc 0.9528
14:56:28.478   Training iter 550, batch loss 0.1768, batch acc 0.9478
14:56:28.991   Training iter 600, batch loss 0.1884, batch acc 0.9428
14:56:28.993 Testing @ 135 epoch...
14:56:29.039     Testing, total mean loss 0.21045, total acc 0.93970
14:56:29.039 Training @ 136 epoch...
14:56:29.572   Training iter 50, batch loss 0.1684, batch acc 0.9498
14:56:30.061   Training iter 100, batch loss 0.1819, batch acc 0.9466
14:56:30.537   Training iter 150, batch loss 0.1467, batch acc 0.9560
14:56:31.049   Training iter 200, batch loss 0.1766, batch acc 0.9462
14:56:31.568   Training iter 250, batch loss 0.1602, batch acc 0.9510
14:56:32.138   Training iter 300, batch loss 0.1534, batch acc 0.9556
14:56:32.684   Training iter 350, batch loss 0.1793, batch acc 0.9454
14:56:33.255   Training iter 400, batch loss 0.1879, batch acc 0.9388
14:56:33.823   Training iter 450, batch loss 0.1823, batch acc 0.9462
14:56:34.408   Training iter 500, batch loss 0.1671, batch acc 0.9526
14:56:34.976   Training iter 550, batch loss 0.1550, batch acc 0.9530
14:56:35.531   Training iter 600, batch loss 0.1799, batch acc 0.9494
14:56:35.533 Training @ 137 epoch...
14:56:36.116   Training iter 50, batch loss 0.1760, batch acc 0.9482
14:56:36.660   Training iter 100, batch loss 0.1673, batch acc 0.9516
14:56:37.204   Training iter 150, batch loss 0.1694, batch acc 0.9478
14:56:37.756   Training iter 200, batch loss 0.1809, batch acc 0.9432
14:56:38.324   Training iter 250, batch loss 0.1629, batch acc 0.9536
14:56:38.863   Training iter 300, batch loss 0.1785, batch acc 0.9458
14:56:39.420   Training iter 350, batch loss 0.1780, batch acc 0.9466
14:56:39.971   Training iter 400, batch loss 0.1916, batch acc 0.9468
14:56:40.528   Training iter 450, batch loss 0.1668, batch acc 0.9480
14:56:41.058   Training iter 500, batch loss 0.1750, batch acc 0.9474
14:56:41.604   Training iter 550, batch loss 0.1469, batch acc 0.9584
14:56:42.142   Training iter 600, batch loss 0.1510, batch acc 0.9534
14:56:42.144 Training @ 138 epoch...
14:56:42.684   Training iter 50, batch loss 0.1753, batch acc 0.9444
14:56:43.192   Training iter 100, batch loss 0.1624, batch acc 0.9540
14:56:43.703   Training iter 150, batch loss 0.1791, batch acc 0.9482
14:56:44.198   Training iter 200, batch loss 0.1593, batch acc 0.9504
14:56:44.710   Training iter 250, batch loss 0.1670, batch acc 0.9490
14:56:45.224   Training iter 300, batch loss 0.1917, batch acc 0.9430
14:56:45.726   Training iter 350, batch loss 0.1666, batch acc 0.9510
14:56:46.228   Training iter 400, batch loss 0.1588, batch acc 0.9528
14:56:46.715   Training iter 450, batch loss 0.1691, batch acc 0.9482
14:56:47.200   Training iter 500, batch loss 0.1623, batch acc 0.9512
14:56:47.683   Training iter 550, batch loss 0.1681, batch acc 0.9504
14:56:48.174   Training iter 600, batch loss 0.1742, batch acc 0.9488
14:56:48.175 Training @ 139 epoch...
14:56:48.660   Training iter 50, batch loss 0.1616, batch acc 0.9486
14:56:49.143   Training iter 100, batch loss 0.1595, batch acc 0.9522
14:56:49.646   Training iter 150, batch loss 0.1713, batch acc 0.9508
14:56:50.145   Training iter 200, batch loss 0.1626, batch acc 0.9486
14:56:50.641   Training iter 250, batch loss 0.1788, batch acc 0.9446
14:56:51.134   Training iter 300, batch loss 0.1931, batch acc 0.9446
14:56:51.618   Training iter 350, batch loss 0.1631, batch acc 0.9522
14:56:52.105   Training iter 400, batch loss 0.1656, batch acc 0.9480
14:56:52.587   Training iter 450, batch loss 0.1768, batch acc 0.9456
14:56:53.084   Training iter 500, batch loss 0.1803, batch acc 0.9540
14:56:53.594   Training iter 550, batch loss 0.1589, batch acc 0.9512
14:56:54.117   Training iter 600, batch loss 0.1597, batch acc 0.9498
14:56:54.119 Training @ 140 epoch...
14:56:54.655   Training iter 50, batch loss 0.1650, batch acc 0.9474
14:56:55.188   Training iter 100, batch loss 0.1522, batch acc 0.9540
14:56:55.723   Training iter 150, batch loss 0.1868, batch acc 0.9460
14:56:56.275   Training iter 200, batch loss 0.1693, batch acc 0.9494
14:56:56.829   Training iter 250, batch loss 0.1740, batch acc 0.9484
14:56:57.384   Training iter 300, batch loss 0.1905, batch acc 0.9442
14:56:57.937   Training iter 350, batch loss 0.1641, batch acc 0.9500
14:56:58.485   Training iter 400, batch loss 0.1534, batch acc 0.9530
14:56:59.035   Training iter 450, batch loss 0.1628, batch acc 0.9502
14:56:59.585   Training iter 500, batch loss 0.1630, batch acc 0.9542
14:57:00.138   Training iter 550, batch loss 0.1661, batch acc 0.9530
14:57:00.698   Training iter 600, batch loss 0.1833, batch acc 0.9410
14:57:00.700 Testing @ 140 epoch...
14:57:00.744     Testing, total mean loss 0.20374, total acc 0.94050
14:57:00.744 Training @ 141 epoch...
14:57:01.304   Training iter 50, batch loss 0.1514, batch acc 0.9544
14:57:01.883   Training iter 100, batch loss 0.1719, batch acc 0.9508
14:57:02.462   Training iter 150, batch loss 0.1674, batch acc 0.9508
14:57:03.011   Training iter 200, batch loss 0.1717, batch acc 0.9480
14:57:03.532   Training iter 250, batch loss 0.1585, batch acc 0.9570
14:57:04.018   Training iter 300, batch loss 0.1768, batch acc 0.9442
14:57:04.497   Training iter 350, batch loss 0.1626, batch acc 0.9530
14:57:04.977   Training iter 400, batch loss 0.1720, batch acc 0.9464
14:57:05.463   Training iter 450, batch loss 0.1705, batch acc 0.9504
14:57:05.944   Training iter 500, batch loss 0.1734, batch acc 0.9468
14:57:06.441   Training iter 550, batch loss 0.1767, batch acc 0.9468
14:57:06.930   Training iter 600, batch loss 0.1744, batch acc 0.9456
14:57:06.932 Training @ 142 epoch...
14:57:07.452   Training iter 50, batch loss 0.1580, batch acc 0.9530
14:57:07.928   Training iter 100, batch loss 0.1719, batch acc 0.9514
14:57:08.409   Training iter 150, batch loss 0.1643, batch acc 0.9504
14:57:08.892   Training iter 200, batch loss 0.1893, batch acc 0.9434
14:57:09.415   Training iter 250, batch loss 0.1803, batch acc 0.9466
14:57:09.947   Training iter 300, batch loss 0.1600, batch acc 0.9514
14:57:10.462   Training iter 350, batch loss 0.1711, batch acc 0.9480
14:57:10.993   Training iter 400, batch loss 0.1581, batch acc 0.9500
14:57:11.545   Training iter 450, batch loss 0.1665, batch acc 0.9512
14:57:12.073   Training iter 500, batch loss 0.1735, batch acc 0.9444
14:57:12.593   Training iter 550, batch loss 0.1714, batch acc 0.9460
14:57:13.114   Training iter 600, batch loss 0.1779, batch acc 0.9486
14:57:13.116 Training @ 143 epoch...
14:57:13.674   Training iter 50, batch loss 0.1740, batch acc 0.9508
14:57:14.231   Training iter 100, batch loss 0.1638, batch acc 0.9482
14:57:14.763   Training iter 150, batch loss 0.1729, batch acc 0.9492
14:57:15.313   Training iter 200, batch loss 0.1828, batch acc 0.9492
14:57:15.856   Training iter 250, batch loss 0.1632, batch acc 0.9530
14:57:16.398   Training iter 300, batch loss 0.1526, batch acc 0.9546
14:57:16.926   Training iter 350, batch loss 0.1725, batch acc 0.9482
14:57:17.469   Training iter 400, batch loss 0.1715, batch acc 0.9488
14:57:17.992   Training iter 450, batch loss 0.1867, batch acc 0.9460
14:57:18.505   Training iter 500, batch loss 0.1562, batch acc 0.9514
14:57:19.015   Training iter 550, batch loss 0.1769, batch acc 0.9462
14:57:19.524   Training iter 600, batch loss 0.1503, batch acc 0.9552
14:57:19.525 Training @ 144 epoch...
14:57:20.053   Training iter 50, batch loss 0.1625, batch acc 0.9490
14:57:20.574   Training iter 100, batch loss 0.1666, batch acc 0.9518
14:57:21.087   Training iter 150, batch loss 0.1869, batch acc 0.9450
14:57:21.604   Training iter 200, batch loss 0.1817, batch acc 0.9438
14:57:22.136   Training iter 250, batch loss 0.1544, batch acc 0.9538
14:57:22.652   Training iter 300, batch loss 0.1606, batch acc 0.9522
14:57:23.172   Training iter 350, batch loss 0.1663, batch acc 0.9498
14:57:23.704   Training iter 400, batch loss 0.1620, batch acc 0.9516
14:57:24.235   Training iter 450, batch loss 0.1762, batch acc 0.9496
14:57:24.764   Training iter 500, batch loss 0.1632, batch acc 0.9476
14:57:25.277   Training iter 550, batch loss 0.1765, batch acc 0.9500
14:57:25.771   Training iter 600, batch loss 0.1634, batch acc 0.9534
14:57:25.773 Training @ 145 epoch...
14:57:26.270   Training iter 50, batch loss 0.1719, batch acc 0.9464
14:57:26.758   Training iter 100, batch loss 0.1577, batch acc 0.9524
14:57:27.235   Training iter 150, batch loss 0.1672, batch acc 0.9494
14:57:27.712   Training iter 200, batch loss 0.1727, batch acc 0.9480
14:57:28.202   Training iter 250, batch loss 0.1769, batch acc 0.9458
14:57:28.670   Training iter 300, batch loss 0.1665, batch acc 0.9544
14:57:29.149   Training iter 350, batch loss 0.1603, batch acc 0.9518
14:57:29.652   Training iter 400, batch loss 0.1749, batch acc 0.9462
14:57:30.151   Training iter 450, batch loss 0.1613, batch acc 0.9518
14:57:30.681   Training iter 500, batch loss 0.1618, batch acc 0.9524
14:57:31.239   Training iter 550, batch loss 0.1753, batch acc 0.9468
14:57:31.779   Training iter 600, batch loss 0.1646, batch acc 0.9480
14:57:31.781 Testing @ 145 epoch...
14:57:31.828     Testing, total mean loss 0.22493, total acc 0.93390
14:57:31.828 Training @ 146 epoch...
14:57:32.375   Training iter 50, batch loss 0.1747, batch acc 0.9496
14:57:32.923   Training iter 100, batch loss 0.1535, batch acc 0.9524
14:57:33.453   Training iter 150, batch loss 0.1811, batch acc 0.9466
14:57:34.017   Training iter 200, batch loss 0.1516, batch acc 0.9496
14:57:34.602   Training iter 250, batch loss 0.1584, batch acc 0.9530
14:57:35.181   Training iter 300, batch loss 0.1826, batch acc 0.9494
14:57:35.766   Training iter 350, batch loss 0.1786, batch acc 0.9476
14:57:36.355   Training iter 400, batch loss 0.1564, batch acc 0.9516
14:57:36.899   Training iter 450, batch loss 0.1853, batch acc 0.9472
14:57:37.433   Training iter 500, batch loss 0.1803, batch acc 0.9444
14:57:37.929   Training iter 550, batch loss 0.1708, batch acc 0.9482
14:57:38.418   Training iter 600, batch loss 0.1664, batch acc 0.9486
14:57:38.419 Training @ 147 epoch...
14:57:38.892   Training iter 50, batch loss 0.1485, batch acc 0.9558
14:57:39.381   Training iter 100, batch loss 0.1563, batch acc 0.9540
14:57:39.900   Training iter 150, batch loss 0.1553, batch acc 0.9532
14:57:40.413   Training iter 200, batch loss 0.1871, batch acc 0.9398
14:57:40.920   Training iter 250, batch loss 0.1605, batch acc 0.9482
14:57:41.434   Training iter 300, batch loss 0.1936, batch acc 0.9422
14:57:41.954   Training iter 350, batch loss 0.1724, batch acc 0.9508
14:57:42.491   Training iter 400, batch loss 0.1759, batch acc 0.9448
14:57:43.014   Training iter 450, batch loss 0.1711, batch acc 0.9514
14:57:43.540   Training iter 500, batch loss 0.1705, batch acc 0.9502
14:57:44.065   Training iter 550, batch loss 0.1774, batch acc 0.9508
14:57:44.604   Training iter 600, batch loss 0.1720, batch acc 0.9458
14:57:44.606 Training @ 148 epoch...
14:57:45.121   Training iter 50, batch loss 0.1607, batch acc 0.9522
14:57:45.622   Training iter 100, batch loss 0.1632, batch acc 0.9494
14:57:46.122   Training iter 150, batch loss 0.1731, batch acc 0.9486
14:57:46.616   Training iter 200, batch loss 0.1696, batch acc 0.9504
14:57:47.108   Training iter 250, batch loss 0.1722, batch acc 0.9494
14:57:47.599   Training iter 300, batch loss 0.1750, batch acc 0.9496
14:57:48.109   Training iter 350, batch loss 0.1727, batch acc 0.9456
14:57:48.615   Training iter 400, batch loss 0.1750, batch acc 0.9498
14:57:49.109   Training iter 450, batch loss 0.1662, batch acc 0.9506
14:57:49.615   Training iter 500, batch loss 0.1579, batch acc 0.9540
14:57:50.114   Training iter 550, batch loss 0.1617, batch acc 0.9520
14:57:50.626   Training iter 600, batch loss 0.1712, batch acc 0.9500
14:57:50.627 Training @ 149 epoch...
14:57:51.144   Training iter 50, batch loss 0.1549, batch acc 0.9508
14:57:51.666   Training iter 100, batch loss 0.1640, batch acc 0.9482
14:57:52.187   Training iter 150, batch loss 0.1674, batch acc 0.9520
14:57:52.718   Training iter 200, batch loss 0.1839, batch acc 0.9454
14:57:53.256   Training iter 250, batch loss 0.1670, batch acc 0.9510
14:57:53.789   Training iter 300, batch loss 0.1715, batch acc 0.9482
14:57:54.322   Training iter 350, batch loss 0.1724, batch acc 0.9522
14:57:54.839   Training iter 400, batch loss 0.1676, batch acc 0.9490
14:57:55.384   Training iter 450, batch loss 0.1714, batch acc 0.9500
14:57:55.910   Training iter 500, batch loss 0.1847, batch acc 0.9450
14:57:56.430   Training iter 550, batch loss 0.1646, batch acc 0.9468
14:57:56.945   Training iter 600, batch loss 0.1591, batch acc 0.9496
14:57:56.947 Training @ 150 epoch...
14:57:57.490   Training iter 50, batch loss 0.1611, batch acc 0.9510
14:57:58.030   Training iter 100, batch loss 0.1494, batch acc 0.9526
14:57:58.566   Training iter 150, batch loss 0.1846, batch acc 0.9434
14:57:59.114   Training iter 200, batch loss 0.1775, batch acc 0.9472
14:57:59.690   Training iter 250, batch loss 0.1706, batch acc 0.9496
14:58:00.276   Training iter 300, batch loss 0.1798, batch acc 0.9480
14:58:00.861   Training iter 350, batch loss 0.1531, batch acc 0.9548
14:58:01.428   Training iter 400, batch loss 0.1627, batch acc 0.9514
14:58:02.014   Training iter 450, batch loss 0.1837, batch acc 0.9458
14:58:02.602   Training iter 500, batch loss 0.1740, batch acc 0.9476
14:58:03.181   Training iter 550, batch loss 0.1693, batch acc 0.9482
14:58:03.750   Training iter 600, batch loss 0.1610, batch acc 0.9488
14:58:03.752 Testing @ 150 epoch...
14:58:03.797     Testing, total mean loss 0.23302, total acc 0.93300
14:58:03.797 Training @ 151 epoch...
14:58:04.349   Training iter 50, batch loss 0.1484, batch acc 0.9540
14:58:04.917   Training iter 100, batch loss 0.1471, batch acc 0.9564
14:58:05.616   Training iter 150, batch loss 0.1710, batch acc 0.9466
14:58:06.173   Training iter 200, batch loss 0.1817, batch acc 0.9454
14:58:06.705   Training iter 250, batch loss 0.1543, batch acc 0.9514
14:58:07.217   Training iter 300, batch loss 0.1788, batch acc 0.9476
14:58:07.731   Training iter 350, batch loss 0.1721, batch acc 0.9504
14:58:08.266   Training iter 400, batch loss 0.1695, batch acc 0.9522
14:58:08.787   Training iter 450, batch loss 0.1563, batch acc 0.9546
14:58:09.295   Training iter 500, batch loss 0.1800, batch acc 0.9478
14:58:09.780   Training iter 550, batch loss 0.1730, batch acc 0.9476
14:58:10.285   Training iter 600, batch loss 0.1885, batch acc 0.9462
14:58:10.287 Training @ 152 epoch...
14:58:10.825   Training iter 50, batch loss 0.1606, batch acc 0.9488
14:58:11.361   Training iter 100, batch loss 0.1596, batch acc 0.9516
14:58:11.866   Training iter 150, batch loss 0.1599, batch acc 0.9536
14:58:12.389   Training iter 200, batch loss 0.1633, batch acc 0.9484
14:58:12.910   Training iter 250, batch loss 0.1745, batch acc 0.9448
14:58:13.421   Training iter 300, batch loss 0.1873, batch acc 0.9436
14:58:13.946   Training iter 350, batch loss 0.1773, batch acc 0.9456
14:58:14.461   Training iter 400, batch loss 0.1687, batch acc 0.9520
14:58:14.979   Training iter 450, batch loss 0.1713, batch acc 0.9496
14:58:15.506   Training iter 500, batch loss 0.1711, batch acc 0.9502
14:58:16.040   Training iter 550, batch loss 0.1655, batch acc 0.9504
14:58:16.570   Training iter 600, batch loss 0.1637, batch acc 0.9518
14:58:16.571 Training @ 153 epoch...
14:58:17.135   Training iter 50, batch loss 0.1716, batch acc 0.9462
14:58:17.692   Training iter 100, batch loss 0.1635, batch acc 0.9532
14:58:18.246   Training iter 150, batch loss 0.1751, batch acc 0.9486
14:58:18.793   Training iter 200, batch loss 0.1561, batch acc 0.9518
14:58:19.340   Training iter 250, batch loss 0.1615, batch acc 0.9478
14:58:19.912   Training iter 300, batch loss 0.1734, batch acc 0.9506
14:58:20.482   Training iter 350, batch loss 0.1663, batch acc 0.9510
14:58:21.041   Training iter 400, batch loss 0.1663, batch acc 0.9490
14:58:21.612   Training iter 450, batch loss 0.1757, batch acc 0.9478
14:58:22.175   Training iter 500, batch loss 0.1815, batch acc 0.9458
14:58:22.717   Training iter 550, batch loss 0.1696, batch acc 0.9514
14:58:23.241   Training iter 600, batch loss 0.1446, batch acc 0.9554
14:58:23.243 Training @ 154 epoch...
14:58:23.766   Training iter 50, batch loss 0.1631, batch acc 0.9516
14:58:24.299   Training iter 100, batch loss 0.1637, batch acc 0.9512
14:58:24.836   Training iter 150, batch loss 0.1714, batch acc 0.9498
14:58:25.383   Training iter 200, batch loss 0.1575, batch acc 0.9528
14:58:25.905   Training iter 250, batch loss 0.1530, batch acc 0.9516
14:58:26.424   Training iter 300, batch loss 0.1690, batch acc 0.9496
14:58:26.942   Training iter 350, batch loss 0.1832, batch acc 0.9446
14:58:27.471   Training iter 400, batch loss 0.1578, batch acc 0.9514
14:58:27.990   Training iter 450, batch loss 0.1779, batch acc 0.9462
14:58:28.506   Training iter 500, batch loss 0.1891, batch acc 0.9460
14:58:28.981   Training iter 550, batch loss 0.1727, batch acc 0.9464
14:58:29.485   Training iter 600, batch loss 0.1652, batch acc 0.9490
14:58:29.486 Training @ 155 epoch...
14:58:29.984   Training iter 50, batch loss 0.1481, batch acc 0.9558
14:58:30.506   Training iter 100, batch loss 0.1564, batch acc 0.9590
14:58:31.028   Training iter 150, batch loss 0.1772, batch acc 0.9460
14:58:31.531   Training iter 200, batch loss 0.1709, batch acc 0.9526
14:58:32.030   Training iter 250, batch loss 0.1640, batch acc 0.9504
14:58:32.538   Training iter 300, batch loss 0.1736, batch acc 0.9510
14:58:33.078   Training iter 350, batch loss 0.1812, batch acc 0.9462
14:58:33.631   Training iter 400, batch loss 0.1684, batch acc 0.9496
14:58:34.186   Training iter 450, batch loss 0.1670, batch acc 0.9476
14:58:34.754   Training iter 500, batch loss 0.1618, batch acc 0.9510
14:58:35.278   Training iter 550, batch loss 0.1711, batch acc 0.9514
14:58:35.773   Training iter 600, batch loss 0.1658, batch acc 0.9500
14:58:35.775 Testing @ 155 epoch...
14:58:35.821     Testing, total mean loss 0.20426, total acc 0.94170
14:58:35.821 Training @ 156 epoch...
14:58:36.320   Training iter 50, batch loss 0.1630, batch acc 0.9534
14:58:36.801   Training iter 100, batch loss 0.1693, batch acc 0.9492
14:58:37.294   Training iter 150, batch loss 0.1677, batch acc 0.9496
14:58:37.784   Training iter 200, batch loss 0.1880, batch acc 0.9428
14:58:38.288   Training iter 250, batch loss 0.1543, batch acc 0.9528
14:58:38.794   Training iter 300, batch loss 0.1746, batch acc 0.9444
14:58:39.282   Training iter 350, batch loss 0.1560, batch acc 0.9550
14:58:39.774   Training iter 400, batch loss 0.1618, batch acc 0.9514
14:58:40.255   Training iter 450, batch loss 0.1662, batch acc 0.9518
14:58:40.747   Training iter 500, batch loss 0.1754, batch acc 0.9500
14:58:41.238   Training iter 550, batch loss 0.1618, batch acc 0.9490
14:58:41.735   Training iter 600, batch loss 0.1705, batch acc 0.9456
14:58:41.736 Training @ 157 epoch...
14:58:42.234   Training iter 50, batch loss 0.1744, batch acc 0.9468
14:58:42.704   Training iter 100, batch loss 0.1526, batch acc 0.9532
14:58:43.173   Training iter 150, batch loss 0.1521, batch acc 0.9532
14:58:43.638   Training iter 200, batch loss 0.1619, batch acc 0.9514
14:58:44.096   Training iter 250, batch loss 0.1788, batch acc 0.9456
14:58:44.558   Training iter 300, batch loss 0.1915, batch acc 0.9448
14:58:45.032   Training iter 350, batch loss 0.1604, batch acc 0.9528
14:58:45.508   Training iter 400, batch loss 0.1835, batch acc 0.9456
14:58:45.960   Training iter 450, batch loss 0.1611, batch acc 0.9510
14:58:46.434   Training iter 500, batch loss 0.1700, batch acc 0.9504
14:58:46.912   Training iter 550, batch loss 0.1747, batch acc 0.9478
14:58:47.390   Training iter 600, batch loss 0.1779, batch acc 0.9430
14:58:47.391 Training @ 158 epoch...
14:58:47.868   Training iter 50, batch loss 0.1681, batch acc 0.9498
14:58:48.338   Training iter 100, batch loss 0.1448, batch acc 0.9544
14:58:48.837   Training iter 150, batch loss 0.1673, batch acc 0.9538
14:58:49.351   Training iter 200, batch loss 0.1702, batch acc 0.9486
14:58:49.863   Training iter 250, batch loss 0.1573, batch acc 0.9528
14:58:50.374   Training iter 300, batch loss 0.1838, batch acc 0.9430
14:58:50.902   Training iter 350, batch loss 0.1656, batch acc 0.9506
14:58:51.461   Training iter 400, batch loss 0.1598, batch acc 0.9522
14:58:52.023   Training iter 450, batch loss 0.2004, batch acc 0.9426
14:58:52.582   Training iter 500, batch loss 0.1625, batch acc 0.9494
14:58:53.115   Training iter 550, batch loss 0.1672, batch acc 0.9506
14:58:53.657   Training iter 600, batch loss 0.1657, batch acc 0.9482
14:58:53.658 Training @ 159 epoch...
14:58:54.203   Training iter 50, batch loss 0.1448, batch acc 0.9588
14:58:54.737   Training iter 100, batch loss 0.1811, batch acc 0.9476
14:58:55.252   Training iter 150, batch loss 0.1599, batch acc 0.9528
14:58:55.753   Training iter 200, batch loss 0.1561, batch acc 0.9512
14:58:56.266   Training iter 250, batch loss 0.1746, batch acc 0.9464
14:58:56.782   Training iter 300, batch loss 0.1746, batch acc 0.9444
14:58:57.317   Training iter 350, batch loss 0.1705, batch acc 0.9482
14:58:57.844   Training iter 400, batch loss 0.1652, batch acc 0.9510
14:58:58.365   Training iter 450, batch loss 0.1773, batch acc 0.9442
14:58:58.878   Training iter 500, batch loss 0.1719, batch acc 0.9510
14:58:59.390   Training iter 550, batch loss 0.1773, batch acc 0.9480
14:58:59.918   Training iter 600, batch loss 0.1725, batch acc 0.9504
14:58:59.920 Training @ 160 epoch...
14:59:00.483   Training iter 50, batch loss 0.1512, batch acc 0.9566
14:59:01.032   Training iter 100, batch loss 0.1634, batch acc 0.9518
14:59:01.579   Training iter 150, batch loss 0.1694, batch acc 0.9514
14:59:02.129   Training iter 200, batch loss 0.1803, batch acc 0.9482
14:59:02.660   Training iter 250, batch loss 0.1791, batch acc 0.9488
14:59:03.192   Training iter 300, batch loss 0.1639, batch acc 0.9490
14:59:03.717   Training iter 350, batch loss 0.1733, batch acc 0.9460
14:59:04.240   Training iter 400, batch loss 0.1587, batch acc 0.9558
14:59:04.762   Training iter 450, batch loss 0.1830, batch acc 0.9484
14:59:05.300   Training iter 500, batch loss 0.1648, batch acc 0.9480
14:59:05.826   Training iter 550, batch loss 0.1577, batch acc 0.9522
14:59:06.354   Training iter 600, batch loss 0.1659, batch acc 0.9512
14:59:06.356 Testing @ 160 epoch...
14:59:06.400     Testing, total mean loss 0.20473, total acc 0.93920
14:59:06.400 Training @ 161 epoch...
14:59:06.917   Training iter 50, batch loss 0.1657, batch acc 0.9506
14:59:07.434   Training iter 100, batch loss 0.1442, batch acc 0.9562
14:59:07.954   Training iter 150, batch loss 0.1514, batch acc 0.9524
14:59:08.473   Training iter 200, batch loss 0.1627, batch acc 0.9540
14:59:08.993   Training iter 250, batch loss 0.1705, batch acc 0.9466
14:59:09.512   Training iter 300, batch loss 0.1541, batch acc 0.9592
14:59:10.024   Training iter 350, batch loss 0.1758, batch acc 0.9444
14:59:10.535   Training iter 400, batch loss 0.1667, batch acc 0.9476
14:59:11.041   Training iter 450, batch loss 0.2138, batch acc 0.9372
14:59:11.531   Training iter 500, batch loss 0.1696, batch acc 0.9478
14:59:12.033   Training iter 550, batch loss 0.1719, batch acc 0.9448
14:59:12.552   Training iter 600, batch loss 0.1809, batch acc 0.9458
14:59:12.554 Training @ 162 epoch...
14:59:13.071   Training iter 50, batch loss 0.1748, batch acc 0.9514
14:59:13.570   Training iter 100, batch loss 0.1603, batch acc 0.9526
14:59:14.054   Training iter 150, batch loss 0.1561, batch acc 0.9508
14:59:14.504   Training iter 200, batch loss 0.1561, batch acc 0.9516
14:59:14.955   Training iter 250, batch loss 0.1711, batch acc 0.9466
14:59:15.414   Training iter 300, batch loss 0.1664, batch acc 0.9500
14:59:15.878   Training iter 350, batch loss 0.1592, batch acc 0.9508
14:59:16.384   Training iter 400, batch loss 0.1667, batch acc 0.9496
14:59:16.864   Training iter 450, batch loss 0.1700, batch acc 0.9476
14:59:17.329   Training iter 500, batch loss 0.1814, batch acc 0.9464
14:59:17.816   Training iter 550, batch loss 0.1683, batch acc 0.9466
14:59:18.295   Training iter 600, batch loss 0.1825, batch acc 0.9452
14:59:18.298 Training @ 163 epoch...
14:59:18.818   Training iter 50, batch loss 0.1504, batch acc 0.9562
14:59:19.338   Training iter 100, batch loss 0.1532, batch acc 0.9534
14:59:19.884   Training iter 150, batch loss 0.1809, batch acc 0.9460
14:59:20.416   Training iter 200, batch loss 0.1725, batch acc 0.9516
14:59:20.956   Training iter 250, batch loss 0.1594, batch acc 0.9510
14:59:21.513   Training iter 300, batch loss 0.1572, batch acc 0.9512
14:59:22.074   Training iter 350, batch loss 0.1713, batch acc 0.9490
14:59:22.602   Training iter 400, batch loss 0.1715, batch acc 0.9430
14:59:23.121   Training iter 450, batch loss 0.1606, batch acc 0.9526
14:59:23.635   Training iter 500, batch loss 0.1652, batch acc 0.9514
14:59:24.143   Training iter 550, batch loss 0.1740, batch acc 0.9510
14:59:24.654   Training iter 600, batch loss 0.1933, batch acc 0.9426
14:59:24.656 Training @ 164 epoch...
14:59:25.172   Training iter 50, batch loss 0.1666, batch acc 0.9462
14:59:25.680   Training iter 100, batch loss 0.1605, batch acc 0.9544
14:59:26.189   Training iter 150, batch loss 0.1896, batch acc 0.9478
14:59:26.702   Training iter 200, batch loss 0.1586, batch acc 0.9510
14:59:27.220   Training iter 250, batch loss 0.1544, batch acc 0.9526
14:59:27.750   Training iter 300, batch loss 0.1683, batch acc 0.9450
14:59:28.285   Training iter 350, batch loss 0.1593, batch acc 0.9516
14:59:28.813   Training iter 400, batch loss 0.1545, batch acc 0.9514
14:59:29.314   Training iter 450, batch loss 0.1751, batch acc 0.9468
14:59:29.809   Training iter 500, batch loss 0.1708, batch acc 0.9512
14:59:30.327   Training iter 550, batch loss 0.1885, batch acc 0.9458
14:59:30.854   Training iter 600, batch loss 0.1586, batch acc 0.9542
14:59:30.856 Training @ 165 epoch...
14:59:31.379   Training iter 50, batch loss 0.1726, batch acc 0.9488
14:59:31.899   Training iter 100, batch loss 0.1694, batch acc 0.9524
14:59:32.416   Training iter 150, batch loss 0.1651, batch acc 0.9498
14:59:32.915   Training iter 200, batch loss 0.1549, batch acc 0.9556
14:59:33.432   Training iter 250, batch loss 0.1683, batch acc 0.9500
14:59:33.947   Training iter 300, batch loss 0.1527, batch acc 0.9552
14:59:34.452   Training iter 350, batch loss 0.1651, batch acc 0.9488
14:59:34.957   Training iter 400, batch loss 0.1791, batch acc 0.9476
14:59:35.483   Training iter 450, batch loss 0.1688, batch acc 0.9526
14:59:36.004   Training iter 500, batch loss 0.1765, batch acc 0.9466
14:59:36.501   Training iter 550, batch loss 0.1609, batch acc 0.9510
14:59:37.059   Training iter 600, batch loss 0.1750, batch acc 0.9464
14:59:37.061 Testing @ 165 epoch...
14:59:37.111     Testing, total mean loss 0.21763, total acc 0.93320
14:59:37.111 Training @ 166 epoch...
14:59:37.707   Training iter 50, batch loss 0.1568, batch acc 0.9494
14:59:38.228   Training iter 100, batch loss 0.1777, batch acc 0.9508
14:59:38.748   Training iter 150, batch loss 0.1815, batch acc 0.9438
14:59:39.262   Training iter 200, batch loss 0.1576, batch acc 0.9530
14:59:39.783   Training iter 250, batch loss 0.1674, batch acc 0.9466
14:59:40.306   Training iter 300, batch loss 0.1596, batch acc 0.9514
14:59:40.813   Training iter 350, batch loss 0.1548, batch acc 0.9546
14:59:41.313   Training iter 400, batch loss 0.1768, batch acc 0.9488
14:59:41.817   Training iter 450, batch loss 0.1736, batch acc 0.9472
14:59:42.320   Training iter 500, batch loss 0.1649, batch acc 0.9500
14:59:42.815   Training iter 550, batch loss 0.1624, batch acc 0.9512
14:59:43.310   Training iter 600, batch loss 0.1703, batch acc 0.9494
14:59:43.312 Training @ 167 epoch...
14:59:43.814   Training iter 50, batch loss 0.1504, batch acc 0.9556
14:59:44.332   Training iter 100, batch loss 0.1470, batch acc 0.9542
14:59:44.854   Training iter 150, batch loss 0.1726, batch acc 0.9486
14:59:45.372   Training iter 200, batch loss 0.1659, batch acc 0.9542
14:59:45.884   Training iter 250, batch loss 0.1725, batch acc 0.9484
14:59:46.391   Training iter 300, batch loss 0.1543, batch acc 0.9496
14:59:46.898   Training iter 350, batch loss 0.1768, batch acc 0.9486
14:59:47.400   Training iter 400, batch loss 0.1866, batch acc 0.9448
14:59:47.905   Training iter 450, batch loss 0.1700, batch acc 0.9510
14:59:48.413   Training iter 500, batch loss 0.1705, batch acc 0.9478
14:59:48.917   Training iter 550, batch loss 0.1722, batch acc 0.9482
14:59:49.419   Training iter 600, batch loss 0.1727, batch acc 0.9486
14:59:49.421 Training @ 168 epoch...
14:59:49.935   Training iter 50, batch loss 0.1615, batch acc 0.9490
14:59:50.439   Training iter 100, batch loss 0.1631, batch acc 0.9506
14:59:50.944   Training iter 150, batch loss 0.1761, batch acc 0.9470
14:59:51.490   Training iter 200, batch loss 0.1728, batch acc 0.9446
14:59:52.003   Training iter 250, batch loss 0.1579, batch acc 0.9512
14:59:52.505   Training iter 300, batch loss 0.1791, batch acc 0.9464
14:59:53.006   Training iter 350, batch loss 0.1820, batch acc 0.9470
14:59:53.521   Training iter 400, batch loss 0.1680, batch acc 0.9490
14:59:54.056   Training iter 450, batch loss 0.1694, batch acc 0.9500
14:59:54.620   Training iter 500, batch loss 0.1556, batch acc 0.9532
14:59:55.166   Training iter 550, batch loss 0.1495, batch acc 0.9554
14:59:55.714   Training iter 600, batch loss 0.1700, batch acc 0.9510
14:59:55.716 Training @ 169 epoch...
14:59:56.257   Training iter 50, batch loss 0.1610, batch acc 0.9552
14:59:56.793   Training iter 100, batch loss 0.1508, batch acc 0.9534
14:59:57.336   Training iter 150, batch loss 0.1579, batch acc 0.9524
14:59:57.865   Training iter 200, batch loss 0.1735, batch acc 0.9512
14:59:58.399   Training iter 250, batch loss 0.1753, batch acc 0.9472
14:59:58.898   Training iter 300, batch loss 0.1591, batch acc 0.9560
14:59:59.426   Training iter 350, batch loss 0.1740, batch acc 0.9524
14:59:59.933   Training iter 400, batch loss 0.1712, batch acc 0.9508
15:00:00.471   Training iter 450, batch loss 0.1839, batch acc 0.9462
15:00:00.993   Training iter 500, batch loss 0.1593, batch acc 0.9500
15:00:01.535   Training iter 550, batch loss 0.1703, batch acc 0.9484
15:00:02.110   Training iter 600, batch loss 0.1604, batch acc 0.9510
15:00:02.112 Training @ 170 epoch...
15:00:02.673   Training iter 50, batch loss 0.1551, batch acc 0.9552
15:00:03.241   Training iter 100, batch loss 0.1538, batch acc 0.9512
15:00:03.782   Training iter 150, batch loss 0.1697, batch acc 0.9504
15:00:04.309   Training iter 200, batch loss 0.1760, batch acc 0.9470
15:00:04.847   Training iter 250, batch loss 0.1722, batch acc 0.9464
15:00:05.388   Training iter 300, batch loss 0.1910, batch acc 0.9410
15:00:05.924   Training iter 350, batch loss 0.1457, batch acc 0.9540
15:00:06.464   Training iter 400, batch loss 0.1607, batch acc 0.9536
15:00:06.989   Training iter 450, batch loss 0.1647, batch acc 0.9498
15:00:07.524   Training iter 500, batch loss 0.1477, batch acc 0.9556
15:00:08.048   Training iter 550, batch loss 0.1802, batch acc 0.9450
15:00:08.586   Training iter 600, batch loss 0.1889, batch acc 0.9450
15:00:08.588 Testing @ 170 epoch...
15:00:08.632     Testing, total mean loss 0.20844, total acc 0.93810
15:00:08.632 Training @ 171 epoch...
15:00:09.193   Training iter 50, batch loss 0.1635, batch acc 0.9478
15:00:09.752   Training iter 100, batch loss 0.1781, batch acc 0.9444
15:00:10.327   Training iter 150, batch loss 0.1701, batch acc 0.9476
15:00:10.891   Training iter 200, batch loss 0.1647, batch acc 0.9478
15:00:11.448   Training iter 250, batch loss 0.1631, batch acc 0.9540
15:00:12.012   Training iter 300, batch loss 0.1637, batch acc 0.9534
15:00:12.576   Training iter 350, batch loss 0.1709, batch acc 0.9496
15:00:13.150   Training iter 400, batch loss 0.1632, batch acc 0.9524
15:00:13.720   Training iter 450, batch loss 0.1648, batch acc 0.9502
15:00:14.279   Training iter 500, batch loss 0.1548, batch acc 0.9502
15:00:14.830   Training iter 550, batch loss 0.1745, batch acc 0.9486
15:00:15.372   Training iter 600, batch loss 0.1771, batch acc 0.9452
15:00:15.373 Training @ 172 epoch...
15:00:15.956   Training iter 50, batch loss 0.1647, batch acc 0.9528
15:00:16.528   Training iter 100, batch loss 0.1490, batch acc 0.9562
15:00:17.079   Training iter 150, batch loss 0.1598, batch acc 0.9478
15:00:17.632   Training iter 200, batch loss 0.1627, batch acc 0.9546
15:00:18.177   Training iter 250, batch loss 0.1683, batch acc 0.9472
15:00:18.712   Training iter 300, batch loss 0.1751, batch acc 0.9474
15:00:19.243   Training iter 350, batch loss 0.1668, batch acc 0.9512
15:00:19.783   Training iter 400, batch loss 0.1765, batch acc 0.9450
15:00:20.320   Training iter 450, batch loss 0.1933, batch acc 0.9436
15:00:20.887   Training iter 500, batch loss 0.1606, batch acc 0.9530
15:00:21.428   Training iter 550, batch loss 0.1738, batch acc 0.9502
15:00:21.981   Training iter 600, batch loss 0.1716, batch acc 0.9490
15:00:21.983 Training @ 173 epoch...
15:00:22.536   Training iter 50, batch loss 0.1798, batch acc 0.9460
15:00:23.094   Training iter 100, batch loss 0.1705, batch acc 0.9510
15:00:23.646   Training iter 150, batch loss 0.1695, batch acc 0.9474
15:00:24.201   Training iter 200, batch loss 0.1727, batch acc 0.9498
15:00:24.799   Training iter 250, batch loss 0.1592, batch acc 0.9542
15:00:25.382   Training iter 300, batch loss 0.1613, batch acc 0.9514
15:00:25.943   Training iter 350, batch loss 0.1689, batch acc 0.9504
15:00:26.471   Training iter 400, batch loss 0.1653, batch acc 0.9492
15:00:26.998   Training iter 450, batch loss 0.1822, batch acc 0.9472
15:00:27.550   Training iter 500, batch loss 0.1603, batch acc 0.9528
15:00:28.096   Training iter 550, batch loss 0.1511, batch acc 0.9532
15:00:28.626   Training iter 600, batch loss 0.1680, batch acc 0.9506
15:00:28.628 Training @ 174 epoch...
15:00:29.159   Training iter 50, batch loss 0.1666, batch acc 0.9486
15:00:29.672   Training iter 100, batch loss 0.1587, batch acc 0.9538
15:00:30.197   Training iter 150, batch loss 0.1634, batch acc 0.9504
15:00:30.728   Training iter 200, batch loss 0.1797, batch acc 0.9504
15:00:31.244   Training iter 250, batch loss 0.1658, batch acc 0.9508
15:00:31.747   Training iter 300, batch loss 0.1501, batch acc 0.9538
15:00:32.258   Training iter 350, batch loss 0.1654, batch acc 0.9484
15:00:32.766   Training iter 400, batch loss 0.1663, batch acc 0.9500
15:00:33.283   Training iter 450, batch loss 0.1670, batch acc 0.9504
15:00:33.790   Training iter 500, batch loss 0.1828, batch acc 0.9428
15:00:34.313   Training iter 550, batch loss 0.1746, batch acc 0.9448
15:00:34.853   Training iter 600, batch loss 0.1697, batch acc 0.9484
15:00:34.855 Training @ 175 epoch...
15:00:35.408   Training iter 50, batch loss 0.1436, batch acc 0.9574
15:00:35.935   Training iter 100, batch loss 0.1606, batch acc 0.9534
15:00:36.444   Training iter 150, batch loss 0.1628, batch acc 0.9538
15:00:36.967   Training iter 200, batch loss 0.1605, batch acc 0.9508
15:00:37.501   Training iter 250, batch loss 0.1736, batch acc 0.9454
15:00:38.035   Training iter 300, batch loss 0.1659, batch acc 0.9494
15:00:38.556   Training iter 350, batch loss 0.1563, batch acc 0.9500
15:00:39.107   Training iter 400, batch loss 0.1748, batch acc 0.9504
15:00:39.655   Training iter 450, batch loss 0.1627, batch acc 0.9504
15:00:40.232   Training iter 500, batch loss 0.1881, batch acc 0.9446
15:00:40.804   Training iter 550, batch loss 0.1744, batch acc 0.9476
15:00:41.386   Training iter 600, batch loss 0.1718, batch acc 0.9492
15:00:41.388 Testing @ 175 epoch...
15:00:41.439     Testing, total mean loss 0.20695, total acc 0.93790
15:00:41.439 Training @ 176 epoch...
15:00:42.007   Training iter 50, batch loss 0.1700, batch acc 0.9532
15:00:42.571   Training iter 100, batch loss 0.1615, batch acc 0.9512
15:00:43.138   Training iter 150, batch loss 0.1851, batch acc 0.9482
15:00:43.697   Training iter 200, batch loss 0.1655, batch acc 0.9466
15:00:44.204   Training iter 250, batch loss 0.1744, batch acc 0.9478
15:00:44.739   Training iter 300, batch loss 0.1616, batch acc 0.9524
15:00:45.287   Training iter 350, batch loss 0.1693, batch acc 0.9500
15:00:45.837   Training iter 400, batch loss 0.1568, batch acc 0.9526
15:00:46.398   Training iter 450, batch loss 0.1559, batch acc 0.9538
15:00:46.950   Training iter 500, batch loss 0.1661, batch acc 0.9490
15:00:47.501   Training iter 550, batch loss 0.1586, batch acc 0.9498
15:00:48.047   Training iter 600, batch loss 0.1721, batch acc 0.9466
15:00:48.049 Training @ 177 epoch...
15:00:48.622   Training iter 50, batch loss 0.1719, batch acc 0.9498
15:00:49.187   Training iter 100, batch loss 0.1843, batch acc 0.9472
15:00:49.741   Training iter 150, batch loss 0.1560, batch acc 0.9556
15:00:50.284   Training iter 200, batch loss 0.1748, batch acc 0.9474
15:00:50.838   Training iter 250, batch loss 0.1616, batch acc 0.9492
15:00:51.381   Training iter 300, batch loss 0.1632, batch acc 0.9516
15:00:51.927   Training iter 350, batch loss 0.1542, batch acc 0.9542
15:00:52.451   Training iter 400, batch loss 0.1663, batch acc 0.9502
15:00:52.940   Training iter 450, batch loss 0.1793, batch acc 0.9488
15:00:53.426   Training iter 500, batch loss 0.1439, batch acc 0.9544
15:00:53.898   Training iter 550, batch loss 0.1655, batch acc 0.9502
15:00:54.384   Training iter 600, batch loss 0.1798, batch acc 0.9484
15:00:54.386 Training @ 178 epoch...
15:00:54.852   Training iter 50, batch loss 0.1574, batch acc 0.9518
15:00:55.349   Training iter 100, batch loss 0.1788, batch acc 0.9468
15:00:55.801   Training iter 150, batch loss 0.1725, batch acc 0.9468
15:00:56.294   Training iter 200, batch loss 0.1692, batch acc 0.9468
15:00:56.774   Training iter 250, batch loss 0.1576, batch acc 0.9522
15:00:57.245   Training iter 300, batch loss 0.1692, batch acc 0.9506
15:00:57.730   Training iter 350, batch loss 0.1736, batch acc 0.9468
15:00:58.244   Training iter 400, batch loss 0.1755, batch acc 0.9436
15:00:58.747   Training iter 450, batch loss 0.1670, batch acc 0.9484
15:00:59.261   Training iter 500, batch loss 0.1554, batch acc 0.9508
15:00:59.766   Training iter 550, batch loss 0.1758, batch acc 0.9482
15:01:00.277   Training iter 600, batch loss 0.1537, batch acc 0.9574
15:01:00.279 Training @ 179 epoch...
15:01:00.798   Training iter 50, batch loss 0.1597, batch acc 0.9532
15:01:01.321   Training iter 100, batch loss 0.1717, batch acc 0.9506
15:01:01.864   Training iter 150, batch loss 0.1675, batch acc 0.9478
15:01:02.391   Training iter 200, batch loss 0.1663, batch acc 0.9494
15:01:02.895   Training iter 250, batch loss 0.1656, batch acc 0.9488
15:01:03.439   Training iter 300, batch loss 0.1449, batch acc 0.9534
15:01:03.984   Training iter 350, batch loss 0.1556, batch acc 0.9524
15:01:04.558   Training iter 400, batch loss 0.1781, batch acc 0.9482
15:01:05.126   Training iter 450, batch loss 0.1779, batch acc 0.9462
15:01:05.689   Training iter 500, batch loss 0.1678, batch acc 0.9496
15:01:06.234   Training iter 550, batch loss 0.1733, batch acc 0.9532
15:01:06.775   Training iter 600, batch loss 0.1822, batch acc 0.9460
15:01:06.776 Training @ 180 epoch...
15:01:07.317   Training iter 50, batch loss 0.1859, batch acc 0.9464
15:01:07.847   Training iter 100, batch loss 0.1696, batch acc 0.9506
15:01:08.374   Training iter 150, batch loss 0.1652, batch acc 0.9498
15:01:08.871   Training iter 200, batch loss 0.1640, batch acc 0.9494
15:01:09.366   Training iter 250, batch loss 0.1664, batch acc 0.9520
15:01:09.855   Training iter 300, batch loss 0.1594, batch acc 0.9468
15:01:10.362   Training iter 350, batch loss 0.1803, batch acc 0.9472
15:01:10.864   Training iter 400, batch loss 0.1592, batch acc 0.9530
15:01:11.372   Training iter 450, batch loss 0.1647, batch acc 0.9520
15:01:11.896   Training iter 500, batch loss 0.1536, batch acc 0.9534
15:01:12.412   Training iter 550, batch loss 0.1725, batch acc 0.9476
15:01:12.929   Training iter 600, batch loss 0.1747, batch acc 0.9426
15:01:12.930 Testing @ 180 epoch...
15:01:12.975     Testing, total mean loss 0.21207, total acc 0.93790
15:01:12.975 Training @ 181 epoch...
15:01:13.482   Training iter 50, batch loss 0.1664, batch acc 0.9536
15:01:13.977   Training iter 100, batch loss 0.1588, batch acc 0.9520
15:01:14.474   Training iter 150, batch loss 0.1726, batch acc 0.9488
15:01:14.951   Training iter 200, batch loss 0.1518, batch acc 0.9552
15:01:15.433   Training iter 250, batch loss 0.1590, batch acc 0.9540
15:01:15.960   Training iter 300, batch loss 0.1795, batch acc 0.9464
15:01:16.539   Training iter 350, batch loss 0.1669, batch acc 0.9488
15:01:17.114   Training iter 400, batch loss 0.1652, batch acc 0.9492
15:01:17.678   Training iter 450, batch loss 0.1648, batch acc 0.9480
15:01:18.200   Training iter 500, batch loss 0.1842, batch acc 0.9468
15:01:18.727   Training iter 550, batch loss 0.1645, batch acc 0.9508
15:01:19.273   Training iter 600, batch loss 0.1719, batch acc 0.9490
15:01:19.275 Training @ 182 epoch...
15:01:19.819   Training iter 50, batch loss 0.1712, batch acc 0.9516
15:01:20.326   Training iter 100, batch loss 0.1624, batch acc 0.9532
15:01:20.815   Training iter 150, batch loss 0.1696, batch acc 0.9466
15:01:21.309   Training iter 200, batch loss 0.1584, batch acc 0.9558
15:01:21.821   Training iter 250, batch loss 0.1768, batch acc 0.9462
15:01:22.342   Training iter 300, batch loss 0.1539, batch acc 0.9536
15:01:22.880   Training iter 350, batch loss 0.1696, batch acc 0.9464
15:01:23.414   Training iter 400, batch loss 0.1893, batch acc 0.9426
15:01:23.930   Training iter 450, batch loss 0.1690, batch acc 0.9466
15:01:24.441   Training iter 500, batch loss 0.1716, batch acc 0.9472
15:01:24.971   Training iter 550, batch loss 0.1474, batch acc 0.9536
15:01:25.496   Training iter 600, batch loss 0.1726, batch acc 0.9492
15:01:25.498 Training @ 183 epoch...
15:01:26.028   Training iter 50, batch loss 0.1581, batch acc 0.9540
15:01:26.539   Training iter 100, batch loss 0.1674, batch acc 0.9468
15:01:27.054   Training iter 150, batch loss 0.1697, batch acc 0.9486
15:01:27.566   Training iter 200, batch loss 0.1579, batch acc 0.9552
15:01:28.080   Training iter 250, batch loss 0.1596, batch acc 0.9542
15:01:28.606   Training iter 300, batch loss 0.1516, batch acc 0.9568
15:01:29.117   Training iter 350, batch loss 0.1789, batch acc 0.9480
15:01:29.654   Training iter 400, batch loss 0.1679, batch acc 0.9510
15:01:30.195   Training iter 450, batch loss 0.1641, batch acc 0.9532
15:01:30.746   Training iter 500, batch loss 0.1627, batch acc 0.9526
15:01:31.266   Training iter 550, batch loss 0.1841, batch acc 0.9474
15:01:31.785   Training iter 600, batch loss 0.1656, batch acc 0.9516
15:01:31.786 Training @ 184 epoch...
15:01:32.331   Training iter 50, batch loss 0.1540, batch acc 0.9548
15:01:32.883   Training iter 100, batch loss 0.1609, batch acc 0.9514
15:01:33.443   Training iter 150, batch loss 0.1599, batch acc 0.9508
15:01:33.991   Training iter 200, batch loss 0.1736, batch acc 0.9496
15:01:34.547   Training iter 250, batch loss 0.1715, batch acc 0.9494
15:01:35.091   Training iter 300, batch loss 0.1634, batch acc 0.9530
15:01:35.609   Training iter 350, batch loss 0.1778, batch acc 0.9450
15:01:36.114   Training iter 400, batch loss 0.1591, batch acc 0.9532
15:01:36.618   Training iter 450, batch loss 0.1744, batch acc 0.9492
15:01:37.131   Training iter 500, batch loss 0.1780, batch acc 0.9456
15:01:37.659   Training iter 550, batch loss 0.1690, batch acc 0.9542
15:01:38.182   Training iter 600, batch loss 0.1683, batch acc 0.9482
15:01:38.184 Training @ 185 epoch...
15:01:38.711   Training iter 50, batch loss 0.1404, batch acc 0.9586
15:01:39.223   Training iter 100, batch loss 0.1584, batch acc 0.9510
15:01:39.758   Training iter 150, batch loss 0.1594, batch acc 0.9536
15:01:40.268   Training iter 200, batch loss 0.1674, batch acc 0.9510
15:01:40.747   Training iter 250, batch loss 0.1654, batch acc 0.9506
15:01:41.236   Training iter 300, batch loss 0.1612, batch acc 0.9530
15:01:41.726   Training iter 350, batch loss 0.1711, batch acc 0.9520
15:01:42.245   Training iter 400, batch loss 0.1690, batch acc 0.9490
15:01:42.765   Training iter 450, batch loss 0.1756, batch acc 0.9474
15:01:43.295   Training iter 500, batch loss 0.1680, batch acc 0.9514
15:01:43.803   Training iter 550, batch loss 0.1760, batch acc 0.9468
15:01:44.303   Training iter 600, batch loss 0.1839, batch acc 0.9490
15:01:44.305 Testing @ 185 epoch...
15:01:44.349     Testing, total mean loss 0.22901, total acc 0.93350
15:01:44.349 Training @ 186 epoch...
15:01:44.875   Training iter 50, batch loss 0.1604, batch acc 0.9528
15:01:45.419   Training iter 100, batch loss 0.1686, batch acc 0.9512
15:01:45.966   Training iter 150, batch loss 0.1784, batch acc 0.9460
15:01:46.509   Training iter 200, batch loss 0.1535, batch acc 0.9516
15:01:47.066   Training iter 250, batch loss 0.1561, batch acc 0.9506
15:01:47.592   Training iter 300, batch loss 0.1506, batch acc 0.9530
15:01:48.103   Training iter 350, batch loss 0.1652, batch acc 0.9506
15:01:48.632   Training iter 400, batch loss 0.1633, batch acc 0.9494
15:01:49.145   Training iter 450, batch loss 0.1977, batch acc 0.9408
15:01:49.669   Training iter 500, batch loss 0.1770, batch acc 0.9478
15:01:50.188   Training iter 550, batch loss 0.1708, batch acc 0.9478
15:01:50.706   Training iter 600, batch loss 0.1692, batch acc 0.9506
15:01:50.708 Training @ 187 epoch...
15:01:51.213   Training iter 50, batch loss 0.1532, batch acc 0.9526
15:01:51.730   Training iter 100, batch loss 0.1821, batch acc 0.9448
15:01:52.255   Training iter 150, batch loss 0.1570, batch acc 0.9540
15:01:52.788   Training iter 200, batch loss 0.1687, batch acc 0.9484
15:01:53.326   Training iter 250, batch loss 0.1682, batch acc 0.9492
15:01:53.838   Training iter 300, batch loss 0.1494, batch acc 0.9530
15:01:54.361   Training iter 350, batch loss 0.1595, batch acc 0.9520
15:01:54.880   Training iter 400, batch loss 0.1625, batch acc 0.9544
15:01:55.420   Training iter 450, batch loss 0.1612, batch acc 0.9536
15:01:55.934   Training iter 500, batch loss 0.1709, batch acc 0.9472
15:01:56.449   Training iter 550, batch loss 0.1664, batch acc 0.9486
15:01:56.966   Training iter 600, batch loss 0.2005, batch acc 0.9452
15:01:56.967 Training @ 188 epoch...
15:01:57.513   Training iter 50, batch loss 0.1547, batch acc 0.9546
15:01:58.050   Training iter 100, batch loss 0.1666, batch acc 0.9536
15:01:58.562   Training iter 150, batch loss 0.1672, batch acc 0.9490
15:01:59.073   Training iter 200, batch loss 0.1547, batch acc 0.9562
15:01:59.591   Training iter 250, batch loss 0.1662, batch acc 0.9514
15:02:00.108   Training iter 300, batch loss 0.1730, batch acc 0.9480
15:02:00.617   Training iter 350, batch loss 0.1720, batch acc 0.9494
15:02:01.135   Training iter 400, batch loss 0.1668, batch acc 0.9494
15:02:01.668   Training iter 450, batch loss 0.1823, batch acc 0.9422
15:02:02.248   Training iter 500, batch loss 0.1795, batch acc 0.9512
15:02:02.807   Training iter 550, batch loss 0.1518, batch acc 0.9506
15:02:03.377   Training iter 600, batch loss 0.1658, batch acc 0.9510
15:02:03.379 Training @ 189 epoch...
15:02:03.949   Training iter 50, batch loss 0.1644, batch acc 0.9510
15:02:04.515   Training iter 100, batch loss 0.1467, batch acc 0.9580
15:02:05.078   Training iter 150, batch loss 0.1553, batch acc 0.9524
15:02:05.661   Training iter 200, batch loss 0.1667, batch acc 0.9476
15:02:06.236   Training iter 250, batch loss 0.1759, batch acc 0.9446
15:02:06.798   Training iter 300, batch loss 0.1590, batch acc 0.9536
15:02:07.354   Training iter 350, batch loss 0.1739, batch acc 0.9466
15:02:07.914   Training iter 400, batch loss 0.1629, batch acc 0.9534
15:02:08.449   Training iter 450, batch loss 0.1680, batch acc 0.9494
15:02:08.968   Training iter 500, batch loss 0.1814, batch acc 0.9440
15:02:09.495   Training iter 550, batch loss 0.1785, batch acc 0.9462
15:02:10.024   Training iter 600, batch loss 0.1764, batch acc 0.9476
15:02:10.026 Training @ 190 epoch...
15:02:10.576   Training iter 50, batch loss 0.1479, batch acc 0.9588
15:02:11.098   Training iter 100, batch loss 0.1553, batch acc 0.9492
15:02:11.637   Training iter 150, batch loss 0.1746, batch acc 0.9448
15:02:12.172   Training iter 200, batch loss 0.1781, batch acc 0.9440
15:02:12.702   Training iter 250, batch loss 0.1523, batch acc 0.9530
15:02:13.268   Training iter 300, batch loss 0.1763, batch acc 0.9498
15:02:13.831   Training iter 350, batch loss 0.1516, batch acc 0.9526
15:02:14.392   Training iter 400, batch loss 0.1682, batch acc 0.9512
15:02:14.942   Training iter 450, batch loss 0.1662, batch acc 0.9474
15:02:15.480   Training iter 500, batch loss 0.1725, batch acc 0.9488
15:02:16.009   Training iter 550, batch loss 0.1907, batch acc 0.9432
15:02:16.502   Training iter 600, batch loss 0.1716, batch acc 0.9490
15:02:16.504 Testing @ 190 epoch...
15:02:16.556     Testing, total mean loss 0.22618, total acc 0.93520
15:02:16.556 Training @ 191 epoch...
15:02:17.057   Training iter 50, batch loss 0.1586, batch acc 0.9530
15:02:17.543   Training iter 100, batch loss 0.1527, batch acc 0.9540
15:02:18.104   Training iter 150, batch loss 0.1736, batch acc 0.9496
15:02:18.813   Training iter 200, batch loss 0.1484, batch acc 0.9528
15:02:19.380   Training iter 250, batch loss 0.1592, batch acc 0.9540
15:02:19.919   Training iter 300, batch loss 0.1694, batch acc 0.9474
15:02:20.455   Training iter 350, batch loss 0.1658, batch acc 0.9504
15:02:20.988   Training iter 400, batch loss 0.1687, batch acc 0.9494
15:02:21.529   Training iter 450, batch loss 0.1684, batch acc 0.9500
15:02:22.072   Training iter 500, batch loss 0.1622, batch acc 0.9538
15:02:22.616   Training iter 550, batch loss 0.1735, batch acc 0.9506
15:02:23.146   Training iter 600, batch loss 0.1798, batch acc 0.9482
15:02:23.148 Training @ 192 epoch...
15:02:23.685   Training iter 50, batch loss 0.1487, batch acc 0.9560
15:02:24.210   Training iter 100, batch loss 0.1617, batch acc 0.9518
15:02:24.730   Training iter 150, batch loss 0.1604, batch acc 0.9510
15:02:25.247   Training iter 200, batch loss 0.1741, batch acc 0.9494
15:02:25.752   Training iter 250, batch loss 0.1519, batch acc 0.9560
15:02:26.212   Training iter 300, batch loss 0.1710, batch acc 0.9486
15:02:26.720   Training iter 350, batch loss 0.1524, batch acc 0.9552
15:02:27.260   Training iter 400, batch loss 0.1578, batch acc 0.9546
15:02:27.793   Training iter 450, batch loss 0.1761, batch acc 0.9446
15:02:28.318   Training iter 500, batch loss 0.1741, batch acc 0.9504
15:02:28.842   Training iter 550, batch loss 0.1868, batch acc 0.9466
15:02:29.387   Training iter 600, batch loss 0.1893, batch acc 0.9400
15:02:29.389 Training @ 193 epoch...
15:02:29.938   Training iter 50, batch loss 0.1550, batch acc 0.9518
15:02:30.481   Training iter 100, batch loss 0.1476, batch acc 0.9536
15:02:31.026   Training iter 150, batch loss 0.1567, batch acc 0.9514
15:02:31.571   Training iter 200, batch loss 0.1610, batch acc 0.9492
15:02:32.099   Training iter 250, batch loss 0.1683, batch acc 0.9482
15:02:32.608   Training iter 300, batch loss 0.1766, batch acc 0.9460
15:02:33.133   Training iter 350, batch loss 0.1685, batch acc 0.9532
15:02:33.647   Training iter 400, batch loss 0.1703, batch acc 0.9474
15:02:34.169   Training iter 450, batch loss 0.1615, batch acc 0.9514
15:02:34.683   Training iter 500, batch loss 0.1749, batch acc 0.9490
15:02:35.197   Training iter 550, batch loss 0.1677, batch acc 0.9508
15:02:35.721   Training iter 600, batch loss 0.1648, batch acc 0.9498
15:02:35.723 Training @ 194 epoch...
15:02:36.269   Training iter 50, batch loss 0.1657, batch acc 0.9512
15:02:36.795   Training iter 100, batch loss 0.1611, batch acc 0.9476
15:02:37.352   Training iter 150, batch loss 0.1390, batch acc 0.9550
15:02:37.906   Training iter 200, batch loss 0.1770, batch acc 0.9492
15:02:38.417   Training iter 250, batch loss 0.1615, batch acc 0.9528
15:02:38.932   Training iter 300, batch loss 0.1832, batch acc 0.9486
15:02:39.412   Training iter 350, batch loss 0.1588, batch acc 0.9498
15:02:39.899   Training iter 400, batch loss 0.1737, batch acc 0.9446
15:02:40.402   Training iter 450, batch loss 0.1688, batch acc 0.9506
15:02:40.900   Training iter 500, batch loss 0.1651, batch acc 0.9474
15:02:41.439   Training iter 550, batch loss 0.1625, batch acc 0.9546
15:02:41.968   Training iter 600, batch loss 0.1717, batch acc 0.9488
15:02:41.969 Training @ 195 epoch...
15:02:42.510   Training iter 50, batch loss 0.1685, batch acc 0.9500
15:02:43.045   Training iter 100, batch loss 0.1609, batch acc 0.9542
15:02:43.559   Training iter 150, batch loss 0.1670, batch acc 0.9514
15:02:44.094   Training iter 200, batch loss 0.1882, batch acc 0.9432
15:02:44.612   Training iter 250, batch loss 0.1450, batch acc 0.9540
15:02:45.117   Training iter 300, batch loss 0.1662, batch acc 0.9522
15:02:45.628   Training iter 350, batch loss 0.1688, batch acc 0.9476
15:02:46.147   Training iter 400, batch loss 0.1613, batch acc 0.9500
15:02:46.644   Training iter 450, batch loss 0.1626, batch acc 0.9530
15:02:47.181   Training iter 500, batch loss 0.1810, batch acc 0.9446
15:02:47.743   Training iter 550, batch loss 0.1401, batch acc 0.9570
15:02:48.233   Training iter 600, batch loss 0.1771, batch acc 0.9494
15:02:48.234 Testing @ 195 epoch...
15:02:48.278     Testing, total mean loss 0.21065, total acc 0.93880
15:02:48.278 Training @ 196 epoch...
15:02:48.741   Training iter 50, batch loss 0.1547, batch acc 0.9536
15:02:49.238   Training iter 100, batch loss 0.1498, batch acc 0.9548
15:02:49.748   Training iter 150, batch loss 0.1785, batch acc 0.9468
15:02:50.253   Training iter 200, batch loss 0.1597, batch acc 0.9502
15:02:50.761   Training iter 250, batch loss 0.1663, batch acc 0.9506
15:02:51.276   Training iter 300, batch loss 0.1607, batch acc 0.9494
15:02:51.811   Training iter 350, batch loss 0.1630, batch acc 0.9484
15:02:52.341   Training iter 400, batch loss 0.1662, batch acc 0.9494
15:02:52.871   Training iter 450, batch loss 0.1831, batch acc 0.9480
15:02:53.417   Training iter 500, batch loss 0.1701, batch acc 0.9490
15:02:53.943   Training iter 550, batch loss 0.1664, batch acc 0.9540
15:02:54.480   Training iter 600, batch loss 0.1738, batch acc 0.9456
15:02:54.482 Training @ 197 epoch...
15:02:55.031   Training iter 50, batch loss 0.1524, batch acc 0.9576
15:02:55.531   Training iter 100, batch loss 0.1831, batch acc 0.9450
15:02:56.051   Training iter 150, batch loss 0.1661, batch acc 0.9522
15:02:56.598   Training iter 200, batch loss 0.1721, batch acc 0.9476
15:02:57.159   Training iter 250, batch loss 0.1484, batch acc 0.9538
15:02:57.722   Training iter 300, batch loss 0.1777, batch acc 0.9438
15:02:58.304   Training iter 350, batch loss 0.1716, batch acc 0.9488
15:02:58.889   Training iter 400, batch loss 0.1487, batch acc 0.9566
15:02:59.464   Training iter 450, batch loss 0.1470, batch acc 0.9552
15:03:00.032   Training iter 500, batch loss 0.1531, batch acc 0.9568
15:03:00.571   Training iter 550, batch loss 0.1797, batch acc 0.9454
15:03:01.114   Training iter 600, batch loss 0.1828, batch acc 0.9454
15:03:01.116 Training @ 198 epoch...
15:03:01.691   Training iter 50, batch loss 0.1685, batch acc 0.9502
15:03:02.285   Training iter 100, batch loss 0.1586, batch acc 0.9528
15:03:02.863   Training iter 150, batch loss 0.1656, batch acc 0.9492
15:03:03.445   Training iter 200, batch loss 0.1541, batch acc 0.9548
15:03:03.988   Training iter 250, batch loss 0.1573, batch acc 0.9540
15:03:04.487   Training iter 300, batch loss 0.1689, batch acc 0.9494
15:03:05.002   Training iter 350, batch loss 0.1458, batch acc 0.9520
15:03:05.543   Training iter 400, batch loss 0.1530, batch acc 0.9536
15:03:06.077   Training iter 450, batch loss 0.1789, batch acc 0.9444
15:03:06.577   Training iter 500, batch loss 0.1935, batch acc 0.9424
15:03:07.126   Training iter 550, batch loss 0.1715, batch acc 0.9518
15:03:07.683   Training iter 600, batch loss 0.1682, batch acc 0.9476
15:03:07.685 Training @ 199 epoch...
15:03:08.245   Training iter 50, batch loss 0.1710, batch acc 0.9516
15:03:08.784   Training iter 100, batch loss 0.1540, batch acc 0.9526
15:03:09.321   Training iter 150, batch loss 0.1698, batch acc 0.9462
15:03:09.850   Training iter 200, batch loss 0.1743, batch acc 0.9468
15:03:10.382   Training iter 250, batch loss 0.1824, batch acc 0.9492
15:03:10.908   Training iter 300, batch loss 0.1675, batch acc 0.9500
15:03:11.410   Training iter 350, batch loss 0.1605, batch acc 0.9500
15:03:11.910   Training iter 400, batch loss 0.1637, batch acc 0.9490
15:03:12.418   Training iter 450, batch loss 0.1474, batch acc 0.9536
15:03:12.943   Training iter 500, batch loss 0.1660, batch acc 0.9492
15:03:13.467   Training iter 550, batch loss 0.1794, batch acc 0.9456
15:03:13.980   Training iter 600, batch loss 0.1553, batch acc 0.9548
15:03:13.982 Training @ 200 epoch...
15:03:14.491   Training iter 50, batch loss 0.1580, batch acc 0.9542
15:03:15.006   Training iter 100, batch loss 0.1775, batch acc 0.9482
15:03:15.536   Training iter 150, batch loss 0.1469, batch acc 0.9562
15:03:16.073   Training iter 200, batch loss 0.1758, batch acc 0.9488
15:03:16.613   Training iter 250, batch loss 0.1627, batch acc 0.9528
15:03:17.135   Training iter 300, batch loss 0.1613, batch acc 0.9472
15:03:17.651   Training iter 350, batch loss 0.1539, batch acc 0.9544
15:03:18.195   Training iter 400, batch loss 0.1737, batch acc 0.9478
15:03:18.715   Training iter 450, batch loss 0.1685, batch acc 0.9476
15:03:19.272   Training iter 500, batch loss 0.1557, batch acc 0.9524
15:03:19.826   Training iter 550, batch loss 0.1866, batch acc 0.9422
15:03:20.372   Training iter 600, batch loss 0.1832, batch acc 0.9456
15:03:20.374 Testing @ 200 epoch...
15:03:20.421     Testing, total mean loss 0.21154, total acc 0.93820
15:03:20.421 Plot @ 200 epoch...
15:03:20.421 Training @ 201 epoch...
15:03:20.962   Training iter 50, batch loss 0.1683, batch acc 0.9520
15:03:21.489   Training iter 100, batch loss 0.1364, batch acc 0.9602
15:03:22.027   Training iter 150, batch loss 0.1719, batch acc 0.9476
15:03:22.571   Training iter 200, batch loss 0.1610, batch acc 0.9488
15:03:23.109   Training iter 250, batch loss 0.1698, batch acc 0.9506
15:03:23.644   Training iter 300, batch loss 0.1664, batch acc 0.9508
15:03:24.165   Training iter 350, batch loss 0.1629, batch acc 0.9480
15:03:24.702   Training iter 400, batch loss 0.1755, batch acc 0.9492
15:03:25.219   Training iter 450, batch loss 0.1786, batch acc 0.9442
15:03:25.722   Training iter 500, batch loss 0.1618, batch acc 0.9498
15:03:26.237   Training iter 550, batch loss 0.1739, batch acc 0.9450
15:03:26.776   Training iter 600, batch loss 0.1603, batch acc 0.9530
15:03:26.778 Training @ 202 epoch...
15:03:27.325   Training iter 50, batch loss 0.1875, batch acc 0.9456
15:03:27.869   Training iter 100, batch loss 0.1542, batch acc 0.9522
15:03:28.415   Training iter 150, batch loss 0.1668, batch acc 0.9476
15:03:28.967   Training iter 200, batch loss 0.1695, batch acc 0.9492
15:03:29.513   Training iter 250, batch loss 0.1569, batch acc 0.9546
15:03:30.054   Training iter 300, batch loss 0.1795, batch acc 0.9502
15:03:30.587   Training iter 350, batch loss 0.1554, batch acc 0.9534
15:03:31.121   Training iter 400, batch loss 0.1625, batch acc 0.9524
15:03:31.656   Training iter 450, batch loss 0.1626, batch acc 0.9524
15:03:32.187   Training iter 500, batch loss 0.1580, batch acc 0.9536
15:03:32.719   Training iter 550, batch loss 0.1589, batch acc 0.9498
15:03:33.240   Training iter 600, batch loss 0.1747, batch acc 0.9496
15:03:33.241 Training @ 203 epoch...
15:03:33.765   Training iter 50, batch loss 0.1562, batch acc 0.9582
15:03:34.284   Training iter 100, batch loss 0.1531, batch acc 0.9560
15:03:34.800   Training iter 150, batch loss 0.1761, batch acc 0.9496
15:03:35.318   Training iter 200, batch loss 0.1705, batch acc 0.9480
15:03:35.832   Training iter 250, batch loss 0.1621, batch acc 0.9512
15:03:36.345   Training iter 300, batch loss 0.1672, batch acc 0.9502
15:03:36.857   Training iter 350, batch loss 0.1758, batch acc 0.9458
15:03:37.400   Training iter 400, batch loss 0.1667, batch acc 0.9514
15:03:37.942   Training iter 450, batch loss 0.1690, batch acc 0.9492
15:03:38.489   Training iter 500, batch loss 0.1491, batch acc 0.9526
15:03:39.037   Training iter 550, batch loss 0.1590, batch acc 0.9534
15:03:39.600   Training iter 600, batch loss 0.1792, batch acc 0.9468
15:03:39.602 Training @ 204 epoch...
15:03:40.145   Training iter 50, batch loss 0.1418, batch acc 0.9564
15:03:40.672   Training iter 100, batch loss 0.1769, batch acc 0.9484
15:03:41.217   Training iter 150, batch loss 0.1725, batch acc 0.9480
15:03:41.767   Training iter 200, batch loss 0.1711, batch acc 0.9490
15:03:42.325   Training iter 250, batch loss 0.1685, batch acc 0.9496
15:03:42.858   Training iter 300, batch loss 0.1563, batch acc 0.9548
15:03:43.377   Training iter 350, batch loss 0.1630, batch acc 0.9536
15:03:43.889   Training iter 400, batch loss 0.1626, batch acc 0.9502
15:03:44.407   Training iter 450, batch loss 0.1588, batch acc 0.9522
15:03:44.908   Training iter 500, batch loss 0.1841, batch acc 0.9444
15:03:45.434   Training iter 550, batch loss 0.1562, batch acc 0.9538
15:03:45.956   Training iter 600, batch loss 0.1699, batch acc 0.9500
15:03:45.957 Training @ 205 epoch...
15:03:46.491   Training iter 50, batch loss 0.1608, batch acc 0.9508
15:03:47.029   Training iter 100, batch loss 0.1489, batch acc 0.9492
15:03:47.534   Training iter 150, batch loss 0.1995, batch acc 0.9424
15:03:48.026   Training iter 200, batch loss 0.1568, batch acc 0.9552
15:03:48.513   Training iter 250, batch loss 0.1663, batch acc 0.9552
15:03:48.988   Training iter 300, batch loss 0.1579, batch acc 0.9510
15:03:49.459   Training iter 350, batch loss 0.1592, batch acc 0.9568
15:03:49.932   Training iter 400, batch loss 0.1523, batch acc 0.9514
15:03:50.406   Training iter 450, batch loss 0.1551, batch acc 0.9516
15:03:50.885   Training iter 500, batch loss 0.1793, batch acc 0.9442
15:03:51.363   Training iter 550, batch loss 0.1726, batch acc 0.9506
15:03:51.853   Training iter 600, batch loss 0.1644, batch acc 0.9546
15:03:51.855 Testing @ 205 epoch...
15:03:51.899     Testing, total mean loss 0.21260, total acc 0.93800
15:03:51.899 Training @ 206 epoch...
15:03:52.408   Training iter 50, batch loss 0.1706, batch acc 0.9468
15:03:52.922   Training iter 100, batch loss 0.1465, batch acc 0.9550
15:03:53.448   Training iter 150, batch loss 0.1620, batch acc 0.9496
15:03:53.939   Training iter 200, batch loss 0.1626, batch acc 0.9518
15:03:54.437   Training iter 250, batch loss 0.1582, batch acc 0.9484
15:03:54.955   Training iter 300, batch loss 0.1673, batch acc 0.9488
15:03:55.490   Training iter 350, batch loss 0.1751, batch acc 0.9510
15:03:56.025   Training iter 400, batch loss 0.1834, batch acc 0.9476
15:03:56.552   Training iter 450, batch loss 0.1554, batch acc 0.9544
15:03:57.088   Training iter 500, batch loss 0.1536, batch acc 0.9532
15:03:57.640   Training iter 550, batch loss 0.1852, batch acc 0.9468
15:03:58.215   Training iter 600, batch loss 0.1816, batch acc 0.9466
15:03:58.216 Training @ 207 epoch...
15:03:58.795   Training iter 50, batch loss 0.1651, batch acc 0.9492
15:03:59.340   Training iter 100, batch loss 0.1679, batch acc 0.9504
15:03:59.871   Training iter 150, batch loss 0.1807, batch acc 0.9494
15:04:00.410   Training iter 200, batch loss 0.1588, batch acc 0.9512
15:04:00.949   Training iter 250, batch loss 0.1700, batch acc 0.9488
15:04:01.491   Training iter 300, batch loss 0.1631, batch acc 0.9516
15:04:02.060   Training iter 350, batch loss 0.1597, batch acc 0.9552
15:04:02.658   Training iter 400, batch loss 0.1526, batch acc 0.9540
15:04:03.421   Training iter 450, batch loss 0.1614, batch acc 0.9522
15:04:04.187   Training iter 500, batch loss 0.1700, batch acc 0.9484
15:04:04.952   Training iter 550, batch loss 0.1669, batch acc 0.9498
15:04:05.546   Training iter 600, batch loss 0.1659, batch acc 0.9546
15:04:05.548 Training @ 208 epoch...
15:04:06.086   Training iter 50, batch loss 0.1559, batch acc 0.9540
15:04:06.598   Training iter 100, batch loss 0.1639, batch acc 0.9514
15:04:07.114   Training iter 150, batch loss 0.1739, batch acc 0.9484
15:04:07.631   Training iter 200, batch loss 0.1735, batch acc 0.9470
15:04:08.117   Training iter 250, batch loss 0.1593, batch acc 0.9510
15:04:08.585   Training iter 300, batch loss 0.1810, batch acc 0.9468
15:04:09.084   Training iter 350, batch loss 0.1683, batch acc 0.9528
15:04:09.618   Training iter 400, batch loss 0.1576, batch acc 0.9468
15:04:10.160   Training iter 450, batch loss 0.1632, batch acc 0.9498
15:04:10.696   Training iter 500, batch loss 0.1602, batch acc 0.9528
15:04:11.244   Training iter 550, batch loss 0.1552, batch acc 0.9548
15:04:11.812   Training iter 600, batch loss 0.1747, batch acc 0.9480
15:04:11.814 Training @ 209 epoch...
15:04:12.344   Training iter 50, batch loss 0.1802, batch acc 0.9480
15:04:12.851   Training iter 100, batch loss 0.1501, batch acc 0.9516
15:04:13.384   Training iter 150, batch loss 0.1714, batch acc 0.9486
15:04:13.912   Training iter 200, batch loss 0.1462, batch acc 0.9548
15:04:14.456   Training iter 250, batch loss 0.1593, batch acc 0.9550
15:04:15.013   Training iter 300, batch loss 0.1684, batch acc 0.9532
15:04:15.523   Training iter 350, batch loss 0.1572, batch acc 0.9512
15:04:16.024   Training iter 400, batch loss 0.1802, batch acc 0.9484
15:04:16.520   Training iter 450, batch loss 0.1799, batch acc 0.9438
15:04:17.019   Training iter 500, batch loss 0.1465, batch acc 0.9528
15:04:17.507   Training iter 550, batch loss 0.1658, batch acc 0.9516
15:04:17.993   Training iter 600, batch loss 0.1797, batch acc 0.9464
15:04:17.995 Training @ 210 epoch...
15:04:18.545   Training iter 50, batch loss 0.1722, batch acc 0.9494
15:04:19.076   Training iter 100, batch loss 0.1458, batch acc 0.9534
15:04:19.642   Training iter 150, batch loss 0.1679, batch acc 0.9520
15:04:20.216   Training iter 200, batch loss 0.1773, batch acc 0.9508
15:04:20.787   Training iter 250, batch loss 0.1690, batch acc 0.9494
15:04:21.352   Training iter 300, batch loss 0.1511, batch acc 0.9512
15:04:21.914   Training iter 350, batch loss 0.1622, batch acc 0.9472
15:04:22.506   Training iter 400, batch loss 0.1672, batch acc 0.9486
15:04:23.074   Training iter 450, batch loss 0.1645, batch acc 0.9524
15:04:23.608   Training iter 500, batch loss 0.1721, batch acc 0.9510
15:04:24.139   Training iter 550, batch loss 0.1539, batch acc 0.9538
15:04:24.675   Training iter 600, batch loss 0.1724, batch acc 0.9492
15:04:24.677 Testing @ 210 epoch...
15:04:24.721     Testing, total mean loss 0.21323, total acc 0.94000
15:04:24.721 Training @ 211 epoch...
15:04:25.292   Training iter 50, batch loss 0.1582, batch acc 0.9552
15:04:25.859   Training iter 100, batch loss 0.1623, batch acc 0.9506
15:04:26.417   Training iter 150, batch loss 0.1417, batch acc 0.9558
15:04:26.978   Training iter 200, batch loss 0.1782, batch acc 0.9488
15:04:27.539   Training iter 250, batch loss 0.1748, batch acc 0.9466
15:04:28.112   Training iter 300, batch loss 0.1623, batch acc 0.9488
15:04:28.696   Training iter 350, batch loss 0.1586, batch acc 0.9536
15:04:29.294   Training iter 400, batch loss 0.1733, batch acc 0.9500
15:04:29.867   Training iter 450, batch loss 0.1621, batch acc 0.9544
15:04:30.440   Training iter 500, batch loss 0.1673, batch acc 0.9496
15:04:31.002   Training iter 550, batch loss 0.1728, batch acc 0.9494
15:04:31.534   Training iter 600, batch loss 0.1706, batch acc 0.9480
15:04:31.536 Training @ 212 epoch...
15:04:32.085   Training iter 50, batch loss 0.1477, batch acc 0.9566
15:04:32.621   Training iter 100, batch loss 0.1677, batch acc 0.9484
15:04:33.164   Training iter 150, batch loss 0.1519, batch acc 0.9526
15:04:33.693   Training iter 200, batch loss 0.1669, batch acc 0.9548
15:04:34.229   Training iter 250, batch loss 0.1747, batch acc 0.9498
15:04:34.771   Training iter 300, batch loss 0.1647, batch acc 0.9536
15:04:35.295   Training iter 350, batch loss 0.1592, batch acc 0.9536
15:04:35.816   Training iter 400, batch loss 0.1625, batch acc 0.9484
15:04:36.336   Training iter 450, batch loss 0.1764, batch acc 0.9476
15:04:36.859   Training iter 500, batch loss 0.1707, batch acc 0.9472
15:04:37.380   Training iter 550, batch loss 0.1788, batch acc 0.9446
15:04:37.856   Training iter 600, batch loss 0.1675, batch acc 0.9486
15:04:37.858 Training @ 213 epoch...
15:04:38.351   Training iter 50, batch loss 0.1729, batch acc 0.9512
15:04:38.829   Training iter 100, batch loss 0.1672, batch acc 0.9514
15:04:39.322   Training iter 150, batch loss 0.1606, batch acc 0.9524
15:04:39.790   Training iter 200, batch loss 0.1630, batch acc 0.9524
15:04:40.272   Training iter 250, batch loss 0.1732, batch acc 0.9460
15:04:40.746   Training iter 300, batch loss 0.1703, batch acc 0.9512
15:04:41.238   Training iter 350, batch loss 0.1686, batch acc 0.9506
15:04:41.752   Training iter 400, batch loss 0.1619, batch acc 0.9536
15:04:42.265   Training iter 450, batch loss 0.1571, batch acc 0.9506
15:04:42.789   Training iter 500, batch loss 0.1709, batch acc 0.9490
15:04:43.422   Training iter 550, batch loss 0.1664, batch acc 0.9542
15:04:43.955   Training iter 600, batch loss 0.1645, batch acc 0.9490
15:04:43.957 Training @ 214 epoch...
15:04:44.480   Training iter 50, batch loss 0.1561, batch acc 0.9558
15:04:45.009   Training iter 100, batch loss 0.1561, batch acc 0.9534
15:04:45.547   Training iter 150, batch loss 0.1531, batch acc 0.9556
15:04:46.086   Training iter 200, batch loss 0.1777, batch acc 0.9468
15:04:46.633   Training iter 250, batch loss 0.1692, batch acc 0.9480
15:04:47.156   Training iter 300, batch loss 0.1719, batch acc 0.9506
15:04:47.657   Training iter 350, batch loss 0.1574, batch acc 0.9472
15:04:48.157   Training iter 400, batch loss 0.1719, batch acc 0.9482
15:04:48.667   Training iter 450, batch loss 0.1715, batch acc 0.9472
15:04:49.162   Training iter 500, batch loss 0.1751, batch acc 0.9494
15:04:49.665   Training iter 550, batch loss 0.1761, batch acc 0.9488
15:04:50.167   Training iter 600, batch loss 0.1621, batch acc 0.9526
15:04:50.169 Training @ 215 epoch...
15:04:50.662   Training iter 50, batch loss 0.1613, batch acc 0.9518
15:04:51.172   Training iter 100, batch loss 0.1545, batch acc 0.9556
15:04:51.675   Training iter 150, batch loss 0.1741, batch acc 0.9486
15:04:52.187   Training iter 200, batch loss 0.1728, batch acc 0.9480
15:04:52.693   Training iter 250, batch loss 0.1614, batch acc 0.9500
15:04:53.203   Training iter 300, batch loss 0.1606, batch acc 0.9498
15:04:53.707   Training iter 350, batch loss 0.1586, batch acc 0.9544
15:04:54.203   Training iter 400, batch loss 0.1838, batch acc 0.9488
15:04:54.705   Training iter 450, batch loss 0.1616, batch acc 0.9494
15:04:55.216   Training iter 500, batch loss 0.1550, batch acc 0.9506
15:04:55.710   Training iter 550, batch loss 0.1660, batch acc 0.9508
15:04:56.199   Training iter 600, batch loss 0.1665, batch acc 0.9506
15:04:56.201 Testing @ 215 epoch...
15:04:56.245     Testing, total mean loss 0.20698, total acc 0.93990
15:04:56.245 Training @ 216 epoch...
15:04:56.779   Training iter 50, batch loss 0.1429, batch acc 0.9612
15:04:57.306   Training iter 100, batch loss 0.1765, batch acc 0.9454
15:04:57.836   Training iter 150, batch loss 0.1690, batch acc 0.9486
15:04:58.384   Training iter 200, batch loss 0.1551, batch acc 0.9562
15:04:58.926   Training iter 250, batch loss 0.1595, batch acc 0.9490
15:04:59.472   Training iter 300, batch loss 0.1811, batch acc 0.9476
15:05:00.020   Training iter 350, batch loss 0.1609, batch acc 0.9486
15:05:00.571   Training iter 400, batch loss 0.1624, batch acc 0.9478
15:05:01.141   Training iter 450, batch loss 0.1584, batch acc 0.9538
15:05:01.743   Training iter 500, batch loss 0.1649, batch acc 0.9514
15:05:02.353   Training iter 550, batch loss 0.1613, batch acc 0.9528
15:05:02.934   Training iter 600, batch loss 0.1835, batch acc 0.9424
15:05:02.936 Training @ 217 epoch...
15:05:03.514   Training iter 50, batch loss 0.1589, batch acc 0.9520
15:05:04.073   Training iter 100, batch loss 0.1593, batch acc 0.9504
15:05:04.639   Training iter 150, batch loss 0.1494, batch acc 0.9566
15:05:05.306   Training iter 200, batch loss 0.1560, batch acc 0.9536
15:05:06.028   Training iter 250, batch loss 0.1683, batch acc 0.9516
15:05:06.777   Training iter 300, batch loss 0.1599, batch acc 0.9500
15:05:07.537   Training iter 350, batch loss 0.1645, batch acc 0.9532
15:05:08.275   Training iter 400, batch loss 0.1616, batch acc 0.9502
15:05:08.878   Training iter 450, batch loss 0.1661, batch acc 0.9488
15:05:09.440   Training iter 500, batch loss 0.1644, batch acc 0.9464
15:05:10.011   Training iter 550, batch loss 0.1609, batch acc 0.9524
15:05:10.553   Training iter 600, batch loss 0.1925, batch acc 0.9420
15:05:10.555 Training @ 218 epoch...
15:05:11.103   Training iter 50, batch loss 0.1645, batch acc 0.9514
15:05:11.643   Training iter 100, batch loss 0.1519, batch acc 0.9534
15:05:12.201   Training iter 150, batch loss 0.1638, batch acc 0.9590
15:05:12.741   Training iter 200, batch loss 0.1486, batch acc 0.9564
15:05:13.287   Training iter 250, batch loss 0.1801, batch acc 0.9468
15:05:13.850   Training iter 300, batch loss 0.1512, batch acc 0.9540
15:05:14.417   Training iter 350, batch loss 0.1474, batch acc 0.9530
15:05:14.979   Training iter 400, batch loss 0.1668, batch acc 0.9488
15:05:15.523   Training iter 450, batch loss 0.1670, batch acc 0.9494
15:05:16.079   Training iter 500, batch loss 0.1834, batch acc 0.9448
15:05:16.617   Training iter 550, batch loss 0.1746, batch acc 0.9530
15:05:17.158   Training iter 600, batch loss 0.1624, batch acc 0.9518
15:05:17.160 Training @ 219 epoch...
15:05:17.713   Training iter 50, batch loss 0.1668, batch acc 0.9484
15:05:18.289   Training iter 100, batch loss 0.1680, batch acc 0.9494
15:05:18.846   Training iter 150, batch loss 0.1594, batch acc 0.9478
15:05:19.403   Training iter 200, batch loss 0.1694, batch acc 0.9496
15:05:19.946   Training iter 250, batch loss 0.1477, batch acc 0.9548
15:05:20.501   Training iter 300, batch loss 0.1697, batch acc 0.9504
15:05:21.017   Training iter 350, batch loss 0.1635, batch acc 0.9472
15:05:21.546   Training iter 400, batch loss 0.1663, batch acc 0.9494
15:05:22.090   Training iter 450, batch loss 0.1593, batch acc 0.9516
15:05:22.649   Training iter 500, batch loss 0.1681, batch acc 0.9508
15:05:23.187   Training iter 550, batch loss 0.1771, batch acc 0.9472
15:05:23.773   Training iter 600, batch loss 0.1722, batch acc 0.9486
15:05:23.775 Training @ 220 epoch...
15:05:24.375   Training iter 50, batch loss 0.1572, batch acc 0.9550
15:05:24.962   Training iter 100, batch loss 0.1501, batch acc 0.9574
15:05:25.495   Training iter 150, batch loss 0.1754, batch acc 0.9472
15:05:25.964   Training iter 200, batch loss 0.1795, batch acc 0.9472
15:05:26.458   Training iter 250, batch loss 0.1664, batch acc 0.9510
15:05:26.954   Training iter 300, batch loss 0.1604, batch acc 0.9494
15:05:27.468   Training iter 350, batch loss 0.1554, batch acc 0.9520
15:05:27.953   Training iter 400, batch loss 0.1690, batch acc 0.9496
15:05:28.439   Training iter 450, batch loss 0.1672, batch acc 0.9490
15:05:28.922   Training iter 500, batch loss 0.1610, batch acc 0.9496
15:05:29.421   Training iter 550, batch loss 0.1721, batch acc 0.9476
15:05:29.923   Training iter 600, batch loss 0.1590, batch acc 0.9522
15:05:29.924 Testing @ 220 epoch...
15:05:29.969     Testing, total mean loss 0.20917, total acc 0.93880
15:05:29.969 Training @ 221 epoch...
15:05:30.476   Training iter 50, batch loss 0.1658, batch acc 0.9468
15:05:31.005   Training iter 100, batch loss 0.1476, batch acc 0.9556
15:05:31.569   Training iter 150, batch loss 0.1618, batch acc 0.9520
15:05:32.120   Training iter 200, batch loss 0.1686, batch acc 0.9488
15:05:32.687   Training iter 250, batch loss 0.1718, batch acc 0.9424
15:05:33.266   Training iter 300, batch loss 0.1632, batch acc 0.9516
15:05:33.811   Training iter 350, batch loss 0.1527, batch acc 0.9550
15:05:34.340   Training iter 400, batch loss 0.1815, batch acc 0.9476
15:05:34.885   Training iter 450, batch loss 0.1784, batch acc 0.9474
15:05:35.424   Training iter 500, batch loss 0.1568, batch acc 0.9514
15:05:35.983   Training iter 550, batch loss 0.1620, batch acc 0.9488
15:05:36.530   Training iter 600, batch loss 0.1635, batch acc 0.9542
15:05:36.532 Training @ 222 epoch...
15:05:37.092   Training iter 50, batch loss 0.1670, batch acc 0.9494
15:05:37.633   Training iter 100, batch loss 0.1590, batch acc 0.9508
15:05:38.157   Training iter 150, batch loss 0.1444, batch acc 0.9540
15:05:38.676   Training iter 200, batch loss 0.1595, batch acc 0.9514
15:05:39.206   Training iter 250, batch loss 0.1654, batch acc 0.9486
15:05:39.712   Training iter 300, batch loss 0.1662, batch acc 0.9514
15:05:40.219   Training iter 350, batch loss 0.1582, batch acc 0.9518
15:05:40.718   Training iter 400, batch loss 0.1599, batch acc 0.9484
15:05:41.223   Training iter 450, batch loss 0.1731, batch acc 0.9476
15:05:41.726   Training iter 500, batch loss 0.1863, batch acc 0.9462
15:05:42.241   Training iter 550, batch loss 0.1744, batch acc 0.9466
15:05:42.761   Training iter 600, batch loss 0.1618, batch acc 0.9516
15:05:42.763 Training @ 223 epoch...
15:05:43.287   Training iter 50, batch loss 0.1550, batch acc 0.9518
15:05:43.784   Training iter 100, batch loss 0.1630, batch acc 0.9506
15:05:44.283   Training iter 150, batch loss 0.1769, batch acc 0.9490
15:05:44.802   Training iter 200, batch loss 0.1681, batch acc 0.9490
15:05:45.343   Training iter 250, batch loss 0.1722, batch acc 0.9438
15:05:45.857   Training iter 300, batch loss 0.1580, batch acc 0.9542
15:05:46.381   Training iter 350, batch loss 0.1671, batch acc 0.9482
15:05:46.887   Training iter 400, batch loss 0.1827, batch acc 0.9436
15:05:47.430   Training iter 450, batch loss 0.1520, batch acc 0.9528
15:05:47.974   Training iter 500, batch loss 0.1700, batch acc 0.9504
15:05:48.525   Training iter 550, batch loss 0.1513, batch acc 0.9564
15:05:49.072   Training iter 600, batch loss 0.1625, batch acc 0.9508
15:05:49.074 Training @ 224 epoch...
15:05:49.647   Training iter 50, batch loss 0.1564, batch acc 0.9516
15:05:50.215   Training iter 100, batch loss 0.1476, batch acc 0.9536
15:05:50.782   Training iter 150, batch loss 0.1522, batch acc 0.9546
15:05:51.353   Training iter 200, batch loss 0.1655, batch acc 0.9488
15:05:51.935   Training iter 250, batch loss 0.1628, batch acc 0.9508
15:05:52.504   Training iter 300, batch loss 0.1601, batch acc 0.9514
15:05:53.046   Training iter 350, batch loss 0.1654, batch acc 0.9542
15:05:53.590   Training iter 400, batch loss 0.1829, batch acc 0.9452
15:05:54.140   Training iter 450, batch loss 0.1655, batch acc 0.9488
15:05:54.700   Training iter 500, batch loss 0.1695, batch acc 0.9492
15:05:55.267   Training iter 550, batch loss 0.1852, batch acc 0.9460
15:05:55.819   Training iter 600, batch loss 0.1736, batch acc 0.9492
15:05:55.820 Training @ 225 epoch...
15:05:56.375   Training iter 50, batch loss 0.1555, batch acc 0.9502
15:05:56.938   Training iter 100, batch loss 0.1815, batch acc 0.9456
15:05:57.507   Training iter 150, batch loss 0.1644, batch acc 0.9508
15:05:58.073   Training iter 200, batch loss 0.1727, batch acc 0.9480
15:05:58.634   Training iter 250, batch loss 0.1738, batch acc 0.9494
15:05:59.204   Training iter 300, batch loss 0.1549, batch acc 0.9552
15:05:59.784   Training iter 350, batch loss 0.1693, batch acc 0.9492
15:06:00.369   Training iter 400, batch loss 0.1747, batch acc 0.9460
15:06:00.932   Training iter 450, batch loss 0.1469, batch acc 0.9560
15:06:01.522   Training iter 500, batch loss 0.1809, batch acc 0.9474
15:06:02.078   Training iter 550, batch loss 0.1611, batch acc 0.9540
15:06:02.632   Training iter 600, batch loss 0.1613, batch acc 0.9512
15:06:02.634 Testing @ 225 epoch...
15:06:02.681     Testing, total mean loss 0.20654, total acc 0.93920
15:06:02.681 Training @ 226 epoch...
15:06:03.254   Training iter 50, batch loss 0.1522, batch acc 0.9578
15:06:03.832   Training iter 100, batch loss 0.1645, batch acc 0.9518
15:06:04.386   Training iter 150, batch loss 0.1609, batch acc 0.9494
15:06:04.935   Training iter 200, batch loss 0.1461, batch acc 0.9572
15:06:05.469   Training iter 250, batch loss 0.1736, batch acc 0.9454
15:06:06.022   Training iter 300, batch loss 0.1636, batch acc 0.9526
15:06:06.575   Training iter 350, batch loss 0.1683, batch acc 0.9510
15:06:07.101   Training iter 400, batch loss 0.1496, batch acc 0.9556
15:06:07.617   Training iter 450, batch loss 0.1843, batch acc 0.9442
15:06:08.154   Training iter 500, batch loss 0.1707, batch acc 0.9522
15:06:08.680   Training iter 550, batch loss 0.1629, batch acc 0.9494
15:06:09.200   Training iter 600, batch loss 0.1740, batch acc 0.9480
15:06:09.201 Training @ 227 epoch...
15:06:09.733   Training iter 50, batch loss 0.1734, batch acc 0.9476
15:06:10.268   Training iter 100, batch loss 0.1767, batch acc 0.9494
15:06:10.803   Training iter 150, batch loss 0.1606, batch acc 0.9512
15:06:11.332   Training iter 200, batch loss 0.1632, batch acc 0.9494
15:06:11.849   Training iter 250, batch loss 0.1462, batch acc 0.9556
15:06:12.377   Training iter 300, batch loss 0.1600, batch acc 0.9522
15:06:12.915   Training iter 350, batch loss 0.1511, batch acc 0.9530
15:06:13.439   Training iter 400, batch loss 0.1806, batch acc 0.9456
15:06:13.979   Training iter 450, batch loss 0.1653, batch acc 0.9508
15:06:14.531   Training iter 500, batch loss 0.1736, batch acc 0.9472
15:06:15.066   Training iter 550, batch loss 0.1716, batch acc 0.9458
15:06:15.597   Training iter 600, batch loss 0.1546, batch acc 0.9570
15:06:15.599 Training @ 228 epoch...
15:06:16.190   Training iter 50, batch loss 0.1747, batch acc 0.9450
15:06:16.790   Training iter 100, batch loss 0.1586, batch acc 0.9542
15:06:17.411   Training iter 150, batch loss 0.1691, batch acc 0.9498
15:06:17.968   Training iter 200, batch loss 0.1628, batch acc 0.9538
15:06:18.514   Training iter 250, batch loss 0.1495, batch acc 0.9536
15:06:19.081   Training iter 300, batch loss 0.1699, batch acc 0.9464
15:06:19.653   Training iter 350, batch loss 0.1585, batch acc 0.9568
15:06:20.227   Training iter 400, batch loss 0.1674, batch acc 0.9454
15:06:20.780   Training iter 450, batch loss 0.1772, batch acc 0.9498
15:06:21.304   Training iter 500, batch loss 0.1878, batch acc 0.9418
15:06:21.826   Training iter 550, batch loss 0.1507, batch acc 0.9566
15:06:22.353   Training iter 600, batch loss 0.1601, batch acc 0.9500
15:06:22.355 Training @ 229 epoch...
15:06:22.881   Training iter 50, batch loss 0.1504, batch acc 0.9534
15:06:23.437   Training iter 100, batch loss 0.1566, batch acc 0.9520
15:06:23.980   Training iter 150, batch loss 0.1699, batch acc 0.9516
15:06:24.536   Training iter 200, batch loss 0.1641, batch acc 0.9520
15:06:25.095   Training iter 250, batch loss 0.1617, batch acc 0.9494
15:06:25.626   Training iter 300, batch loss 0.1636, batch acc 0.9524
15:06:26.164   Training iter 350, batch loss 0.1542, batch acc 0.9542
15:06:26.693   Training iter 400, batch loss 0.1811, batch acc 0.9436
15:06:27.238   Training iter 450, batch loss 0.1623, batch acc 0.9508
15:06:27.784   Training iter 500, batch loss 0.1623, batch acc 0.9512
15:06:28.330   Training iter 550, batch loss 0.1732, batch acc 0.9496
15:06:28.858   Training iter 600, batch loss 0.1769, batch acc 0.9446
15:06:28.860 Training @ 230 epoch...
15:06:29.400   Training iter 50, batch loss 0.1813, batch acc 0.9490
15:06:29.937   Training iter 100, batch loss 0.1585, batch acc 0.9552
15:06:30.484   Training iter 150, batch loss 0.1594, batch acc 0.9478
15:06:31.038   Training iter 200, batch loss 0.1665, batch acc 0.9492
15:06:31.595   Training iter 250, batch loss 0.1483, batch acc 0.9536
15:06:32.158   Training iter 300, batch loss 0.1704, batch acc 0.9486
15:06:32.694   Training iter 350, batch loss 0.1701, batch acc 0.9510
15:06:33.262   Training iter 400, batch loss 0.1566, batch acc 0.9508
15:06:33.853   Training iter 450, batch loss 0.1494, batch acc 0.9542
15:06:34.441   Training iter 500, batch loss 0.1826, batch acc 0.9444
15:06:35.086   Training iter 550, batch loss 0.1578, batch acc 0.9510
15:06:35.681   Training iter 600, batch loss 0.1675, batch acc 0.9506
15:06:35.683 Testing @ 230 epoch...
15:06:35.729     Testing, total mean loss 0.21713, total acc 0.93610
15:06:35.729 Training @ 231 epoch...
15:06:36.323   Training iter 50, batch loss 0.1410, batch acc 0.9566
15:06:36.912   Training iter 100, batch loss 0.1802, batch acc 0.9470
15:06:37.503   Training iter 150, batch loss 0.1541, batch acc 0.9522
15:06:38.083   Training iter 200, batch loss 0.1540, batch acc 0.9540
15:06:38.661   Training iter 250, batch loss 0.1470, batch acc 0.9548
15:06:39.254   Training iter 300, batch loss 0.1865, batch acc 0.9454
15:06:39.852   Training iter 350, batch loss 0.1757, batch acc 0.9494
15:06:40.387   Training iter 400, batch loss 0.1765, batch acc 0.9512
15:06:40.906   Training iter 450, batch loss 0.1591, batch acc 0.9540
15:06:41.470   Training iter 500, batch loss 0.1582, batch acc 0.9532
15:06:42.023   Training iter 550, batch loss 0.1706, batch acc 0.9486
15:06:42.591   Training iter 600, batch loss 0.1696, batch acc 0.9440
15:06:42.593 Training @ 232 epoch...
15:06:43.167   Training iter 50, batch loss 0.1656, batch acc 0.9478
15:06:43.734   Training iter 100, batch loss 0.1631, batch acc 0.9504
15:06:44.289   Training iter 150, batch loss 0.1641, batch acc 0.9494
15:06:44.840   Training iter 200, batch loss 0.1620, batch acc 0.9520
15:06:45.388   Training iter 250, batch loss 0.1559, batch acc 0.9534
15:06:45.952   Training iter 300, batch loss 0.1638, batch acc 0.9500
15:06:46.515   Training iter 350, batch loss 0.1687, batch acc 0.9514
15:06:47.078   Training iter 400, batch loss 0.1586, batch acc 0.9540
15:06:47.627   Training iter 450, batch loss 0.1753, batch acc 0.9506
15:06:48.177   Training iter 500, batch loss 0.1603, batch acc 0.9506
15:06:48.725   Training iter 550, batch loss 0.1615, batch acc 0.9512
15:06:49.280   Training iter 600, batch loss 0.1614, batch acc 0.9514
15:06:49.282 Training @ 233 epoch...
15:06:49.848   Training iter 50, batch loss 0.1632, batch acc 0.9518
15:06:50.432   Training iter 100, batch loss 0.1549, batch acc 0.9504
15:06:51.014   Training iter 150, batch loss 0.1698, batch acc 0.9508
15:06:51.588   Training iter 200, batch loss 0.1570, batch acc 0.9546
15:06:52.181   Training iter 250, batch loss 0.1721, batch acc 0.9470
15:06:52.778   Training iter 300, batch loss 0.1622, batch acc 0.9524
15:06:53.350   Training iter 350, batch loss 0.1705, batch acc 0.9464
15:06:53.929   Training iter 400, batch loss 0.1605, batch acc 0.9512
15:06:54.505   Training iter 450, batch loss 0.1465, batch acc 0.9596
15:06:55.097   Training iter 500, batch loss 0.1621, batch acc 0.9512
15:06:55.675   Training iter 550, batch loss 0.1780, batch acc 0.9456
15:06:56.246   Training iter 600, batch loss 0.1583, batch acc 0.9516
15:06:56.248 Training @ 234 epoch...
15:06:56.822   Training iter 50, batch loss 0.1693, batch acc 0.9498
15:06:57.397   Training iter 100, batch loss 0.1507, batch acc 0.9554
15:06:58.039   Training iter 150, batch loss 0.1813, batch acc 0.9448
15:06:58.563   Training iter 200, batch loss 0.1812, batch acc 0.9464
15:06:59.092   Training iter 250, batch loss 0.1519, batch acc 0.9550
15:06:59.635   Training iter 300, batch loss 0.1566, batch acc 0.9514
15:07:00.168   Training iter 350, batch loss 0.1561, batch acc 0.9524
15:07:00.667   Training iter 400, batch loss 0.1520, batch acc 0.9536
15:07:01.180   Training iter 450, batch loss 0.1690, batch acc 0.9500
15:07:01.743   Training iter 500, batch loss 0.1725, batch acc 0.9448
15:07:02.345   Training iter 550, batch loss 0.1613, batch acc 0.9528
15:07:02.922   Training iter 600, batch loss 0.1776, batch acc 0.9508
15:07:02.924 Training @ 235 epoch...
15:07:03.519   Training iter 50, batch loss 0.1567, batch acc 0.9470
15:07:04.094   Training iter 100, batch loss 0.1759, batch acc 0.9486
15:07:04.705   Training iter 150, batch loss 0.1733, batch acc 0.9480
15:07:05.287   Training iter 200, batch loss 0.1591, batch acc 0.9526
15:07:05.855   Training iter 250, batch loss 0.1658, batch acc 0.9524
15:07:06.450   Training iter 300, batch loss 0.1627, batch acc 0.9524
15:07:07.049   Training iter 350, batch loss 0.1630, batch acc 0.9472
15:07:07.629   Training iter 400, batch loss 0.1627, batch acc 0.9528
15:07:08.198   Training iter 450, batch loss 0.1569, batch acc 0.9538
15:07:08.749   Training iter 500, batch loss 0.1712, batch acc 0.9466
15:07:09.306   Training iter 550, batch loss 0.1480, batch acc 0.9562
15:07:09.847   Training iter 600, batch loss 0.1763, batch acc 0.9494
15:07:09.849 Testing @ 235 epoch...
15:07:09.895     Testing, total mean loss 0.20899, total acc 0.94070
15:07:09.895 Training @ 236 epoch...
15:07:10.493   Training iter 50, batch loss 0.1451, batch acc 0.9580
15:07:11.064   Training iter 100, batch loss 0.1654, batch acc 0.9468
15:07:11.632   Training iter 150, batch loss 0.1765, batch acc 0.9450
15:07:12.224   Training iter 200, batch loss 0.1765, batch acc 0.9478
15:07:12.997   Training iter 250, batch loss 0.1539, batch acc 0.9540
15:07:13.777   Training iter 300, batch loss 0.1511, batch acc 0.9538
15:07:14.391   Training iter 350, batch loss 0.1616, batch acc 0.9508
15:07:14.952   Training iter 400, batch loss 0.1715, batch acc 0.9474
15:07:15.501   Training iter 450, batch loss 0.1802, batch acc 0.9468
15:07:16.045   Training iter 500, batch loss 0.1598, batch acc 0.9530
15:07:16.586   Training iter 550, batch loss 0.1684, batch acc 0.9518
15:07:17.121   Training iter 600, batch loss 0.1657, batch acc 0.9536
15:07:17.123 Training @ 237 epoch...
15:07:17.652   Training iter 50, batch loss 0.1613, batch acc 0.9494
15:07:18.184   Training iter 100, batch loss 0.1558, batch acc 0.9534
15:07:18.707   Training iter 150, batch loss 0.1701, batch acc 0.9478
15:07:19.232   Training iter 200, batch loss 0.1694, batch acc 0.9494
15:07:19.782   Training iter 250, batch loss 0.1778, batch acc 0.9478
15:07:20.349   Training iter 300, batch loss 0.1484, batch acc 0.9550
15:07:20.909   Training iter 350, batch loss 0.1580, batch acc 0.9562
15:07:21.396   Training iter 400, batch loss 0.1399, batch acc 0.9558
15:07:21.882   Training iter 450, batch loss 0.1674, batch acc 0.9496
15:07:22.408   Training iter 500, batch loss 0.1712, batch acc 0.9460
15:07:22.921   Training iter 550, batch loss 0.1759, batch acc 0.9466
15:07:23.463   Training iter 600, batch loss 0.1766, batch acc 0.9488
15:07:23.465 Training @ 238 epoch...
15:07:24.032   Training iter 50, batch loss 0.1682, batch acc 0.9504
15:07:24.590   Training iter 100, batch loss 0.1499, batch acc 0.9556
15:07:25.166   Training iter 150, batch loss 0.1503, batch acc 0.9522
15:07:25.737   Training iter 200, batch loss 0.1677, batch acc 0.9518
15:07:26.275   Training iter 250, batch loss 0.1643, batch acc 0.9474
15:07:26.812   Training iter 300, batch loss 0.1792, batch acc 0.9448
15:07:27.384   Training iter 350, batch loss 0.1821, batch acc 0.9474
15:07:27.968   Training iter 400, batch loss 0.1645, batch acc 0.9520
15:07:28.557   Training iter 450, batch loss 0.1716, batch acc 0.9466
15:07:29.148   Training iter 500, batch loss 0.1580, batch acc 0.9522
15:07:29.715   Training iter 550, batch loss 0.1734, batch acc 0.9448
15:07:30.296   Training iter 600, batch loss 0.1429, batch acc 0.9606
15:07:30.298 Training @ 239 epoch...
15:07:30.889   Training iter 50, batch loss 0.1547, batch acc 0.9532
15:07:31.440   Training iter 100, batch loss 0.1656, batch acc 0.9540
15:07:31.968   Training iter 150, batch loss 0.1682, batch acc 0.9512
15:07:32.496   Training iter 200, batch loss 0.1536, batch acc 0.9514
15:07:33.048   Training iter 250, batch loss 0.1660, batch acc 0.9480
15:07:33.588   Training iter 300, batch loss 0.1710, batch acc 0.9498
15:07:34.126   Training iter 350, batch loss 0.1491, batch acc 0.9570
15:07:34.671   Training iter 400, batch loss 0.1618, batch acc 0.9504
15:07:35.225   Training iter 450, batch loss 0.1679, batch acc 0.9492
15:07:35.756   Training iter 500, batch loss 0.1879, batch acc 0.9450
15:07:36.295   Training iter 550, batch loss 0.1721, batch acc 0.9486
15:07:36.831   Training iter 600, batch loss 0.1518, batch acc 0.9546
15:07:36.833 Training @ 240 epoch...
15:07:37.376   Training iter 50, batch loss 0.1641, batch acc 0.9522
15:07:37.913   Training iter 100, batch loss 0.1436, batch acc 0.9588
15:07:38.445   Training iter 150, batch loss 0.1795, batch acc 0.9472
15:07:38.973   Training iter 200, batch loss 0.1701, batch acc 0.9460
15:07:39.502   Training iter 250, batch loss 0.1546, batch acc 0.9534
15:07:40.027   Training iter 300, batch loss 0.1536, batch acc 0.9534
15:07:40.557   Training iter 350, batch loss 0.1740, batch acc 0.9466
15:07:41.087   Training iter 400, batch loss 0.1701, batch acc 0.9492
15:07:41.632   Training iter 450, batch loss 0.1580, batch acc 0.9488
15:07:42.210   Training iter 500, batch loss 0.1504, batch acc 0.9550
15:07:42.773   Training iter 550, batch loss 0.1680, batch acc 0.9488
15:07:43.346   Training iter 600, batch loss 0.1836, batch acc 0.9490
15:07:43.348 Testing @ 240 epoch...
15:07:43.394     Testing, total mean loss 0.22081, total acc 0.93460
15:07:43.394 Training @ 241 epoch...
15:07:43.968   Training iter 50, batch loss 0.1535, batch acc 0.9542
15:07:44.544   Training iter 100, batch loss 0.1646, batch acc 0.9526
15:07:45.140   Training iter 150, batch loss 0.1606, batch acc 0.9490
15:07:45.697   Training iter 200, batch loss 0.1641, batch acc 0.9518
15:07:46.252   Training iter 250, batch loss 0.1685, batch acc 0.9488
15:07:46.804   Training iter 300, batch loss 0.1728, batch acc 0.9490
15:07:47.345   Training iter 350, batch loss 0.1517, batch acc 0.9534
15:07:47.890   Training iter 400, batch loss 0.1656, batch acc 0.9512
15:07:48.461   Training iter 450, batch loss 0.1532, batch acc 0.9526
15:07:49.029   Training iter 500, batch loss 0.1593, batch acc 0.9514
15:07:49.589   Training iter 550, batch loss 0.1830, batch acc 0.9450
15:07:50.139   Training iter 600, batch loss 0.1611, batch acc 0.9494
15:07:50.141 Training @ 242 epoch...
15:07:50.684   Training iter 50, batch loss 0.1693, batch acc 0.9504
15:07:51.230   Training iter 100, batch loss 0.1563, batch acc 0.9534
15:07:51.766   Training iter 150, batch loss 0.1643, batch acc 0.9504
15:07:52.318   Training iter 200, batch loss 0.1740, batch acc 0.9484
15:07:52.868   Training iter 250, batch loss 0.1642, batch acc 0.9500
15:07:53.397   Training iter 300, batch loss 0.1533, batch acc 0.9506
15:07:53.932   Training iter 350, batch loss 0.1604, batch acc 0.9498
15:07:54.464   Training iter 400, batch loss 0.1517, batch acc 0.9526
15:07:55.021   Training iter 450, batch loss 0.1619, batch acc 0.9516
15:07:55.578   Training iter 500, batch loss 0.1667, batch acc 0.9502
15:07:56.179   Training iter 550, batch loss 0.1766, batch acc 0.9462
15:07:56.774   Training iter 600, batch loss 0.1830, batch acc 0.9448
15:07:56.776 Training @ 243 epoch...
15:07:57.371   Training iter 50, batch loss 0.1660, batch acc 0.9508
15:07:57.950   Training iter 100, batch loss 0.1568, batch acc 0.9540
15:07:58.531   Training iter 150, batch loss 0.1684, batch acc 0.9510
15:07:59.109   Training iter 200, batch loss 0.1690, batch acc 0.9508
15:07:59.673   Training iter 250, batch loss 0.1660, batch acc 0.9490
15:08:00.247   Training iter 300, batch loss 0.1686, batch acc 0.9488
15:08:00.823   Training iter 350, batch loss 0.1471, batch acc 0.9552
15:08:01.399   Training iter 400, batch loss 0.1615, batch acc 0.9502
15:08:01.976   Training iter 450, batch loss 0.1547, batch acc 0.9504
15:08:02.566   Training iter 500, batch loss 0.1773, batch acc 0.9476
15:08:03.136   Training iter 550, batch loss 0.1583, batch acc 0.9500
15:08:03.678   Training iter 600, batch loss 0.1738, batch acc 0.9510
15:08:03.680 Training @ 244 epoch...
15:08:04.220   Training iter 50, batch loss 0.1611, batch acc 0.9540
15:08:04.751   Training iter 100, batch loss 0.1617, batch acc 0.9506
15:08:05.330   Training iter 150, batch loss 0.1541, batch acc 0.9522
15:08:05.911   Training iter 200, batch loss 0.1591, batch acc 0.9520
15:08:06.468   Training iter 250, batch loss 0.1591, batch acc 0.9502
15:08:07.016   Training iter 300, batch loss 0.1630, batch acc 0.9516
15:08:07.549   Training iter 350, batch loss 0.1754, batch acc 0.9526
15:08:08.075   Training iter 400, batch loss 0.1729, batch acc 0.9500
15:08:08.602   Training iter 450, batch loss 0.1693, batch acc 0.9482
15:08:09.130   Training iter 500, batch loss 0.1610, batch acc 0.9524
15:08:09.713   Training iter 550, batch loss 0.1749, batch acc 0.9492
15:08:10.303   Training iter 600, batch loss 0.1601, batch acc 0.9496
15:08:10.305 Training @ 245 epoch...
15:08:10.898   Training iter 50, batch loss 0.1629, batch acc 0.9474
15:08:11.433   Training iter 100, batch loss 0.1556, batch acc 0.9516
15:08:11.973   Training iter 150, batch loss 0.1456, batch acc 0.9606
15:08:12.523   Training iter 200, batch loss 0.1506, batch acc 0.9558
15:08:13.073   Training iter 250, batch loss 0.1616, batch acc 0.9528
15:08:13.651   Training iter 300, batch loss 0.1647, batch acc 0.9492
15:08:14.249   Training iter 350, batch loss 0.1572, batch acc 0.9522
15:08:14.836   Training iter 400, batch loss 0.1717, batch acc 0.9482
15:08:15.420   Training iter 450, batch loss 0.1737, batch acc 0.9472
15:08:16.012   Training iter 500, batch loss 0.1742, batch acc 0.9504
15:08:16.600   Training iter 550, batch loss 0.1772, batch acc 0.9466
15:08:17.385   Training iter 600, batch loss 0.1558, batch acc 0.9504
15:08:17.387 Testing @ 245 epoch...
15:08:17.486     Testing, total mean loss 0.30934, total acc 0.91090
15:08:17.486 Training @ 246 epoch...
15:08:18.365   Training iter 50, batch loss 0.1716, batch acc 0.9484
15:08:18.924   Training iter 100, batch loss 0.1640, batch acc 0.9520
15:08:19.485   Training iter 150, batch loss 0.1611, batch acc 0.9526
15:08:20.049   Training iter 200, batch loss 0.1585, batch acc 0.9538
15:08:20.593   Training iter 250, batch loss 0.1635, batch acc 0.9480
15:08:21.131   Training iter 300, batch loss 0.1627, batch acc 0.9496
15:08:21.665   Training iter 350, batch loss 0.1745, batch acc 0.9434
15:08:22.207   Training iter 400, batch loss 0.1761, batch acc 0.9468
15:08:22.743   Training iter 450, batch loss 0.1509, batch acc 0.9536
15:08:23.301   Training iter 500, batch loss 0.1548, batch acc 0.9546
15:08:23.869   Training iter 550, batch loss 0.1562, batch acc 0.9514
15:08:24.438   Training iter 600, batch loss 0.1673, batch acc 0.9486
15:08:24.440 Training @ 247 epoch...
15:08:25.012   Training iter 50, batch loss 0.1542, batch acc 0.9560
15:08:25.589   Training iter 100, batch loss 0.1809, batch acc 0.9468
15:08:26.149   Training iter 150, batch loss 0.1661, batch acc 0.9524
15:08:26.712   Training iter 200, batch loss 0.1818, batch acc 0.9480
15:08:27.273   Training iter 250, batch loss 0.1709, batch acc 0.9498
15:08:27.840   Training iter 300, batch loss 0.1644, batch acc 0.9506
15:08:28.436   Training iter 350, batch loss 0.1517, batch acc 0.9548
15:08:29.035   Training iter 400, batch loss 0.1498, batch acc 0.9566
15:08:29.613   Training iter 450, batch loss 0.1454, batch acc 0.9548
15:08:30.190   Training iter 500, batch loss 0.1635, batch acc 0.9488
15:08:30.767   Training iter 550, batch loss 0.1711, batch acc 0.9478
15:08:31.341   Training iter 600, batch loss 0.1682, batch acc 0.9494
15:08:31.343 Training @ 248 epoch...
15:08:31.902   Training iter 50, batch loss 0.1502, batch acc 0.9574
15:08:32.452   Training iter 100, batch loss 0.1651, batch acc 0.9490
15:08:33.005   Training iter 150, batch loss 0.1703, batch acc 0.9486
15:08:33.549   Training iter 200, batch loss 0.1761, batch acc 0.9466
15:08:34.064   Training iter 250, batch loss 0.1656, batch acc 0.9526
15:08:34.579   Training iter 300, batch loss 0.1481, batch acc 0.9582
15:08:35.098   Training iter 350, batch loss 0.1715, batch acc 0.9482
15:08:35.618   Training iter 400, batch loss 0.1540, batch acc 0.9524
15:08:36.143   Training iter 450, batch loss 0.1785, batch acc 0.9458
15:08:36.657   Training iter 500, batch loss 0.1649, batch acc 0.9504
15:08:37.185   Training iter 550, batch loss 0.1784, batch acc 0.9444
15:08:37.702   Training iter 600, batch loss 0.1556, batch acc 0.9502
15:08:37.704 Training @ 249 epoch...
15:08:38.236   Training iter 50, batch loss 0.1477, batch acc 0.9550
15:08:38.763   Training iter 100, batch loss 0.1692, batch acc 0.9468
15:08:39.274   Training iter 150, batch loss 0.1612, batch acc 0.9528
15:08:39.799   Training iter 200, batch loss 0.1588, batch acc 0.9512
15:08:40.329   Training iter 250, batch loss 0.1692, batch acc 0.9496
15:08:40.840   Training iter 300, batch loss 0.1590, batch acc 0.9506
15:08:41.356   Training iter 350, batch loss 0.1657, batch acc 0.9488
15:08:41.881   Training iter 400, batch loss 0.1669, batch acc 0.9540
15:08:42.449   Training iter 450, batch loss 0.1598, batch acc 0.9500
15:08:43.005   Training iter 500, batch loss 0.1636, batch acc 0.9502
15:08:43.695   Training iter 550, batch loss 0.1740, batch acc 0.9498
15:08:44.448   Training iter 600, batch loss 0.1623, batch acc 0.9538
15:08:44.451 Training @ 250 epoch...
15:08:45.264   Training iter 50, batch loss 0.1673, batch acc 0.9532
15:08:45.950   Training iter 100, batch loss 0.1623, batch acc 0.9534
15:08:46.490   Training iter 150, batch loss 0.1487, batch acc 0.9564
15:08:47.045   Training iter 200, batch loss 0.1557, batch acc 0.9544
15:08:47.618   Training iter 250, batch loss 0.1731, batch acc 0.9482
15:08:48.166   Training iter 300, batch loss 0.1636, batch acc 0.9512
15:08:48.695   Training iter 350, batch loss 0.1702, batch acc 0.9536
15:08:49.216   Training iter 400, batch loss 0.1401, batch acc 0.9580
15:08:49.745   Training iter 450, batch loss 0.1629, batch acc 0.9502
15:08:50.287   Training iter 500, batch loss 0.1927, batch acc 0.9434
15:08:50.803   Training iter 550, batch loss 0.1480, batch acc 0.9558
15:08:51.318   Training iter 600, batch loss 0.1695, batch acc 0.9504
15:08:51.320 Testing @ 250 epoch...
15:08:51.366     Testing, total mean loss 0.22779, total acc 0.93270
15:08:51.366 Training @ 251 epoch...
15:08:51.895   Training iter 50, batch loss 0.1646, batch acc 0.9546
15:08:52.440   Training iter 100, batch loss 0.1543, batch acc 0.9512
15:08:52.971   Training iter 150, batch loss 0.1740, batch acc 0.9482
15:08:53.521   Training iter 200, batch loss 0.1594, batch acc 0.9536
15:08:54.034   Training iter 250, batch loss 0.1769, batch acc 0.9480
15:08:54.563   Training iter 300, batch loss 0.1688, batch acc 0.9510
15:08:55.114   Training iter 350, batch loss 0.1561, batch acc 0.9504
15:08:55.661   Training iter 400, batch loss 0.1610, batch acc 0.9516
15:08:56.179   Training iter 450, batch loss 0.1739, batch acc 0.9478
15:08:56.685   Training iter 500, batch loss 0.1558, batch acc 0.9518
15:08:57.221   Training iter 550, batch loss 0.1599, batch acc 0.9506
15:08:57.743   Training iter 600, batch loss 0.1705, batch acc 0.9480
15:08:57.745 Training @ 252 epoch...
15:08:58.288   Training iter 50, batch loss 0.1590, batch acc 0.9548
15:08:58.791   Training iter 100, batch loss 0.1588, batch acc 0.9534
15:08:59.355   Training iter 150, batch loss 0.1550, batch acc 0.9514
15:08:59.931   Training iter 200, batch loss 0.1516, batch acc 0.9566
15:09:00.505   Training iter 250, batch loss 0.1590, batch acc 0.9534
15:09:01.021   Training iter 300, batch loss 0.1616, batch acc 0.9504
15:09:01.623   Training iter 350, batch loss 0.1732, batch acc 0.9458
15:09:02.322   Training iter 400, batch loss 0.1517, batch acc 0.9510
15:09:02.948   Training iter 450, batch loss 0.1935, batch acc 0.9428
15:09:03.496   Training iter 500, batch loss 0.1637, batch acc 0.9496
15:09:04.020   Training iter 550, batch loss 0.1688, batch acc 0.9514
15:09:04.542   Training iter 600, batch loss 0.1636, batch acc 0.9478
15:09:04.544 Training @ 253 epoch...
15:09:05.084   Training iter 50, batch loss 0.1654, batch acc 0.9556
15:09:05.614   Training iter 100, batch loss 0.1610, batch acc 0.9492
15:09:06.123   Training iter 150, batch loss 0.1502, batch acc 0.9556
15:09:06.682   Training iter 200, batch loss 0.1668, batch acc 0.9480
15:09:07.256   Training iter 250, batch loss 0.1643, batch acc 0.9484
15:09:07.815   Training iter 300, batch loss 0.1630, batch acc 0.9534
15:09:08.316   Training iter 350, batch loss 0.1591, batch acc 0.9536
15:09:08.800   Training iter 400, batch loss 0.1566, batch acc 0.9530
15:09:09.291   Training iter 450, batch loss 0.1632, batch acc 0.9498
15:09:09.788   Training iter 500, batch loss 0.1623, batch acc 0.9498
15:09:10.279   Training iter 550, batch loss 0.1662, batch acc 0.9496
15:09:10.740   Training iter 600, batch loss 0.1741, batch acc 0.9442
15:09:10.742 Training @ 254 epoch...
15:09:11.208   Training iter 50, batch loss 0.1624, batch acc 0.9482
15:09:11.665   Training iter 100, batch loss 0.1475, batch acc 0.9540
15:09:12.142   Training iter 150, batch loss 0.1662, batch acc 0.9532
15:09:12.606   Training iter 200, batch loss 0.1599, batch acc 0.9528
15:09:13.073   Training iter 250, batch loss 0.1651, batch acc 0.9488
15:09:13.541   Training iter 300, batch loss 0.1531, batch acc 0.9524
15:09:13.997   Training iter 350, batch loss 0.1772, batch acc 0.9444
15:09:14.467   Training iter 400, batch loss 0.1617, batch acc 0.9506
15:09:14.928   Training iter 450, batch loss 0.1656, batch acc 0.9508
15:09:15.390   Training iter 500, batch loss 0.1596, batch acc 0.9528
15:09:15.888   Training iter 550, batch loss 0.1652, batch acc 0.9514
15:09:16.393   Training iter 600, batch loss 0.1735, batch acc 0.9520
15:09:16.395 Training @ 255 epoch...
15:09:16.902   Training iter 50, batch loss 0.1553, batch acc 0.9542
15:09:17.400   Training iter 100, batch loss 0.1766, batch acc 0.9452
15:09:17.922   Training iter 150, batch loss 0.1547, batch acc 0.9518
15:09:18.459   Training iter 200, batch loss 0.1703, batch acc 0.9488
15:09:18.992   Training iter 250, batch loss 0.1870, batch acc 0.9490
15:09:19.537   Training iter 300, batch loss 0.1583, batch acc 0.9508
15:09:20.115   Training iter 350, batch loss 0.1677, batch acc 0.9486
15:09:20.681   Training iter 400, batch loss 0.1440, batch acc 0.9560
15:09:21.231   Training iter 450, batch loss 0.1503, batch acc 0.9520
15:09:21.783   Training iter 500, batch loss 0.1755, batch acc 0.9464
15:09:22.327   Training iter 550, batch loss 0.1589, batch acc 0.9540
15:09:22.874   Training iter 600, batch loss 0.1710, batch acc 0.9492
15:09:22.876 Testing @ 255 epoch...
15:09:22.920     Testing, total mean loss 0.20760, total acc 0.93790
15:09:22.920 Training @ 256 epoch...
15:09:23.445   Training iter 50, batch loss 0.1517, batch acc 0.9534
15:09:23.954   Training iter 100, batch loss 0.1688, batch acc 0.9514
15:09:24.461   Training iter 150, batch loss 0.1722, batch acc 0.9474
15:09:24.983   Training iter 200, batch loss 0.1563, batch acc 0.9516
15:09:25.516   Training iter 250, batch loss 0.1588, batch acc 0.9542
15:09:26.037   Training iter 300, batch loss 0.1529, batch acc 0.9558
15:09:26.561   Training iter 350, batch loss 0.1713, batch acc 0.9456
15:09:27.084   Training iter 400, batch loss 0.1937, batch acc 0.9412
15:09:27.609   Training iter 450, batch loss 0.1569, batch acc 0.9498
15:09:28.132   Training iter 500, batch loss 0.1505, batch acc 0.9548
15:09:28.649   Training iter 550, batch loss 0.1712, batch acc 0.9504
15:09:29.193   Training iter 600, batch loss 0.1745, batch acc 0.9482
15:09:29.194 Training @ 257 epoch...
15:09:29.748   Training iter 50, batch loss 0.1636, batch acc 0.9534
15:09:30.280   Training iter 100, batch loss 0.1762, batch acc 0.9470
15:09:30.800   Training iter 150, batch loss 0.1669, batch acc 0.9480
15:09:31.352   Training iter 200, batch loss 0.1669, batch acc 0.9502
15:09:31.866   Training iter 250, batch loss 0.1552, batch acc 0.9566
15:09:32.382   Training iter 300, batch loss 0.1680, batch acc 0.9512
15:09:32.890   Training iter 350, batch loss 0.1604, batch acc 0.9526
15:09:33.407   Training iter 400, batch loss 0.1638, batch acc 0.9520
15:09:33.921   Training iter 450, batch loss 0.1597, batch acc 0.9470
15:09:34.432   Training iter 500, batch loss 0.1682, batch acc 0.9522
15:09:34.977   Training iter 550, batch loss 0.1603, batch acc 0.9528
15:09:35.473   Training iter 600, batch loss 0.1682, batch acc 0.9486
15:09:35.475 Training @ 258 epoch...
15:09:35.947   Training iter 50, batch loss 0.1510, batch acc 0.9570
15:09:36.415   Training iter 100, batch loss 0.1458, batch acc 0.9532
15:09:36.902   Training iter 150, batch loss 0.1400, batch acc 0.9524
15:09:37.413   Training iter 200, batch loss 0.1716, batch acc 0.9448
15:09:37.929   Training iter 250, batch loss 0.1701, batch acc 0.9500
15:09:38.448   Training iter 300, batch loss 0.1690, batch acc 0.9496
15:09:38.949   Training iter 350, batch loss 0.1791, batch acc 0.9456
15:09:39.459   Training iter 400, batch loss 0.1692, batch acc 0.9502
15:09:39.969   Training iter 450, batch loss 0.1648, batch acc 0.9528
15:09:40.481   Training iter 500, batch loss 0.1615, batch acc 0.9512
15:09:41.039   Training iter 550, batch loss 0.1706, batch acc 0.9488
15:09:41.604   Training iter 600, batch loss 0.1681, batch acc 0.9498
15:09:41.606 Training @ 259 epoch...
15:09:42.176   Training iter 50, batch loss 0.1566, batch acc 0.9510
15:09:42.690   Training iter 100, batch loss 0.1714, batch acc 0.9526
15:09:43.203   Training iter 150, batch loss 0.1527, batch acc 0.9510
15:09:43.705   Training iter 200, batch loss 0.1629, batch acc 0.9494
15:09:44.226   Training iter 250, batch loss 0.1558, batch acc 0.9546
15:09:44.772   Training iter 300, batch loss 0.1572, batch acc 0.9524
15:09:45.313   Training iter 350, batch loss 0.1536, batch acc 0.9528
15:09:45.812   Training iter 400, batch loss 0.1731, batch acc 0.9482
15:09:46.326   Training iter 450, batch loss 0.1603, batch acc 0.9520
15:09:46.841   Training iter 500, batch loss 0.1630, batch acc 0.9512
15:09:47.336   Training iter 550, batch loss 0.1805, batch acc 0.9512
15:09:47.839   Training iter 600, batch loss 0.1746, batch acc 0.9508
15:09:47.841 Training @ 260 epoch...
15:09:48.376   Training iter 50, batch loss 0.1666, batch acc 0.9518
15:09:48.923   Training iter 100, batch loss 0.1678, batch acc 0.9508
15:09:49.456   Training iter 150, batch loss 0.1547, batch acc 0.9512
15:09:49.986   Training iter 200, batch loss 0.1729, batch acc 0.9482
15:09:50.521   Training iter 250, batch loss 0.1569, batch acc 0.9510
15:09:51.044   Training iter 300, batch loss 0.1503, batch acc 0.9538
15:09:51.588   Training iter 350, batch loss 0.1552, batch acc 0.9538
15:09:52.138   Training iter 400, batch loss 0.1650, batch acc 0.9528
15:09:52.678   Training iter 450, batch loss 0.1715, batch acc 0.9504
15:09:53.212   Training iter 500, batch loss 0.1621, batch acc 0.9524
15:09:53.747   Training iter 550, batch loss 0.1771, batch acc 0.9502
15:09:54.245   Training iter 600, batch loss 0.1667, batch acc 0.9492
15:09:54.247 Testing @ 260 epoch...
15:09:54.293     Testing, total mean loss 0.20698, total acc 0.93960
15:09:54.293 Training @ 261 epoch...
15:09:54.797   Training iter 50, batch loss 0.1599, batch acc 0.9518
15:09:55.348   Training iter 100, batch loss 0.1577, batch acc 0.9506
15:09:55.873   Training iter 150, batch loss 0.1565, batch acc 0.9522
15:09:56.394   Training iter 200, batch loss 0.1615, batch acc 0.9512
15:09:56.920   Training iter 250, batch loss 0.1587, batch acc 0.9518
15:09:57.458   Training iter 300, batch loss 0.1750, batch acc 0.9448
15:09:58.001   Training iter 350, batch loss 0.1624, batch acc 0.9512
15:09:58.545   Training iter 400, batch loss 0.1733, batch acc 0.9496
15:09:59.068   Training iter 450, batch loss 0.1779, batch acc 0.9514
15:09:59.591   Training iter 500, batch loss 0.1539, batch acc 0.9566
15:10:00.134   Training iter 550, batch loss 0.1526, batch acc 0.9564
15:10:00.664   Training iter 600, batch loss 0.1583, batch acc 0.9520
15:10:00.666 Training @ 262 epoch...
15:10:01.203   Training iter 50, batch loss 0.1803, batch acc 0.9490
15:10:01.773   Training iter 100, batch loss 0.1504, batch acc 0.9536
15:10:02.344   Training iter 150, batch loss 0.1516, batch acc 0.9534
15:10:02.862   Training iter 200, batch loss 0.1498, batch acc 0.9572
15:10:03.402   Training iter 250, batch loss 0.1847, batch acc 0.9430
15:10:03.978   Training iter 300, batch loss 0.1625, batch acc 0.9516
15:10:04.538   Training iter 350, batch loss 0.1669, batch acc 0.9504
15:10:05.107   Training iter 400, batch loss 0.1646, batch acc 0.9502
15:10:05.684   Training iter 450, batch loss 0.1574, batch acc 0.9520
15:10:06.273   Training iter 500, batch loss 0.1593, batch acc 0.9510
15:10:06.832   Training iter 550, batch loss 0.1634, batch acc 0.9522
15:10:07.411   Training iter 600, batch loss 0.1647, batch acc 0.9494
15:10:07.413 Training @ 263 epoch...
15:10:08.014   Training iter 50, batch loss 0.1574, batch acc 0.9532
15:10:08.607   Training iter 100, batch loss 0.1722, batch acc 0.9482
15:10:09.178   Training iter 150, batch loss 0.1322, batch acc 0.9566
15:10:09.731   Training iter 200, batch loss 0.1739, batch acc 0.9444
15:10:10.275   Training iter 250, batch loss 0.1646, batch acc 0.9514
15:10:10.777   Training iter 300, batch loss 0.1725, batch acc 0.9508
15:10:11.302   Training iter 350, batch loss 0.1706, batch acc 0.9490
15:10:11.830   Training iter 400, batch loss 0.1698, batch acc 0.9484
15:10:12.367   Training iter 450, batch loss 0.1716, batch acc 0.9498
15:10:12.903   Training iter 500, batch loss 0.1397, batch acc 0.9582
15:10:13.402   Training iter 550, batch loss 0.1603, batch acc 0.9504
15:10:13.887   Training iter 600, batch loss 0.1654, batch acc 0.9522
15:10:13.889 Training @ 264 epoch...
15:10:14.383   Training iter 50, batch loss 0.1443, batch acc 0.9556
15:10:14.870   Training iter 100, batch loss 0.1712, batch acc 0.9484
15:10:15.377   Training iter 150, batch loss 0.1675, batch acc 0.9456
15:10:15.879   Training iter 200, batch loss 0.1501, batch acc 0.9542
15:10:16.381   Training iter 250, batch loss 0.1649, batch acc 0.9488
15:10:16.889   Training iter 300, batch loss 0.1740, batch acc 0.9472
15:10:17.404   Training iter 350, batch loss 0.1602, batch acc 0.9524
15:10:17.922   Training iter 400, batch loss 0.1614, batch acc 0.9500
15:10:18.444   Training iter 450, batch loss 0.1686, batch acc 0.9488
15:10:18.940   Training iter 500, batch loss 0.1607, batch acc 0.9524
15:10:19.445   Training iter 550, batch loss 0.1775, batch acc 0.9494
15:10:19.933   Training iter 600, batch loss 0.1672, batch acc 0.9506
15:10:19.935 Training @ 265 epoch...
15:10:20.455   Training iter 50, batch loss 0.1595, batch acc 0.9568
15:10:20.961   Training iter 100, batch loss 0.1537, batch acc 0.9522
15:10:21.463   Training iter 150, batch loss 0.1693, batch acc 0.9476
15:10:21.969   Training iter 200, batch loss 0.1617, batch acc 0.9524
15:10:22.475   Training iter 250, batch loss 0.1708, batch acc 0.9468
15:10:22.992   Training iter 300, batch loss 0.1662, batch acc 0.9536
15:10:23.514   Training iter 350, batch loss 0.1674, batch acc 0.9492
15:10:24.024   Training iter 400, batch loss 0.1665, batch acc 0.9456
15:10:24.542   Training iter 450, batch loss 0.1678, batch acc 0.9462
15:10:25.073   Training iter 500, batch loss 0.1546, batch acc 0.9550
15:10:25.611   Training iter 550, batch loss 0.1495, batch acc 0.9560
15:10:26.150   Training iter 600, batch loss 0.1692, batch acc 0.9478
15:10:26.152 Testing @ 265 epoch...
15:10:26.195     Testing, total mean loss 0.20809, total acc 0.93950
15:10:26.195 Training @ 266 epoch...
15:10:26.716   Training iter 50, batch loss 0.1636, batch acc 0.9502
15:10:27.261   Training iter 100, batch loss 0.1660, batch acc 0.9498
15:10:27.851   Training iter 150, batch loss 0.1579, batch acc 0.9546
15:10:28.438   Training iter 200, batch loss 0.1718, batch acc 0.9420
15:10:29.013   Training iter 250, batch loss 0.1642, batch acc 0.9514
15:10:29.511   Training iter 300, batch loss 0.1666, batch acc 0.9492
15:10:30.053   Training iter 350, batch loss 0.1589, batch acc 0.9482
15:10:30.684   Training iter 400, batch loss 0.1610, batch acc 0.9516
15:10:31.297   Training iter 450, batch loss 0.1592, batch acc 0.9508
15:10:31.843   Training iter 500, batch loss 0.1645, batch acc 0.9504
15:10:32.369   Training iter 550, batch loss 0.1591, batch acc 0.9548
15:10:32.906   Training iter 600, batch loss 0.1651, batch acc 0.9502
15:10:32.908 Training @ 267 epoch...
15:10:33.461   Training iter 50, batch loss 0.1433, batch acc 0.9560
15:10:33.996   Training iter 100, batch loss 0.1559, batch acc 0.9538
15:10:34.552   Training iter 150, batch loss 0.1635, batch acc 0.9524
15:10:35.092   Training iter 200, batch loss 0.1677, batch acc 0.9520
15:10:35.626   Training iter 250, batch loss 0.1578, batch acc 0.9520
15:10:36.151   Training iter 300, batch loss 0.1777, batch acc 0.9444
15:10:36.688   Training iter 350, batch loss 0.1632, batch acc 0.9526
15:10:37.242   Training iter 400, batch loss 0.1708, batch acc 0.9496
15:10:37.780   Training iter 450, batch loss 0.1707, batch acc 0.9478
15:10:38.338   Training iter 500, batch loss 0.1410, batch acc 0.9546
15:10:38.877   Training iter 550, batch loss 0.1776, batch acc 0.9494
15:10:39.415   Training iter 600, batch loss 0.1576, batch acc 0.9532
15:10:39.417 Training @ 268 epoch...
15:10:39.936   Training iter 50, batch loss 0.1385, batch acc 0.9598
15:10:40.474   Training iter 100, batch loss 0.1546, batch acc 0.9546
15:10:41.003   Training iter 150, batch loss 0.1605, batch acc 0.9530
15:10:41.537   Training iter 200, batch loss 0.1566, batch acc 0.9542
15:10:42.066   Training iter 250, batch loss 0.1587, batch acc 0.9530
15:10:42.596   Training iter 300, batch loss 0.1637, batch acc 0.9498
15:10:43.137   Training iter 350, batch loss 0.1684, batch acc 0.9494
15:10:43.667   Training iter 400, batch loss 0.1889, batch acc 0.9436
15:10:44.205   Training iter 450, batch loss 0.1588, batch acc 0.9528
15:10:44.748   Training iter 500, batch loss 0.1736, batch acc 0.9486
15:10:45.292   Training iter 550, batch loss 0.1677, batch acc 0.9484
15:10:45.828   Training iter 600, batch loss 0.1621, batch acc 0.9480
15:10:45.829 Training @ 269 epoch...
15:10:46.356   Training iter 50, batch loss 0.1376, batch acc 0.9584
15:10:46.867   Training iter 100, batch loss 0.1530, batch acc 0.9552
15:10:47.393   Training iter 150, batch loss 0.1455, batch acc 0.9542
15:10:47.917   Training iter 200, batch loss 0.1674, batch acc 0.9492
15:10:48.431   Training iter 250, batch loss 0.1725, batch acc 0.9484
15:10:48.932   Training iter 300, batch loss 0.1619, batch acc 0.9498
15:10:49.440   Training iter 350, batch loss 0.1782, batch acc 0.9466
15:10:49.944   Training iter 400, batch loss 0.1638, batch acc 0.9472
15:10:50.450   Training iter 450, batch loss 0.1901, batch acc 0.9462
15:10:50.955   Training iter 500, batch loss 0.1498, batch acc 0.9572
15:10:51.475   Training iter 550, batch loss 0.1786, batch acc 0.9474
15:10:52.016   Training iter 600, batch loss 0.1575, batch acc 0.9544
15:10:52.018 Training @ 270 epoch...
15:10:52.544   Training iter 50, batch loss 0.1697, batch acc 0.9458
15:10:53.046   Training iter 100, batch loss 0.1747, batch acc 0.9486
15:10:53.557   Training iter 150, batch loss 0.1771, batch acc 0.9438
15:10:54.066   Training iter 200, batch loss 0.1576, batch acc 0.9552
15:10:54.590   Training iter 250, batch loss 0.1612, batch acc 0.9538
15:10:55.134   Training iter 300, batch loss 0.1467, batch acc 0.9584
15:10:55.681   Training iter 350, batch loss 0.1600, batch acc 0.9516
15:10:56.244   Training iter 400, batch loss 0.1593, batch acc 0.9522
15:10:56.785   Training iter 450, batch loss 0.1672, batch acc 0.9486
15:10:57.360   Training iter 500, batch loss 0.1722, batch acc 0.9482
15:10:57.914   Training iter 550, batch loss 0.1740, batch acc 0.9438
15:10:58.449   Training iter 600, batch loss 0.1350, batch acc 0.9614
15:10:58.451 Testing @ 270 epoch...
15:10:58.495     Testing, total mean loss 0.20785, total acc 0.93740
15:10:58.495 Training @ 271 epoch...
15:10:59.029   Training iter 50, batch loss 0.1436, batch acc 0.9570
15:10:59.558   Training iter 100, batch loss 0.1429, batch acc 0.9582
15:11:00.087   Training iter 150, batch loss 0.1724, batch acc 0.9500
15:11:00.616   Training iter 200, batch loss 0.1604, batch acc 0.9512
15:11:01.157   Training iter 250, batch loss 0.1747, batch acc 0.9514
15:11:01.678   Training iter 300, batch loss 0.1572, batch acc 0.9528
15:11:02.236   Training iter 350, batch loss 0.1798, batch acc 0.9464
15:11:02.782   Training iter 400, batch loss 0.1681, batch acc 0.9468
15:11:03.341   Training iter 450, batch loss 0.1671, batch acc 0.9514
15:11:03.859   Training iter 500, batch loss 0.1611, batch acc 0.9504
15:11:04.375   Training iter 550, batch loss 0.1530, batch acc 0.9534
15:11:04.902   Training iter 600, batch loss 0.1723, batch acc 0.9502
15:11:04.904 Training @ 272 epoch...
15:11:05.444   Training iter 50, batch loss 0.1556, batch acc 0.9542
15:11:05.963   Training iter 100, batch loss 0.1631, batch acc 0.9518
15:11:06.514   Training iter 150, batch loss 0.1528, batch acc 0.9538
15:11:07.053   Training iter 200, batch loss 0.1524, batch acc 0.9532
15:11:07.591   Training iter 250, batch loss 0.1685, batch acc 0.9516
15:11:08.158   Training iter 300, batch loss 0.1601, batch acc 0.9508
15:11:08.710   Training iter 350, batch loss 0.1622, batch acc 0.9496
15:11:09.276   Training iter 400, batch loss 0.1535, batch acc 0.9544
15:11:09.837   Training iter 450, batch loss 0.1591, batch acc 0.9548
15:11:10.388   Training iter 500, batch loss 0.1745, batch acc 0.9480
15:11:10.962   Training iter 550, batch loss 0.1579, batch acc 0.9498
15:11:11.504   Training iter 600, batch loss 0.1834, batch acc 0.9480
15:11:11.506 Training @ 273 epoch...
15:11:12.066   Training iter 50, batch loss 0.1558, batch acc 0.9542
15:11:12.599   Training iter 100, batch loss 0.1713, batch acc 0.9450
15:11:13.149   Training iter 150, batch loss 0.1602, batch acc 0.9516
15:11:13.702   Training iter 200, batch loss 0.1656, batch acc 0.9522
15:11:14.244   Training iter 250, batch loss 0.1486, batch acc 0.9582
15:11:14.764   Training iter 300, batch loss 0.1599, batch acc 0.9536
15:11:15.283   Training iter 350, batch loss 0.1675, batch acc 0.9502
15:11:15.805   Training iter 400, batch loss 0.1737, batch acc 0.9496
15:11:16.333   Training iter 450, batch loss 0.1619, batch acc 0.9524
15:11:16.858   Training iter 500, batch loss 0.1549, batch acc 0.9512
15:11:17.390   Training iter 550, batch loss 0.1546, batch acc 0.9532
15:11:17.934   Training iter 600, batch loss 0.1656, batch acc 0.9484
15:11:17.935 Training @ 274 epoch...
15:11:18.488   Training iter 50, batch loss 0.1738, batch acc 0.9504
15:11:19.014   Training iter 100, batch loss 0.1586, batch acc 0.9538
15:11:19.538   Training iter 150, batch loss 0.1546, batch acc 0.9520
15:11:20.114   Training iter 200, batch loss 0.1680, batch acc 0.9508
15:11:20.692   Training iter 250, batch loss 0.1607, batch acc 0.9546
15:11:21.257   Training iter 300, batch loss 0.1605, batch acc 0.9496
15:11:21.788   Training iter 350, batch loss 0.1666, batch acc 0.9496
15:11:22.315   Training iter 400, batch loss 0.1899, batch acc 0.9442
15:11:22.842   Training iter 450, batch loss 0.1505, batch acc 0.9550
15:11:23.359   Training iter 500, batch loss 0.1629, batch acc 0.9528
15:11:23.833   Training iter 550, batch loss 0.1623, batch acc 0.9518
15:11:24.348   Training iter 600, batch loss 0.1508, batch acc 0.9552
15:11:24.350 Training @ 275 epoch...
15:11:24.873   Training iter 50, batch loss 0.1503, batch acc 0.9544
15:11:25.413   Training iter 100, batch loss 0.1488, batch acc 0.9548
15:11:25.955   Training iter 150, batch loss 0.1587, batch acc 0.9518
15:11:26.495   Training iter 200, batch loss 0.1556, batch acc 0.9506
15:11:27.033   Training iter 250, batch loss 0.1692, batch acc 0.9510
15:11:27.581   Training iter 300, batch loss 0.1546, batch acc 0.9540
15:11:28.129   Training iter 350, batch loss 0.1690, batch acc 0.9504
15:11:28.671   Training iter 400, batch loss 0.1485, batch acc 0.9542
15:11:29.224   Training iter 450, batch loss 0.1645, batch acc 0.9486
15:11:29.792   Training iter 500, batch loss 0.1658, batch acc 0.9508
15:11:30.358   Training iter 550, batch loss 0.1638, batch acc 0.9504
15:11:30.893   Training iter 600, batch loss 0.1868, batch acc 0.9448
15:11:30.895 Testing @ 275 epoch...
15:11:30.942     Testing, total mean loss 0.20416, total acc 0.93980
15:11:30.942 Training @ 276 epoch...
15:11:31.503   Training iter 50, batch loss 0.1623, batch acc 0.9480
15:11:32.052   Training iter 100, batch loss 0.1437, batch acc 0.9564
15:11:32.587   Training iter 150, batch loss 0.1640, batch acc 0.9522
15:11:33.103   Training iter 200, batch loss 0.1611, batch acc 0.9506
15:11:33.616   Training iter 250, batch loss 0.1582, batch acc 0.9528
15:11:34.135   Training iter 300, batch loss 0.1667, batch acc 0.9484
15:11:34.664   Training iter 350, batch loss 0.1558, batch acc 0.9534
15:11:35.207   Training iter 400, batch loss 0.1786, batch acc 0.9430
15:11:35.713   Training iter 450, batch loss 0.1651, batch acc 0.9504
15:11:36.187   Training iter 500, batch loss 0.1714, batch acc 0.9508
15:11:36.647   Training iter 550, batch loss 0.1601, batch acc 0.9506
15:11:37.150   Training iter 600, batch loss 0.1640, batch acc 0.9508
15:11:37.151 Training @ 277 epoch...
15:11:37.659   Training iter 50, batch loss 0.1496, batch acc 0.9548
15:11:38.174   Training iter 100, batch loss 0.1535, batch acc 0.9554
15:11:38.665   Training iter 150, batch loss 0.1592, batch acc 0.9540
15:11:39.163   Training iter 200, batch loss 0.1842, batch acc 0.9476
15:11:39.681   Training iter 250, batch loss 0.1558, batch acc 0.9542
15:11:40.210   Training iter 300, batch loss 0.1710, batch acc 0.9504
15:11:40.737   Training iter 350, batch loss 0.1546, batch acc 0.9568
15:11:41.264   Training iter 400, batch loss 0.1674, batch acc 0.9486
15:11:41.792   Training iter 450, batch loss 0.1541, batch acc 0.9518
15:11:42.337   Training iter 500, batch loss 0.1790, batch acc 0.9452
15:11:42.871   Training iter 550, batch loss 0.1580, batch acc 0.9528
15:11:43.382   Training iter 600, batch loss 0.1709, batch acc 0.9474
15:11:43.384 Training @ 278 epoch...
15:11:43.902   Training iter 50, batch loss 0.1708, batch acc 0.9490
15:11:44.420   Training iter 100, batch loss 0.1726, batch acc 0.9506
15:11:44.943   Training iter 150, batch loss 0.1541, batch acc 0.9570
15:11:45.479   Training iter 200, batch loss 0.1700, batch acc 0.9502
15:11:46.018   Training iter 250, batch loss 0.1579, batch acc 0.9526
15:11:46.552   Training iter 300, batch loss 0.1476, batch acc 0.9526
15:11:47.073   Training iter 350, batch loss 0.1694, batch acc 0.9484
15:11:47.597   Training iter 400, batch loss 0.1481, batch acc 0.9528
15:11:48.119   Training iter 450, batch loss 0.1666, batch acc 0.9556
15:11:48.631   Training iter 500, batch loss 0.1759, batch acc 0.9452
15:11:49.136   Training iter 550, batch loss 0.1628, batch acc 0.9510
15:11:49.644   Training iter 600, batch loss 0.1625, batch acc 0.9508
15:11:49.645 Training @ 279 epoch...
15:11:50.156   Training iter 50, batch loss 0.1761, batch acc 0.9478
15:11:50.659   Training iter 100, batch loss 0.1472, batch acc 0.9550
15:11:51.184   Training iter 150, batch loss 0.1552, batch acc 0.9508
15:11:51.707   Training iter 200, batch loss 0.1656, batch acc 0.9534
15:11:52.233   Training iter 250, batch loss 0.1555, batch acc 0.9548
15:11:52.750   Training iter 300, batch loss 0.1694, batch acc 0.9500
15:11:53.288   Training iter 350, batch loss 0.1605, batch acc 0.9494
15:11:53.830   Training iter 400, batch loss 0.1666, batch acc 0.9472
15:11:54.359   Training iter 450, batch loss 0.1874, batch acc 0.9474
15:11:54.900   Training iter 500, batch loss 0.1485, batch acc 0.9550
15:11:55.433   Training iter 550, batch loss 0.1526, batch acc 0.9544
15:11:55.947   Training iter 600, batch loss 0.1502, batch acc 0.9532
15:11:55.949 Training @ 280 epoch...
15:11:56.473   Training iter 50, batch loss 0.1512, batch acc 0.9516
15:11:56.996   Training iter 100, batch loss 0.1679, batch acc 0.9514
15:11:57.536   Training iter 150, batch loss 0.1459, batch acc 0.9576
15:11:58.071   Training iter 200, batch loss 0.1706, batch acc 0.9484
15:11:58.578   Training iter 250, batch loss 0.1635, batch acc 0.9508
15:11:59.093   Training iter 300, batch loss 0.1565, batch acc 0.9520
15:11:59.600   Training iter 350, batch loss 0.1525, batch acc 0.9526
15:12:00.120   Training iter 400, batch loss 0.1517, batch acc 0.9536
15:12:00.636   Training iter 450, batch loss 0.1658, batch acc 0.9490
15:12:01.165   Training iter 500, batch loss 0.1718, batch acc 0.9506
15:12:01.720   Training iter 550, batch loss 0.1762, batch acc 0.9480
15:12:02.258   Training iter 600, batch loss 0.1728, batch acc 0.9506
15:12:02.260 Testing @ 280 epoch...
15:12:02.304     Testing, total mean loss 0.21057, total acc 0.93940
15:12:02.304 Training @ 281 epoch...
15:12:02.792   Training iter 50, batch loss 0.1574, batch acc 0.9524
15:12:03.321   Training iter 100, batch loss 0.1468, batch acc 0.9538
15:12:03.866   Training iter 150, batch loss 0.1794, batch acc 0.9448
15:12:04.402   Training iter 200, batch loss 0.1557, batch acc 0.9532
15:12:04.947   Training iter 250, batch loss 0.1615, batch acc 0.9504
15:12:05.500   Training iter 300, batch loss 0.1598, batch acc 0.9534
15:12:06.057   Training iter 350, batch loss 0.1756, batch acc 0.9484
15:12:06.623   Training iter 400, batch loss 0.1630, batch acc 0.9518
15:12:07.193   Training iter 450, batch loss 0.1587, batch acc 0.9528
15:12:07.738   Training iter 500, batch loss 0.1660, batch acc 0.9522
15:12:08.279   Training iter 550, batch loss 0.1590, batch acc 0.9520
15:12:08.817   Training iter 600, batch loss 0.1606, batch acc 0.9494
15:12:08.819 Training @ 282 epoch...
15:12:09.362   Training iter 50, batch loss 0.1519, batch acc 0.9562
15:12:09.907   Training iter 100, batch loss 0.1641, batch acc 0.9474
15:12:10.465   Training iter 150, batch loss 0.1651, batch acc 0.9544
15:12:10.999   Training iter 200, batch loss 0.1605, batch acc 0.9526
15:12:11.554   Training iter 250, batch loss 0.1708, batch acc 0.9526
15:12:12.088   Training iter 300, batch loss 0.1700, batch acc 0.9466
15:12:12.603   Training iter 350, batch loss 0.1598, batch acc 0.9480
15:12:13.126   Training iter 400, batch loss 0.1691, batch acc 0.9498
15:12:13.645   Training iter 450, batch loss 0.1638, batch acc 0.9526
15:12:14.185   Training iter 500, batch loss 0.1791, batch acc 0.9456
15:12:14.691   Training iter 550, batch loss 0.1573, batch acc 0.9478
15:12:15.231   Training iter 600, batch loss 0.1581, batch acc 0.9510
15:12:15.232 Training @ 283 epoch...
15:12:15.815   Training iter 50, batch loss 0.1654, batch acc 0.9498
15:12:16.399   Training iter 100, batch loss 0.1672, batch acc 0.9482
15:12:16.974   Training iter 150, batch loss 0.1735, batch acc 0.9504
15:12:17.495   Training iter 200, batch loss 0.1659, batch acc 0.9530
15:12:18.023   Training iter 250, batch loss 0.1618, batch acc 0.9532
15:12:18.546   Training iter 300, batch loss 0.1704, batch acc 0.9468
15:12:19.050   Training iter 350, batch loss 0.1508, batch acc 0.9550
15:12:19.563   Training iter 400, batch loss 0.1712, batch acc 0.9502
15:12:20.099   Training iter 450, batch loss 0.1672, batch acc 0.9516
15:12:20.623   Training iter 500, batch loss 0.1674, batch acc 0.9482
15:12:21.110   Training iter 550, batch loss 0.1508, batch acc 0.9510
15:12:21.615   Training iter 600, batch loss 0.1496, batch acc 0.9534
15:12:21.617 Training @ 284 epoch...
15:12:22.115   Training iter 50, batch loss 0.1525, batch acc 0.9562
15:12:22.594   Training iter 100, batch loss 0.1585, batch acc 0.9498
15:12:23.080   Training iter 150, batch loss 0.1572, batch acc 0.9510
15:12:23.531   Training iter 200, batch loss 0.1640, batch acc 0.9534
15:12:23.982   Training iter 250, batch loss 0.1573, batch acc 0.9538
15:12:24.458   Training iter 300, batch loss 0.1631, batch acc 0.9480
15:12:24.943   Training iter 350, batch loss 0.1636, batch acc 0.9528
15:12:25.429   Training iter 400, batch loss 0.1560, batch acc 0.9488
15:12:25.895   Training iter 450, batch loss 0.1747, batch acc 0.9478
15:12:26.381   Training iter 500, batch loss 0.1689, batch acc 0.9480
15:12:26.855   Training iter 550, batch loss 0.1704, batch acc 0.9438
15:12:27.341   Training iter 600, batch loss 0.1704, batch acc 0.9486
15:12:27.343 Training @ 285 epoch...
15:12:27.837   Training iter 50, batch loss 0.1581, batch acc 0.9574
15:12:28.361   Training iter 100, batch loss 0.1573, batch acc 0.9508
15:12:28.898   Training iter 150, batch loss 0.1540, batch acc 0.9502
15:12:29.439   Training iter 200, batch loss 0.1890, batch acc 0.9462
15:12:29.976   Training iter 250, batch loss 0.1615, batch acc 0.9492
15:12:30.524   Training iter 300, batch loss 0.1465, batch acc 0.9538
15:12:31.074   Training iter 350, batch loss 0.1505, batch acc 0.9544
15:12:31.604   Training iter 400, batch loss 0.1613, batch acc 0.9522
15:12:32.127   Training iter 450, batch loss 0.1590, batch acc 0.9520
15:12:32.678   Training iter 500, batch loss 0.1810, batch acc 0.9474
15:12:33.235   Training iter 550, batch loss 0.1787, batch acc 0.9520
15:12:33.810   Training iter 600, batch loss 0.1482, batch acc 0.9550
15:12:33.812 Testing @ 285 epoch...
15:12:33.858     Testing, total mean loss 0.21635, total acc 0.93680
15:12:33.858 Training @ 286 epoch...
15:12:34.403   Training iter 50, batch loss 0.1586, batch acc 0.9516
15:12:34.939   Training iter 100, batch loss 0.1801, batch acc 0.9488
15:12:35.471   Training iter 150, batch loss 0.1453, batch acc 0.9574
15:12:35.968   Training iter 200, batch loss 0.1606, batch acc 0.9528
15:12:36.460   Training iter 250, batch loss 0.1691, batch acc 0.9518
15:12:36.957   Training iter 300, batch loss 0.1616, batch acc 0.9536
15:12:37.469   Training iter 350, batch loss 0.1630, batch acc 0.9484
15:12:38.002   Training iter 400, batch loss 0.1608, batch acc 0.9510
15:12:38.573   Training iter 450, batch loss 0.1658, batch acc 0.9534
15:12:39.073   Training iter 500, batch loss 0.1497, batch acc 0.9568
15:12:39.571   Training iter 550, batch loss 0.1686, batch acc 0.9508
15:12:40.081   Training iter 600, batch loss 0.1625, batch acc 0.9500
15:12:40.083 Training @ 287 epoch...
15:12:40.600   Training iter 50, batch loss 0.1680, batch acc 0.9488
15:12:41.091   Training iter 100, batch loss 0.1491, batch acc 0.9554
15:12:41.614   Training iter 150, batch loss 0.1637, batch acc 0.9500
15:12:42.152   Training iter 200, batch loss 0.1626, batch acc 0.9534
15:12:42.688   Training iter 250, batch loss 0.1591, batch acc 0.9544
15:12:43.217   Training iter 300, batch loss 0.1534, batch acc 0.9570
15:12:43.709   Training iter 350, batch loss 0.1754, batch acc 0.9446
15:12:44.219   Training iter 400, batch loss 0.1639, batch acc 0.9554
15:12:44.751   Training iter 450, batch loss 0.1554, batch acc 0.9542
15:12:45.298   Training iter 500, batch loss 0.1627, batch acc 0.9496
15:12:45.850   Training iter 550, batch loss 0.1551, batch acc 0.9520
15:12:46.422   Training iter 600, batch loss 0.1764, batch acc 0.9458
15:12:46.424 Training @ 288 epoch...
15:12:46.980   Training iter 50, batch loss 0.1515, batch acc 0.9566
15:12:47.533   Training iter 100, batch loss 0.1497, batch acc 0.9518
15:12:48.105   Training iter 150, batch loss 0.1706, batch acc 0.9474
15:12:48.636   Training iter 200, batch loss 0.1629, batch acc 0.9514
15:12:49.140   Training iter 250, batch loss 0.1694, batch acc 0.9488
15:12:49.681   Training iter 300, batch loss 0.1643, batch acc 0.9474
15:12:50.223   Training iter 350, batch loss 0.1492, batch acc 0.9558
15:12:50.761   Training iter 400, batch loss 0.1725, batch acc 0.9454
15:12:51.280   Training iter 450, batch loss 0.1557, batch acc 0.9540
15:12:51.794   Training iter 500, batch loss 0.1663, batch acc 0.9478
15:12:52.313   Training iter 550, batch loss 0.1529, batch acc 0.9598
15:12:52.817   Training iter 600, batch loss 0.1650, batch acc 0.9518
15:12:52.819 Training @ 289 epoch...
15:12:53.327   Training iter 50, batch loss 0.1532, batch acc 0.9514
15:12:53.820   Training iter 100, batch loss 0.1471, batch acc 0.9548
15:12:54.324   Training iter 150, batch loss 0.1679, batch acc 0.9502
15:12:54.835   Training iter 200, batch loss 0.1683, batch acc 0.9496
15:12:55.356   Training iter 250, batch loss 0.1598, batch acc 0.9538
15:12:55.855   Training iter 300, batch loss 0.1648, batch acc 0.9492
15:12:56.374   Training iter 350, batch loss 0.1514, batch acc 0.9546
15:12:56.884   Training iter 400, batch loss 0.1655, batch acc 0.9548
15:12:57.391   Training iter 450, batch loss 0.1749, batch acc 0.9470
15:12:57.889   Training iter 500, batch loss 0.1638, batch acc 0.9554
15:12:58.376   Training iter 550, batch loss 0.1761, batch acc 0.9492
15:12:58.852   Training iter 600, batch loss 0.1486, batch acc 0.9560
15:12:58.854 Training @ 290 epoch...
15:12:59.341   Training iter 50, batch loss 0.1606, batch acc 0.9542
15:12:59.817   Training iter 100, batch loss 0.1571, batch acc 0.9506
15:13:00.271   Training iter 150, batch loss 0.1482, batch acc 0.9554
15:13:00.735   Training iter 200, batch loss 0.1730, batch acc 0.9456
15:13:01.207   Training iter 250, batch loss 0.1662, batch acc 0.9528
15:13:01.740   Training iter 300, batch loss 0.1588, batch acc 0.9524
15:13:02.313   Training iter 350, batch loss 0.1710, batch acc 0.9512
15:13:02.900   Training iter 400, batch loss 0.1556, batch acc 0.9516
15:13:03.508   Training iter 450, batch loss 0.1698, batch acc 0.9472
15:13:04.075   Training iter 500, batch loss 0.1559, batch acc 0.9532
15:13:04.604   Training iter 550, batch loss 0.1746, batch acc 0.9504
15:13:05.142   Training iter 600, batch loss 0.1572, batch acc 0.9550
15:13:05.144 Testing @ 290 epoch...
15:13:05.188     Testing, total mean loss 0.20516, total acc 0.93870
15:13:05.188 Training @ 291 epoch...
15:13:05.717   Training iter 50, batch loss 0.1635, batch acc 0.9520
15:13:06.248   Training iter 100, batch loss 0.1563, batch acc 0.9556
15:13:06.757   Training iter 150, batch loss 0.1640, batch acc 0.9490
15:13:07.271   Training iter 200, batch loss 0.1461, batch acc 0.9508
15:13:07.791   Training iter 250, batch loss 0.1636, batch acc 0.9504
15:13:08.342   Training iter 300, batch loss 0.1511, batch acc 0.9542
15:13:08.866   Training iter 350, batch loss 0.1621, batch acc 0.9512
15:13:09.415   Training iter 400, batch loss 0.1744, batch acc 0.9490
15:13:09.940   Training iter 450, batch loss 0.1713, batch acc 0.9494
15:13:10.483   Training iter 500, batch loss 0.1599, batch acc 0.9524
15:13:11.014   Training iter 550, batch loss 0.1627, batch acc 0.9526
15:13:11.559   Training iter 600, batch loss 0.1722, batch acc 0.9466
15:13:11.561 Training @ 292 epoch...
15:13:12.126   Training iter 50, batch loss 0.1616, batch acc 0.9516
15:13:12.685   Training iter 100, batch loss 0.1580, batch acc 0.9558
15:13:13.258   Training iter 150, batch loss 0.1544, batch acc 0.9508
15:13:13.802   Training iter 200, batch loss 0.1615, batch acc 0.9530
15:13:14.370   Training iter 250, batch loss 0.1694, batch acc 0.9458
15:13:14.936   Training iter 300, batch loss 0.1575, batch acc 0.9526
15:13:15.509   Training iter 350, batch loss 0.1552, batch acc 0.9520
15:13:16.068   Training iter 400, batch loss 0.1692, batch acc 0.9502
15:13:16.657   Training iter 450, batch loss 0.1656, batch acc 0.9510
15:13:17.258   Training iter 500, batch loss 0.1684, batch acc 0.9478
15:13:17.844   Training iter 550, batch loss 0.1683, batch acc 0.9482
15:13:18.437   Training iter 600, batch loss 0.1720, batch acc 0.9500
15:13:18.439 Training @ 293 epoch...
15:13:19.024   Training iter 50, batch loss 0.1575, batch acc 0.9526
15:13:19.603   Training iter 100, batch loss 0.1757, batch acc 0.9484
15:13:20.189   Training iter 150, batch loss 0.1569, batch acc 0.9518
15:13:20.767   Training iter 200, batch loss 0.1577, batch acc 0.9514
15:13:21.352   Training iter 250, batch loss 0.1526, batch acc 0.9522
15:13:21.923   Training iter 300, batch loss 0.1759, batch acc 0.9506
15:13:22.483   Training iter 350, batch loss 0.1607, batch acc 0.9510
15:13:23.005   Training iter 400, batch loss 0.1670, batch acc 0.9490
15:13:23.536   Training iter 450, batch loss 0.1600, batch acc 0.9524
15:13:24.057   Training iter 500, batch loss 0.1761, batch acc 0.9478
15:13:24.594   Training iter 550, batch loss 0.1532, batch acc 0.9522
15:13:25.140   Training iter 600, batch loss 0.1648, batch acc 0.9500
15:13:25.142 Training @ 294 epoch...
15:13:25.695   Training iter 50, batch loss 0.1495, batch acc 0.9544
15:13:26.230   Training iter 100, batch loss 0.1576, batch acc 0.9512
15:13:26.747   Training iter 150, batch loss 0.1513, batch acc 0.9556
15:13:27.266   Training iter 200, batch loss 0.1532, batch acc 0.9514
15:13:27.775   Training iter 250, batch loss 0.1662, batch acc 0.9486
15:13:28.290   Training iter 300, batch loss 0.1640, batch acc 0.9512
15:13:28.805   Training iter 350, batch loss 0.1664, batch acc 0.9534
15:13:29.337   Training iter 400, batch loss 0.1721, batch acc 0.9514
15:13:29.878   Training iter 450, batch loss 0.1630, batch acc 0.9534
15:13:30.430   Training iter 500, batch loss 0.1762, batch acc 0.9464
15:13:30.961   Training iter 550, batch loss 0.1714, batch acc 0.9528
15:13:31.493   Training iter 600, batch loss 0.1427, batch acc 0.9570
15:13:31.494 Training @ 295 epoch...
15:13:32.033   Training iter 50, batch loss 0.1556, batch acc 0.9544
15:13:32.593   Training iter 100, batch loss 0.1702, batch acc 0.9482
15:13:33.151   Training iter 150, batch loss 0.1614, batch acc 0.9538
15:13:33.701   Training iter 200, batch loss 0.1530, batch acc 0.9556
15:13:34.238   Training iter 250, batch loss 0.1581, batch acc 0.9536
15:13:34.761   Training iter 300, batch loss 0.1557, batch acc 0.9540
15:13:35.291   Training iter 350, batch loss 0.1584, batch acc 0.9494
15:13:35.827   Training iter 400, batch loss 0.1633, batch acc 0.9522
15:13:36.366   Training iter 450, batch loss 0.1683, batch acc 0.9512
15:13:36.906   Training iter 500, batch loss 0.1515, batch acc 0.9526
15:13:37.464   Training iter 550, batch loss 0.1764, batch acc 0.9476
15:13:38.036   Training iter 600, batch loss 0.1607, batch acc 0.9522
15:13:38.038 Testing @ 295 epoch...
15:13:38.084     Testing, total mean loss 0.21947, total acc 0.93690
15:13:38.084 Training @ 296 epoch...
15:13:38.626   Training iter 50, batch loss 0.1409, batch acc 0.9592
15:13:39.144   Training iter 100, batch loss 0.1588, batch acc 0.9512
15:13:39.671   Training iter 150, batch loss 0.1733, batch acc 0.9488
15:13:40.195   Training iter 200, batch loss 0.1808, batch acc 0.9490
15:13:40.741   Training iter 250, batch loss 0.1693, batch acc 0.9500
15:13:41.269   Training iter 300, batch loss 0.1766, batch acc 0.9486
15:13:41.795   Training iter 350, batch loss 0.1577, batch acc 0.9530
15:13:42.321   Training iter 400, batch loss 0.1523, batch acc 0.9554
15:13:42.843   Training iter 450, batch loss 0.1686, batch acc 0.9500
15:13:43.392   Training iter 500, batch loss 0.1539, batch acc 0.9534
15:13:43.926   Training iter 550, batch loss 0.1641, batch acc 0.9500
15:13:44.465   Training iter 600, batch loss 0.1492, batch acc 0.9582
15:13:44.467 Training @ 297 epoch...
15:13:44.999   Training iter 50, batch loss 0.1514, batch acc 0.9562
15:13:45.522   Training iter 100, batch loss 0.1480, batch acc 0.9558
15:13:46.034   Training iter 150, batch loss 0.1580, batch acc 0.9506
15:13:46.524   Training iter 200, batch loss 0.1588, batch acc 0.9510
15:13:47.023   Training iter 250, batch loss 0.1573, batch acc 0.9560
15:13:47.523   Training iter 300, batch loss 0.1518, batch acc 0.9566
15:13:48.007   Training iter 350, batch loss 0.1502, batch acc 0.9520
15:13:48.524   Training iter 400, batch loss 0.1712, batch acc 0.9494
15:13:49.045   Training iter 450, batch loss 0.1763, batch acc 0.9444
15:13:49.578   Training iter 500, batch loss 0.1613, batch acc 0.9520
15:13:50.163   Training iter 550, batch loss 0.1920, batch acc 0.9436
15:13:50.747   Training iter 600, batch loss 0.1822, batch acc 0.9460
15:13:50.748 Training @ 298 epoch...
15:13:51.330   Training iter 50, batch loss 0.1543, batch acc 0.9546
15:13:51.828   Training iter 100, batch loss 0.1716, batch acc 0.9452
15:13:52.336   Training iter 150, batch loss 0.1626, batch acc 0.9498
15:13:52.865   Training iter 200, batch loss 0.1443, batch acc 0.9544
15:13:53.425   Training iter 250, batch loss 0.1518, batch acc 0.9544
15:13:53.967   Training iter 300, batch loss 0.1662, batch acc 0.9546
15:13:54.470   Training iter 350, batch loss 0.1512, batch acc 0.9534
15:13:54.952   Training iter 400, batch loss 0.1673, batch acc 0.9510
15:13:55.457   Training iter 450, batch loss 0.1790, batch acc 0.9436
15:13:55.947   Training iter 500, batch loss 0.1805, batch acc 0.9462
15:13:56.450   Training iter 550, batch loss 0.1707, batch acc 0.9474
15:13:56.943   Training iter 600, batch loss 0.1468, batch acc 0.9536
15:13:56.945 Training @ 299 epoch...
15:13:57.443   Training iter 50, batch loss 0.1584, batch acc 0.9504
15:13:57.948   Training iter 100, batch loss 0.1485, batch acc 0.9564
15:13:58.457   Training iter 150, batch loss 0.1647, batch acc 0.9516
15:13:58.953   Training iter 200, batch loss 0.1517, batch acc 0.9554
15:13:59.449   Training iter 250, batch loss 0.1608, batch acc 0.9544
15:13:59.959   Training iter 300, batch loss 0.1652, batch acc 0.9520
15:14:00.474   Training iter 350, batch loss 0.1732, batch acc 0.9482
15:14:00.987   Training iter 400, batch loss 0.1587, batch acc 0.9534
15:14:01.520   Training iter 450, batch loss 0.1511, batch acc 0.9552
15:14:02.085   Training iter 500, batch loss 0.1813, batch acc 0.9470
15:14:02.637   Training iter 550, batch loss 0.1639, batch acc 0.9494
15:14:03.173   Training iter 600, batch loss 0.1594, batch acc 0.9486
15:14:03.175 Training @ 300 epoch...
15:14:03.776   Training iter 50, batch loss 0.1764, batch acc 0.9524
15:14:04.528   Training iter 100, batch loss 0.1506, batch acc 0.9602
15:14:05.156   Training iter 150, batch loss 0.1564, batch acc 0.9538
15:14:05.766   Training iter 200, batch loss 0.1604, batch acc 0.9490
15:14:06.387   Training iter 250, batch loss 0.1499, batch acc 0.9540
15:14:06.997   Training iter 300, batch loss 0.1662, batch acc 0.9514
15:14:07.604   Training iter 350, batch loss 0.1440, batch acc 0.9566
15:14:08.200   Training iter 400, batch loss 0.1499, batch acc 0.9536
15:14:08.778   Training iter 450, batch loss 0.1650, batch acc 0.9512
15:14:09.350   Training iter 500, batch loss 0.1763, batch acc 0.9476
15:14:09.905   Training iter 550, batch loss 0.1687, batch acc 0.9462
15:14:10.448   Training iter 600, batch loss 0.1766, batch acc 0.9452
15:14:10.449 Testing @ 300 epoch...
15:14:10.495     Testing, total mean loss 0.20960, total acc 0.93960
15:14:10.495 Plot @ 300 epoch...
15:14:10.495 Training @ 301 epoch...
15:14:11.020   Training iter 50, batch loss 0.1481, batch acc 0.9550
15:14:11.546   Training iter 100, batch loss 0.1771, batch acc 0.9454
15:14:12.068   Training iter 150, batch loss 0.1669, batch acc 0.9508
15:14:12.604   Training iter 200, batch loss 0.1712, batch acc 0.9452
15:14:13.141   Training iter 250, batch loss 0.1712, batch acc 0.9488
15:14:13.710   Training iter 300, batch loss 0.1557, batch acc 0.9538
15:14:14.286   Training iter 350, batch loss 0.1574, batch acc 0.9536
15:14:14.851   Training iter 400, batch loss 0.1524, batch acc 0.9550
15:14:15.412   Training iter 450, batch loss 0.1533, batch acc 0.9534
15:14:16.023   Training iter 500, batch loss 0.1549, batch acc 0.9534
15:14:16.573   Training iter 550, batch loss 0.1760, batch acc 0.9494
15:14:17.116   Training iter 600, batch loss 0.1618, batch acc 0.9566
15:14:17.118 Training @ 302 epoch...
15:14:17.670   Training iter 50, batch loss 0.1632, batch acc 0.9478
15:14:18.228   Training iter 100, batch loss 0.1623, batch acc 0.9546
15:14:18.764   Training iter 150, batch loss 0.1782, batch acc 0.9466
15:14:19.300   Training iter 200, batch loss 0.1599, batch acc 0.9506
15:14:19.857   Training iter 250, batch loss 0.1604, batch acc 0.9504
15:14:20.432   Training iter 300, batch loss 0.1501, batch acc 0.9548
15:14:21.004   Training iter 350, batch loss 0.1529, batch acc 0.9540
15:14:21.571   Training iter 400, batch loss 0.1694, batch acc 0.9516
15:14:22.143   Training iter 450, batch loss 0.1655, batch acc 0.9502
15:14:22.708   Training iter 500, batch loss 0.1755, batch acc 0.9446
15:14:23.281   Training iter 550, batch loss 0.1569, batch acc 0.9546
15:14:23.833   Training iter 600, batch loss 0.1647, batch acc 0.9510
15:14:23.835 Training @ 303 epoch...
15:14:24.408   Training iter 50, batch loss 0.1580, batch acc 0.9528
15:14:24.979   Training iter 100, batch loss 0.1452, batch acc 0.9582
15:14:25.556   Training iter 150, batch loss 0.1623, batch acc 0.9536
15:14:26.129   Training iter 200, batch loss 0.1643, batch acc 0.9534
15:14:26.683   Training iter 250, batch loss 0.1664, batch acc 0.9478
15:14:27.232   Training iter 300, batch loss 0.1631, batch acc 0.9508
15:14:27.778   Training iter 350, batch loss 0.1560, batch acc 0.9480
15:14:28.326   Training iter 400, batch loss 0.1581, batch acc 0.9528
15:14:28.829   Training iter 450, batch loss 0.1616, batch acc 0.9530
15:14:29.366   Training iter 500, batch loss 0.1660, batch acc 0.9478
15:14:29.910   Training iter 550, batch loss 0.1709, batch acc 0.9496
15:14:30.463   Training iter 600, batch loss 0.1766, batch acc 0.9474
15:14:30.465 Training @ 304 epoch...
15:14:31.002   Training iter 50, batch loss 0.1690, batch acc 0.9528
15:14:31.545   Training iter 100, batch loss 0.1565, batch acc 0.9494
15:14:32.095   Training iter 150, batch loss 0.1611, batch acc 0.9504
15:14:32.647   Training iter 200, batch loss 0.1577, batch acc 0.9542
15:14:33.198   Training iter 250, batch loss 0.1575, batch acc 0.9520
15:14:33.752   Training iter 300, batch loss 0.1719, batch acc 0.9478
15:14:34.306   Training iter 350, batch loss 0.1625, batch acc 0.9524
15:14:34.874   Training iter 400, batch loss 0.1637, batch acc 0.9514
15:14:35.426   Training iter 450, batch loss 0.1690, batch acc 0.9492
15:14:35.976   Training iter 500, batch loss 0.1505, batch acc 0.9546
15:14:36.512   Training iter 550, batch loss 0.1578, batch acc 0.9512
15:14:37.062   Training iter 600, batch loss 0.1591, batch acc 0.9518
15:14:37.064 Training @ 305 epoch...
15:14:37.617   Training iter 50, batch loss 0.1805, batch acc 0.9478
15:14:38.184   Training iter 100, batch loss 0.1406, batch acc 0.9554
15:14:38.763   Training iter 150, batch loss 0.1349, batch acc 0.9582
15:14:39.323   Training iter 200, batch loss 0.1608, batch acc 0.9552
15:14:39.887   Training iter 250, batch loss 0.1643, batch acc 0.9526
15:14:40.482   Training iter 300, batch loss 0.1484, batch acc 0.9526
15:14:41.066   Training iter 350, batch loss 0.1755, batch acc 0.9466
15:14:41.640   Training iter 400, batch loss 0.1805, batch acc 0.9464
15:14:42.229   Training iter 450, batch loss 0.1676, batch acc 0.9486
15:14:42.832   Training iter 500, batch loss 0.1617, batch acc 0.9528
15:14:43.417   Training iter 550, batch loss 0.1778, batch acc 0.9472
15:14:44.023   Training iter 600, batch loss 0.1532, batch acc 0.9530
15:14:44.026 Testing @ 305 epoch...
15:14:44.090     Testing, total mean loss 0.21787, total acc 0.93720
15:14:44.090 Training @ 306 epoch...
15:14:44.842   Training iter 50, batch loss 0.1528, batch acc 0.9538
15:14:45.586   Training iter 100, batch loss 0.1497, batch acc 0.9578
15:14:46.209   Training iter 150, batch loss 0.1582, batch acc 0.9528
15:14:46.762   Training iter 200, batch loss 0.1686, batch acc 0.9502
15:14:47.319   Training iter 250, batch loss 0.1568, batch acc 0.9542
15:14:47.883   Training iter 300, batch loss 0.1728, batch acc 0.9482
15:14:48.453   Training iter 350, batch loss 0.1760, batch acc 0.9472
15:14:49.024   Training iter 400, batch loss 0.1706, batch acc 0.9522
15:14:49.566   Training iter 450, batch loss 0.1536, batch acc 0.9544
15:14:50.107   Training iter 500, batch loss 0.1539, batch acc 0.9500
15:14:50.649   Training iter 550, batch loss 0.1593, batch acc 0.9542
15:14:51.213   Training iter 600, batch loss 0.1609, batch acc 0.9564
15:14:51.215 Training @ 307 epoch...
15:14:51.770   Training iter 50, batch loss 0.1396, batch acc 0.9582
15:14:52.335   Training iter 100, batch loss 0.1652, batch acc 0.9464
15:14:52.914   Training iter 150, batch loss 0.1868, batch acc 0.9436
15:14:53.490   Training iter 200, batch loss 0.1624, batch acc 0.9528
15:14:54.060   Training iter 250, batch loss 0.1450, batch acc 0.9554
15:14:54.634   Training iter 300, batch loss 0.1531, batch acc 0.9550
15:14:55.210   Training iter 350, batch loss 0.1668, batch acc 0.9492
15:14:55.771   Training iter 400, batch loss 0.1631, batch acc 0.9484
15:14:56.337   Training iter 450, batch loss 0.1573, batch acc 0.9546
15:14:56.899   Training iter 500, batch loss 0.1660, batch acc 0.9488
15:14:57.467   Training iter 550, batch loss 0.1775, batch acc 0.9454
15:14:58.029   Training iter 600, batch loss 0.1701, batch acc 0.9482
15:14:58.031 Training @ 308 epoch...
15:14:58.573   Training iter 50, batch loss 0.1548, batch acc 0.9530
15:14:59.097   Training iter 100, batch loss 0.1658, batch acc 0.9526
15:14:59.671   Training iter 150, batch loss 0.1669, batch acc 0.9490
15:15:00.224   Training iter 200, batch loss 0.1615, batch acc 0.9486
15:15:00.730   Training iter 250, batch loss 0.1606, batch acc 0.9492
15:15:01.233   Training iter 300, batch loss 0.1772, batch acc 0.9472
15:15:01.782   Training iter 350, batch loss 0.1723, batch acc 0.9464
15:15:02.334   Training iter 400, batch loss 0.1689, batch acc 0.9486
15:15:02.861   Training iter 450, batch loss 0.1448, batch acc 0.9540
15:15:03.370   Training iter 500, batch loss 0.1541, batch acc 0.9572
15:15:03.866   Training iter 550, batch loss 0.1545, batch acc 0.9524
15:15:04.388   Training iter 600, batch loss 0.1634, batch acc 0.9494
15:15:04.390 Training @ 309 epoch...
15:15:04.939   Training iter 50, batch loss 0.1446, batch acc 0.9550
15:15:05.481   Training iter 100, batch loss 0.1586, batch acc 0.9550
15:15:05.991   Training iter 150, batch loss 0.1598, batch acc 0.9514
15:15:06.502   Training iter 200, batch loss 0.1648, batch acc 0.9482
15:15:06.998   Training iter 250, batch loss 0.1737, batch acc 0.9506
15:15:07.496   Training iter 300, batch loss 0.1760, batch acc 0.9448
15:15:08.012   Training iter 350, batch loss 0.1540, batch acc 0.9520
15:15:08.507   Training iter 400, batch loss 0.1468, batch acc 0.9550
15:15:08.999   Training iter 450, batch loss 0.1545, batch acc 0.9532
15:15:09.495   Training iter 500, batch loss 0.1873, batch acc 0.9406
15:15:10.021   Training iter 550, batch loss 0.1634, batch acc 0.9488
15:15:10.531   Training iter 600, batch loss 0.1688, batch acc 0.9506
15:15:10.533 Training @ 310 epoch...
15:15:11.038   Training iter 50, batch loss 0.1688, batch acc 0.9522
15:15:11.579   Training iter 100, batch loss 0.1628, batch acc 0.9536
15:15:12.136   Training iter 150, batch loss 0.1448, batch acc 0.9576
15:15:12.673   Training iter 200, batch loss 0.1537, batch acc 0.9528
15:15:13.211   Training iter 250, batch loss 0.1688, batch acc 0.9514
15:15:13.751   Training iter 300, batch loss 0.1657, batch acc 0.9536
15:15:14.294   Training iter 350, batch loss 0.1618, batch acc 0.9538
15:15:14.833   Training iter 400, batch loss 0.1605, batch acc 0.9484
15:15:15.373   Training iter 450, batch loss 0.1683, batch acc 0.9484
15:15:15.904   Training iter 500, batch loss 0.1615, batch acc 0.9490
15:15:16.468   Training iter 550, batch loss 0.1634, batch acc 0.9508
15:15:17.073   Training iter 600, batch loss 0.1576, batch acc 0.9506
15:15:17.075 Testing @ 310 epoch...
15:15:17.121     Testing, total mean loss 0.20989, total acc 0.93920
15:15:17.121 Training @ 311 epoch...
15:15:17.722   Training iter 50, batch loss 0.1718, batch acc 0.9486
15:15:18.264   Training iter 100, batch loss 0.1662, batch acc 0.9540
15:15:18.774   Training iter 150, batch loss 0.1572, batch acc 0.9524
15:15:19.301   Training iter 200, batch loss 0.1498, batch acc 0.9562
15:15:19.840   Training iter 250, batch loss 0.1721, batch acc 0.9544
15:15:20.364   Training iter 300, batch loss 0.1565, batch acc 0.9512
15:15:20.869   Training iter 350, batch loss 0.1528, batch acc 0.9526
15:15:21.382   Training iter 400, batch loss 0.1645, batch acc 0.9510
15:15:21.893   Training iter 450, batch loss 0.1632, batch acc 0.9488
15:15:22.407   Training iter 500, batch loss 0.1616, batch acc 0.9506
15:15:22.927   Training iter 550, batch loss 0.1760, batch acc 0.9462
15:15:23.448   Training iter 600, batch loss 0.1542, batch acc 0.9530
15:15:23.450 Training @ 312 epoch...
15:15:23.967   Training iter 50, batch loss 0.1539, batch acc 0.9526
15:15:24.501   Training iter 100, batch loss 0.1598, batch acc 0.9528
15:15:25.034   Training iter 150, batch loss 0.1457, batch acc 0.9526
15:15:25.604   Training iter 200, batch loss 0.1646, batch acc 0.9508
15:15:26.185   Training iter 250, batch loss 0.1562, batch acc 0.9524
15:15:26.759   Training iter 300, batch loss 0.1765, batch acc 0.9480
15:15:27.343   Training iter 350, batch loss 0.1508, batch acc 0.9540
15:15:27.921   Training iter 400, batch loss 0.1782, batch acc 0.9464
15:15:28.485   Training iter 450, batch loss 0.1751, batch acc 0.9480
15:15:29.047   Training iter 500, batch loss 0.1616, batch acc 0.9544
15:15:29.608   Training iter 550, batch loss 0.1640, batch acc 0.9504
15:15:30.173   Training iter 600, batch loss 0.1531, batch acc 0.9554
15:15:30.175 Training @ 313 epoch...
15:15:30.709   Training iter 50, batch loss 0.1668, batch acc 0.9482
15:15:31.247   Training iter 100, batch loss 0.1515, batch acc 0.9520
15:15:31.782   Training iter 150, batch loss 0.1543, batch acc 0.9504
15:15:32.308   Training iter 200, batch loss 0.1768, batch acc 0.9482
15:15:32.801   Training iter 250, batch loss 0.1691, batch acc 0.9496
15:15:33.312   Training iter 300, batch loss 0.1752, batch acc 0.9510
15:15:33.812   Training iter 350, batch loss 0.1581, batch acc 0.9502
15:15:34.321   Training iter 400, batch loss 0.1557, batch acc 0.9536
15:15:34.847   Training iter 450, batch loss 0.1739, batch acc 0.9494
15:15:35.375   Training iter 500, batch loss 0.1590, batch acc 0.9538
15:15:35.919   Training iter 550, batch loss 0.1577, batch acc 0.9502
15:15:36.470   Training iter 600, batch loss 0.1554, batch acc 0.9532
15:15:36.471 Training @ 314 epoch...
15:15:37.039   Training iter 50, batch loss 0.1673, batch acc 0.9498
15:15:37.586   Training iter 100, batch loss 0.1603, batch acc 0.9520
15:15:38.147   Training iter 150, batch loss 0.1463, batch acc 0.9554
15:15:38.700   Training iter 200, batch loss 0.1572, batch acc 0.9532
15:15:39.234   Training iter 250, batch loss 0.1644, batch acc 0.9506
15:15:39.727   Training iter 300, batch loss 0.1590, batch acc 0.9490
15:15:40.224   Training iter 350, batch loss 0.1605, batch acc 0.9518
15:15:40.714   Training iter 400, batch loss 0.1679, batch acc 0.9516
15:15:41.198   Training iter 450, batch loss 0.1721, batch acc 0.9494
15:15:41.707   Training iter 500, batch loss 0.1626, batch acc 0.9512
15:15:42.209   Training iter 550, batch loss 0.1687, batch acc 0.9468
15:15:42.718   Training iter 600, batch loss 0.1583, batch acc 0.9540
15:15:42.720 Training @ 315 epoch...
15:15:43.241   Training iter 50, batch loss 0.1502, batch acc 0.9544
15:15:43.702   Training iter 100, batch loss 0.1458, batch acc 0.9540
15:15:44.170   Training iter 150, batch loss 0.1551, batch acc 0.9564
15:15:44.666   Training iter 200, batch loss 0.1604, batch acc 0.9538
15:15:45.214   Training iter 250, batch loss 0.1630, batch acc 0.9522
15:15:45.690   Training iter 300, batch loss 0.1735, batch acc 0.9520
15:15:46.201   Training iter 350, batch loss 0.1569, batch acc 0.9534
15:15:46.662   Training iter 400, batch loss 0.1761, batch acc 0.9474
15:15:47.124   Training iter 450, batch loss 0.1653, batch acc 0.9478
15:15:47.580   Training iter 500, batch loss 0.1716, batch acc 0.9450
15:15:48.052   Training iter 550, batch loss 0.1703, batch acc 0.9518
15:15:48.542   Training iter 600, batch loss 0.1641, batch acc 0.9490
15:15:48.544 Testing @ 315 epoch...
15:15:48.590     Testing, total mean loss 0.21027, total acc 0.93790
15:15:48.590 Training @ 316 epoch...
15:15:49.065   Training iter 50, batch loss 0.1606, batch acc 0.9468
15:15:49.562   Training iter 100, batch loss 0.1492, batch acc 0.9520
15:15:50.056   Training iter 150, batch loss 0.1569, batch acc 0.9542
15:15:50.563   Training iter 200, batch loss 0.1567, batch acc 0.9552
15:15:51.056   Training iter 250, batch loss 0.1688, batch acc 0.9498
15:15:51.533   Training iter 300, batch loss 0.1542, batch acc 0.9536
15:15:52.065   Training iter 350, batch loss 0.1521, batch acc 0.9532
15:15:52.596   Training iter 400, batch loss 0.1748, batch acc 0.9478
15:15:53.103   Training iter 450, batch loss 0.1756, batch acc 0.9462
15:15:53.604   Training iter 500, batch loss 0.1572, batch acc 0.9544
15:15:54.103   Training iter 550, batch loss 0.1581, batch acc 0.9524
15:15:54.623   Training iter 600, batch loss 0.1683, batch acc 0.9498
15:15:54.625 Training @ 317 epoch...
15:15:55.183   Training iter 50, batch loss 0.1537, batch acc 0.9536
15:15:55.711   Training iter 100, batch loss 0.1437, batch acc 0.9558
15:15:56.227   Training iter 150, batch loss 0.1560, batch acc 0.9502
15:15:56.745   Training iter 200, batch loss 0.1640, batch acc 0.9532
15:15:57.272   Training iter 250, batch loss 0.1630, batch acc 0.9500
15:15:57.817   Training iter 300, batch loss 0.1704, batch acc 0.9538
15:15:58.393   Training iter 350, batch loss 0.1516, batch acc 0.9538
15:15:58.927   Training iter 400, batch loss 0.1571, batch acc 0.9570
15:15:59.480   Training iter 450, batch loss 0.1736, batch acc 0.9462
15:16:00.038   Training iter 500, batch loss 0.1620, batch acc 0.9528
15:16:00.631   Training iter 550, batch loss 0.1703, batch acc 0.9464
15:16:01.197   Training iter 600, batch loss 0.1725, batch acc 0.9490
15:16:01.199 Training @ 318 epoch...
15:16:01.795   Training iter 50, batch loss 0.1631, batch acc 0.9502
15:16:02.385   Training iter 100, batch loss 0.1447, batch acc 0.9552
15:16:02.959   Training iter 150, batch loss 0.1562, batch acc 0.9536
15:16:03.544   Training iter 200, batch loss 0.1540, batch acc 0.9514
15:16:04.102   Training iter 250, batch loss 0.1869, batch acc 0.9436
15:16:04.669   Training iter 300, batch loss 0.1589, batch acc 0.9500
15:16:05.222   Training iter 350, batch loss 0.1847, batch acc 0.9486
15:16:05.785   Training iter 400, batch loss 0.1594, batch acc 0.9502
15:16:06.362   Training iter 450, batch loss 0.1521, batch acc 0.9558
15:16:07.010   Training iter 500, batch loss 0.1646, batch acc 0.9508
15:16:07.581   Training iter 550, batch loss 0.1475, batch acc 0.9566
15:16:08.121   Training iter 600, batch loss 0.1768, batch acc 0.9446
15:16:08.122 Training @ 319 epoch...
15:16:08.656   Training iter 50, batch loss 0.1355, batch acc 0.9570
15:16:09.183   Training iter 100, batch loss 0.1739, batch acc 0.9468
15:16:09.738   Training iter 150, batch loss 0.1610, batch acc 0.9522
15:16:10.276   Training iter 200, batch loss 0.1668, batch acc 0.9512
15:16:10.837   Training iter 250, batch loss 0.1670, batch acc 0.9516
15:16:11.404   Training iter 300, batch loss 0.1665, batch acc 0.9504
15:16:11.946   Training iter 350, batch loss 0.1617, batch acc 0.9538
15:16:12.478   Training iter 400, batch loss 0.1687, batch acc 0.9500
15:16:13.034   Training iter 450, batch loss 0.1782, batch acc 0.9496
15:16:13.575   Training iter 500, batch loss 0.1725, batch acc 0.9472
15:16:14.143   Training iter 550, batch loss 0.1467, batch acc 0.9546
15:16:14.708   Training iter 600, batch loss 0.1494, batch acc 0.9562
15:16:14.710 Training @ 320 epoch...
15:16:15.275   Training iter 50, batch loss 0.1554, batch acc 0.9496
15:16:15.839   Training iter 100, batch loss 0.1598, batch acc 0.9524
15:16:16.416   Training iter 150, batch loss 0.1744, batch acc 0.9454
15:16:17.006   Training iter 200, batch loss 0.1558, batch acc 0.9504
15:16:17.589   Training iter 250, batch loss 0.1807, batch acc 0.9440
15:16:18.179   Training iter 300, batch loss 0.1558, batch acc 0.9518
15:16:18.770   Training iter 350, batch loss 0.1599, batch acc 0.9522
15:16:19.355   Training iter 400, batch loss 0.1757, batch acc 0.9502
15:16:19.933   Training iter 450, batch loss 0.1592, batch acc 0.9528
15:16:20.509   Training iter 500, batch loss 0.1492, batch acc 0.9562
15:16:21.074   Training iter 550, batch loss 0.1474, batch acc 0.9568
15:16:21.632   Training iter 600, batch loss 0.1695, batch acc 0.9494
15:16:21.634 Testing @ 320 epoch...
15:16:21.683     Testing, total mean loss 0.24879, total acc 0.92920
15:16:21.683 Training @ 321 epoch...
15:16:22.242   Training iter 50, batch loss 0.1868, batch acc 0.9420
15:16:22.793   Training iter 100, batch loss 0.1655, batch acc 0.9494
15:16:23.345   Training iter 150, batch loss 0.1779, batch acc 0.9484
15:16:23.900   Training iter 200, batch loss 0.1486, batch acc 0.9528
15:16:24.448   Training iter 250, batch loss 0.1430, batch acc 0.9572
15:16:25.006   Training iter 300, batch loss 0.1521, batch acc 0.9596
15:16:25.547   Training iter 350, batch loss 0.1677, batch acc 0.9452
15:16:26.089   Training iter 400, batch loss 0.1490, batch acc 0.9582
15:16:26.629   Training iter 450, batch loss 0.1700, batch acc 0.9460
15:16:27.203   Training iter 500, batch loss 0.1758, batch acc 0.9464
15:16:27.756   Training iter 550, batch loss 0.1587, batch acc 0.9520
15:16:28.312   Training iter 600, batch loss 0.1486, batch acc 0.9564
15:16:28.314 Training @ 322 epoch...
15:16:28.831   Training iter 50, batch loss 0.1533, batch acc 0.9496
15:16:29.340   Training iter 100, batch loss 0.1401, batch acc 0.9578
15:16:29.889   Training iter 150, batch loss 0.1616, batch acc 0.9534
15:16:30.494   Training iter 200, batch loss 0.1523, batch acc 0.9534
15:16:31.064   Training iter 250, batch loss 0.1673, batch acc 0.9530
15:16:31.621   Training iter 300, batch loss 0.1543, batch acc 0.9552
15:16:32.189   Training iter 350, batch loss 0.1631, batch acc 0.9500
15:16:32.756   Training iter 400, batch loss 0.1774, batch acc 0.9452
15:16:33.327   Training iter 450, batch loss 0.1533, batch acc 0.9510
15:16:33.880   Training iter 500, batch loss 0.1668, batch acc 0.9482
15:16:34.447   Training iter 550, batch loss 0.1802, batch acc 0.9484
15:16:35.013   Training iter 600, batch loss 0.1611, batch acc 0.9496
15:16:35.015 Training @ 323 epoch...
15:16:35.576   Training iter 50, batch loss 0.1567, batch acc 0.9548
15:16:36.120   Training iter 100, batch loss 0.1594, batch acc 0.9534
15:16:36.658   Training iter 150, batch loss 0.1501, batch acc 0.9576
15:16:37.208   Training iter 200, batch loss 0.1612, batch acc 0.9486
15:16:37.759   Training iter 250, batch loss 0.1693, batch acc 0.9488
15:16:38.318   Training iter 300, batch loss 0.1475, batch acc 0.9560
15:16:38.861   Training iter 350, batch loss 0.1519, batch acc 0.9544
15:16:39.407   Training iter 400, batch loss 0.1795, batch acc 0.9474
15:16:39.942   Training iter 450, batch loss 0.1539, batch acc 0.9548
15:16:40.491   Training iter 500, batch loss 0.1660, batch acc 0.9498
15:16:41.023   Training iter 550, batch loss 0.1757, batch acc 0.9452
15:16:41.556   Training iter 600, batch loss 0.1669, batch acc 0.9470
15:16:41.558 Training @ 324 epoch...
15:16:42.087   Training iter 50, batch loss 0.1479, batch acc 0.9536
15:16:42.608   Training iter 100, batch loss 0.1529, batch acc 0.9510
15:16:43.133   Training iter 150, batch loss 0.1629, batch acc 0.9500
15:16:43.658   Training iter 200, batch loss 0.1536, batch acc 0.9564
15:16:44.179   Training iter 250, batch loss 0.1464, batch acc 0.9568
15:16:44.706   Training iter 300, batch loss 0.1609, batch acc 0.9506
15:16:45.215   Training iter 350, batch loss 0.1577, batch acc 0.9518
15:16:45.742   Training iter 400, batch loss 0.1600, batch acc 0.9506
15:16:46.287   Training iter 450, batch loss 0.1874, batch acc 0.9438
15:16:46.831   Training iter 500, batch loss 0.1562, batch acc 0.9538
15:16:47.367   Training iter 550, batch loss 0.1823, batch acc 0.9474
15:16:47.903   Training iter 600, batch loss 0.1568, batch acc 0.9508
15:16:47.905 Training @ 325 epoch...
15:16:48.465   Training iter 50, batch loss 0.1497, batch acc 0.9564
15:16:49.026   Training iter 100, batch loss 0.1633, batch acc 0.9524
15:16:49.577   Training iter 150, batch loss 0.1450, batch acc 0.9580
15:16:50.149   Training iter 200, batch loss 0.1660, batch acc 0.9520
15:16:50.712   Training iter 250, batch loss 0.1644, batch acc 0.9492
15:16:51.271   Training iter 300, batch loss 0.1600, batch acc 0.9528
15:16:51.813   Training iter 350, batch loss 0.1463, batch acc 0.9566
15:16:52.338   Training iter 400, batch loss 0.1795, batch acc 0.9496
15:16:52.867   Training iter 450, batch loss 0.1630, batch acc 0.9522
15:16:53.401   Training iter 500, batch loss 0.1624, batch acc 0.9518
15:16:53.930   Training iter 550, batch loss 0.1649, batch acc 0.9510
15:16:54.468   Training iter 600, batch loss 0.1648, batch acc 0.9508
15:16:54.469 Testing @ 325 epoch...
15:16:54.515     Testing, total mean loss 0.21991, total acc 0.93490
15:16:54.515 Training @ 326 epoch...
15:16:55.070   Training iter 50, batch loss 0.1458, batch acc 0.9552
15:16:55.626   Training iter 100, batch loss 0.1776, batch acc 0.9486
15:16:56.171   Training iter 150, batch loss 0.1761, batch acc 0.9462
15:16:56.709   Training iter 200, batch loss 0.1601, batch acc 0.9500
15:16:57.263   Training iter 250, batch loss 0.1749, batch acc 0.9532
15:16:57.813   Training iter 300, batch loss 0.1677, batch acc 0.9450
15:16:58.390   Training iter 350, batch loss 0.1599, batch acc 0.9510
15:16:58.960   Training iter 400, batch loss 0.1510, batch acc 0.9578
15:16:59.537   Training iter 450, batch loss 0.1684, batch acc 0.9476
15:17:00.028   Training iter 500, batch loss 0.1552, batch acc 0.9544
15:17:00.548   Training iter 550, batch loss 0.1466, batch acc 0.9554
15:17:01.041   Training iter 600, batch loss 0.1470, batch acc 0.9536
15:17:01.042 Training @ 327 epoch...
15:17:01.577   Training iter 50, batch loss 0.1569, batch acc 0.9510
15:17:02.175   Training iter 100, batch loss 0.1727, batch acc 0.9486
15:17:02.744   Training iter 150, batch loss 0.1516, batch acc 0.9510
15:17:03.302   Training iter 200, batch loss 0.1689, batch acc 0.9482
15:17:03.872   Training iter 250, batch loss 0.1555, batch acc 0.9528
15:17:04.428   Training iter 300, batch loss 0.1611, batch acc 0.9516
15:17:04.955   Training iter 350, batch loss 0.1433, batch acc 0.9586
15:17:05.500   Training iter 400, batch loss 0.1665, batch acc 0.9480
15:17:06.064   Training iter 450, batch loss 0.1712, batch acc 0.9460
15:17:06.604   Training iter 500, batch loss 0.1736, batch acc 0.9510
15:17:07.110   Training iter 550, batch loss 0.1503, batch acc 0.9540
15:17:07.597   Training iter 600, batch loss 0.1588, batch acc 0.9514
15:17:07.599 Training @ 328 epoch...
15:17:08.094   Training iter 50, batch loss 0.1475, batch acc 0.9554
15:17:08.604   Training iter 100, batch loss 0.1601, batch acc 0.9502
15:17:09.194   Training iter 150, batch loss 0.1487, batch acc 0.9568
15:17:09.695   Training iter 200, batch loss 0.1332, batch acc 0.9598
15:17:10.208   Training iter 250, batch loss 0.1630, batch acc 0.9536
15:17:10.783   Training iter 300, batch loss 0.1633, batch acc 0.9492
15:17:11.353   Training iter 350, batch loss 0.1670, batch acc 0.9490
15:17:11.889   Training iter 400, batch loss 0.1528, batch acc 0.9522
15:17:12.429   Training iter 450, batch loss 0.1782, batch acc 0.9446
15:17:12.923   Training iter 500, batch loss 0.1750, batch acc 0.9492
15:17:13.413   Training iter 550, batch loss 0.1670, batch acc 0.9456
15:17:13.899   Training iter 600, batch loss 0.1709, batch acc 0.9512
15:17:13.901 Training @ 329 epoch...
15:17:14.399   Training iter 50, batch loss 0.1535, batch acc 0.9528
15:17:14.892   Training iter 100, batch loss 0.1745, batch acc 0.9514
15:17:15.400   Training iter 150, batch loss 0.1569, batch acc 0.9498
15:17:15.890   Training iter 200, batch loss 0.1742, batch acc 0.9518
15:17:16.396   Training iter 250, batch loss 0.1489, batch acc 0.9536
15:17:16.903   Training iter 300, batch loss 0.1547, batch acc 0.9544
15:17:17.409   Training iter 350, batch loss 0.1510, batch acc 0.9550
15:17:17.980   Training iter 400, batch loss 0.1672, batch acc 0.9462
15:17:18.563   Training iter 450, batch loss 0.1454, batch acc 0.9556
15:17:19.139   Training iter 500, batch loss 0.1557, batch acc 0.9514
15:17:19.710   Training iter 550, batch loss 0.1666, batch acc 0.9500
15:17:20.285   Training iter 600, batch loss 0.1748, batch acc 0.9502
15:17:20.286 Training @ 330 epoch...
15:17:20.867   Training iter 50, batch loss 0.1431, batch acc 0.9586
15:17:21.440   Training iter 100, batch loss 0.1662, batch acc 0.9478
15:17:22.012   Training iter 150, batch loss 0.1776, batch acc 0.9446
15:17:22.595   Training iter 200, batch loss 0.1489, batch acc 0.9560
15:17:23.183   Training iter 250, batch loss 0.1504, batch acc 0.9540
15:17:23.764   Training iter 300, batch loss 0.1844, batch acc 0.9492
15:17:24.310   Training iter 350, batch loss 0.1520, batch acc 0.9544
15:17:24.847   Training iter 400, batch loss 0.1564, batch acc 0.9506
15:17:25.396   Training iter 450, batch loss 0.1550, batch acc 0.9568
15:17:25.945   Training iter 500, batch loss 0.1702, batch acc 0.9488
15:17:26.495   Training iter 550, batch loss 0.1598, batch acc 0.9522
15:17:27.057   Training iter 600, batch loss 0.1767, batch acc 0.9504
15:17:27.059 Testing @ 330 epoch...
15:17:27.108     Testing, total mean loss 0.22186, total acc 0.93690
15:17:27.108 Training @ 331 epoch...
15:17:27.659   Training iter 50, batch loss 0.1686, batch acc 0.9526
15:17:28.237   Training iter 100, batch loss 0.1478, batch acc 0.9530
15:17:28.846   Training iter 150, batch loss 0.1658, batch acc 0.9494
15:17:29.359   Training iter 200, batch loss 0.1672, batch acc 0.9466
15:17:29.874   Training iter 250, batch loss 0.1600, batch acc 0.9488
15:17:30.388   Training iter 300, batch loss 0.1643, batch acc 0.9526
15:17:30.902   Training iter 350, batch loss 0.1535, batch acc 0.9540
15:17:31.418   Training iter 400, batch loss 0.1511, batch acc 0.9562
15:17:31.936   Training iter 450, batch loss 0.1737, batch acc 0.9500
15:17:32.443   Training iter 500, batch loss 0.1746, batch acc 0.9496
15:17:32.949   Training iter 550, batch loss 0.1599, batch acc 0.9510
15:17:33.460   Training iter 600, batch loss 0.1754, batch acc 0.9488
15:17:33.461 Training @ 332 epoch...
15:17:33.984   Training iter 50, batch loss 0.1698, batch acc 0.9490
15:17:34.537   Training iter 100, batch loss 0.1680, batch acc 0.9498
15:17:35.084   Training iter 150, batch loss 0.1438, batch acc 0.9572
15:17:35.627   Training iter 200, batch loss 0.1436, batch acc 0.9572
15:17:36.153   Training iter 250, batch loss 0.1618, batch acc 0.9518
15:17:36.683   Training iter 300, batch loss 0.1623, batch acc 0.9534
15:17:37.215   Training iter 350, batch loss 0.1697, batch acc 0.9474
15:17:37.738   Training iter 400, batch loss 0.1623, batch acc 0.9488
15:17:38.265   Training iter 450, batch loss 0.1516, batch acc 0.9546
15:17:38.778   Training iter 500, batch loss 0.1633, batch acc 0.9496
15:17:39.310   Training iter 550, batch loss 0.1552, batch acc 0.9524
15:17:39.848   Training iter 600, batch loss 0.1693, batch acc 0.9492
15:17:39.850 Training @ 333 epoch...
15:17:40.383   Training iter 50, batch loss 0.1618, batch acc 0.9526
15:17:40.878   Training iter 100, batch loss 0.1569, batch acc 0.9528
15:17:41.374   Training iter 150, batch loss 0.1589, batch acc 0.9558
15:17:41.869   Training iter 200, batch loss 0.1556, batch acc 0.9532
15:17:42.381   Training iter 250, batch loss 0.1665, batch acc 0.9532
15:17:42.886   Training iter 300, batch loss 0.1713, batch acc 0.9478
15:17:43.384   Training iter 350, batch loss 0.1515, batch acc 0.9542
15:17:43.877   Training iter 400, batch loss 0.1494, batch acc 0.9552
15:17:44.383   Training iter 450, batch loss 0.1640, batch acc 0.9526
15:17:44.896   Training iter 500, batch loss 0.1759, batch acc 0.9452
15:17:45.427   Training iter 550, batch loss 0.1674, batch acc 0.9494
15:17:45.946   Training iter 600, batch loss 0.1581, batch acc 0.9520
15:17:45.948 Training @ 334 epoch...
15:17:46.480   Training iter 50, batch loss 0.1727, batch acc 0.9480
15:17:46.993   Training iter 100, batch loss 0.1426, batch acc 0.9566
15:17:47.501   Training iter 150, batch loss 0.1625, batch acc 0.9478
15:17:48.011   Training iter 200, batch loss 0.1810, batch acc 0.9468
15:17:48.526   Training iter 250, batch loss 0.1684, batch acc 0.9524
15:17:49.022   Training iter 300, batch loss 0.1612, batch acc 0.9494
15:17:49.517   Training iter 350, batch loss 0.1655, batch acc 0.9518
15:17:50.020   Training iter 400, batch loss 0.1755, batch acc 0.9464
15:17:50.549   Training iter 450, batch loss 0.1512, batch acc 0.9532
15:17:51.072   Training iter 500, batch loss 0.1638, batch acc 0.9476
15:17:51.651   Training iter 550, batch loss 0.1535, batch acc 0.9528
15:17:52.225   Training iter 600, batch loss 0.1554, batch acc 0.9550
15:17:52.226 Training @ 335 epoch...
15:17:52.736   Training iter 50, batch loss 0.1586, batch acc 0.9544
15:17:53.243   Training iter 100, batch loss 0.1558, batch acc 0.9532
15:17:53.759   Training iter 150, batch loss 0.1739, batch acc 0.9468
15:17:54.285   Training iter 200, batch loss 0.1546, batch acc 0.9552
15:17:54.801   Training iter 250, batch loss 0.1714, batch acc 0.9488
15:17:55.346   Training iter 300, batch loss 0.1673, batch acc 0.9462
15:17:55.857   Training iter 350, batch loss 0.1496, batch acc 0.9514
15:17:56.380   Training iter 400, batch loss 0.1760, batch acc 0.9502
15:17:56.881   Training iter 450, batch loss 0.1530, batch acc 0.9546
15:17:57.403   Training iter 500, batch loss 0.1668, batch acc 0.9506
15:17:57.920   Training iter 550, batch loss 0.1427, batch acc 0.9572
15:17:58.445   Training iter 600, batch loss 0.1744, batch acc 0.9504
15:17:58.447 Testing @ 335 epoch...
15:17:58.491     Testing, total mean loss 0.22222, total acc 0.93240
15:17:58.491 Training @ 336 epoch...
15:17:59.013   Training iter 50, batch loss 0.1548, batch acc 0.9540
15:17:59.545   Training iter 100, batch loss 0.1512, batch acc 0.9550
15:18:00.061   Training iter 150, batch loss 0.1544, batch acc 0.9514
15:18:00.606   Training iter 200, batch loss 0.1726, batch acc 0.9484
15:18:01.139   Training iter 250, batch loss 0.1617, batch acc 0.9520
15:18:01.694   Training iter 300, batch loss 0.1531, batch acc 0.9538
15:18:02.252   Training iter 350, batch loss 0.1691, batch acc 0.9478
15:18:02.760   Training iter 400, batch loss 0.1541, batch acc 0.9526
15:18:03.275   Training iter 450, batch loss 0.1664, batch acc 0.9506
15:18:03.798   Training iter 500, batch loss 0.1653, batch acc 0.9532
15:18:04.314   Training iter 550, batch loss 0.1724, batch acc 0.9480
15:18:04.828   Training iter 600, batch loss 0.1502, batch acc 0.9550
15:18:04.830 Training @ 337 epoch...
15:18:05.349   Training iter 50, batch loss 0.1437, batch acc 0.9546
15:18:05.860   Training iter 100, batch loss 0.1626, batch acc 0.9472
15:18:06.385   Training iter 150, batch loss 0.1606, batch acc 0.9476
15:18:06.942   Training iter 200, batch loss 0.1811, batch acc 0.9482
15:18:07.485   Training iter 250, batch loss 0.1695, batch acc 0.9516
15:18:08.005   Training iter 300, batch loss 0.1523, batch acc 0.9546
15:18:08.516   Training iter 350, batch loss 0.1567, batch acc 0.9542
15:18:09.015   Training iter 400, batch loss 0.1645, batch acc 0.9510
15:18:09.538   Training iter 450, batch loss 0.1474, batch acc 0.9578
15:18:10.069   Training iter 500, batch loss 0.1553, batch acc 0.9520
15:18:10.602   Training iter 550, batch loss 0.1604, batch acc 0.9526
15:18:11.102   Training iter 600, batch loss 0.1487, batch acc 0.9558
15:18:11.104 Training @ 338 epoch...
15:18:11.618   Training iter 50, batch loss 0.1444, batch acc 0.9576
15:18:12.128   Training iter 100, batch loss 0.1560, batch acc 0.9556
15:18:12.638   Training iter 150, batch loss 0.1509, batch acc 0.9560
15:18:13.132   Training iter 200, batch loss 0.1665, batch acc 0.9496
15:18:13.620   Training iter 250, batch loss 0.1739, batch acc 0.9486
15:18:14.129   Training iter 300, batch loss 0.1491, batch acc 0.9518
15:18:14.661   Training iter 350, batch loss 0.1634, batch acc 0.9524
15:18:15.183   Training iter 400, batch loss 0.1714, batch acc 0.9488
15:18:15.703   Training iter 450, batch loss 0.1484, batch acc 0.9536
15:18:16.237   Training iter 500, batch loss 0.1749, batch acc 0.9464
15:18:16.771   Training iter 550, batch loss 0.1707, batch acc 0.9472
15:18:17.281   Training iter 600, batch loss 0.1681, batch acc 0.9458
15:18:17.283 Training @ 339 epoch...
15:18:17.771   Training iter 50, batch loss 0.1626, batch acc 0.9516
15:18:18.251   Training iter 100, batch loss 0.1500, batch acc 0.9558
15:18:18.742   Training iter 150, batch loss 0.1498, batch acc 0.9544
15:18:19.242   Training iter 200, batch loss 0.1665, batch acc 0.9464
15:18:19.760   Training iter 250, batch loss 0.1435, batch acc 0.9556
15:18:20.292   Training iter 300, batch loss 0.1747, batch acc 0.9514
15:18:20.773   Training iter 350, batch loss 0.1523, batch acc 0.9548
15:18:21.258   Training iter 400, batch loss 0.1625, batch acc 0.9522
15:18:21.729   Training iter 450, batch loss 0.1636, batch acc 0.9520
15:18:22.230   Training iter 500, batch loss 0.1706, batch acc 0.9520
15:18:22.723   Training iter 550, batch loss 0.1574, batch acc 0.9514
15:18:23.216   Training iter 600, batch loss 0.1893, batch acc 0.9428
15:18:23.218 Training @ 340 epoch...
15:18:23.738   Training iter 50, batch loss 0.1778, batch acc 0.9450
15:18:24.251   Training iter 100, batch loss 0.1662, batch acc 0.9514
15:18:24.768   Training iter 150, batch loss 0.1461, batch acc 0.9540
15:18:25.294   Training iter 200, batch loss 0.1681, batch acc 0.9482
15:18:25.803   Training iter 250, batch loss 0.1614, batch acc 0.9530
15:18:26.318   Training iter 300, batch loss 0.1559, batch acc 0.9546
15:18:26.840   Training iter 350, batch loss 0.1568, batch acc 0.9514
15:18:27.378   Training iter 400, batch loss 0.1686, batch acc 0.9528
15:18:27.892   Training iter 450, batch loss 0.1582, batch acc 0.9484
15:18:28.405   Training iter 500, batch loss 0.1636, batch acc 0.9484
15:18:28.940   Training iter 550, batch loss 0.1598, batch acc 0.9538
15:18:29.487   Training iter 600, batch loss 0.1683, batch acc 0.9510
15:18:29.489 Testing @ 340 epoch...
15:18:29.536     Testing, total mean loss 0.21013, total acc 0.93990
15:18:29.536 Training @ 341 epoch...
15:18:30.088   Training iter 50, batch loss 0.1702, batch acc 0.9492
15:18:30.623   Training iter 100, batch loss 0.1703, batch acc 0.9478
15:18:31.129   Training iter 150, batch loss 0.1594, batch acc 0.9500
15:18:31.633   Training iter 200, batch loss 0.1529, batch acc 0.9536
15:18:32.147   Training iter 250, batch loss 0.1683, batch acc 0.9480
15:18:32.656   Training iter 300, batch loss 0.1688, batch acc 0.9496
15:18:33.152   Training iter 350, batch loss 0.1464, batch acc 0.9554
15:18:33.642   Training iter 400, batch loss 0.1591, batch acc 0.9508
15:18:34.146   Training iter 450, batch loss 0.1529, batch acc 0.9544
15:18:34.646   Training iter 500, batch loss 0.1608, batch acc 0.9530
15:18:35.142   Training iter 550, batch loss 0.1573, batch acc 0.9508
15:18:35.635   Training iter 600, batch loss 0.1692, batch acc 0.9476
15:18:35.637 Training @ 342 epoch...
15:18:36.137   Training iter 50, batch loss 0.1518, batch acc 0.9514
15:18:36.653   Training iter 100, batch loss 0.1685, batch acc 0.9488
15:18:37.148   Training iter 150, batch loss 0.1677, batch acc 0.9510
15:18:37.649   Training iter 200, batch loss 0.1620, batch acc 0.9524
15:18:38.169   Training iter 250, batch loss 0.1672, batch acc 0.9490
15:18:38.682   Training iter 300, batch loss 0.1599, batch acc 0.9486
15:18:39.177   Training iter 350, batch loss 0.1676, batch acc 0.9476
15:18:39.674   Training iter 400, batch loss 0.1543, batch acc 0.9530
15:18:40.180   Training iter 450, batch loss 0.1540, batch acc 0.9552
15:18:40.696   Training iter 500, batch loss 0.1659, batch acc 0.9508
15:18:41.244   Training iter 550, batch loss 0.1560, batch acc 0.9526
15:18:41.780   Training iter 600, batch loss 0.1632, batch acc 0.9520
15:18:41.782 Training @ 343 epoch...
15:18:42.332   Training iter 50, batch loss 0.1551, batch acc 0.9536
15:18:42.832   Training iter 100, batch loss 0.1598, batch acc 0.9560
15:18:43.469   Training iter 150, batch loss 0.1671, batch acc 0.9500
15:18:43.989   Training iter 200, batch loss 0.1704, batch acc 0.9470
15:18:44.565   Training iter 250, batch loss 0.1584, batch acc 0.9522
15:18:45.099   Training iter 300, batch loss 0.1631, batch acc 0.9502
15:18:45.637   Training iter 350, batch loss 0.1554, batch acc 0.9534
15:18:46.153   Training iter 400, batch loss 0.1624, batch acc 0.9522
15:18:46.686   Training iter 450, batch loss 0.1456, batch acc 0.9554
15:18:47.224   Training iter 500, batch loss 0.1595, batch acc 0.9498
15:18:47.746   Training iter 550, batch loss 0.1704, batch acc 0.9528
15:18:48.305   Training iter 600, batch loss 0.1688, batch acc 0.9488
15:18:48.306 Training @ 344 epoch...
15:18:48.826   Training iter 50, batch loss 0.1515, batch acc 0.9558
15:18:49.327   Training iter 100, batch loss 0.1670, batch acc 0.9482
15:18:49.794   Training iter 150, batch loss 0.1403, batch acc 0.9580
15:18:50.267   Training iter 200, batch loss 0.1531, batch acc 0.9564
15:18:50.744   Training iter 250, batch loss 0.1652, batch acc 0.9524
15:18:51.263   Training iter 300, batch loss 0.1755, batch acc 0.9480
15:18:51.768   Training iter 350, batch loss 0.1674, batch acc 0.9480
15:18:52.255   Training iter 400, batch loss 0.1612, batch acc 0.9512
15:18:52.730   Training iter 450, batch loss 0.1645, batch acc 0.9510
15:18:53.203   Training iter 500, batch loss 0.1700, batch acc 0.9498
15:18:53.674   Training iter 550, batch loss 0.1596, batch acc 0.9540
15:18:54.170   Training iter 600, batch loss 0.1552, batch acc 0.9534
15:18:54.171 Training @ 345 epoch...
15:18:54.663   Training iter 50, batch loss 0.1434, batch acc 0.9586
15:18:55.138   Training iter 100, batch loss 0.1672, batch acc 0.9502
15:18:55.618   Training iter 150, batch loss 0.1698, batch acc 0.9512
15:18:56.088   Training iter 200, batch loss 0.1609, batch acc 0.9504
15:18:56.591   Training iter 250, batch loss 0.1583, batch acc 0.9526
15:18:57.084   Training iter 300, batch loss 0.1393, batch acc 0.9580
15:18:57.604   Training iter 350, batch loss 0.1626, batch acc 0.9564
15:18:58.147   Training iter 400, batch loss 0.1573, batch acc 0.9560
15:18:58.690   Training iter 450, batch loss 0.1776, batch acc 0.9436
15:18:59.212   Training iter 500, batch loss 0.1589, batch acc 0.9502
15:18:59.748   Training iter 550, batch loss 0.1628, batch acc 0.9522
15:19:00.303   Training iter 600, batch loss 0.1720, batch acc 0.9478
15:19:00.305 Testing @ 345 epoch...
15:19:00.355     Testing, total mean loss 0.23662, total acc 0.92930
15:19:00.355 Training @ 346 epoch...
15:19:00.889   Training iter 50, batch loss 0.1515, batch acc 0.9566
15:19:01.478   Training iter 100, batch loss 0.1729, batch acc 0.9508
15:19:02.069   Training iter 150, batch loss 0.1768, batch acc 0.9486
15:19:02.646   Training iter 200, batch loss 0.1763, batch acc 0.9506
15:19:03.214   Training iter 250, batch loss 0.1562, batch acc 0.9528
15:19:03.747   Training iter 300, batch loss 0.1501, batch acc 0.9520
15:19:04.250   Training iter 350, batch loss 0.1594, batch acc 0.9506
15:19:04.749   Training iter 400, batch loss 0.1642, batch acc 0.9502
15:19:05.249   Training iter 450, batch loss 0.1712, batch acc 0.9526
15:19:05.741   Training iter 500, batch loss 0.1685, batch acc 0.9464
15:19:06.253   Training iter 550, batch loss 0.1569, batch acc 0.9538
15:19:06.766   Training iter 600, batch loss 0.1497, batch acc 0.9520
15:19:06.768 Training @ 347 epoch...
15:19:07.281   Training iter 50, batch loss 0.1446, batch acc 0.9584
15:19:07.823   Training iter 100, batch loss 0.1539, batch acc 0.9558
15:19:08.330   Training iter 150, batch loss 0.1450, batch acc 0.9524
15:19:08.815   Training iter 200, batch loss 0.1607, batch acc 0.9548
15:19:09.327   Training iter 250, batch loss 0.1810, batch acc 0.9448
15:19:09.810   Training iter 300, batch loss 0.1565, batch acc 0.9506
15:19:10.318   Training iter 350, batch loss 0.1606, batch acc 0.9532
15:19:10.818   Training iter 400, batch loss 0.1534, batch acc 0.9560
15:19:11.317   Training iter 450, batch loss 0.1787, batch acc 0.9506
15:19:11.800   Training iter 500, batch loss 0.1563, batch acc 0.9528
15:19:12.310   Training iter 550, batch loss 0.1561, batch acc 0.9506
15:19:12.828   Training iter 600, batch loss 0.1745, batch acc 0.9496
15:19:12.830 Training @ 348 epoch...
15:19:13.312   Training iter 50, batch loss 0.1583, batch acc 0.9506
15:19:13.759   Training iter 100, batch loss 0.1508, batch acc 0.9538
15:19:14.239   Training iter 150, batch loss 0.1662, batch acc 0.9500
15:19:14.746   Training iter 200, batch loss 0.1654, batch acc 0.9546
15:19:15.226   Training iter 250, batch loss 0.1683, batch acc 0.9490
15:19:15.699   Training iter 300, batch loss 0.1609, batch acc 0.9506
15:19:16.138   Training iter 350, batch loss 0.1602, batch acc 0.9492
15:19:16.618   Training iter 400, batch loss 0.1551, batch acc 0.9546
15:19:17.086   Training iter 450, batch loss 0.1633, batch acc 0.9530
15:19:17.541   Training iter 500, batch loss 0.1707, batch acc 0.9482
15:19:18.034   Training iter 550, batch loss 0.1746, batch acc 0.9468
15:19:18.510   Training iter 600, batch loss 0.1576, batch acc 0.9490
15:19:18.512 Training @ 349 epoch...
15:19:18.984   Training iter 50, batch loss 0.1665, batch acc 0.9492
15:19:19.445   Training iter 100, batch loss 0.1649, batch acc 0.9532
15:19:19.890   Training iter 150, batch loss 0.1365, batch acc 0.9582
15:19:20.379   Training iter 200, batch loss 0.1596, batch acc 0.9536
15:19:20.837   Training iter 250, batch loss 0.1554, batch acc 0.9514
15:19:21.303   Training iter 300, batch loss 0.1589, batch acc 0.9538
15:19:21.799   Training iter 350, batch loss 0.1661, batch acc 0.9514
15:19:22.301   Training iter 400, batch loss 0.1678, batch acc 0.9516
15:19:22.775   Training iter 450, batch loss 0.1643, batch acc 0.9516
15:19:23.265   Training iter 500, batch loss 0.1560, batch acc 0.9530
15:19:23.743   Training iter 550, batch loss 0.1814, batch acc 0.9482
15:19:24.241   Training iter 600, batch loss 0.1634, batch acc 0.9502
15:19:24.243 Training @ 350 epoch...
15:19:24.744   Training iter 50, batch loss 0.1443, batch acc 0.9590
15:19:25.242   Training iter 100, batch loss 0.1683, batch acc 0.9532
15:19:25.771   Training iter 150, batch loss 0.1683, batch acc 0.9516
15:19:26.306   Training iter 200, batch loss 0.1527, batch acc 0.9544
15:19:26.861   Training iter 250, batch loss 0.1676, batch acc 0.9470
15:19:27.411   Training iter 300, batch loss 0.1517, batch acc 0.9544
15:19:27.954   Training iter 350, batch loss 0.1585, batch acc 0.9528
15:19:28.501   Training iter 400, batch loss 0.1520, batch acc 0.9494
15:19:29.030   Training iter 450, batch loss 0.1681, batch acc 0.9498
15:19:29.557   Training iter 500, batch loss 0.1669, batch acc 0.9490
15:19:30.083   Training iter 550, batch loss 0.1660, batch acc 0.9478
15:19:30.589   Training iter 600, batch loss 0.1671, batch acc 0.9490
15:19:30.591 Testing @ 350 epoch...
15:19:30.635     Testing, total mean loss 0.20958, total acc 0.93980
15:19:30.635 Training @ 351 epoch...
15:19:31.175   Training iter 50, batch loss 0.1524, batch acc 0.9546
15:19:31.686   Training iter 100, batch loss 0.1599, batch acc 0.9504
15:19:32.224   Training iter 150, batch loss 0.1804, batch acc 0.9486
15:19:32.713   Training iter 200, batch loss 0.1741, batch acc 0.9458
15:19:33.249   Training iter 250, batch loss 0.1484, batch acc 0.9542
15:19:33.718   Training iter 300, batch loss 0.1739, batch acc 0.9492
15:19:34.188   Training iter 350, batch loss 0.1634, batch acc 0.9536
15:19:34.676   Training iter 400, batch loss 0.1661, batch acc 0.9524
15:19:35.180   Training iter 450, batch loss 0.1537, batch acc 0.9534
15:19:35.687   Training iter 500, batch loss 0.1490, batch acc 0.9538
15:19:36.173   Training iter 550, batch loss 0.1481, batch acc 0.9546
15:19:36.642   Training iter 600, batch loss 0.1658, batch acc 0.9524
15:19:36.644 Training @ 352 epoch...
15:19:37.136   Training iter 50, batch loss 0.1633, batch acc 0.9528
15:19:37.622   Training iter 100, batch loss 0.1683, batch acc 0.9520
15:19:38.101   Training iter 150, batch loss 0.1345, batch acc 0.9566
15:19:38.646   Training iter 200, batch loss 0.1719, batch acc 0.9500
15:19:39.199   Training iter 250, batch loss 0.1498, batch acc 0.9556
15:19:39.766   Training iter 300, batch loss 0.1519, batch acc 0.9532
15:19:40.275   Training iter 350, batch loss 0.1578, batch acc 0.9560
15:19:40.745   Training iter 400, batch loss 0.1609, batch acc 0.9506
15:19:41.241   Training iter 450, batch loss 0.1809, batch acc 0.9464
15:19:41.695   Training iter 500, batch loss 0.1695, batch acc 0.9516
15:19:42.147   Training iter 550, batch loss 0.1669, batch acc 0.9452
15:19:42.611   Training iter 600, batch loss 0.1659, batch acc 0.9498
15:19:42.613 Training @ 353 epoch...
15:19:43.057   Training iter 50, batch loss 0.1618, batch acc 0.9494
15:19:43.488   Training iter 100, batch loss 0.1636, batch acc 0.9522
15:19:43.917   Training iter 150, batch loss 0.1441, batch acc 0.9558
15:19:44.362   Training iter 200, batch loss 0.1590, batch acc 0.9554
15:19:44.801   Training iter 250, batch loss 0.1608, batch acc 0.9512
15:19:45.255   Training iter 300, batch loss 0.1687, batch acc 0.9506
15:19:45.709   Training iter 350, batch loss 0.1683, batch acc 0.9502
15:19:46.139   Training iter 400, batch loss 0.1676, batch acc 0.9490
15:19:46.578   Training iter 450, batch loss 0.1487, batch acc 0.9564
15:19:47.013   Training iter 500, batch loss 0.1594, batch acc 0.9540
15:19:47.466   Training iter 550, batch loss 0.1726, batch acc 0.9500
15:19:47.887   Training iter 600, batch loss 0.1576, batch acc 0.9516
15:19:47.888 Training @ 354 epoch...
15:19:48.334   Training iter 50, batch loss 0.1465, batch acc 0.9600
15:19:48.759   Training iter 100, batch loss 0.1463, batch acc 0.9532
15:19:49.174   Training iter 150, batch loss 0.1815, batch acc 0.9500
15:19:49.604   Training iter 200, batch loss 0.1640, batch acc 0.9492
15:19:50.033   Training iter 250, batch loss 0.1505, batch acc 0.9558
15:19:50.491   Training iter 300, batch loss 0.1595, batch acc 0.9538
15:19:50.913   Training iter 350, batch loss 0.1612, batch acc 0.9550
15:19:51.358   Training iter 400, batch loss 0.1703, batch acc 0.9482
15:19:51.819   Training iter 450, batch loss 0.1739, batch acc 0.9480
15:19:52.289   Training iter 500, batch loss 0.1569, batch acc 0.9544
15:19:52.714   Training iter 550, batch loss 0.1491, batch acc 0.9532
15:19:53.129   Training iter 600, batch loss 0.1658, batch acc 0.9514
15:19:53.130 Training @ 355 epoch...
15:19:53.566   Training iter 50, batch loss 0.1729, batch acc 0.9486
15:19:53.981   Training iter 100, batch loss 0.1683, batch acc 0.9492
15:19:54.405   Training iter 150, batch loss 0.1475, batch acc 0.9514
15:19:54.818   Training iter 200, batch loss 0.1744, batch acc 0.9470
15:19:55.256   Training iter 250, batch loss 0.1559, batch acc 0.9516
15:19:55.689   Training iter 300, batch loss 0.1731, batch acc 0.9488
15:19:56.102   Training iter 350, batch loss 0.1700, batch acc 0.9512
15:19:56.520   Training iter 400, batch loss 0.1501, batch acc 0.9556
15:19:56.939   Training iter 450, batch loss 0.1580, batch acc 0.9490
15:19:57.377   Training iter 500, batch loss 0.1672, batch acc 0.9494
15:19:57.784   Training iter 550, batch loss 0.1516, batch acc 0.9542
15:19:58.208   Training iter 600, batch loss 0.1716, batch acc 0.9472
15:19:58.210 Testing @ 355 epoch...
15:19:58.253     Testing, total mean loss 0.21467, total acc 0.93660
15:19:58.253 Training @ 356 epoch...
15:19:58.701   Training iter 50, batch loss 0.1581, batch acc 0.9510
15:19:59.127   Training iter 100, batch loss 0.1769, batch acc 0.9476
15:19:59.558   Training iter 150, batch loss 0.1448, batch acc 0.9538
15:19:59.990   Training iter 200, batch loss 0.1550, batch acc 0.9514
15:20:00.482   Training iter 250, batch loss 0.1486, batch acc 0.9560
15:20:00.959   Training iter 300, batch loss 0.1650, batch acc 0.9502
15:20:01.479   Training iter 350, batch loss 0.1507, batch acc 0.9498
15:20:01.994   Training iter 400, batch loss 0.1693, batch acc 0.9480
15:20:02.478   Training iter 450, batch loss 0.1686, batch acc 0.9502
15:20:02.902   Training iter 500, batch loss 0.1533, batch acc 0.9536
15:20:03.410   Training iter 550, batch loss 0.1629, batch acc 0.9494
15:20:03.925   Training iter 600, batch loss 0.1609, batch acc 0.9522
15:20:03.927 Training @ 357 epoch...
15:20:04.439   Training iter 50, batch loss 0.1536, batch acc 0.9522
15:20:04.917   Training iter 100, batch loss 0.1676, batch acc 0.9516
15:20:05.401   Training iter 150, batch loss 0.1616, batch acc 0.9492
15:20:05.884   Training iter 200, batch loss 0.1648, batch acc 0.9508
15:20:06.394   Training iter 250, batch loss 0.1595, batch acc 0.9514
15:20:06.836   Training iter 300, batch loss 0.1602, batch acc 0.9552
15:20:07.274   Training iter 350, batch loss 0.1573, batch acc 0.9524
15:20:07.720   Training iter 400, batch loss 0.1571, batch acc 0.9520
15:20:08.171   Training iter 450, batch loss 0.1563, batch acc 0.9544
15:20:08.616   Training iter 500, batch loss 0.1848, batch acc 0.9464
15:20:09.044   Training iter 550, batch loss 0.1514, batch acc 0.9520
15:20:09.479   Training iter 600, batch loss 0.1653, batch acc 0.9454
15:20:09.480 Training @ 358 epoch...
15:20:09.904   Training iter 50, batch loss 0.1604, batch acc 0.9482
15:20:10.346   Training iter 100, batch loss 0.1430, batch acc 0.9572
15:20:10.777   Training iter 150, batch loss 0.1415, batch acc 0.9568
15:20:11.218   Training iter 200, batch loss 0.1618, batch acc 0.9488
15:20:11.643   Training iter 250, batch loss 0.1797, batch acc 0.9508
15:20:12.053   Training iter 300, batch loss 0.1603, batch acc 0.9534
15:20:12.494   Training iter 350, batch loss 0.1821, batch acc 0.9424
15:20:12.930   Training iter 400, batch loss 0.1727, batch acc 0.9480
15:20:13.377   Training iter 450, batch loss 0.1695, batch acc 0.9476
15:20:13.811   Training iter 500, batch loss 0.1636, batch acc 0.9480
15:20:14.265   Training iter 550, batch loss 0.1613, batch acc 0.9536
15:20:14.710   Training iter 600, batch loss 0.1477, batch acc 0.9532
15:20:14.711 Training @ 359 epoch...
15:20:15.148   Training iter 50, batch loss 0.1628, batch acc 0.9508
15:20:15.607   Training iter 100, batch loss 0.1499, batch acc 0.9556
15:20:16.071   Training iter 150, batch loss 0.1744, batch acc 0.9458
15:20:16.527   Training iter 200, batch loss 0.1562, batch acc 0.9520
15:20:16.983   Training iter 250, batch loss 0.1634, batch acc 0.9550
15:20:17.457   Training iter 300, batch loss 0.1593, batch acc 0.9528
15:20:17.888   Training iter 350, batch loss 0.1727, batch acc 0.9510
15:20:18.346   Training iter 400, batch loss 0.1536, batch acc 0.9524
15:20:18.791   Training iter 450, batch loss 0.1551, batch acc 0.9540
15:20:19.235   Training iter 500, batch loss 0.1584, batch acc 0.9534
15:20:19.664   Training iter 550, batch loss 0.1563, batch acc 0.9506
15:20:20.111   Training iter 600, batch loss 0.1583, batch acc 0.9538
15:20:20.113 Training @ 360 epoch...
15:20:20.639   Training iter 50, batch loss 0.1533, batch acc 0.9550
15:20:21.127   Training iter 100, batch loss 0.1466, batch acc 0.9576
15:20:21.610   Training iter 150, batch loss 0.1585, batch acc 0.9494
15:20:22.094   Training iter 200, batch loss 0.1653, batch acc 0.9456
15:20:22.556   Training iter 250, batch loss 0.1538, batch acc 0.9538
15:20:23.011   Training iter 300, batch loss 0.1498, batch acc 0.9536
15:20:23.462   Training iter 350, batch loss 0.1696, batch acc 0.9490
15:20:23.896   Training iter 400, batch loss 0.1547, batch acc 0.9544
15:20:24.356   Training iter 450, batch loss 0.1617, batch acc 0.9502
15:20:24.804   Training iter 500, batch loss 0.1830, batch acc 0.9432
15:20:25.274   Training iter 550, batch loss 0.1674, batch acc 0.9492
15:20:25.728   Training iter 600, batch loss 0.1725, batch acc 0.9500
15:20:25.730 Testing @ 360 epoch...
15:20:25.779     Testing, total mean loss 0.22235, total acc 0.93690
15:20:25.779 Training @ 361 epoch...
15:20:26.245   Training iter 50, batch loss 0.1753, batch acc 0.9460
15:20:26.688   Training iter 100, batch loss 0.1615, batch acc 0.9502
15:20:27.128   Training iter 150, batch loss 0.1479, batch acc 0.9562
15:20:27.576   Training iter 200, batch loss 0.1494, batch acc 0.9570
15:20:28.024   Training iter 250, batch loss 0.1626, batch acc 0.9480
15:20:28.481   Training iter 300, batch loss 0.1709, batch acc 0.9456
15:20:28.927   Training iter 350, batch loss 0.1667, batch acc 0.9524
15:20:29.405   Training iter 400, batch loss 0.1753, batch acc 0.9478
15:20:29.869   Training iter 450, batch loss 0.1580, batch acc 0.9552
15:20:30.333   Training iter 500, batch loss 0.1650, batch acc 0.9494
15:20:30.776   Training iter 550, batch loss 0.1524, batch acc 0.9556
15:20:31.209   Training iter 600, batch loss 0.1573, batch acc 0.9514
15:20:31.211 Training @ 362 epoch...
15:20:31.690   Training iter 50, batch loss 0.1813, batch acc 0.9450
15:20:32.136   Training iter 100, batch loss 0.1503, batch acc 0.9560
15:20:32.594   Training iter 150, batch loss 0.1537, batch acc 0.9542
15:20:33.036   Training iter 200, batch loss 0.1560, batch acc 0.9548
15:20:33.509   Training iter 250, batch loss 0.1681, batch acc 0.9500
15:20:33.948   Training iter 300, batch loss 0.1635, batch acc 0.9480
15:20:34.381   Training iter 350, batch loss 0.1630, batch acc 0.9510
15:20:34.809   Training iter 400, batch loss 0.1608, batch acc 0.9516
15:20:35.248   Training iter 450, batch loss 0.1459, batch acc 0.9514
15:20:35.691   Training iter 500, batch loss 0.1583, batch acc 0.9512
15:20:36.132   Training iter 550, batch loss 0.1714, batch acc 0.9472
15:20:36.611   Training iter 600, batch loss 0.1618, batch acc 0.9530
15:20:36.612 Training @ 363 epoch...
15:20:37.151   Training iter 50, batch loss 0.1741, batch acc 0.9480
15:20:37.605   Training iter 100, batch loss 0.1423, batch acc 0.9582
15:20:38.026   Training iter 150, batch loss 0.1602, batch acc 0.9494
15:20:38.444   Training iter 200, batch loss 0.1539, batch acc 0.9530
15:20:38.852   Training iter 250, batch loss 0.1632, batch acc 0.9552
15:20:39.295   Training iter 300, batch loss 0.1454, batch acc 0.9548
15:20:39.724   Training iter 350, batch loss 0.1614, batch acc 0.9524
15:20:40.137   Training iter 400, batch loss 0.1642, batch acc 0.9478
15:20:40.570   Training iter 450, batch loss 0.1599, batch acc 0.9544
15:20:40.979   Training iter 500, batch loss 0.1665, batch acc 0.9496
15:20:41.411   Training iter 550, batch loss 0.1599, batch acc 0.9498
15:20:41.820   Training iter 600, batch loss 0.1728, batch acc 0.9506
15:20:41.822 Training @ 364 epoch...
15:20:42.237   Training iter 50, batch loss 0.1440, batch acc 0.9550
15:20:42.664   Training iter 100, batch loss 0.1604, batch acc 0.9500
15:20:43.103   Training iter 150, batch loss 0.1631, batch acc 0.9512
15:20:43.531   Training iter 200, batch loss 0.1698, batch acc 0.9494
15:20:43.955   Training iter 250, batch loss 0.1534, batch acc 0.9518
15:20:44.400   Training iter 300, batch loss 0.1555, batch acc 0.9532
15:20:44.818   Training iter 350, batch loss 0.1690, batch acc 0.9480
15:20:45.235   Training iter 400, batch loss 0.1725, batch acc 0.9490
15:20:45.649   Training iter 450, batch loss 0.1496, batch acc 0.9544
15:20:46.066   Training iter 500, batch loss 0.1674, batch acc 0.9502
15:20:46.497   Training iter 550, batch loss 0.1544, batch acc 0.9534
15:20:46.918   Training iter 600, batch loss 0.1665, batch acc 0.9524
15:20:46.920 Training @ 365 epoch...
15:20:47.344   Training iter 50, batch loss 0.1497, batch acc 0.9526
15:20:47.741   Training iter 100, batch loss 0.1608, batch acc 0.9540
15:20:48.151   Training iter 150, batch loss 0.1636, batch acc 0.9500
15:20:48.572   Training iter 200, batch loss 0.1464, batch acc 0.9526
15:20:49.012   Training iter 250, batch loss 0.1490, batch acc 0.9542
15:20:49.484   Training iter 300, batch loss 0.1747, batch acc 0.9512
15:20:49.939   Training iter 350, batch loss 0.1751, batch acc 0.9464
15:20:50.422   Training iter 400, batch loss 0.1792, batch acc 0.9480
15:20:50.871   Training iter 450, batch loss 0.1413, batch acc 0.9558
15:20:51.323   Training iter 500, batch loss 0.1779, batch acc 0.9512
15:20:51.766   Training iter 550, batch loss 0.1738, batch acc 0.9496
15:20:52.227   Training iter 600, batch loss 0.1469, batch acc 0.9524
15:20:52.228 Testing @ 365 epoch...
15:20:52.274     Testing, total mean loss 0.20291, total acc 0.94000
15:20:52.274 Training @ 366 epoch...
15:20:52.738   Training iter 50, batch loss 0.1510, batch acc 0.9532
15:20:53.215   Training iter 100, batch loss 0.1605, batch acc 0.9548
15:20:53.693   Training iter 150, batch loss 0.1569, batch acc 0.9554
15:20:54.112   Training iter 200, batch loss 0.1720, batch acc 0.9494
15:20:54.539   Training iter 250, batch loss 0.1639, batch acc 0.9496
15:20:54.961   Training iter 300, batch loss 0.1605, batch acc 0.9526
15:20:55.395   Training iter 350, batch loss 0.1726, batch acc 0.9488
15:20:55.819   Training iter 400, batch loss 0.1435, batch acc 0.9560
15:20:56.252   Training iter 450, batch loss 0.1711, batch acc 0.9468
15:20:56.690   Training iter 500, batch loss 0.1549, batch acc 0.9518
15:20:57.113   Training iter 550, batch loss 0.1728, batch acc 0.9474
15:20:57.529   Training iter 600, batch loss 0.1510, batch acc 0.9550
15:20:57.531 Training @ 367 epoch...
15:20:57.958   Training iter 50, batch loss 0.1480, batch acc 0.9580
15:20:58.395   Training iter 100, batch loss 0.1665, batch acc 0.9508
15:20:58.823   Training iter 150, batch loss 0.1659, batch acc 0.9504
15:20:59.277   Training iter 200, batch loss 0.1601, batch acc 0.9514
15:20:59.718   Training iter 250, batch loss 0.1583, batch acc 0.9500
15:21:00.161   Training iter 300, batch loss 0.1535, batch acc 0.9534
15:21:00.627   Training iter 350, batch loss 0.1587, batch acc 0.9540
15:21:01.064   Training iter 400, batch loss 0.1772, batch acc 0.9446
15:21:01.525   Training iter 450, batch loss 0.1714, batch acc 0.9448
15:21:01.992   Training iter 500, batch loss 0.1645, batch acc 0.9500
15:21:02.536   Training iter 550, batch loss 0.1612, batch acc 0.9494
15:21:03.084   Training iter 600, batch loss 0.1535, batch acc 0.9548
15:21:03.086 Training @ 368 epoch...
15:21:03.658   Training iter 50, batch loss 0.1652, batch acc 0.9506
15:21:04.200   Training iter 100, batch loss 0.1607, batch acc 0.9480
15:21:04.744   Training iter 150, batch loss 0.1387, batch acc 0.9558
15:21:05.263   Training iter 200, batch loss 0.1645, batch acc 0.9506
15:21:05.775   Training iter 250, batch loss 0.1552, batch acc 0.9510
15:21:06.285   Training iter 300, batch loss 0.1664, batch acc 0.9526
15:21:06.782   Training iter 350, batch loss 0.1583, batch acc 0.9536
15:21:07.302   Training iter 400, batch loss 0.1552, batch acc 0.9536
15:21:07.835   Training iter 450, batch loss 0.1592, batch acc 0.9574
15:21:08.393   Training iter 500, batch loss 0.1724, batch acc 0.9492
15:21:08.906   Training iter 550, batch loss 0.1546, batch acc 0.9524
15:21:09.415   Training iter 600, batch loss 0.1654, batch acc 0.9508
15:21:09.417 Training @ 369 epoch...
15:21:09.912   Training iter 50, batch loss 0.1708, batch acc 0.9514
15:21:10.406   Training iter 100, batch loss 0.1413, batch acc 0.9568
15:21:10.898   Training iter 150, batch loss 0.1654, batch acc 0.9516
15:21:11.401   Training iter 200, batch loss 0.1508, batch acc 0.9530
15:21:11.864   Training iter 250, batch loss 0.1648, batch acc 0.9500
15:21:12.325   Training iter 300, batch loss 0.1639, batch acc 0.9522
15:21:12.780   Training iter 350, batch loss 0.1614, batch acc 0.9502
15:21:13.237   Training iter 400, batch loss 0.1639, batch acc 0.9498
15:21:13.675   Training iter 450, batch loss 0.1794, batch acc 0.9440
15:21:14.105   Training iter 500, batch loss 0.1608, batch acc 0.9548
15:21:14.538   Training iter 550, batch loss 0.1642, batch acc 0.9528
15:21:14.971   Training iter 600, batch loss 0.1397, batch acc 0.9578
15:21:14.972 Training @ 370 epoch...
15:21:15.440   Training iter 50, batch loss 0.1724, batch acc 0.9486
15:21:15.873   Training iter 100, batch loss 0.1468, batch acc 0.9560
15:21:16.340   Training iter 150, batch loss 0.1624, batch acc 0.9508
15:21:16.828   Training iter 200, batch loss 0.1884, batch acc 0.9436
15:21:17.301   Training iter 250, batch loss 0.1495, batch acc 0.9532
15:21:17.767   Training iter 300, batch loss 0.1647, batch acc 0.9502
15:21:18.225   Training iter 350, batch loss 0.1711, batch acc 0.9496
15:21:18.717   Training iter 400, batch loss 0.1385, batch acc 0.9578
15:21:19.192   Training iter 450, batch loss 0.1672, batch acc 0.9466
15:21:19.679   Training iter 500, batch loss 0.1665, batch acc 0.9496
15:21:20.172   Training iter 550, batch loss 0.1537, batch acc 0.9560
15:21:20.684   Training iter 600, batch loss 0.1567, batch acc 0.9522
15:21:20.686 Testing @ 370 epoch...
15:21:20.730     Testing, total mean loss 0.21965, total acc 0.93850
15:21:20.730 Training @ 371 epoch...
15:21:21.265   Training iter 50, batch loss 0.1635, batch acc 0.9534
15:21:21.802   Training iter 100, batch loss 0.1588, batch acc 0.9506
15:21:22.339   Training iter 150, batch loss 0.1574, batch acc 0.9538
15:21:22.874   Training iter 200, batch loss 0.1650, batch acc 0.9526
15:21:23.391   Training iter 250, batch loss 0.1582, batch acc 0.9524
15:21:23.903   Training iter 300, batch loss 0.1683, batch acc 0.9488
15:21:24.390   Training iter 350, batch loss 0.1569, batch acc 0.9510
15:21:24.827   Training iter 400, batch loss 0.1884, batch acc 0.9446
15:21:25.318   Training iter 450, batch loss 0.1664, batch acc 0.9548
15:21:25.821   Training iter 500, batch loss 0.1542, batch acc 0.9544
15:21:26.309   Training iter 550, batch loss 0.1453, batch acc 0.9530
15:21:26.800   Training iter 600, batch loss 0.1531, batch acc 0.9518
15:21:26.802 Training @ 372 epoch...
15:21:27.258   Training iter 50, batch loss 0.1446, batch acc 0.9550
15:21:27.749   Training iter 100, batch loss 0.1596, batch acc 0.9510
15:21:28.247   Training iter 150, batch loss 0.1568, batch acc 0.9538
15:21:28.694   Training iter 200, batch loss 0.1558, batch acc 0.9552
15:21:29.121   Training iter 250, batch loss 0.1563, batch acc 0.9542
15:21:29.566   Training iter 300, batch loss 0.1755, batch acc 0.9436
15:21:29.994   Training iter 350, batch loss 0.1717, batch acc 0.9488
15:21:30.465   Training iter 400, batch loss 0.1489, batch acc 0.9526
15:21:30.950   Training iter 450, batch loss 0.1573, batch acc 0.9532
15:21:31.430   Training iter 500, batch loss 0.1721, batch acc 0.9468
15:21:31.898   Training iter 550, batch loss 0.1554, batch acc 0.9502
15:21:32.383   Training iter 600, batch loss 0.1580, batch acc 0.9538
15:21:32.384 Training @ 373 epoch...
15:21:32.858   Training iter 50, batch loss 0.1720, batch acc 0.9516
15:21:33.344   Training iter 100, batch loss 0.1512, batch acc 0.9534
15:21:33.821   Training iter 150, batch loss 0.1695, batch acc 0.9518
15:21:34.324   Training iter 200, batch loss 0.1574, batch acc 0.9506
15:21:34.833   Training iter 250, batch loss 0.1424, batch acc 0.9592
15:21:35.351   Training iter 300, batch loss 0.1672, batch acc 0.9464
15:21:35.879   Training iter 350, batch loss 0.1524, batch acc 0.9564
15:21:36.415   Training iter 400, batch loss 0.1634, batch acc 0.9510
15:21:36.927   Training iter 450, batch loss 0.1482, batch acc 0.9578
15:21:37.455   Training iter 500, batch loss 0.1732, batch acc 0.9480
15:21:37.964   Training iter 550, batch loss 0.1574, batch acc 0.9558
15:21:38.490   Training iter 600, batch loss 0.1759, batch acc 0.9462
15:21:38.491 Training @ 374 epoch...
15:21:39.022   Training iter 50, batch loss 0.1267, batch acc 0.9572
15:21:39.548   Training iter 100, batch loss 0.1491, batch acc 0.9528
15:21:40.083   Training iter 150, batch loss 0.1701, batch acc 0.9482
15:21:40.587   Training iter 200, batch loss 0.1539, batch acc 0.9556
15:21:41.054   Training iter 250, batch loss 0.1759, batch acc 0.9476
15:21:41.525   Training iter 300, batch loss 0.1569, batch acc 0.9524
15:21:41.996   Training iter 350, batch loss 0.1639, batch acc 0.9512
15:21:42.479   Training iter 400, batch loss 0.1731, batch acc 0.9492
15:21:42.952   Training iter 450, batch loss 0.1737, batch acc 0.9494
15:21:43.444   Training iter 500, batch loss 0.1691, batch acc 0.9534
15:21:43.926   Training iter 550, batch loss 0.1688, batch acc 0.9512
15:21:44.424   Training iter 600, batch loss 0.1704, batch acc 0.9472
15:21:44.425 Training @ 375 epoch...
15:21:44.884   Training iter 50, batch loss 0.1451, batch acc 0.9562
15:21:45.349   Training iter 100, batch loss 0.1612, batch acc 0.9502
15:21:45.807   Training iter 150, batch loss 0.1614, batch acc 0.9490
15:21:46.293   Training iter 200, batch loss 0.1561, batch acc 0.9568
15:21:46.804   Training iter 250, batch loss 0.1762, batch acc 0.9498
15:21:47.303   Training iter 300, batch loss 0.1691, batch acc 0.9476
15:21:47.775   Training iter 350, batch loss 0.1579, batch acc 0.9518
15:21:48.227   Training iter 400, batch loss 0.1501, batch acc 0.9570
15:21:48.680   Training iter 450, batch loss 0.1671, batch acc 0.9490
15:21:49.159   Training iter 500, batch loss 0.1577, batch acc 0.9514
15:21:49.629   Training iter 550, batch loss 0.1630, batch acc 0.9514
15:21:50.116   Training iter 600, batch loss 0.1723, batch acc 0.9450
15:21:50.117 Testing @ 375 epoch...
15:21:50.161     Testing, total mean loss 0.20846, total acc 0.93970
15:21:50.161 Training @ 376 epoch...
15:21:50.667   Training iter 50, batch loss 0.1501, batch acc 0.9546
15:21:51.172   Training iter 100, batch loss 0.1586, batch acc 0.9530
15:21:51.681   Training iter 150, batch loss 0.1498, batch acc 0.9544
15:21:52.193   Training iter 200, batch loss 0.1507, batch acc 0.9584
15:21:52.699   Training iter 250, batch loss 0.1734, batch acc 0.9500
15:21:53.220   Training iter 300, batch loss 0.1627, batch acc 0.9508
15:21:53.724   Training iter 350, batch loss 0.1631, batch acc 0.9510
15:21:54.200   Training iter 400, batch loss 0.1609, batch acc 0.9526
15:21:54.704   Training iter 450, batch loss 0.1634, batch acc 0.9486
15:21:55.171   Training iter 500, batch loss 0.1642, batch acc 0.9490
15:21:55.645   Training iter 550, batch loss 0.1518, batch acc 0.9542
15:21:56.102   Training iter 600, batch loss 0.1629, batch acc 0.9520
15:21:56.103 Training @ 377 epoch...
15:21:56.577   Training iter 50, batch loss 0.1623, batch acc 0.9496
15:21:57.022   Training iter 100, batch loss 0.1474, batch acc 0.9534
15:21:57.488   Training iter 150, batch loss 0.1645, batch acc 0.9512
15:21:57.972   Training iter 200, batch loss 0.1584, batch acc 0.9518
15:21:58.469   Training iter 250, batch loss 0.1451, batch acc 0.9580
15:21:58.923   Training iter 300, batch loss 0.1538, batch acc 0.9538
15:21:59.391   Training iter 350, batch loss 0.1746, batch acc 0.9448
15:21:59.847   Training iter 400, batch loss 0.1593, batch acc 0.9530
15:22:00.308   Training iter 450, batch loss 0.1683, batch acc 0.9510
15:22:00.736   Training iter 500, batch loss 0.1669, batch acc 0.9510
15:22:01.168   Training iter 550, batch loss 0.1409, batch acc 0.9598
15:22:01.647   Training iter 600, batch loss 0.1721, batch acc 0.9482
15:22:01.649 Training @ 378 epoch...
15:22:02.167   Training iter 50, batch loss 0.1489, batch acc 0.9554
15:22:02.660   Training iter 100, batch loss 0.1506, batch acc 0.9554
15:22:03.165   Training iter 150, batch loss 0.1548, batch acc 0.9518
15:22:03.695   Training iter 200, batch loss 0.1703, batch acc 0.9500
15:22:04.224   Training iter 250, batch loss 0.1751, batch acc 0.9482
15:22:04.712   Training iter 300, batch loss 0.1519, batch acc 0.9566
15:22:05.179   Training iter 350, batch loss 0.1548, batch acc 0.9548
15:22:05.696   Training iter 400, batch loss 0.1606, batch acc 0.9520
15:22:06.173   Training iter 450, batch loss 0.1536, batch acc 0.9570
15:22:06.696   Training iter 500, batch loss 0.1742, batch acc 0.9474
15:22:07.223   Training iter 550, batch loss 0.1790, batch acc 0.9486
15:22:07.729   Training iter 600, batch loss 0.1562, batch acc 0.9514
15:22:07.730 Training @ 379 epoch...
15:22:08.225   Training iter 50, batch loss 0.1520, batch acc 0.9546
15:22:08.684   Training iter 100, batch loss 0.1653, batch acc 0.9508
15:22:09.136   Training iter 150, batch loss 0.1696, batch acc 0.9530
15:22:09.627   Training iter 200, batch loss 0.1582, batch acc 0.9510
15:22:10.104   Training iter 250, batch loss 0.1637, batch acc 0.9518
15:22:10.579   Training iter 300, batch loss 0.1554, batch acc 0.9558
15:22:11.034   Training iter 350, batch loss 0.1455, batch acc 0.9540
15:22:11.490   Training iter 400, batch loss 0.1699, batch acc 0.9494
15:22:11.942   Training iter 450, batch loss 0.1729, batch acc 0.9520
15:22:12.406   Training iter 500, batch loss 0.1595, batch acc 0.9520
15:22:12.849   Training iter 550, batch loss 0.1599, batch acc 0.9502
15:22:13.283   Training iter 600, batch loss 0.1616, batch acc 0.9516
15:22:13.284 Training @ 380 epoch...
15:22:13.750   Training iter 50, batch loss 0.1661, batch acc 0.9498
15:22:14.217   Training iter 100, batch loss 0.1615, batch acc 0.9528
15:22:14.700   Training iter 150, batch loss 0.1825, batch acc 0.9444
15:22:15.142   Training iter 200, batch loss 0.1482, batch acc 0.9546
15:22:15.591   Training iter 250, batch loss 0.1536, batch acc 0.9560
15:22:16.026   Training iter 300, batch loss 0.1515, batch acc 0.9526
15:22:16.451   Training iter 350, batch loss 0.1560, batch acc 0.9506
15:22:16.877   Training iter 400, batch loss 0.1582, batch acc 0.9526
15:22:17.300   Training iter 450, batch loss 0.1740, batch acc 0.9486
15:22:17.760   Training iter 500, batch loss 0.1601, batch acc 0.9524
15:22:18.192   Training iter 550, batch loss 0.1591, batch acc 0.9552
15:22:18.653   Training iter 600, batch loss 0.1528, batch acc 0.9546
15:22:18.655 Testing @ 380 epoch...
15:22:18.698     Testing, total mean loss 0.20353, total acc 0.94180
15:22:18.698 Training @ 381 epoch...
15:22:19.131   Training iter 50, batch loss 0.1669, batch acc 0.9524
15:22:19.582   Training iter 100, batch loss 0.1428, batch acc 0.9580
15:22:20.044   Training iter 150, batch loss 0.1448, batch acc 0.9562
15:22:20.495   Training iter 200, batch loss 0.1574, batch acc 0.9504
15:22:20.924   Training iter 250, batch loss 0.1621, batch acc 0.9514
15:22:21.349   Training iter 300, batch loss 0.1747, batch acc 0.9484
15:22:21.779   Training iter 350, batch loss 0.1689, batch acc 0.9488
15:22:22.208   Training iter 400, batch loss 0.1699, batch acc 0.9520
15:22:22.645   Training iter 450, batch loss 0.1793, batch acc 0.9442
15:22:23.073   Training iter 500, batch loss 0.1663, batch acc 0.9510
15:22:23.525   Training iter 550, batch loss 0.1657, batch acc 0.9488
15:22:23.976   Training iter 600, batch loss 0.1535, batch acc 0.9548
15:22:23.977 Training @ 382 epoch...
15:22:24.438   Training iter 50, batch loss 0.1439, batch acc 0.9576
15:22:24.884   Training iter 100, batch loss 0.1511, batch acc 0.9536
15:22:25.356   Training iter 150, batch loss 0.1531, batch acc 0.9578
15:22:25.807   Training iter 200, batch loss 0.1561, batch acc 0.9522
15:22:26.245   Training iter 250, batch loss 0.1497, batch acc 0.9554
15:22:26.707   Training iter 300, batch loss 0.1697, batch acc 0.9490
15:22:27.152   Training iter 350, batch loss 0.1598, batch acc 0.9512
15:22:27.600   Training iter 400, batch loss 0.1672, batch acc 0.9486
15:22:28.051   Training iter 450, batch loss 0.1631, batch acc 0.9570
15:22:28.509   Training iter 500, batch loss 0.1820, batch acc 0.9462
15:22:28.941   Training iter 550, batch loss 0.1703, batch acc 0.9456
15:22:29.406   Training iter 600, batch loss 0.1626, batch acc 0.9486
15:22:29.407 Training @ 383 epoch...
15:22:29.853   Training iter 50, batch loss 0.1795, batch acc 0.9426
15:22:30.298   Training iter 100, batch loss 0.1617, batch acc 0.9520
15:22:30.745   Training iter 150, batch loss 0.1539, batch acc 0.9538
15:22:31.175   Training iter 200, batch loss 0.1367, batch acc 0.9608
15:22:31.589   Training iter 250, batch loss 0.1673, batch acc 0.9502
15:22:31.999   Training iter 300, batch loss 0.1572, batch acc 0.9548
15:22:32.423   Training iter 350, batch loss 0.1795, batch acc 0.9460
15:22:32.854   Training iter 400, batch loss 0.1588, batch acc 0.9504
15:22:33.304   Training iter 450, batch loss 0.1499, batch acc 0.9558
15:22:33.759   Training iter 500, batch loss 0.1543, batch acc 0.9568
15:22:34.188   Training iter 550, batch loss 0.1624, batch acc 0.9520
15:22:34.649   Training iter 600, batch loss 0.1687, batch acc 0.9470
15:22:34.651 Training @ 384 epoch...
15:22:35.079   Training iter 50, batch loss 0.1549, batch acc 0.9554
15:22:35.512   Training iter 100, batch loss 0.1476, batch acc 0.9564
15:22:35.936   Training iter 150, batch loss 0.1713, batch acc 0.9488
15:22:36.391   Training iter 200, batch loss 0.1687, batch acc 0.9468
15:22:36.824   Training iter 250, batch loss 0.1649, batch acc 0.9488
15:22:37.258   Training iter 300, batch loss 0.1648, batch acc 0.9508
15:22:37.704   Training iter 350, batch loss 0.1501, batch acc 0.9524
15:22:38.136   Training iter 400, batch loss 0.1587, batch acc 0.9484
15:22:38.571   Training iter 450, batch loss 0.1545, batch acc 0.9540
15:22:38.998   Training iter 500, batch loss 0.1636, batch acc 0.9532
15:22:39.435   Training iter 550, batch loss 0.1546, batch acc 0.9536
15:22:39.882   Training iter 600, batch loss 0.1647, batch acc 0.9500
15:22:39.884 Training @ 385 epoch...
15:22:40.350   Training iter 50, batch loss 0.1428, batch acc 0.9598
15:22:40.824   Training iter 100, batch loss 0.1652, batch acc 0.9522
15:22:41.297   Training iter 150, batch loss 0.1773, batch acc 0.9466
15:22:41.775   Training iter 200, batch loss 0.1697, batch acc 0.9450
15:22:42.248   Training iter 250, batch loss 0.1564, batch acc 0.9522
15:22:42.722   Training iter 300, batch loss 0.1526, batch acc 0.9550
15:22:43.184   Training iter 350, batch loss 0.1682, batch acc 0.9512
15:22:43.663   Training iter 400, batch loss 0.1426, batch acc 0.9600
15:22:44.120   Training iter 450, batch loss 0.1473, batch acc 0.9544
15:22:44.579   Training iter 500, batch loss 0.1609, batch acc 0.9506
15:22:45.060   Training iter 550, batch loss 0.1742, batch acc 0.9464
15:22:45.500   Training iter 600, batch loss 0.1742, batch acc 0.9478
15:22:45.502 Testing @ 385 epoch...
15:22:45.545     Testing, total mean loss 0.20986, total acc 0.94030
15:22:45.545 Training @ 386 epoch...
15:22:45.996   Training iter 50, batch loss 0.1706, batch acc 0.9472
15:22:46.451   Training iter 100, batch loss 0.1455, batch acc 0.9554
15:22:46.869   Training iter 150, batch loss 0.1594, batch acc 0.9542
15:22:47.305   Training iter 200, batch loss 0.1661, batch acc 0.9500
15:22:47.735   Training iter 250, batch loss 0.1515, batch acc 0.9556
15:22:48.224   Training iter 300, batch loss 0.1545, batch acc 0.9550
15:22:48.733   Training iter 350, batch loss 0.1672, batch acc 0.9500
15:22:49.239   Training iter 400, batch loss 0.1474, batch acc 0.9546
15:22:49.772   Training iter 450, batch loss 0.1783, batch acc 0.9428
15:22:50.251   Training iter 500, batch loss 0.1717, batch acc 0.9518
15:22:50.747   Training iter 550, batch loss 0.1531, batch acc 0.9546
15:22:51.273   Training iter 600, batch loss 0.1584, batch acc 0.9514
15:22:51.275 Training @ 387 epoch...
15:22:51.773   Training iter 50, batch loss 0.1543, batch acc 0.9560
15:22:52.255   Training iter 100, batch loss 0.1571, batch acc 0.9538
15:22:52.750   Training iter 150, batch loss 0.1546, batch acc 0.9540
15:22:53.216   Training iter 200, batch loss 0.1519, batch acc 0.9542
15:22:53.693   Training iter 250, batch loss 0.1578, batch acc 0.9514
15:22:54.150   Training iter 300, batch loss 0.1620, batch acc 0.9546
15:22:54.643   Training iter 350, batch loss 0.1594, batch acc 0.9512
15:22:55.217   Training iter 400, batch loss 0.1851, batch acc 0.9478
15:22:55.768   Training iter 450, batch loss 0.1505, batch acc 0.9550
15:22:56.273   Training iter 500, batch loss 0.1547, batch acc 0.9530
15:22:56.787   Training iter 550, batch loss 0.1608, batch acc 0.9516
15:22:57.291   Training iter 600, batch loss 0.1529, batch acc 0.9542
15:22:57.293 Training @ 388 epoch...
15:22:57.800   Training iter 50, batch loss 0.1689, batch acc 0.9514
15:22:58.318   Training iter 100, batch loss 0.1712, batch acc 0.9532
15:22:58.833   Training iter 150, batch loss 0.1576, batch acc 0.9524
15:22:59.338   Training iter 200, batch loss 0.1611, batch acc 0.9524
15:22:59.853   Training iter 250, batch loss 0.1751, batch acc 0.9482
15:23:00.359   Training iter 300, batch loss 0.1565, batch acc 0.9536
15:23:00.846   Training iter 350, batch loss 0.1612, batch acc 0.9494
15:23:01.318   Training iter 400, batch loss 0.1714, batch acc 0.9462
15:23:01.861   Training iter 450, batch loss 0.1472, batch acc 0.9590
15:23:02.376   Training iter 500, batch loss 0.1543, batch acc 0.9530
15:23:02.837   Training iter 550, batch loss 0.1494, batch acc 0.9554
15:23:03.334   Training iter 600, batch loss 0.1429, batch acc 0.9576
15:23:03.336 Training @ 389 epoch...
15:23:03.907   Training iter 50, batch loss 0.1615, batch acc 0.9492
15:23:04.436   Training iter 100, batch loss 0.1538, batch acc 0.9540
15:23:04.946   Training iter 150, batch loss 0.1488, batch acc 0.9524
15:23:05.467   Training iter 200, batch loss 0.1658, batch acc 0.9518
15:23:05.972   Training iter 250, batch loss 0.1795, batch acc 0.9482
15:23:06.511   Training iter 300, batch loss 0.1507, batch acc 0.9562
15:23:07.017   Training iter 350, batch loss 0.1487, batch acc 0.9564
15:23:07.546   Training iter 400, batch loss 0.1599, batch acc 0.9510
15:23:08.029   Training iter 450, batch loss 0.1903, batch acc 0.9462
15:23:08.538   Training iter 500, batch loss 0.1555, batch acc 0.9528
15:23:09.014   Training iter 550, batch loss 0.1603, batch acc 0.9520
15:23:09.494   Training iter 600, batch loss 0.1376, batch acc 0.9582
15:23:09.495 Training @ 390 epoch...
15:23:09.975   Training iter 50, batch loss 0.1554, batch acc 0.9508
15:23:10.467   Training iter 100, batch loss 0.1634, batch acc 0.9488
15:23:10.987   Training iter 150, batch loss 0.1722, batch acc 0.9500
15:23:11.520   Training iter 200, batch loss 0.1717, batch acc 0.9510
15:23:12.035   Training iter 250, batch loss 0.1498, batch acc 0.9554
15:23:12.540   Training iter 300, batch loss 0.1735, batch acc 0.9474
15:23:13.046   Training iter 350, batch loss 0.1737, batch acc 0.9474
15:23:13.593   Training iter 400, batch loss 0.1590, batch acc 0.9530
15:23:14.096   Training iter 450, batch loss 0.1626, batch acc 0.9532
15:23:14.626   Training iter 500, batch loss 0.1432, batch acc 0.9566
15:23:15.146   Training iter 550, batch loss 0.1528, batch acc 0.9518
15:23:15.673   Training iter 600, batch loss 0.1526, batch acc 0.9500
15:23:15.675 Testing @ 390 epoch...
15:23:15.728     Testing, total mean loss 0.20509, total acc 0.94080
15:23:15.728 Training @ 391 epoch...
15:23:16.270   Training iter 50, batch loss 0.1705, batch acc 0.9488
15:23:16.756   Training iter 100, batch loss 0.1474, batch acc 0.9574
15:23:17.241   Training iter 150, batch loss 0.1541, batch acc 0.9556
15:23:17.719   Training iter 200, batch loss 0.1634, batch acc 0.9482
15:23:18.219   Training iter 250, batch loss 0.1590, batch acc 0.9560
15:23:18.747   Training iter 300, batch loss 0.1698, batch acc 0.9466
15:23:19.249   Training iter 350, batch loss 0.1626, batch acc 0.9484
15:23:19.751   Training iter 400, batch loss 0.1653, batch acc 0.9512
15:23:20.233   Training iter 450, batch loss 0.1597, batch acc 0.9522
15:23:20.737   Training iter 500, batch loss 0.1622, batch acc 0.9518
15:23:21.226   Training iter 550, batch loss 0.1614, batch acc 0.9528
15:23:21.714   Training iter 600, batch loss 0.1590, batch acc 0.9498
15:23:21.716 Training @ 392 epoch...
15:23:22.230   Training iter 50, batch loss 0.1454, batch acc 0.9550
15:23:22.714   Training iter 100, batch loss 0.1580, batch acc 0.9570
15:23:23.172   Training iter 150, batch loss 0.1563, batch acc 0.9508
15:23:23.675   Training iter 200, batch loss 0.1445, batch acc 0.9572
15:23:24.196   Training iter 250, batch loss 0.1420, batch acc 0.9600
15:23:24.755   Training iter 300, batch loss 0.1693, batch acc 0.9468
15:23:25.329   Training iter 350, batch loss 0.1522, batch acc 0.9556
15:23:25.876   Training iter 400, batch loss 0.1633, batch acc 0.9530
15:23:26.447   Training iter 450, batch loss 0.1864, batch acc 0.9446
15:23:27.031   Training iter 500, batch loss 0.1679, batch acc 0.9470
15:23:27.625   Training iter 550, batch loss 0.1848, batch acc 0.9408
15:23:28.195   Training iter 600, batch loss 0.1571, batch acc 0.9510
15:23:28.197 Training @ 393 epoch...
15:23:28.770   Training iter 50, batch loss 0.1524, batch acc 0.9494
15:23:29.340   Training iter 100, batch loss 0.1476, batch acc 0.9574
15:23:29.908   Training iter 150, batch loss 0.1563, batch acc 0.9568
15:23:30.475   Training iter 200, batch loss 0.1718, batch acc 0.9490
15:23:31.034   Training iter 250, batch loss 0.1573, batch acc 0.9514
15:23:31.610   Training iter 300, batch loss 0.1604, batch acc 0.9544
15:23:32.161   Training iter 350, batch loss 0.1622, batch acc 0.9490
15:23:32.653   Training iter 400, batch loss 0.1639, batch acc 0.9484
15:23:33.139   Training iter 450, batch loss 0.1692, batch acc 0.9510
15:23:33.614   Training iter 500, batch loss 0.1481, batch acc 0.9566
15:23:34.088   Training iter 550, batch loss 0.1610, batch acc 0.9520
15:23:34.567   Training iter 600, batch loss 0.1594, batch acc 0.9496
15:23:34.569 Training @ 394 epoch...
15:23:35.077   Training iter 50, batch loss 0.1752, batch acc 0.9510
15:23:35.588   Training iter 100, batch loss 0.1445, batch acc 0.9538
15:23:36.092   Training iter 150, batch loss 0.1794, batch acc 0.9474
15:23:36.621   Training iter 200, batch loss 0.1472, batch acc 0.9554
15:23:37.127   Training iter 250, batch loss 0.1563, batch acc 0.9538
15:23:37.651   Training iter 300, batch loss 0.1587, batch acc 0.9540
15:23:38.162   Training iter 350, batch loss 0.1571, batch acc 0.9524
15:23:38.699   Training iter 400, batch loss 0.1510, batch acc 0.9526
15:23:39.201   Training iter 450, batch loss 0.1501, batch acc 0.9556
15:23:39.725   Training iter 500, batch loss 0.1678, batch acc 0.9498
15:23:40.243   Training iter 550, batch loss 0.1604, batch acc 0.9516
15:23:40.758   Training iter 600, batch loss 0.1720, batch acc 0.9490
15:23:40.760 Training @ 395 epoch...
15:23:41.267   Training iter 50, batch loss 0.1604, batch acc 0.9528
15:23:41.800   Training iter 100, batch loss 0.1358, batch acc 0.9572
15:23:42.288   Training iter 150, batch loss 0.1565, batch acc 0.9538
15:23:42.795   Training iter 200, batch loss 0.1768, batch acc 0.9502
15:23:43.355   Training iter 250, batch loss 0.1606, batch acc 0.9522
15:23:43.949   Training iter 300, batch loss 0.1474, batch acc 0.9548
15:23:44.504   Training iter 350, batch loss 0.1712, batch acc 0.9486
15:23:45.046   Training iter 400, batch loss 0.1575, batch acc 0.9520
15:23:45.612   Training iter 450, batch loss 0.1741, batch acc 0.9474
15:23:46.157   Training iter 500, batch loss 0.1619, batch acc 0.9492
15:23:46.675   Training iter 550, batch loss 0.1489, batch acc 0.9550
15:23:47.157   Training iter 600, batch loss 0.1681, batch acc 0.9530
15:23:47.159 Testing @ 395 epoch...
15:23:47.210     Testing, total mean loss 0.21231, total acc 0.93940
15:23:47.210 Training @ 396 epoch...
15:23:47.728   Training iter 50, batch loss 0.1595, batch acc 0.9510
15:23:48.239   Training iter 100, batch loss 0.1633, batch acc 0.9492
15:23:48.754   Training iter 150, batch loss 0.1503, batch acc 0.9512
15:23:49.232   Training iter 200, batch loss 0.1631, batch acc 0.9476
15:23:49.745   Training iter 250, batch loss 0.1617, batch acc 0.9504
15:23:50.248   Training iter 300, batch loss 0.1496, batch acc 0.9532
15:23:50.761   Training iter 350, batch loss 0.1618, batch acc 0.9542
15:23:51.234   Training iter 400, batch loss 0.1722, batch acc 0.9496
15:23:51.734   Training iter 450, batch loss 0.1543, batch acc 0.9516
15:23:52.218   Training iter 500, batch loss 0.1592, batch acc 0.9562
15:23:52.732   Training iter 550, batch loss 0.1567, batch acc 0.9540
15:23:53.247   Training iter 600, batch loss 0.1750, batch acc 0.9478
15:23:53.249 Training @ 397 epoch...
15:23:53.777   Training iter 50, batch loss 0.1644, batch acc 0.9538
15:23:54.275   Training iter 100, batch loss 0.1480, batch acc 0.9542
15:23:54.757   Training iter 150, batch loss 0.1536, batch acc 0.9572
15:23:55.272   Training iter 200, batch loss 0.1432, batch acc 0.9528
15:23:55.768   Training iter 250, batch loss 0.1711, batch acc 0.9496
15:23:56.279   Training iter 300, batch loss 0.1563, batch acc 0.9512
15:23:56.809   Training iter 350, batch loss 0.1531, batch acc 0.9530
15:23:57.330   Training iter 400, batch loss 0.1650, batch acc 0.9498
15:23:57.864   Training iter 450, batch loss 0.1639, batch acc 0.9514
15:23:58.422   Training iter 500, batch loss 0.1773, batch acc 0.9498
15:23:58.973   Training iter 550, batch loss 0.1729, batch acc 0.9504
15:23:59.549   Training iter 600, batch loss 0.1682, batch acc 0.9462
15:23:59.551 Training @ 398 epoch...
15:24:00.136   Training iter 50, batch loss 0.1659, batch acc 0.9520
15:24:00.713   Training iter 100, batch loss 0.1481, batch acc 0.9560
15:24:01.281   Training iter 150, batch loss 0.1631, batch acc 0.9554
15:24:01.859   Training iter 200, batch loss 0.1752, batch acc 0.9448
15:24:02.471   Training iter 250, batch loss 0.1624, batch acc 0.9498
15:24:03.075   Training iter 300, batch loss 0.1611, batch acc 0.9496
15:24:03.697   Training iter 350, batch loss 0.1545, batch acc 0.9540
15:24:04.319   Training iter 400, batch loss 0.1785, batch acc 0.9454
15:24:04.917   Training iter 450, batch loss 0.1563, batch acc 0.9526
15:24:05.503   Training iter 500, batch loss 0.1528, batch acc 0.9526
15:24:06.100   Training iter 550, batch loss 0.1501, batch acc 0.9556
15:24:06.707   Training iter 600, batch loss 0.1643, batch acc 0.9500
15:24:06.709 Training @ 399 epoch...
15:24:07.349   Training iter 50, batch loss 0.1591, batch acc 0.9538
15:24:07.953   Training iter 100, batch loss 0.1505, batch acc 0.9532
15:24:08.550   Training iter 150, batch loss 0.1524, batch acc 0.9564
15:24:09.142   Training iter 200, batch loss 0.1514, batch acc 0.9548
15:24:09.700   Training iter 250, batch loss 0.1478, batch acc 0.9558
15:24:10.264   Training iter 300, batch loss 0.1632, batch acc 0.9480
15:24:10.804   Training iter 350, batch loss 0.1772, batch acc 0.9502
15:24:11.302   Training iter 400, batch loss 0.1704, batch acc 0.9492
15:24:11.785   Training iter 450, batch loss 0.1454, batch acc 0.9548
15:24:12.269   Training iter 500, batch loss 0.1594, batch acc 0.9532
15:24:12.749   Training iter 550, batch loss 0.1657, batch acc 0.9498
15:24:13.220   Training iter 600, batch loss 0.1695, batch acc 0.9526
15:24:13.222 Training @ 400 epoch...
15:24:13.699   Training iter 50, batch loss 0.1496, batch acc 0.9558
15:24:14.180   Training iter 100, batch loss 0.1540, batch acc 0.9552
15:24:14.706   Training iter 150, batch loss 0.1420, batch acc 0.9596
15:24:15.254   Training iter 200, batch loss 0.1656, batch acc 0.9514
15:24:15.843   Training iter 250, batch loss 0.1675, batch acc 0.9506
15:24:16.433   Training iter 300, batch loss 0.1715, batch acc 0.9480
15:24:17.012   Training iter 350, batch loss 0.1594, batch acc 0.9514
15:24:17.606   Training iter 400, batch loss 0.1631, batch acc 0.9520
15:24:18.195   Training iter 450, batch loss 0.1616, batch acc 0.9524
15:24:18.791   Training iter 500, batch loss 0.1706, batch acc 0.9484
15:24:19.400   Training iter 550, batch loss 0.1521, batch acc 0.9556
15:24:19.970   Training iter 600, batch loss 0.1561, batch acc 0.9540
15:24:19.972 Testing @ 400 epoch...
15:24:20.025     Testing, total mean loss 0.23632, total acc 0.93190
15:24:20.025 Plot @ 400 epoch...
15:24:20.025 Training @ 401 epoch...
15:24:20.605   Training iter 50, batch loss 0.1704, batch acc 0.9506
15:24:21.134   Training iter 100, batch loss 0.1585, batch acc 0.9518
15:24:21.620   Training iter 150, batch loss 0.1592, batch acc 0.9540
15:24:22.125   Training iter 200, batch loss 0.1670, batch acc 0.9494
15:24:22.674   Training iter 250, batch loss 0.1466, batch acc 0.9548
15:24:23.206   Training iter 300, batch loss 0.1627, batch acc 0.9510
15:24:23.748   Training iter 350, batch loss 0.1423, batch acc 0.9570
15:24:24.309   Training iter 400, batch loss 0.1801, batch acc 0.9486
15:24:24.865   Training iter 450, batch loss 0.1587, batch acc 0.9516
15:24:25.422   Training iter 500, batch loss 0.1498, batch acc 0.9520
15:24:25.964   Training iter 550, batch loss 0.1631, batch acc 0.9530
15:24:26.530   Training iter 600, batch loss 0.1660, batch acc 0.9482
15:24:26.533 Training @ 402 epoch...
15:24:27.089   Training iter 50, batch loss 0.1536, batch acc 0.9520
15:24:27.654   Training iter 100, batch loss 0.1469, batch acc 0.9568
15:24:28.193   Training iter 150, batch loss 0.1533, batch acc 0.9540
15:24:28.731   Training iter 200, batch loss 0.1427, batch acc 0.9588
15:24:29.306   Training iter 250, batch loss 0.1515, batch acc 0.9538
15:24:29.855   Training iter 300, batch loss 0.1771, batch acc 0.9514
15:24:30.401   Training iter 350, batch loss 0.1667, batch acc 0.9492
15:24:30.937   Training iter 400, batch loss 0.1617, batch acc 0.9534
15:24:31.504   Training iter 450, batch loss 0.1658, batch acc 0.9486
15:24:32.112   Training iter 500, batch loss 0.1602, batch acc 0.9494
15:24:32.708   Training iter 550, batch loss 0.1677, batch acc 0.9484
15:24:33.270   Training iter 600, batch loss 0.1569, batch acc 0.9502
15:24:33.272 Training @ 403 epoch...
15:24:33.806   Training iter 50, batch loss 0.1674, batch acc 0.9518
15:24:34.339   Training iter 100, batch loss 0.1553, batch acc 0.9526
15:24:34.885   Training iter 150, batch loss 0.1534, batch acc 0.9500
15:24:35.420   Training iter 200, batch loss 0.1581, batch acc 0.9502
15:24:35.934   Training iter 250, batch loss 0.1645, batch acc 0.9522
15:24:36.435   Training iter 300, batch loss 0.1507, batch acc 0.9540
15:24:36.951   Training iter 350, batch loss 0.1666, batch acc 0.9488
15:24:37.457   Training iter 400, batch loss 0.1655, batch acc 0.9484
15:24:37.970   Training iter 450, batch loss 0.1585, batch acc 0.9514
15:24:38.497   Training iter 500, batch loss 0.1542, batch acc 0.9536
15:24:38.997   Training iter 550, batch loss 0.1566, batch acc 0.9530
15:24:39.501   Training iter 600, batch loss 0.1807, batch acc 0.9462
15:24:39.503 Training @ 404 epoch...
15:24:40.010   Training iter 50, batch loss 0.1708, batch acc 0.9480
15:24:40.528   Training iter 100, batch loss 0.1567, batch acc 0.9522
15:24:40.993   Training iter 150, batch loss 0.1405, batch acc 0.9556
15:24:41.496   Training iter 200, batch loss 0.1479, batch acc 0.9556
15:24:42.064   Training iter 250, batch loss 0.1724, batch acc 0.9502
15:24:42.598   Training iter 300, batch loss 0.1686, batch acc 0.9484
15:24:43.134   Training iter 350, batch loss 0.1385, batch acc 0.9574
15:24:43.650   Training iter 400, batch loss 0.1683, batch acc 0.9506
15:24:44.145   Training iter 450, batch loss 0.1873, batch acc 0.9426
15:24:44.655   Training iter 500, batch loss 0.1623, batch acc 0.9476
15:24:45.129   Training iter 550, batch loss 0.1570, batch acc 0.9540
15:24:45.625   Training iter 600, batch loss 0.1552, batch acc 0.9542
15:24:45.627 Training @ 405 epoch...
15:24:46.116   Training iter 50, batch loss 0.1593, batch acc 0.9514
15:24:46.617   Training iter 100, batch loss 0.1666, batch acc 0.9524
15:24:47.110   Training iter 150, batch loss 0.1485, batch acc 0.9568
15:24:47.634   Training iter 200, batch loss 0.1590, batch acc 0.9530
15:24:48.146   Training iter 250, batch loss 0.1619, batch acc 0.9516
15:24:48.692   Training iter 300, batch loss 0.1588, batch acc 0.9468
15:24:49.215   Training iter 350, batch loss 0.1633, batch acc 0.9498
15:24:49.729   Training iter 400, batch loss 0.1586, batch acc 0.9508
15:24:50.203   Training iter 450, batch loss 0.1582, batch acc 0.9510
15:24:50.716   Training iter 500, batch loss 0.1654, batch acc 0.9494
15:24:51.207   Training iter 550, batch loss 0.1577, batch acc 0.9542
15:24:51.761   Training iter 600, batch loss 0.1663, batch acc 0.9524
15:24:51.763 Testing @ 405 epoch...
15:24:51.814     Testing, total mean loss 0.20733, total acc 0.94020
15:24:51.814 Training @ 406 epoch...
15:24:52.371   Training iter 50, batch loss 0.1724, batch acc 0.9494
15:24:52.910   Training iter 100, batch loss 0.1441, batch acc 0.9560
15:24:53.448   Training iter 150, batch loss 0.1929, batch acc 0.9456
15:24:54.010   Training iter 200, batch loss 0.1620, batch acc 0.9486
15:24:54.534   Training iter 250, batch loss 0.1502, batch acc 0.9540
15:24:55.043   Training iter 300, batch loss 0.1574, batch acc 0.9534
15:24:55.577   Training iter 350, batch loss 0.1582, batch acc 0.9504
15:24:56.070   Training iter 400, batch loss 0.1518, batch acc 0.9554
15:24:56.584   Training iter 450, batch loss 0.1492, batch acc 0.9548
15:24:57.099   Training iter 500, batch loss 0.1592, batch acc 0.9548
15:24:57.641   Training iter 550, batch loss 0.1640, batch acc 0.9512
15:24:58.187   Training iter 600, batch loss 0.1570, batch acc 0.9502
15:24:58.189 Training @ 407 epoch...
15:24:58.679   Training iter 50, batch loss 0.1464, batch acc 0.9578
15:24:59.119   Training iter 100, batch loss 0.1643, batch acc 0.9498
15:24:59.565   Training iter 150, batch loss 0.1522, batch acc 0.9542
15:25:00.023   Training iter 200, batch loss 0.1571, batch acc 0.9530
15:25:00.488   Training iter 250, batch loss 0.1589, batch acc 0.9548
15:25:00.967   Training iter 300, batch loss 0.1586, batch acc 0.9554
15:25:01.480   Training iter 350, batch loss 0.1502, batch acc 0.9526
15:25:02.049   Training iter 400, batch loss 0.1605, batch acc 0.9504
15:25:02.595   Training iter 450, batch loss 0.1651, batch acc 0.9528
15:25:03.110   Training iter 500, batch loss 0.1674, batch acc 0.9534
15:25:03.678   Training iter 550, batch loss 0.1840, batch acc 0.9442
15:25:04.230   Training iter 600, batch loss 0.1639, batch acc 0.9496
15:25:04.232 Training @ 408 epoch...
15:25:04.783   Training iter 50, batch loss 0.1734, batch acc 0.9456
15:25:05.318   Training iter 100, batch loss 0.1426, batch acc 0.9574
15:25:05.861   Training iter 150, batch loss 0.1472, batch acc 0.9586
15:25:06.392   Training iter 200, batch loss 0.1462, batch acc 0.9558
15:25:06.973   Training iter 250, batch loss 0.1552, batch acc 0.9528
15:25:07.562   Training iter 300, batch loss 0.1564, batch acc 0.9512
15:25:08.145   Training iter 350, batch loss 0.1609, batch acc 0.9496
15:25:08.691   Training iter 400, batch loss 0.1637, batch acc 0.9542
15:25:09.228   Training iter 450, batch loss 0.1583, batch acc 0.9532
15:25:09.759   Training iter 500, batch loss 0.1576, batch acc 0.9556
15:25:10.277   Training iter 550, batch loss 0.1713, batch acc 0.9498
15:25:10.809   Training iter 600, batch loss 0.1781, batch acc 0.9464
15:25:10.811 Training @ 409 epoch...
15:25:11.327   Training iter 50, batch loss 0.1394, batch acc 0.9586
15:25:11.850   Training iter 100, batch loss 0.1304, batch acc 0.9598
15:25:12.357   Training iter 150, batch loss 0.1591, batch acc 0.9538
15:25:12.869   Training iter 200, batch loss 0.1668, batch acc 0.9554
15:25:13.387   Training iter 250, batch loss 0.1568, batch acc 0.9524
15:25:13.929   Training iter 300, batch loss 0.1707, batch acc 0.9494
15:25:14.438   Training iter 350, batch loss 0.1601, batch acc 0.9568
15:25:14.963   Training iter 400, batch loss 0.1620, batch acc 0.9500
15:25:15.482   Training iter 450, batch loss 0.1774, batch acc 0.9458
15:25:16.010   Training iter 500, batch loss 0.1667, batch acc 0.9520
15:25:16.599   Training iter 550, batch loss 0.1652, batch acc 0.9452
15:25:17.148   Training iter 600, batch loss 0.1562, batch acc 0.9524
15:25:17.150 Training @ 410 epoch...
15:25:17.669   Training iter 50, batch loss 0.1482, batch acc 0.9568
15:25:18.195   Training iter 100, batch loss 0.1669, batch acc 0.9504
15:25:18.759   Training iter 150, batch loss 0.1599, batch acc 0.9524
15:25:19.326   Training iter 200, batch loss 0.1684, batch acc 0.9482
15:25:19.916   Training iter 250, batch loss 0.1490, batch acc 0.9524
15:25:20.511   Training iter 300, batch loss 0.1703, batch acc 0.9462
15:25:21.095   Training iter 350, batch loss 0.1453, batch acc 0.9554
15:25:21.646   Training iter 400, batch loss 0.1461, batch acc 0.9540
15:25:22.184   Training iter 450, batch loss 0.1620, batch acc 0.9510
15:25:22.728   Training iter 500, batch loss 0.1525, batch acc 0.9534
15:25:23.252   Training iter 550, batch loss 0.1692, batch acc 0.9498
15:25:23.788   Training iter 600, batch loss 0.1761, batch acc 0.9494
15:25:23.789 Testing @ 410 epoch...
15:25:23.839     Testing, total mean loss 0.21810, total acc 0.93700
15:25:23.839 Training @ 411 epoch...
15:25:24.393   Training iter 50, batch loss 0.1521, batch acc 0.9534
15:25:24.922   Training iter 100, batch loss 0.1429, batch acc 0.9562
15:25:25.448   Training iter 150, batch loss 0.1630, batch acc 0.9498
15:25:25.994   Training iter 200, batch loss 0.1664, batch acc 0.9534
15:25:26.542   Training iter 250, batch loss 0.1572, batch acc 0.9512
15:25:27.084   Training iter 300, batch loss 0.1549, batch acc 0.9522
15:25:27.628   Training iter 350, batch loss 0.1802, batch acc 0.9472
15:25:28.184   Training iter 400, batch loss 0.1583, batch acc 0.9528
15:25:28.750   Training iter 450, batch loss 0.1628, batch acc 0.9504
15:25:29.291   Training iter 500, batch loss 0.1498, batch acc 0.9548
15:25:29.844   Training iter 550, batch loss 0.1544, batch acc 0.9554
15:25:30.374   Training iter 600, batch loss 0.1657, batch acc 0.9512
15:25:30.376 Training @ 412 epoch...
15:25:30.909   Training iter 50, batch loss 0.1710, batch acc 0.9492
15:25:31.418   Training iter 100, batch loss 0.1568, batch acc 0.9556
15:25:31.934   Training iter 150, batch loss 0.1519, batch acc 0.9520
15:25:32.424   Training iter 200, batch loss 0.1756, batch acc 0.9500
15:25:32.926   Training iter 250, batch loss 0.1563, batch acc 0.9522
15:25:33.456   Training iter 300, batch loss 0.1570, batch acc 0.9510
15:25:33.986   Training iter 350, batch loss 0.1514, batch acc 0.9548
15:25:34.526   Training iter 400, batch loss 0.1640, batch acc 0.9526
15:25:35.085   Training iter 450, batch loss 0.1530, batch acc 0.9588
15:25:35.658   Training iter 500, batch loss 0.1743, batch acc 0.9450
15:25:36.196   Training iter 550, batch loss 0.1524, batch acc 0.9520
15:25:36.757   Training iter 600, batch loss 0.1576, batch acc 0.9506
15:25:36.759 Training @ 413 epoch...
15:25:37.323   Training iter 50, batch loss 0.1503, batch acc 0.9536
15:25:37.859   Training iter 100, batch loss 0.1477, batch acc 0.9560
15:25:38.414   Training iter 150, batch loss 0.1617, batch acc 0.9498
15:25:38.955   Training iter 200, batch loss 0.1676, batch acc 0.9522
15:25:39.492   Training iter 250, batch loss 0.1423, batch acc 0.9576
15:25:39.977   Training iter 300, batch loss 0.1545, batch acc 0.9524
15:25:40.481   Training iter 350, batch loss 0.1692, batch acc 0.9486
15:25:40.979   Training iter 400, batch loss 0.1727, batch acc 0.9492
15:25:41.479   Training iter 450, batch loss 0.1528, batch acc 0.9534
15:25:41.966   Training iter 500, batch loss 0.1790, batch acc 0.9448
15:25:42.426   Training iter 550, batch loss 0.1708, batch acc 0.9516
15:25:42.914   Training iter 600, batch loss 0.1559, batch acc 0.9556
15:25:42.915 Training @ 414 epoch...
15:25:43.428   Training iter 50, batch loss 0.1526, batch acc 0.9542
15:25:43.942   Training iter 100, batch loss 0.1500, batch acc 0.9540
15:25:44.472   Training iter 150, batch loss 0.1554, batch acc 0.9530
15:25:45.003   Training iter 200, batch loss 0.1639, batch acc 0.9508
15:25:45.545   Training iter 250, batch loss 0.1485, batch acc 0.9574
15:25:46.042   Training iter 300, batch loss 0.1487, batch acc 0.9554
15:25:46.559   Training iter 350, batch loss 0.1746, batch acc 0.9486
15:25:47.049   Training iter 400, batch loss 0.1748, batch acc 0.9482
15:25:47.535   Training iter 450, batch loss 0.1617, batch acc 0.9516
15:25:48.010   Training iter 500, batch loss 0.1693, batch acc 0.9452
15:25:48.504   Training iter 550, batch loss 0.1579, batch acc 0.9546
15:25:48.972   Training iter 600, batch loss 0.1503, batch acc 0.9542
15:25:48.974 Training @ 415 epoch...
15:25:49.440   Training iter 50, batch loss 0.1596, batch acc 0.9530
15:25:49.917   Training iter 100, batch loss 0.1634, batch acc 0.9492
15:25:50.425   Training iter 150, batch loss 0.1699, batch acc 0.9518
15:25:50.946   Training iter 200, batch loss 0.1760, batch acc 0.9468
15:25:51.443   Training iter 250, batch loss 0.1482, batch acc 0.9564
15:25:51.980   Training iter 300, batch loss 0.1657, batch acc 0.9520
15:25:52.494   Training iter 350, batch loss 0.1595, batch acc 0.9506
15:25:52.987   Training iter 400, batch loss 0.1510, batch acc 0.9570
15:25:53.495   Training iter 450, batch loss 0.1551, batch acc 0.9564
15:25:53.977   Training iter 500, batch loss 0.1554, batch acc 0.9548
15:25:54.482   Training iter 550, batch loss 0.1738, batch acc 0.9450
15:25:54.959   Training iter 600, batch loss 0.1556, batch acc 0.9530
15:25:54.961 Testing @ 415 epoch...
15:25:55.012     Testing, total mean loss 0.21172, total acc 0.93720
15:25:55.012 Training @ 416 epoch...
15:25:55.477   Training iter 50, batch loss 0.1543, batch acc 0.9536
15:25:55.933   Training iter 100, batch loss 0.1522, batch acc 0.9556
15:25:56.405   Training iter 150, batch loss 0.1747, batch acc 0.9430
15:25:56.890   Training iter 200, batch loss 0.1564, batch acc 0.9514
15:25:57.357   Training iter 250, batch loss 0.1437, batch acc 0.9544
15:25:57.835   Training iter 300, batch loss 0.1644, batch acc 0.9554
15:25:58.300   Training iter 350, batch loss 0.1625, batch acc 0.9514
15:25:58.773   Training iter 400, batch loss 0.1485, batch acc 0.9550
15:25:59.245   Training iter 450, batch loss 0.1719, batch acc 0.9480
15:25:59.697   Training iter 500, batch loss 0.1661, batch acc 0.9520
15:26:00.152   Training iter 550, batch loss 0.1642, batch acc 0.9484
15:26:00.670   Training iter 600, batch loss 0.1493, batch acc 0.9556
15:26:00.672 Training @ 417 epoch...
15:26:01.239   Training iter 50, batch loss 0.1637, batch acc 0.9524
15:26:01.809   Training iter 100, batch loss 0.1394, batch acc 0.9590
15:26:02.369   Training iter 150, batch loss 0.1620, batch acc 0.9522
15:26:02.956   Training iter 200, batch loss 0.1804, batch acc 0.9454
15:26:03.515   Training iter 250, batch loss 0.1669, batch acc 0.9506
15:26:04.065   Training iter 300, batch loss 0.1554, batch acc 0.9516
15:26:04.576   Training iter 350, batch loss 0.1483, batch acc 0.9524
15:26:05.071   Training iter 400, batch loss 0.1567, batch acc 0.9504
15:26:05.562   Training iter 450, batch loss 0.1634, batch acc 0.9536
15:26:06.049   Training iter 500, batch loss 0.1641, batch acc 0.9534
15:26:06.593   Training iter 550, batch loss 0.1614, batch acc 0.9524
15:26:07.104   Training iter 600, batch loss 0.1524, batch acc 0.9516
15:26:07.106 Training @ 418 epoch...
15:26:07.666   Training iter 50, batch loss 0.1374, batch acc 0.9558
15:26:08.188   Training iter 100, batch loss 0.1619, batch acc 0.9502
15:26:08.705   Training iter 150, batch loss 0.1504, batch acc 0.9552
15:26:09.200   Training iter 200, batch loss 0.1655, batch acc 0.9516
15:26:09.720   Training iter 250, batch loss 0.1505, batch acc 0.9592
15:26:10.200   Training iter 300, batch loss 0.1711, batch acc 0.9460
15:26:10.730   Training iter 350, batch loss 0.1650, batch acc 0.9532
15:26:11.228   Training iter 400, batch loss 0.1764, batch acc 0.9466
15:26:11.698   Training iter 450, batch loss 0.1544, batch acc 0.9514
15:26:12.173   Training iter 500, batch loss 0.1619, batch acc 0.9478
15:26:12.663   Training iter 550, batch loss 0.1726, batch acc 0.9462
15:26:13.151   Training iter 600, batch loss 0.1670, batch acc 0.9532
15:26:13.153 Training @ 419 epoch...
15:26:13.676   Training iter 50, batch loss 0.1474, batch acc 0.9550
15:26:14.184   Training iter 100, batch loss 0.1695, batch acc 0.9482
15:26:14.678   Training iter 150, batch loss 0.1526, batch acc 0.9528
15:26:15.177   Training iter 200, batch loss 0.1371, batch acc 0.9542
15:26:15.696   Training iter 250, batch loss 0.1607, batch acc 0.9538
15:26:16.208   Training iter 300, batch loss 0.1558, batch acc 0.9560
15:26:16.750   Training iter 350, batch loss 0.1557, batch acc 0.9518
15:26:17.308   Training iter 400, batch loss 0.1657, batch acc 0.9508
15:26:17.830   Training iter 450, batch loss 0.1591, batch acc 0.9496
15:26:18.387   Training iter 500, batch loss 0.1588, batch acc 0.9508
15:26:18.940   Training iter 550, batch loss 0.1709, batch acc 0.9466
15:26:19.511   Training iter 600, batch loss 0.1776, batch acc 0.9474
15:26:19.513 Training @ 420 epoch...
15:26:20.038   Training iter 50, batch loss 0.1406, batch acc 0.9554
15:26:20.558   Training iter 100, batch loss 0.1533, batch acc 0.9532
15:26:21.114   Training iter 150, batch loss 0.1726, batch acc 0.9462
15:26:21.642   Training iter 200, batch loss 0.1580, batch acc 0.9530
15:26:22.217   Training iter 250, batch loss 0.1712, batch acc 0.9476
15:26:22.819   Training iter 300, batch loss 0.1486, batch acc 0.9560
15:26:23.396   Training iter 350, batch loss 0.1621, batch acc 0.9472
15:26:23.971   Training iter 400, batch loss 0.1672, batch acc 0.9472
15:26:24.559   Training iter 450, batch loss 0.1599, batch acc 0.9496
15:26:25.155   Training iter 500, batch loss 0.1526, batch acc 0.9562
15:26:25.754   Training iter 550, batch loss 0.1710, batch acc 0.9504
15:26:26.348   Training iter 600, batch loss 0.1715, batch acc 0.9508
15:26:26.350 Testing @ 420 epoch...
15:26:26.401     Testing, total mean loss 0.20356, total acc 0.94060
15:26:26.401 Training @ 421 epoch...
15:26:27.016   Training iter 50, batch loss 0.1534, batch acc 0.9570
15:26:27.602   Training iter 100, batch loss 0.1622, batch acc 0.9466
15:26:28.174   Training iter 150, batch loss 0.1562, batch acc 0.9500
15:26:28.706   Training iter 200, batch loss 0.1588, batch acc 0.9544
15:26:29.193   Training iter 250, batch loss 0.1730, batch acc 0.9520
15:26:29.713   Training iter 300, batch loss 0.1705, batch acc 0.9498
15:26:30.199   Training iter 350, batch loss 0.1459, batch acc 0.9560
15:26:30.685   Training iter 400, batch loss 0.1546, batch acc 0.9530
15:26:31.172   Training iter 450, batch loss 0.1602, batch acc 0.9514
15:26:31.658   Training iter 500, batch loss 0.1555, batch acc 0.9534
15:26:32.145   Training iter 550, batch loss 0.1602, batch acc 0.9490
15:26:32.589   Training iter 600, batch loss 0.1578, batch acc 0.9536
15:26:32.591 Training @ 422 epoch...
15:26:33.051   Training iter 50, batch loss 0.1519, batch acc 0.9600
15:26:33.534   Training iter 100, batch loss 0.1595, batch acc 0.9510
15:26:34.006   Training iter 150, batch loss 0.1673, batch acc 0.9518
15:26:34.478   Training iter 200, batch loss 0.1672, batch acc 0.9496
15:26:34.949   Training iter 250, batch loss 0.1536, batch acc 0.9538
15:26:35.414   Training iter 300, batch loss 0.1640, batch acc 0.9492
15:26:35.884   Training iter 350, batch loss 0.1464, batch acc 0.9544
15:26:36.367   Training iter 400, batch loss 0.1671, batch acc 0.9494
15:26:36.809   Training iter 450, batch loss 0.1659, batch acc 0.9504
15:26:37.262   Training iter 500, batch loss 0.1496, batch acc 0.9558
15:26:37.780   Training iter 550, batch loss 0.1765, batch acc 0.9516
15:26:38.266   Training iter 600, batch loss 0.1508, batch acc 0.9524
15:26:38.268 Training @ 423 epoch...
15:26:38.791   Training iter 50, batch loss 0.1609, batch acc 0.9548
15:26:39.299   Training iter 100, batch loss 0.1484, batch acc 0.9588
15:26:39.840   Training iter 150, batch loss 0.1594, batch acc 0.9506
15:26:40.332   Training iter 200, batch loss 0.1640, batch acc 0.9508
15:26:40.824   Training iter 250, batch loss 0.1591, batch acc 0.9528
15:26:41.334   Training iter 300, batch loss 0.1634, batch acc 0.9528
15:26:41.880   Training iter 350, batch loss 0.1675, batch acc 0.9450
15:26:42.389   Training iter 400, batch loss 0.1351, batch acc 0.9564
15:26:42.911   Training iter 450, batch loss 0.1611, batch acc 0.9518
15:26:43.422   Training iter 500, batch loss 0.1651, batch acc 0.9486
15:26:43.922   Training iter 550, batch loss 0.1716, batch acc 0.9516
15:26:44.399   Training iter 600, batch loss 0.1780, batch acc 0.9480
15:26:44.400 Training @ 424 epoch...
15:26:44.872   Training iter 50, batch loss 0.1387, batch acc 0.9570
15:26:45.331   Training iter 100, batch loss 0.1662, batch acc 0.9520
15:26:45.803   Training iter 150, batch loss 0.1453, batch acc 0.9566
15:26:46.277   Training iter 200, batch loss 0.1394, batch acc 0.9590
15:26:46.796   Training iter 250, batch loss 0.1701, batch acc 0.9526
15:26:47.286   Training iter 300, batch loss 0.1686, batch acc 0.9532
15:26:47.778   Training iter 350, batch loss 0.1678, batch acc 0.9516
15:26:48.264   Training iter 400, batch loss 0.1743, batch acc 0.9496
15:26:48.752   Training iter 450, batch loss 0.1758, batch acc 0.9486
15:26:49.229   Training iter 500, batch loss 0.1518, batch acc 0.9540
15:26:49.701   Training iter 550, batch loss 0.1846, batch acc 0.9446
15:26:50.162   Training iter 600, batch loss 0.1510, batch acc 0.9534
15:26:50.163 Training @ 425 epoch...
15:26:50.642   Training iter 50, batch loss 0.1539, batch acc 0.9518
15:26:51.120   Training iter 100, batch loss 0.1599, batch acc 0.9536
15:26:51.631   Training iter 150, batch loss 0.1496, batch acc 0.9542
15:26:52.128   Training iter 200, batch loss 0.1625, batch acc 0.9538
15:26:52.596   Training iter 250, batch loss 0.1455, batch acc 0.9578
15:26:53.043   Training iter 300, batch loss 0.1605, batch acc 0.9534
15:26:53.503   Training iter 350, batch loss 0.1699, batch acc 0.9474
15:26:53.953   Training iter 400, batch loss 0.1605, batch acc 0.9512
15:26:54.395   Training iter 450, batch loss 0.1664, batch acc 0.9502
15:26:54.871   Training iter 500, batch loss 0.1583, batch acc 0.9540
15:26:55.325   Training iter 550, batch loss 0.1628, batch acc 0.9510
15:26:55.803   Training iter 600, batch loss 0.1649, batch acc 0.9516
15:26:55.805 Testing @ 425 epoch...
15:26:55.854     Testing, total mean loss 0.21751, total acc 0.93650
15:26:55.854 Training @ 426 epoch...
15:26:56.322   Training iter 50, batch loss 0.1551, batch acc 0.9534
15:26:56.784   Training iter 100, batch loss 0.1683, batch acc 0.9496
15:26:57.221   Training iter 150, batch loss 0.1833, batch acc 0.9436
15:26:57.663   Training iter 200, batch loss 0.1616, batch acc 0.9526
15:26:58.108   Training iter 250, batch loss 0.1478, batch acc 0.9528
15:26:58.544   Training iter 300, batch loss 0.1444, batch acc 0.9554
15:26:58.971   Training iter 350, batch loss 0.1666, batch acc 0.9480
15:26:59.388   Training iter 400, batch loss 0.1653, batch acc 0.9492
15:26:59.821   Training iter 450, batch loss 0.1366, batch acc 0.9604
15:27:00.267   Training iter 500, batch loss 0.1616, batch acc 0.9504
15:27:00.705   Training iter 550, batch loss 0.1652, batch acc 0.9504
15:27:01.126   Training iter 600, batch loss 0.1619, batch acc 0.9510
15:27:01.127 Training @ 427 epoch...
15:27:01.571   Training iter 50, batch loss 0.1545, batch acc 0.9510
15:27:02.045   Training iter 100, batch loss 0.1704, batch acc 0.9504
15:27:02.525   Training iter 150, batch loss 0.1619, batch acc 0.9494
15:27:02.995   Training iter 200, batch loss 0.1502, batch acc 0.9592
15:27:03.502   Training iter 250, batch loss 0.1662, batch acc 0.9514
15:27:04.021   Training iter 300, batch loss 0.1504, batch acc 0.9518
15:27:04.518   Training iter 350, batch loss 0.1539, batch acc 0.9524
15:27:05.027   Training iter 400, batch loss 0.1557, batch acc 0.9536
15:27:05.505   Training iter 450, batch loss 0.1720, batch acc 0.9514
15:27:05.965   Training iter 500, batch loss 0.1649, batch acc 0.9524
15:27:06.413   Training iter 550, batch loss 0.1518, batch acc 0.9550
15:27:06.873   Training iter 600, batch loss 0.1580, batch acc 0.9510
15:27:06.875 Training @ 428 epoch...
15:27:07.379   Training iter 50, batch loss 0.1594, batch acc 0.9534
15:27:07.841   Training iter 100, batch loss 0.1500, batch acc 0.9580
15:27:08.276   Training iter 150, batch loss 0.1718, batch acc 0.9520
15:27:08.695   Training iter 200, batch loss 0.1561, batch acc 0.9536
15:27:09.127   Training iter 250, batch loss 0.1477, batch acc 0.9544
15:27:09.571   Training iter 300, batch loss 0.1674, batch acc 0.9492
15:27:10.015   Training iter 350, batch loss 0.1493, batch acc 0.9578
15:27:10.462   Training iter 400, batch loss 0.1515, batch acc 0.9538
15:27:10.895   Training iter 450, batch loss 0.1552, batch acc 0.9530
15:27:11.336   Training iter 500, batch loss 0.1756, batch acc 0.9470
15:27:11.772   Training iter 550, batch loss 0.1576, batch acc 0.9522
15:27:12.198   Training iter 600, batch loss 0.1595, batch acc 0.9522
15:27:12.200 Training @ 429 epoch...
15:27:12.624   Training iter 50, batch loss 0.1329, batch acc 0.9614
15:27:13.045   Training iter 100, batch loss 0.1524, batch acc 0.9562
15:27:13.467   Training iter 150, batch loss 0.1657, batch acc 0.9494
15:27:13.901   Training iter 200, batch loss 0.1662, batch acc 0.9490
15:27:14.327   Training iter 250, batch loss 0.1477, batch acc 0.9564
15:27:14.759   Training iter 300, batch loss 0.1537, batch acc 0.9508
15:27:15.184   Training iter 350, batch loss 0.1663, batch acc 0.9506
15:27:15.608   Training iter 400, batch loss 0.1631, batch acc 0.9500
15:27:16.040   Training iter 450, batch loss 0.1796, batch acc 0.9482
15:27:16.478   Training iter 500, batch loss 0.1570, batch acc 0.9496
15:27:16.905   Training iter 550, batch loss 0.1639, batch acc 0.9492
15:27:17.341   Training iter 600, batch loss 0.1650, batch acc 0.9496
15:27:17.342 Training @ 430 epoch...
15:27:17.792   Training iter 50, batch loss 0.1675, batch acc 0.9512
15:27:18.230   Training iter 100, batch loss 0.1478, batch acc 0.9550
15:27:18.660   Training iter 150, batch loss 0.1444, batch acc 0.9550
15:27:19.102   Training iter 200, batch loss 0.1711, batch acc 0.9462
15:27:19.538   Training iter 250, batch loss 0.1794, batch acc 0.9520
15:27:19.950   Training iter 300, batch loss 0.1638, batch acc 0.9508
15:27:20.392   Training iter 350, batch loss 0.1521, batch acc 0.9572
15:27:20.838   Training iter 400, batch loss 0.1533, batch acc 0.9560
15:27:21.278   Training iter 450, batch loss 0.1502, batch acc 0.9526
15:27:21.709   Training iter 500, batch loss 0.1636, batch acc 0.9506
15:27:22.145   Training iter 550, batch loss 0.1539, batch acc 0.9548
15:27:22.571   Training iter 600, batch loss 0.1686, batch acc 0.9484
15:27:22.572 Testing @ 430 epoch...
15:27:22.616     Testing, total mean loss 0.20664, total acc 0.93860
15:27:22.616 Training @ 431 epoch...
15:27:23.046   Training iter 50, batch loss 0.1585, batch acc 0.9554
15:27:23.486   Training iter 100, batch loss 0.1436, batch acc 0.9562
15:27:23.948   Training iter 150, batch loss 0.1546, batch acc 0.9538
15:27:24.392   Training iter 200, batch loss 0.1686, batch acc 0.9464
15:27:24.853   Training iter 250, batch loss 0.1661, batch acc 0.9536
15:27:25.332   Training iter 300, batch loss 0.1720, batch acc 0.9490
15:27:25.826   Training iter 350, batch loss 0.1496, batch acc 0.9564
15:27:26.299   Training iter 400, batch loss 0.1606, batch acc 0.9530
15:27:26.802   Training iter 450, batch loss 0.1583, batch acc 0.9532
15:27:27.319   Training iter 500, batch loss 0.1596, batch acc 0.9538
15:27:27.847   Training iter 550, batch loss 0.1602, batch acc 0.9492
15:27:28.332   Training iter 600, batch loss 0.1706, batch acc 0.9472
15:27:28.333 Training @ 432 epoch...
15:27:28.813   Training iter 50, batch loss 0.1562, batch acc 0.9540
15:27:29.311   Training iter 100, batch loss 0.1514, batch acc 0.9512
15:27:29.784   Training iter 150, batch loss 0.1479, batch acc 0.9550
15:27:30.276   Training iter 200, batch loss 0.1640, batch acc 0.9512
15:27:30.756   Training iter 250, batch loss 0.1707, batch acc 0.9516
15:27:31.212   Training iter 300, batch loss 0.1443, batch acc 0.9556
15:27:31.670   Training iter 350, batch loss 0.1705, batch acc 0.9512
15:27:32.114   Training iter 400, batch loss 0.1766, batch acc 0.9434
15:27:32.530   Training iter 450, batch loss 0.1599, batch acc 0.9516
15:27:32.942   Training iter 500, batch loss 0.1714, batch acc 0.9474
15:27:33.364   Training iter 550, batch loss 0.1564, batch acc 0.9524
15:27:33.783   Training iter 600, batch loss 0.1684, batch acc 0.9500
15:27:33.785 Training @ 433 epoch...
15:27:34.238   Training iter 50, batch loss 0.1389, batch acc 0.9614
15:27:34.664   Training iter 100, batch loss 0.1501, batch acc 0.9552
15:27:35.126   Training iter 150, batch loss 0.1540, batch acc 0.9512
15:27:35.602   Training iter 200, batch loss 0.1616, batch acc 0.9492
15:27:36.101   Training iter 250, batch loss 0.1670, batch acc 0.9526
15:27:36.577   Training iter 300, batch loss 0.1599, batch acc 0.9528
15:27:37.049   Training iter 350, batch loss 0.1713, batch acc 0.9470
15:27:37.501   Training iter 400, batch loss 0.1658, batch acc 0.9488
15:27:37.952   Training iter 450, batch loss 0.1812, batch acc 0.9460
15:27:38.403   Training iter 500, batch loss 0.1522, batch acc 0.9510
15:27:38.861   Training iter 550, batch loss 0.1663, batch acc 0.9488
15:27:39.309   Training iter 600, batch loss 0.1596, batch acc 0.9516
15:27:39.311 Training @ 434 epoch...
15:27:39.778   Training iter 50, batch loss 0.1664, batch acc 0.9472
15:27:40.228   Training iter 100, batch loss 0.1442, batch acc 0.9564
15:27:40.705   Training iter 150, batch loss 0.1586, batch acc 0.9494
15:27:41.203   Training iter 200, batch loss 0.1632, batch acc 0.9550
15:27:41.716   Training iter 250, batch loss 0.1532, batch acc 0.9522
15:27:42.222   Training iter 300, batch loss 0.1437, batch acc 0.9566
15:27:42.712   Training iter 350, batch loss 0.1596, batch acc 0.9520
15:27:43.193   Training iter 400, batch loss 0.1717, batch acc 0.9514
15:27:43.662   Training iter 450, batch loss 0.1452, batch acc 0.9558
15:27:44.126   Training iter 500, batch loss 0.1638, batch acc 0.9510
15:27:44.576   Training iter 550, batch loss 0.1630, batch acc 0.9548
15:27:45.046   Training iter 600, batch loss 0.1674, batch acc 0.9462
15:27:45.047 Training @ 435 epoch...
15:27:45.532   Training iter 50, batch loss 0.1652, batch acc 0.9478
15:27:46.032   Training iter 100, batch loss 0.1537, batch acc 0.9546
15:27:46.517   Training iter 150, batch loss 0.1710, batch acc 0.9544
15:27:47.012   Training iter 200, batch loss 0.1572, batch acc 0.9548
15:27:47.502   Training iter 250, batch loss 0.1494, batch acc 0.9542
15:27:47.980   Training iter 300, batch loss 0.1650, batch acc 0.9486
15:27:48.442   Training iter 350, batch loss 0.1497, batch acc 0.9562
15:27:48.885   Training iter 400, batch loss 0.1754, batch acc 0.9480
15:27:49.301   Training iter 450, batch loss 0.1493, batch acc 0.9568
15:27:49.712   Training iter 500, batch loss 0.1661, batch acc 0.9502
15:27:50.126   Training iter 550, batch loss 0.1451, batch acc 0.9550
15:27:50.557   Training iter 600, batch loss 0.1533, batch acc 0.9542
15:27:50.558 Testing @ 435 epoch...
15:27:50.602     Testing, total mean loss 0.20853, total acc 0.94020
15:27:50.602 Training @ 436 epoch...
15:27:51.045   Training iter 50, batch loss 0.1562, batch acc 0.9530
15:27:51.477   Training iter 100, batch loss 0.1697, batch acc 0.9534
15:27:51.903   Training iter 150, batch loss 0.1519, batch acc 0.9558
15:27:52.357   Training iter 200, batch loss 0.1625, batch acc 0.9490
15:27:52.810   Training iter 250, batch loss 0.1484, batch acc 0.9574
15:27:53.251   Training iter 300, batch loss 0.1653, batch acc 0.9520
15:27:53.684   Training iter 350, batch loss 0.1512, batch acc 0.9532
15:27:54.121   Training iter 400, batch loss 0.1634, batch acc 0.9508
15:27:54.559   Training iter 450, batch loss 0.1556, batch acc 0.9514
15:27:54.992   Training iter 500, batch loss 0.1744, batch acc 0.9500
15:27:55.460   Training iter 550, batch loss 0.1560, batch acc 0.9530
15:27:55.890   Training iter 600, batch loss 0.1616, batch acc 0.9544
15:27:55.892 Training @ 437 epoch...
15:27:56.329   Training iter 50, batch loss 0.1599, batch acc 0.9526
15:27:56.752   Training iter 100, batch loss 0.1853, batch acc 0.9466
15:27:57.206   Training iter 150, batch loss 0.1571, batch acc 0.9524
15:27:57.647   Training iter 200, batch loss 0.1449, batch acc 0.9564
15:27:58.116   Training iter 250, batch loss 0.1608, batch acc 0.9522
15:27:58.572   Training iter 300, batch loss 0.1516, batch acc 0.9544
15:27:59.001   Training iter 350, batch loss 0.1516, batch acc 0.9538
15:27:59.438   Training iter 400, batch loss 0.1605, batch acc 0.9532
15:27:59.880   Training iter 450, batch loss 0.1598, batch acc 0.9502
15:28:00.360   Training iter 500, batch loss 0.1594, batch acc 0.9512
15:28:00.830   Training iter 550, batch loss 0.1531, batch acc 0.9544
15:28:01.266   Training iter 600, batch loss 0.1659, batch acc 0.9472
15:28:01.268 Training @ 438 epoch...
15:28:01.744   Training iter 50, batch loss 0.1665, batch acc 0.9490
15:28:02.230   Training iter 100, batch loss 0.1612, batch acc 0.9526
15:28:02.709   Training iter 150, batch loss 0.1545, batch acc 0.9528
15:28:03.202   Training iter 200, batch loss 0.1543, batch acc 0.9562
15:28:03.723   Training iter 250, batch loss 0.1662, batch acc 0.9522
15:28:04.255   Training iter 300, batch loss 0.1472, batch acc 0.9528
15:28:04.789   Training iter 350, batch loss 0.1697, batch acc 0.9478
15:28:05.339   Training iter 400, batch loss 0.1495, batch acc 0.9526
15:28:05.929   Training iter 450, batch loss 0.1392, batch acc 0.9602
15:28:06.497   Training iter 500, batch loss 0.1631, batch acc 0.9526
15:28:07.054   Training iter 550, batch loss 0.1723, batch acc 0.9524
15:28:07.611   Training iter 600, batch loss 0.1620, batch acc 0.9504
15:28:07.613 Training @ 439 epoch...
15:28:08.181   Training iter 50, batch loss 0.1534, batch acc 0.9558
15:28:08.731   Training iter 100, batch loss 0.1478, batch acc 0.9576
15:28:09.264   Training iter 150, batch loss 0.1662, batch acc 0.9526
15:28:09.813   Training iter 200, batch loss 0.1860, batch acc 0.9462
15:28:10.386   Training iter 250, batch loss 0.1479, batch acc 0.9566
15:28:10.920   Training iter 300, batch loss 0.1615, batch acc 0.9516
15:28:11.474   Training iter 350, batch loss 0.1642, batch acc 0.9540
15:28:12.020   Training iter 400, batch loss 0.1561, batch acc 0.9520
15:28:12.604   Training iter 450, batch loss 0.1654, batch acc 0.9472
15:28:13.161   Training iter 500, batch loss 0.1566, batch acc 0.9552
15:28:13.702   Training iter 550, batch loss 0.1535, batch acc 0.9520
15:28:14.246   Training iter 600, batch loss 0.1577, batch acc 0.9526
15:28:14.248 Training @ 440 epoch...
15:28:14.867   Training iter 50, batch loss 0.1538, batch acc 0.9524
15:28:15.450   Training iter 100, batch loss 0.1555, batch acc 0.9530
15:28:16.013   Training iter 150, batch loss 0.1470, batch acc 0.9550
15:28:16.577   Training iter 200, batch loss 0.1747, batch acc 0.9466
15:28:17.139   Training iter 250, batch loss 0.1671, batch acc 0.9498
15:28:17.705   Training iter 300, batch loss 0.1658, batch acc 0.9494
15:28:18.348   Training iter 350, batch loss 0.1639, batch acc 0.9520
15:28:19.055   Training iter 400, batch loss 0.1586, batch acc 0.9538
15:28:19.616   Training iter 450, batch loss 0.1612, batch acc 0.9500
15:28:20.201   Training iter 500, batch loss 0.1657, batch acc 0.9524
15:28:20.754   Training iter 550, batch loss 0.1536, batch acc 0.9520
15:28:21.297   Training iter 600, batch loss 0.1519, batch acc 0.9560
15:28:21.299 Testing @ 440 epoch...
15:28:21.344     Testing, total mean loss 0.21192, total acc 0.93790
15:28:21.344 Training @ 441 epoch...
15:28:21.885   Training iter 50, batch loss 0.1693, batch acc 0.9498
15:28:22.405   Training iter 100, batch loss 0.1553, batch acc 0.9542
15:28:22.927   Training iter 150, batch loss 0.1621, batch acc 0.9514
15:28:23.442   Training iter 200, batch loss 0.1456, batch acc 0.9560
15:28:23.948   Training iter 250, batch loss 0.1456, batch acc 0.9540
15:28:24.468   Training iter 300, batch loss 0.1803, batch acc 0.9484
15:28:24.992   Training iter 350, batch loss 0.1560, batch acc 0.9530
15:28:25.526   Training iter 400, batch loss 0.1600, batch acc 0.9530
15:28:26.021   Training iter 450, batch loss 0.1711, batch acc 0.9450
15:28:26.523   Training iter 500, batch loss 0.1588, batch acc 0.9510
15:28:27.037   Training iter 550, batch loss 0.1583, batch acc 0.9496
15:28:27.569   Training iter 600, batch loss 0.1527, batch acc 0.9556
15:28:27.571 Training @ 442 epoch...
15:28:28.108   Training iter 50, batch loss 0.1667, batch acc 0.9528
15:28:28.633   Training iter 100, batch loss 0.1541, batch acc 0.9554
15:28:29.157   Training iter 150, batch loss 0.1766, batch acc 0.9486
15:28:29.688   Training iter 200, batch loss 0.1652, batch acc 0.9500
15:28:30.250   Training iter 250, batch loss 0.1700, batch acc 0.9520
15:28:30.818   Training iter 300, batch loss 0.1594, batch acc 0.9506
15:28:31.388   Training iter 350, batch loss 0.1645, batch acc 0.9530
15:28:31.928   Training iter 400, batch loss 0.1471, batch acc 0.9558
15:28:32.479   Training iter 450, batch loss 0.1590, batch acc 0.9468
15:28:33.063   Training iter 500, batch loss 0.1543, batch acc 0.9496
15:28:33.630   Training iter 550, batch loss 0.1584, batch acc 0.9512
15:28:34.195   Training iter 600, batch loss 0.1435, batch acc 0.9548
15:28:34.197 Training @ 443 epoch...
15:28:34.789   Training iter 50, batch loss 0.1498, batch acc 0.9564
15:28:35.401   Training iter 100, batch loss 0.1483, batch acc 0.9530
15:28:35.996   Training iter 150, batch loss 0.1791, batch acc 0.9492
15:28:36.567   Training iter 200, batch loss 0.1434, batch acc 0.9530
15:28:37.048   Training iter 250, batch loss 0.1461, batch acc 0.9540
15:28:37.535   Training iter 300, batch loss 0.1703, batch acc 0.9518
15:28:38.051   Training iter 350, batch loss 0.1678, batch acc 0.9486
15:28:38.577   Training iter 400, batch loss 0.1624, batch acc 0.9512
15:28:39.105   Training iter 450, batch loss 0.1655, batch acc 0.9538
15:28:39.643   Training iter 500, batch loss 0.1656, batch acc 0.9520
15:28:40.165   Training iter 550, batch loss 0.1696, batch acc 0.9500
15:28:40.692   Training iter 600, batch loss 0.1517, batch acc 0.9554
15:28:40.694 Training @ 444 epoch...
15:28:41.218   Training iter 50, batch loss 0.1493, batch acc 0.9564
15:28:41.760   Training iter 100, batch loss 0.1629, batch acc 0.9518
15:28:42.319   Training iter 150, batch loss 0.1469, batch acc 0.9546
15:28:42.850   Training iter 200, batch loss 0.1586, batch acc 0.9516
15:28:43.395   Training iter 250, batch loss 0.1444, batch acc 0.9550
15:28:43.932   Training iter 300, batch loss 0.1778, batch acc 0.9498
15:28:44.490   Training iter 350, batch loss 0.1731, batch acc 0.9478
15:28:45.039   Training iter 400, batch loss 0.1436, batch acc 0.9556
15:28:45.585   Training iter 450, batch loss 0.1608, batch acc 0.9512
15:28:46.121   Training iter 500, batch loss 0.1674, batch acc 0.9464
15:28:46.657   Training iter 550, batch loss 0.1565, batch acc 0.9536
15:28:47.206   Training iter 600, batch loss 0.1759, batch acc 0.9472
15:28:47.208 Training @ 445 epoch...
15:28:47.772   Training iter 50, batch loss 0.1636, batch acc 0.9498
15:28:48.325   Training iter 100, batch loss 0.1538, batch acc 0.9568
15:28:48.876   Training iter 150, batch loss 0.1607, batch acc 0.9534
15:28:49.431   Training iter 200, batch loss 0.1721, batch acc 0.9500
15:28:49.981   Training iter 250, batch loss 0.1570, batch acc 0.9550
15:28:50.536   Training iter 300, batch loss 0.1716, batch acc 0.9522
15:28:51.080   Training iter 350, batch loss 0.1608, batch acc 0.9536
15:28:51.626   Training iter 400, batch loss 0.1576, batch acc 0.9504
15:28:52.182   Training iter 450, batch loss 0.1332, batch acc 0.9572
15:28:52.727   Training iter 500, batch loss 0.1550, batch acc 0.9548
15:28:53.232   Training iter 550, batch loss 0.1554, batch acc 0.9520
15:28:53.736   Training iter 600, batch loss 0.1621, batch acc 0.9510
15:28:53.738 Testing @ 445 epoch...
15:28:53.781     Testing, total mean loss 0.22100, total acc 0.93590
15:28:53.781 Training @ 446 epoch...
15:28:54.279   Training iter 50, batch loss 0.1633, batch acc 0.9500
15:28:54.774   Training iter 100, batch loss 0.1464, batch acc 0.9534
15:28:55.273   Training iter 150, batch loss 0.1567, batch acc 0.9544
15:28:55.780   Training iter 200, batch loss 0.1492, batch acc 0.9536
15:28:56.296   Training iter 250, batch loss 0.1445, batch acc 0.9592
15:28:56.808   Training iter 300, batch loss 0.1703, batch acc 0.9522
15:28:57.320   Training iter 350, batch loss 0.1631, batch acc 0.9524
15:28:57.843   Training iter 400, batch loss 0.1538, batch acc 0.9566
15:28:58.361   Training iter 450, batch loss 0.1692, batch acc 0.9540
15:28:58.869   Training iter 500, batch loss 0.1653, batch acc 0.9522
15:28:59.388   Training iter 550, batch loss 0.1570, batch acc 0.9514
15:28:59.910   Training iter 600, batch loss 0.1700, batch acc 0.9504
15:28:59.912 Training @ 447 epoch...
15:29:00.442   Training iter 50, batch loss 0.1389, batch acc 0.9588
15:29:00.947   Training iter 100, batch loss 0.1631, batch acc 0.9500
15:29:01.447   Training iter 150, batch loss 0.1706, batch acc 0.9488
15:29:01.988   Training iter 200, batch loss 0.1598, batch acc 0.9488
15:29:02.562   Training iter 250, batch loss 0.1809, batch acc 0.9484
15:29:03.114   Training iter 300, batch loss 0.1685, batch acc 0.9528
15:29:03.664   Training iter 350, batch loss 0.1500, batch acc 0.9540
15:29:04.216   Training iter 400, batch loss 0.1497, batch acc 0.9566
15:29:04.775   Training iter 450, batch loss 0.1643, batch acc 0.9502
15:29:05.343   Training iter 500, batch loss 0.1550, batch acc 0.9556
15:29:05.850   Training iter 550, batch loss 0.1590, batch acc 0.9518
15:29:06.349   Training iter 600, batch loss 0.1605, batch acc 0.9518
15:29:06.351 Training @ 448 epoch...
15:29:06.898   Training iter 50, batch loss 0.1516, batch acc 0.9566
15:29:07.437   Training iter 100, batch loss 0.1698, batch acc 0.9488
15:29:07.961   Training iter 150, batch loss 0.1545, batch acc 0.9544
15:29:08.474   Training iter 200, batch loss 0.1617, batch acc 0.9520
15:29:08.978   Training iter 250, batch loss 0.1539, batch acc 0.9514
15:29:09.491   Training iter 300, batch loss 0.1660, batch acc 0.9506
15:29:09.957   Training iter 350, batch loss 0.1440, batch acc 0.9564
15:29:10.450   Training iter 400, batch loss 0.1557, batch acc 0.9528
15:29:10.953   Training iter 450, batch loss 0.1652, batch acc 0.9502
15:29:11.465   Training iter 500, batch loss 0.1486, batch acc 0.9556
15:29:11.993   Training iter 550, batch loss 0.1681, batch acc 0.9532
15:29:12.536   Training iter 600, batch loss 0.1702, batch acc 0.9488
15:29:12.538 Training @ 449 epoch...
15:29:13.061   Training iter 50, batch loss 0.1631, batch acc 0.9490
15:29:13.573   Training iter 100, batch loss 0.1490, batch acc 0.9564
15:29:14.097   Training iter 150, batch loss 0.1543, batch acc 0.9532
15:29:14.622   Training iter 200, batch loss 0.1477, batch acc 0.9548
15:29:15.143   Training iter 250, batch loss 0.1679, batch acc 0.9482
15:29:15.662   Training iter 300, batch loss 0.1646, batch acc 0.9524
15:29:16.179   Training iter 350, batch loss 0.1563, batch acc 0.9504
15:29:16.681   Training iter 400, batch loss 0.1588, batch acc 0.9524
15:29:17.194   Training iter 450, batch loss 0.1606, batch acc 0.9562
15:29:17.711   Training iter 500, batch loss 0.1590, batch acc 0.9506
15:29:18.219   Training iter 550, batch loss 0.1669, batch acc 0.9498
15:29:18.731   Training iter 600, batch loss 0.1686, batch acc 0.9474
15:29:18.733 Training @ 450 epoch...
15:29:19.267   Training iter 50, batch loss 0.1433, batch acc 0.9578
15:29:19.797   Training iter 100, batch loss 0.1575, batch acc 0.9524
15:29:20.335   Training iter 150, batch loss 0.1503, batch acc 0.9524
15:29:20.855   Training iter 200, batch loss 0.1547, batch acc 0.9544
15:29:21.367   Training iter 250, batch loss 0.1644, batch acc 0.9508
15:29:21.910   Training iter 300, batch loss 0.1787, batch acc 0.9438
15:29:22.458   Training iter 350, batch loss 0.1606, batch acc 0.9506
15:29:23.007   Training iter 400, batch loss 0.1600, batch acc 0.9538
15:29:23.560   Training iter 450, batch loss 0.1451, batch acc 0.9582
15:29:24.114   Training iter 500, batch loss 0.1700, batch acc 0.9506
15:29:24.673   Training iter 550, batch loss 0.1848, batch acc 0.9442
15:29:25.249   Training iter 600, batch loss 0.1611, batch acc 0.9522
15:29:25.250 Testing @ 450 epoch...
15:29:25.298     Testing, total mean loss 0.21880, total acc 0.93620
15:29:25.298 Training @ 451 epoch...
15:29:25.839   Training iter 50, batch loss 0.1451, batch acc 0.9534
15:29:26.369   Training iter 100, batch loss 0.1777, batch acc 0.9502
15:29:26.904   Training iter 150, batch loss 0.1579, batch acc 0.9540
15:29:27.477   Training iter 200, batch loss 0.1557, batch acc 0.9554
15:29:28.075   Training iter 250, batch loss 0.1627, batch acc 0.9498
15:29:28.656   Training iter 300, batch loss 0.1466, batch acc 0.9546
15:29:29.220   Training iter 350, batch loss 0.1564, batch acc 0.9544
15:29:29.738   Training iter 400, batch loss 0.1579, batch acc 0.9512
15:29:30.260   Training iter 450, batch loss 0.1713, batch acc 0.9484
15:29:30.794   Training iter 500, batch loss 0.1708, batch acc 0.9492
15:29:31.328   Training iter 550, batch loss 0.1434, batch acc 0.9572
15:29:31.846   Training iter 600, batch loss 0.1546, batch acc 0.9538
15:29:31.848 Training @ 452 epoch...
15:29:32.363   Training iter 50, batch loss 0.1543, batch acc 0.9536
15:29:32.881   Training iter 100, batch loss 0.1516, batch acc 0.9574
15:29:33.418   Training iter 150, batch loss 0.1651, batch acc 0.9534
15:29:33.932   Training iter 200, batch loss 0.1605, batch acc 0.9494
15:29:34.444   Training iter 250, batch loss 0.1631, batch acc 0.9506
15:29:34.968   Training iter 300, batch loss 0.1516, batch acc 0.9520
15:29:35.496   Training iter 350, batch loss 0.1748, batch acc 0.9456
15:29:36.033   Training iter 400, batch loss 0.1538, batch acc 0.9498
15:29:36.523   Training iter 450, batch loss 0.1650, batch acc 0.9524
15:29:36.993   Training iter 500, batch loss 0.1643, batch acc 0.9520
15:29:37.468   Training iter 550, batch loss 0.1667, batch acc 0.9538
15:29:37.933   Training iter 600, batch loss 0.1567, batch acc 0.9562
15:29:37.934 Training @ 453 epoch...
15:29:38.421   Training iter 50, batch loss 0.1498, batch acc 0.9530
15:29:38.893   Training iter 100, batch loss 0.1534, batch acc 0.9576
15:29:39.366   Training iter 150, batch loss 0.1434, batch acc 0.9548
15:29:39.851   Training iter 200, batch loss 0.1709, batch acc 0.9496
15:29:40.343   Training iter 250, batch loss 0.1564, batch acc 0.9490
15:29:40.831   Training iter 300, batch loss 0.1652, batch acc 0.9514
15:29:41.299   Training iter 350, batch loss 0.1570, batch acc 0.9488
15:29:41.760   Training iter 400, batch loss 0.1651, batch acc 0.9480
15:29:42.235   Training iter 450, batch loss 0.1613, batch acc 0.9520
15:29:42.702   Training iter 500, batch loss 0.1589, batch acc 0.9536
15:29:43.199   Training iter 550, batch loss 0.1628, batch acc 0.9526
15:29:43.666   Training iter 600, batch loss 0.1601, batch acc 0.9556
15:29:43.668 Training @ 454 epoch...
15:29:44.159   Training iter 50, batch loss 0.1456, batch acc 0.9576
15:29:44.635   Training iter 100, batch loss 0.1518, batch acc 0.9576
15:29:45.128   Training iter 150, batch loss 0.1696, batch acc 0.9476
15:29:45.633   Training iter 200, batch loss 0.1571, batch acc 0.9564
15:29:46.156   Training iter 250, batch loss 0.1582, batch acc 0.9468
15:29:46.686   Training iter 300, batch loss 0.1476, batch acc 0.9558
15:29:47.213   Training iter 350, batch loss 0.1714, batch acc 0.9498
15:29:47.743   Training iter 400, batch loss 0.1589, batch acc 0.9508
15:29:48.260   Training iter 450, batch loss 0.1680, batch acc 0.9524
15:29:48.770   Training iter 500, batch loss 0.1700, batch acc 0.9482
15:29:49.278   Training iter 550, batch loss 0.1720, batch acc 0.9492
15:29:49.802   Training iter 600, batch loss 0.1484, batch acc 0.9556
15:29:49.804 Training @ 455 epoch...
15:29:50.341   Training iter 50, batch loss 0.1572, batch acc 0.9526
15:29:50.864   Training iter 100, batch loss 0.1556, batch acc 0.9596
15:29:51.409   Training iter 150, batch loss 0.1512, batch acc 0.9540
15:29:51.956   Training iter 200, batch loss 0.1649, batch acc 0.9494
15:29:52.518   Training iter 250, batch loss 0.1558, batch acc 0.9548
15:29:53.076   Training iter 300, batch loss 0.1537, batch acc 0.9532
15:29:53.628   Training iter 350, batch loss 0.1515, batch acc 0.9538
15:29:54.179   Training iter 400, batch loss 0.1621, batch acc 0.9502
15:29:54.729   Training iter 450, batch loss 0.1626, batch acc 0.9516
15:29:55.284   Training iter 500, batch loss 0.1756, batch acc 0.9508
15:29:55.826   Training iter 550, batch loss 0.1551, batch acc 0.9522
15:29:56.349   Training iter 600, batch loss 0.1589, batch acc 0.9526
15:29:56.351 Testing @ 455 epoch...
15:29:56.396     Testing, total mean loss 0.21609, total acc 0.93690
15:29:56.396 Training @ 456 epoch...
15:29:56.904   Training iter 50, batch loss 0.1679, batch acc 0.9500
15:29:57.383   Training iter 100, batch loss 0.1605, batch acc 0.9522
15:29:57.871   Training iter 150, batch loss 0.1605, batch acc 0.9512
15:29:58.369   Training iter 200, batch loss 0.1532, batch acc 0.9556
15:29:58.859   Training iter 250, batch loss 0.1685, batch acc 0.9462
15:29:59.354   Training iter 300, batch loss 0.1676, batch acc 0.9512
15:29:59.846   Training iter 350, batch loss 0.1649, batch acc 0.9508
15:30:00.349   Training iter 400, batch loss 0.1511, batch acc 0.9542
15:30:00.880   Training iter 450, batch loss 0.1424, batch acc 0.9578
15:30:01.406   Training iter 500, batch loss 0.1631, batch acc 0.9490
15:30:01.989   Training iter 550, batch loss 0.1563, batch acc 0.9544
15:30:02.530   Training iter 600, batch loss 0.1795, batch acc 0.9480
15:30:02.532 Training @ 457 epoch...
15:30:03.024   Training iter 50, batch loss 0.1581, batch acc 0.9554
15:30:03.537   Training iter 100, batch loss 0.1508, batch acc 0.9544
15:30:04.046   Training iter 150, batch loss 0.1704, batch acc 0.9498
15:30:04.527   Training iter 200, batch loss 0.1569, batch acc 0.9522
15:30:05.020   Training iter 250, batch loss 0.1594, batch acc 0.9510
15:30:05.528   Training iter 300, batch loss 0.1538, batch acc 0.9570
15:30:06.036   Training iter 350, batch loss 0.1694, batch acc 0.9494
15:30:06.521   Training iter 400, batch loss 0.1581, batch acc 0.9524
15:30:07.035   Training iter 450, batch loss 0.1602, batch acc 0.9482
15:30:07.571   Training iter 500, batch loss 0.1643, batch acc 0.9530
15:30:08.111   Training iter 550, batch loss 0.1580, batch acc 0.9526
15:30:08.692   Training iter 600, batch loss 0.1523, batch acc 0.9562
15:30:08.694 Training @ 458 epoch...
15:30:09.267   Training iter 50, batch loss 0.1484, batch acc 0.9554
15:30:09.824   Training iter 100, batch loss 0.1487, batch acc 0.9544
15:30:10.388   Training iter 150, batch loss 0.1602, batch acc 0.9540
15:30:10.951   Training iter 200, batch loss 0.1425, batch acc 0.9600
15:30:11.514   Training iter 250, batch loss 0.1784, batch acc 0.9456
15:30:12.047   Training iter 300, batch loss 0.1475, batch acc 0.9544
15:30:12.584   Training iter 350, batch loss 0.1726, batch acc 0.9500
15:30:13.094   Training iter 400, batch loss 0.1664, batch acc 0.9484
15:30:13.561   Training iter 450, batch loss 0.1638, batch acc 0.9500
15:30:14.048   Training iter 500, batch loss 0.1680, batch acc 0.9514
15:30:14.525   Training iter 550, batch loss 0.1499, batch acc 0.9522
15:30:14.987   Training iter 600, batch loss 0.1574, batch acc 0.9544
15:30:14.989 Training @ 459 epoch...
15:30:15.470   Training iter 50, batch loss 0.1586, batch acc 0.9502
15:30:15.941   Training iter 100, batch loss 0.1645, batch acc 0.9462
15:30:16.424   Training iter 150, batch loss 0.1675, batch acc 0.9484
15:30:16.965   Training iter 200, batch loss 0.1631, batch acc 0.9524
15:30:17.543   Training iter 250, batch loss 0.1639, batch acc 0.9514
15:30:18.132   Training iter 300, batch loss 0.1576, batch acc 0.9496
15:30:18.671   Training iter 350, batch loss 0.1695, batch acc 0.9506
15:30:19.180   Training iter 400, batch loss 0.1668, batch acc 0.9498
15:30:19.723   Training iter 450, batch loss 0.1514, batch acc 0.9556
15:30:20.285   Training iter 500, batch loss 0.1539, batch acc 0.9576
15:30:20.845   Training iter 550, batch loss 0.1425, batch acc 0.9554
15:30:21.427   Training iter 600, batch loss 0.1542, batch acc 0.9508
15:30:21.429 Training @ 460 epoch...
15:30:22.013   Training iter 50, batch loss 0.1452, batch acc 0.9524
15:30:22.597   Training iter 100, batch loss 0.1463, batch acc 0.9570
15:30:23.184   Training iter 150, batch loss 0.1620, batch acc 0.9506
15:30:23.744   Training iter 200, batch loss 0.1582, batch acc 0.9530
15:30:24.300   Training iter 250, batch loss 0.1437, batch acc 0.9564
15:30:24.888   Training iter 300, batch loss 0.1766, batch acc 0.9480
15:30:25.478   Training iter 350, batch loss 0.1643, batch acc 0.9506
15:30:26.029   Training iter 400, batch loss 0.1871, batch acc 0.9424
15:30:26.602   Training iter 450, batch loss 0.1578, batch acc 0.9530
15:30:27.186   Training iter 500, batch loss 0.1638, batch acc 0.9486
15:30:27.764   Training iter 550, batch loss 0.1558, batch acc 0.9514
15:30:28.348   Training iter 600, batch loss 0.1589, batch acc 0.9488
15:30:28.350 Testing @ 460 epoch...
15:30:28.401     Testing, total mean loss 0.23102, total acc 0.93290
15:30:28.401 Training @ 461 epoch...
15:30:28.984   Training iter 50, batch loss 0.1549, batch acc 0.9530
15:30:29.580   Training iter 100, batch loss 0.1555, batch acc 0.9506
15:30:30.165   Training iter 150, batch loss 0.1590, batch acc 0.9540
15:30:30.746   Training iter 200, batch loss 0.1504, batch acc 0.9566
15:30:31.309   Training iter 250, batch loss 0.1628, batch acc 0.9510
15:30:31.862   Training iter 300, batch loss 0.1610, batch acc 0.9542
15:30:32.421   Training iter 350, batch loss 0.1557, batch acc 0.9526
15:30:32.978   Training iter 400, batch loss 0.1617, batch acc 0.9534
15:30:33.536   Training iter 450, batch loss 0.1634, batch acc 0.9494
15:30:34.098   Training iter 500, batch loss 0.1660, batch acc 0.9500
15:30:34.658   Training iter 550, batch loss 0.1454, batch acc 0.9570
15:30:35.211   Training iter 600, batch loss 0.1524, batch acc 0.9538
15:30:35.213 Training @ 462 epoch...
15:30:35.796   Training iter 50, batch loss 0.1539, batch acc 0.9542
15:30:36.357   Training iter 100, batch loss 0.1496, batch acc 0.9602
15:30:36.918   Training iter 150, batch loss 0.1670, batch acc 0.9516
15:30:37.494   Training iter 200, batch loss 0.1625, batch acc 0.9494
15:30:38.066   Training iter 250, batch loss 0.1572, batch acc 0.9514
15:30:38.640   Training iter 300, batch loss 0.1455, batch acc 0.9570
15:30:39.213   Training iter 350, batch loss 0.1591, batch acc 0.9544
15:30:39.796   Training iter 400, batch loss 0.1659, batch acc 0.9444
15:30:40.388   Training iter 450, batch loss 0.1695, batch acc 0.9524
15:30:40.981   Training iter 500, batch loss 0.1520, batch acc 0.9552
15:30:41.575   Training iter 550, batch loss 0.1660, batch acc 0.9504
15:30:42.167   Training iter 600, batch loss 0.1600, batch acc 0.9498
15:30:42.169 Training @ 463 epoch...
15:30:42.760   Training iter 50, batch loss 0.1564, batch acc 0.9512
15:30:43.345   Training iter 100, batch loss 0.1555, batch acc 0.9518
15:30:43.932   Training iter 150, batch loss 0.1627, batch acc 0.9484
15:30:44.509   Training iter 200, batch loss 0.1570, batch acc 0.9580
15:30:45.067   Training iter 250, batch loss 0.1804, batch acc 0.9494
15:30:45.612   Training iter 300, batch loss 0.1470, batch acc 0.9554
15:30:46.177   Training iter 350, batch loss 0.1509, batch acc 0.9544
15:30:46.688   Training iter 400, batch loss 0.1635, batch acc 0.9492
15:30:47.206   Training iter 450, batch loss 0.1606, batch acc 0.9544
15:30:47.727   Training iter 500, batch loss 0.1597, batch acc 0.9530
15:30:48.284   Training iter 550, batch loss 0.1537, batch acc 0.9548
15:30:48.828   Training iter 600, batch loss 0.1514, batch acc 0.9550
15:30:48.830 Training @ 464 epoch...
15:30:49.358   Training iter 50, batch loss 0.1507, batch acc 0.9542
15:30:49.842   Training iter 100, batch loss 0.1480, batch acc 0.9554
15:30:50.322   Training iter 150, batch loss 0.1449, batch acc 0.9570
15:30:50.800   Training iter 200, batch loss 0.1539, batch acc 0.9532
15:30:51.283   Training iter 250, batch loss 0.1644, batch acc 0.9528
15:30:51.758   Training iter 300, batch loss 0.1558, batch acc 0.9528
15:30:52.272   Training iter 350, batch loss 0.1591, batch acc 0.9556
15:30:52.784   Training iter 400, batch loss 0.1559, batch acc 0.9528
15:30:53.292   Training iter 450, batch loss 0.1850, batch acc 0.9460
15:30:53.775   Training iter 500, batch loss 0.1526, batch acc 0.9540
15:30:54.262   Training iter 550, batch loss 0.1650, batch acc 0.9512
15:30:54.769   Training iter 600, batch loss 0.1657, batch acc 0.9514
15:30:54.771 Training @ 465 epoch...
15:30:55.322   Training iter 50, batch loss 0.1442, batch acc 0.9574
15:30:55.839   Training iter 100, batch loss 0.1631, batch acc 0.9512
15:30:56.362   Training iter 150, batch loss 0.1603, batch acc 0.9514
15:30:56.917   Training iter 200, batch loss 0.1591, batch acc 0.9522
15:30:57.501   Training iter 250, batch loss 0.1529, batch acc 0.9514
15:30:58.061   Training iter 300, batch loss 0.1595, batch acc 0.9512
15:30:58.727   Training iter 350, batch loss 0.1559, batch acc 0.9528
15:30:59.427   Training iter 400, batch loss 0.1555, batch acc 0.9538
15:31:00.096   Training iter 450, batch loss 0.1666, batch acc 0.9498
15:31:00.761   Training iter 500, batch loss 0.1732, batch acc 0.9492
15:31:01.387   Training iter 550, batch loss 0.1727, batch acc 0.9476
15:31:02.131   Training iter 600, batch loss 0.1521, batch acc 0.9530
15:31:02.134 Testing @ 465 epoch...
15:31:02.201     Testing, total mean loss 0.21115, total acc 0.93890
15:31:02.201 Training @ 466 epoch...
15:31:02.962   Training iter 50, batch loss 0.1598, batch acc 0.9500
15:31:03.724   Training iter 100, batch loss 0.1523, batch acc 0.9540
15:31:04.427   Training iter 150, batch loss 0.1602, batch acc 0.9492
15:31:05.063   Training iter 200, batch loss 0.1588, batch acc 0.9522
15:31:05.709   Training iter 250, batch loss 0.1625, batch acc 0.9530
15:31:06.262   Training iter 300, batch loss 0.1554, batch acc 0.9534
15:31:06.794   Training iter 350, batch loss 0.1583, batch acc 0.9520
15:31:07.330   Training iter 400, batch loss 0.1702, batch acc 0.9488
15:31:07.860   Training iter 450, batch loss 0.1408, batch acc 0.9592
15:31:08.351   Training iter 500, batch loss 0.1791, batch acc 0.9460
15:31:08.821   Training iter 550, batch loss 0.1695, batch acc 0.9498
15:31:09.303   Training iter 600, batch loss 0.1474, batch acc 0.9562
15:31:09.305 Training @ 467 epoch...
15:31:09.785   Training iter 50, batch loss 0.1468, batch acc 0.9534
15:31:10.274   Training iter 100, batch loss 0.1704, batch acc 0.9512
15:31:10.772   Training iter 150, batch loss 0.1475, batch acc 0.9534
15:31:11.285   Training iter 200, batch loss 0.1475, batch acc 0.9576
15:31:11.795   Training iter 250, batch loss 0.1543, batch acc 0.9534
15:31:12.307   Training iter 300, batch loss 0.1561, batch acc 0.9540
15:31:12.819   Training iter 350, batch loss 0.1552, batch acc 0.9520
15:31:13.330   Training iter 400, batch loss 0.1611, batch acc 0.9528
15:31:13.835   Training iter 450, batch loss 0.1793, batch acc 0.9466
15:31:14.341   Training iter 500, batch loss 0.1537, batch acc 0.9516
15:31:14.849   Training iter 550, batch loss 0.1785, batch acc 0.9488
15:31:15.359   Training iter 600, batch loss 0.1738, batch acc 0.9506
15:31:15.361 Training @ 468 epoch...
15:31:15.878   Training iter 50, batch loss 0.1580, batch acc 0.9498
15:31:16.391   Training iter 100, batch loss 0.1414, batch acc 0.9586
15:31:16.902   Training iter 150, batch loss 0.1615, batch acc 0.9486
15:31:17.403   Training iter 200, batch loss 0.1641, batch acc 0.9484
15:31:17.923   Training iter 250, batch loss 0.1522, batch acc 0.9524
15:31:18.440   Training iter 300, batch loss 0.1614, batch acc 0.9540
15:31:18.949   Training iter 350, batch loss 0.1604, batch acc 0.9518
15:31:19.474   Training iter 400, batch loss 0.1686, batch acc 0.9510
15:31:19.998   Training iter 450, batch loss 0.1539, batch acc 0.9548
15:31:20.527   Training iter 500, batch loss 0.1693, batch acc 0.9464
15:31:21.054   Training iter 550, batch loss 0.1680, batch acc 0.9492
15:31:21.567   Training iter 600, batch loss 0.1599, batch acc 0.9516
15:31:21.568 Training @ 469 epoch...
15:31:22.096   Training iter 50, batch loss 0.1535, batch acc 0.9550
15:31:22.621   Training iter 100, batch loss 0.1576, batch acc 0.9500
15:31:23.153   Training iter 150, batch loss 0.1548, batch acc 0.9508
15:31:23.688   Training iter 200, batch loss 0.1661, batch acc 0.9482
15:31:24.220   Training iter 250, batch loss 0.1690, batch acc 0.9494
15:31:24.759   Training iter 300, batch loss 0.1466, batch acc 0.9576
15:31:25.305   Training iter 350, batch loss 0.1668, batch acc 0.9496
15:31:25.835   Training iter 400, batch loss 0.1641, batch acc 0.9530
15:31:26.354   Training iter 450, batch loss 0.1657, batch acc 0.9528
15:31:26.867   Training iter 500, batch loss 0.1631, batch acc 0.9520
15:31:27.391   Training iter 550, batch loss 0.1628, batch acc 0.9492
15:31:27.916   Training iter 600, batch loss 0.1630, batch acc 0.9530
15:31:27.918 Training @ 470 epoch...
15:31:28.443   Training iter 50, batch loss 0.1500, batch acc 0.9542
15:31:28.947   Training iter 100, batch loss 0.1791, batch acc 0.9476
15:31:29.467   Training iter 150, batch loss 0.1736, batch acc 0.9500
15:31:29.987   Training iter 200, batch loss 0.1419, batch acc 0.9594
15:31:30.534   Training iter 250, batch loss 0.1403, batch acc 0.9586
15:31:31.076   Training iter 300, batch loss 0.1552, batch acc 0.9530
15:31:31.606   Training iter 350, batch loss 0.1540, batch acc 0.9536
15:31:32.142   Training iter 400, batch loss 0.1540, batch acc 0.9520
15:31:32.681   Training iter 450, batch loss 0.1447, batch acc 0.9526
15:31:33.227   Training iter 500, batch loss 0.1716, batch acc 0.9472
15:31:33.742   Training iter 550, batch loss 0.1736, batch acc 0.9452
15:31:34.284   Training iter 600, batch loss 0.1640, batch acc 0.9524
15:31:34.285 Testing @ 470 epoch...
15:31:34.329     Testing, total mean loss 0.21321, total acc 0.93840
15:31:34.329 Training @ 471 epoch...
15:31:34.861   Training iter 50, batch loss 0.1499, batch acc 0.9580
15:31:35.390   Training iter 100, batch loss 0.1648, batch acc 0.9494
15:31:35.906   Training iter 150, batch loss 0.1455, batch acc 0.9592
15:31:36.435   Training iter 200, batch loss 0.1632, batch acc 0.9558
15:31:36.964   Training iter 250, batch loss 0.1648, batch acc 0.9496
15:31:37.499   Training iter 300, batch loss 0.1735, batch acc 0.9508
15:31:38.032   Training iter 350, batch loss 0.1664, batch acc 0.9510
15:31:38.569   Training iter 400, batch loss 0.1608, batch acc 0.9520
15:31:39.099   Training iter 450, batch loss 0.1331, batch acc 0.9564
15:31:39.637   Training iter 500, batch loss 0.1472, batch acc 0.9550
15:31:40.264   Training iter 550, batch loss 0.1508, batch acc 0.9522
15:31:40.773   Training iter 600, batch loss 0.1706, batch acc 0.9504
15:31:40.775 Training @ 472 epoch...
15:31:41.288   Training iter 50, batch loss 0.1509, batch acc 0.9558
15:31:41.782   Training iter 100, batch loss 0.1583, batch acc 0.9540
15:31:42.277   Training iter 150, batch loss 0.1355, batch acc 0.9574
15:31:42.772   Training iter 200, batch loss 0.1561, batch acc 0.9522
15:31:43.278   Training iter 250, batch loss 0.1552, batch acc 0.9528
15:31:43.783   Training iter 300, batch loss 0.1744, batch acc 0.9464
15:31:44.288   Training iter 350, batch loss 0.1626, batch acc 0.9522
15:31:44.803   Training iter 400, batch loss 0.1607, batch acc 0.9562
15:31:45.312   Training iter 450, batch loss 0.1583, batch acc 0.9520
15:31:45.824   Training iter 500, batch loss 0.1592, batch acc 0.9522
15:31:46.336   Training iter 550, batch loss 0.1544, batch acc 0.9524
15:31:46.854   Training iter 600, batch loss 0.1872, batch acc 0.9476
15:31:46.856 Training @ 473 epoch...
15:31:47.377   Training iter 50, batch loss 0.1724, batch acc 0.9492
15:31:47.882   Training iter 100, batch loss 0.1558, batch acc 0.9542
15:31:48.400   Training iter 150, batch loss 0.1416, batch acc 0.9522
15:31:48.914   Training iter 200, batch loss 0.1538, batch acc 0.9554
15:31:49.430   Training iter 250, batch loss 0.1579, batch acc 0.9516
15:31:49.948   Training iter 300, batch loss 0.1579, batch acc 0.9562
15:31:50.463   Training iter 350, batch loss 0.1530, batch acc 0.9564
15:31:50.991   Training iter 400, batch loss 0.1552, batch acc 0.9476
15:31:51.512   Training iter 450, batch loss 0.1688, batch acc 0.9542
15:31:52.035   Training iter 500, batch loss 0.1714, batch acc 0.9492
15:31:52.559   Training iter 550, batch loss 0.1729, batch acc 0.9482
15:31:53.089   Training iter 600, batch loss 0.1548, batch acc 0.9512
15:31:53.090 Training @ 474 epoch...
15:31:53.624   Training iter 50, batch loss 0.1445, batch acc 0.9518
15:31:54.146   Training iter 100, batch loss 0.1468, batch acc 0.9544
15:31:54.677   Training iter 150, batch loss 0.1556, batch acc 0.9526
15:31:55.202   Training iter 200, batch loss 0.1570, batch acc 0.9540
15:31:55.730   Training iter 250, batch loss 0.1835, batch acc 0.9492
15:31:56.253   Training iter 300, batch loss 0.1635, batch acc 0.9506
15:31:56.778   Training iter 350, batch loss 0.1733, batch acc 0.9488
15:31:57.307   Training iter 400, batch loss 0.1611, batch acc 0.9504
15:31:57.844   Training iter 450, batch loss 0.1585, batch acc 0.9516
15:31:58.363   Training iter 500, batch loss 0.1583, batch acc 0.9528
15:31:58.879   Training iter 550, batch loss 0.1527, batch acc 0.9562
15:31:59.423   Training iter 600, batch loss 0.1520, batch acc 0.9526
15:31:59.425 Training @ 475 epoch...
15:31:59.977   Training iter 50, batch loss 0.1603, batch acc 0.9528
15:32:00.542   Training iter 100, batch loss 0.1678, batch acc 0.9480
15:32:01.092   Training iter 150, batch loss 0.1465, batch acc 0.9542
15:32:01.658   Training iter 200, batch loss 0.1511, batch acc 0.9542
15:32:02.244   Training iter 250, batch loss 0.1454, batch acc 0.9574
15:32:02.820   Training iter 300, batch loss 0.1673, batch acc 0.9538
15:32:03.390   Training iter 350, batch loss 0.1489, batch acc 0.9550
15:32:03.963   Training iter 400, batch loss 0.1648, batch acc 0.9472
15:32:04.535   Training iter 450, batch loss 0.1595, batch acc 0.9522
15:32:05.103   Training iter 500, batch loss 0.1508, batch acc 0.9548
15:32:05.647   Training iter 550, batch loss 0.1807, batch acc 0.9504
15:32:06.195   Training iter 600, batch loss 0.1730, batch acc 0.9498
15:32:06.197 Testing @ 475 epoch...
15:32:06.240     Testing, total mean loss 0.21319, total acc 0.93800
15:32:06.240 Training @ 476 epoch...
15:32:06.766   Training iter 50, batch loss 0.1507, batch acc 0.9562
15:32:07.292   Training iter 100, batch loss 0.1491, batch acc 0.9538
15:32:07.813   Training iter 150, batch loss 0.1786, batch acc 0.9496
15:32:08.350   Training iter 200, batch loss 0.1573, batch acc 0.9510
15:32:08.896   Training iter 250, batch loss 0.1611, batch acc 0.9506
15:32:09.420   Training iter 300, batch loss 0.1632, batch acc 0.9504
15:32:09.937   Training iter 350, batch loss 0.1696, batch acc 0.9484
15:32:10.461   Training iter 400, batch loss 0.1695, batch acc 0.9530
15:32:10.968   Training iter 450, batch loss 0.1596, batch acc 0.9528
15:32:11.482   Training iter 500, batch loss 0.1618, batch acc 0.9552
15:32:12.005   Training iter 550, batch loss 0.1490, batch acc 0.9522
15:32:12.528   Training iter 600, batch loss 0.1604, batch acc 0.9500
15:32:12.530 Training @ 477 epoch...
15:32:13.049   Training iter 50, batch loss 0.1467, batch acc 0.9556
15:32:13.570   Training iter 100, batch loss 0.1553, batch acc 0.9526
15:32:14.106   Training iter 150, batch loss 0.1681, batch acc 0.9546
15:32:14.627   Training iter 200, batch loss 0.1603, batch acc 0.9560
15:32:15.172   Training iter 250, batch loss 0.1596, batch acc 0.9524
15:32:15.727   Training iter 300, batch loss 0.1515, batch acc 0.9542
15:32:16.282   Training iter 350, batch loss 0.1584, batch acc 0.9526
15:32:16.823   Training iter 400, batch loss 0.1464, batch acc 0.9562
15:32:17.367   Training iter 450, batch loss 0.1499, batch acc 0.9536
15:32:17.913   Training iter 500, batch loss 0.1534, batch acc 0.9532
15:32:18.459   Training iter 550, batch loss 0.1666, batch acc 0.9514
15:32:18.997   Training iter 600, batch loss 0.1839, batch acc 0.9476
15:32:18.999 Training @ 478 epoch...
15:32:19.537   Training iter 50, batch loss 0.1461, batch acc 0.9564
15:32:20.055   Training iter 100, batch loss 0.1513, batch acc 0.9564
15:32:20.563   Training iter 150, batch loss 0.1499, batch acc 0.9560
15:32:21.080   Training iter 200, batch loss 0.1639, batch acc 0.9506
15:32:21.586   Training iter 250, batch loss 0.1721, batch acc 0.9520
15:32:22.096   Training iter 300, batch loss 0.1501, batch acc 0.9546
15:32:22.602   Training iter 350, batch loss 0.1617, batch acc 0.9512
15:32:23.115   Training iter 400, batch loss 0.1493, batch acc 0.9528
15:32:23.658   Training iter 450, batch loss 0.1542, batch acc 0.9534
15:32:24.173   Training iter 500, batch loss 0.1746, batch acc 0.9472
15:32:24.686   Training iter 550, batch loss 0.1605, batch acc 0.9554
15:32:25.214   Training iter 600, batch loss 0.1626, batch acc 0.9530
15:32:25.216 Training @ 479 epoch...
15:32:25.775   Training iter 50, batch loss 0.1501, batch acc 0.9572
15:32:26.310   Training iter 100, batch loss 0.1581, batch acc 0.9536
15:32:26.844   Training iter 150, batch loss 0.1654, batch acc 0.9478
15:32:27.373   Training iter 200, batch loss 0.1421, batch acc 0.9586
15:32:27.886   Training iter 250, batch loss 0.1504, batch acc 0.9540
15:32:28.391   Training iter 300, batch loss 0.1691, batch acc 0.9482
15:32:28.890   Training iter 350, batch loss 0.1684, batch acc 0.9536
15:32:29.403   Training iter 400, batch loss 0.1749, batch acc 0.9482
15:32:29.933   Training iter 450, batch loss 0.1498, batch acc 0.9546
15:32:30.451   Training iter 500, batch loss 0.1611, batch acc 0.9522
15:32:30.945   Training iter 550, batch loss 0.1546, batch acc 0.9558
15:32:31.460   Training iter 600, batch loss 0.1653, batch acc 0.9512
15:32:31.462 Training @ 480 epoch...
15:32:32.012   Training iter 50, batch loss 0.1511, batch acc 0.9528
15:32:32.552   Training iter 100, batch loss 0.1440, batch acc 0.9540
15:32:33.088   Training iter 150, batch loss 0.1755, batch acc 0.9478
15:32:33.626   Training iter 200, batch loss 0.1734, batch acc 0.9506
15:32:34.162   Training iter 250, batch loss 0.1403, batch acc 0.9568
15:32:34.691   Training iter 300, batch loss 0.1653, batch acc 0.9488
15:32:35.222   Training iter 350, batch loss 0.1603, batch acc 0.9520
15:32:35.753   Training iter 400, batch loss 0.1556, batch acc 0.9526
15:32:36.284   Training iter 450, batch loss 0.1725, batch acc 0.9484
15:32:36.809   Training iter 500, batch loss 0.1636, batch acc 0.9524
15:32:37.322   Training iter 550, batch loss 0.1560, batch acc 0.9538
15:32:37.805   Training iter 600, batch loss 0.1653, batch acc 0.9526
15:32:37.807 Testing @ 480 epoch...
15:32:37.851     Testing, total mean loss 0.22330, total acc 0.93720
15:32:37.851 Training @ 481 epoch...
15:32:38.338   Training iter 50, batch loss 0.1398, batch acc 0.9638
15:32:38.821   Training iter 100, batch loss 0.1454, batch acc 0.9620
15:32:39.272   Training iter 150, batch loss 0.1607, batch acc 0.9542
15:32:39.733   Training iter 200, batch loss 0.1507, batch acc 0.9546
15:32:40.252   Training iter 250, batch loss 0.1639, batch acc 0.9514
15:32:40.819   Training iter 300, batch loss 0.1447, batch acc 0.9538
15:32:41.387   Training iter 350, batch loss 0.1602, batch acc 0.9484
15:32:41.931   Training iter 400, batch loss 0.1629, batch acc 0.9514
15:32:42.447   Training iter 450, batch loss 0.1730, batch acc 0.9472
15:32:42.964   Training iter 500, batch loss 0.1514, batch acc 0.9516
15:32:43.485   Training iter 550, batch loss 0.1598, batch acc 0.9550
15:32:44.005   Training iter 600, batch loss 0.1828, batch acc 0.9448
15:32:44.006 Training @ 482 epoch...
15:32:44.538   Training iter 50, batch loss 0.1544, batch acc 0.9528
15:32:45.051   Training iter 100, batch loss 0.1482, batch acc 0.9528
15:32:45.561   Training iter 150, batch loss 0.1703, batch acc 0.9506
15:32:46.070   Training iter 200, batch loss 0.1724, batch acc 0.9496
15:32:46.580   Training iter 250, batch loss 0.1517, batch acc 0.9542
15:32:47.105   Training iter 300, batch loss 0.1789, batch acc 0.9454
15:32:47.640   Training iter 350, batch loss 0.1490, batch acc 0.9540
15:32:48.188   Training iter 400, batch loss 0.1727, batch acc 0.9476
15:32:48.720   Training iter 450, batch loss 0.1403, batch acc 0.9586
15:32:49.254   Training iter 500, batch loss 0.1683, batch acc 0.9514
15:32:49.790   Training iter 550, batch loss 0.1633, batch acc 0.9508
15:32:50.340   Training iter 600, batch loss 0.1611, batch acc 0.9532
15:32:50.342 Training @ 483 epoch...
15:32:50.889   Training iter 50, batch loss 0.1487, batch acc 0.9580
15:32:51.434   Training iter 100, batch loss 0.1420, batch acc 0.9584
15:32:51.987   Training iter 150, batch loss 0.1497, batch acc 0.9558
15:32:52.548   Training iter 200, batch loss 0.1641, batch acc 0.9520
15:32:53.108   Training iter 250, batch loss 0.1616, batch acc 0.9494
15:32:53.651   Training iter 300, batch loss 0.1580, batch acc 0.9532
15:32:54.190   Training iter 350, batch loss 0.1530, batch acc 0.9544
15:32:54.725   Training iter 400, batch loss 0.1648, batch acc 0.9538
15:32:55.277   Training iter 450, batch loss 0.1675, batch acc 0.9506
15:32:55.812   Training iter 500, batch loss 0.1561, batch acc 0.9516
15:32:56.354   Training iter 550, batch loss 0.1597, batch acc 0.9522
15:32:56.882   Training iter 600, batch loss 0.1738, batch acc 0.9456
15:32:56.884 Training @ 484 epoch...
15:32:57.430   Training iter 50, batch loss 0.1514, batch acc 0.9552
15:32:57.969   Training iter 100, batch loss 0.1707, batch acc 0.9504
15:32:58.506   Training iter 150, batch loss 0.1602, batch acc 0.9514
15:32:59.040   Training iter 200, batch loss 0.1614, batch acc 0.9536
15:32:59.584   Training iter 250, batch loss 0.1463, batch acc 0.9580
15:33:00.132   Training iter 300, batch loss 0.1802, batch acc 0.9490
15:33:00.672   Training iter 350, batch loss 0.1415, batch acc 0.9616
15:33:01.228   Training iter 400, batch loss 0.1565, batch acc 0.9534
15:33:01.757   Training iter 450, batch loss 0.1615, batch acc 0.9506
15:33:02.282   Training iter 500, batch loss 0.1599, batch acc 0.9508
15:33:02.818   Training iter 550, batch loss 0.1646, batch acc 0.9538
15:33:03.368   Training iter 600, batch loss 0.1503, batch acc 0.9524
15:33:03.369 Training @ 485 epoch...
15:33:03.937   Training iter 50, batch loss 0.1615, batch acc 0.9506
15:33:04.479   Training iter 100, batch loss 0.1569, batch acc 0.9504
15:33:04.979   Training iter 150, batch loss 0.1474, batch acc 0.9570
15:33:05.487   Training iter 200, batch loss 0.1601, batch acc 0.9524
15:33:05.994   Training iter 250, batch loss 0.1492, batch acc 0.9580
15:33:06.528   Training iter 300, batch loss 0.1561, batch acc 0.9502
15:33:07.065   Training iter 350, batch loss 0.1676, batch acc 0.9530
15:33:07.599   Training iter 400, batch loss 0.1610, batch acc 0.9506
15:33:08.132   Training iter 450, batch loss 0.1725, batch acc 0.9466
15:33:08.665   Training iter 500, batch loss 0.1557, batch acc 0.9538
15:33:09.211   Training iter 550, batch loss 0.1773, batch acc 0.9474
15:33:09.750   Training iter 600, batch loss 0.1542, batch acc 0.9518
15:33:09.752 Testing @ 485 epoch...
15:33:09.796     Testing, total mean loss 0.21452, total acc 0.93800
15:33:09.796 Training @ 486 epoch...
15:33:10.317   Training iter 50, batch loss 0.1474, batch acc 0.9552
15:33:10.813   Training iter 100, batch loss 0.1419, batch acc 0.9580
15:33:11.305   Training iter 150, batch loss 0.1567, batch acc 0.9520
15:33:11.776   Training iter 200, batch loss 0.1525, batch acc 0.9538
15:33:12.241   Training iter 250, batch loss 0.1631, batch acc 0.9508
15:33:12.703   Training iter 300, batch loss 0.1746, batch acc 0.9538
15:33:13.158   Training iter 350, batch loss 0.1634, batch acc 0.9514
15:33:13.616   Training iter 400, batch loss 0.1567, batch acc 0.9496
15:33:14.091   Training iter 450, batch loss 0.1688, batch acc 0.9496
15:33:14.565   Training iter 500, batch loss 0.1534, batch acc 0.9560
15:33:15.036   Training iter 550, batch loss 0.1573, batch acc 0.9548
15:33:15.509   Training iter 600, batch loss 0.1677, batch acc 0.9464
15:33:15.511 Training @ 487 epoch...
15:33:16.003   Training iter 50, batch loss 0.1632, batch acc 0.9530
15:33:16.487   Training iter 100, batch loss 0.1579, batch acc 0.9532
15:33:16.952   Training iter 150, batch loss 0.1604, batch acc 0.9534
15:33:17.427   Training iter 200, batch loss 0.1636, batch acc 0.9518
15:33:17.899   Training iter 250, batch loss 0.1580, batch acc 0.9556
15:33:18.375   Training iter 300, batch loss 0.1672, batch acc 0.9496
15:33:18.846   Training iter 350, batch loss 0.1647, batch acc 0.9496
15:33:19.323   Training iter 400, batch loss 0.1462, batch acc 0.9566
15:33:19.818   Training iter 450, batch loss 0.1581, batch acc 0.9550
15:33:20.346   Training iter 500, batch loss 0.1548, batch acc 0.9522
15:33:20.881   Training iter 550, batch loss 0.1560, batch acc 0.9538
15:33:21.418   Training iter 600, batch loss 0.1566, batch acc 0.9502
15:33:21.419 Training @ 488 epoch...
15:33:21.954   Training iter 50, batch loss 0.1494, batch acc 0.9564
15:33:22.494   Training iter 100, batch loss 0.1560, batch acc 0.9522
15:33:23.038   Training iter 150, batch loss 0.1411, batch acc 0.9570
15:33:23.570   Training iter 200, batch loss 0.1649, batch acc 0.9492
15:33:24.105   Training iter 250, batch loss 0.1652, batch acc 0.9500
15:33:24.625   Training iter 300, batch loss 0.1524, batch acc 0.9538
15:33:25.148   Training iter 350, batch loss 0.1546, batch acc 0.9558
15:33:25.687   Training iter 400, batch loss 0.1682, batch acc 0.9534
15:33:26.199   Training iter 450, batch loss 0.1651, batch acc 0.9506
15:33:26.689   Training iter 500, batch loss 0.1743, batch acc 0.9496
15:33:27.165   Training iter 550, batch loss 0.1546, batch acc 0.9498
15:33:27.684   Training iter 600, batch loss 0.1753, batch acc 0.9474
15:33:27.685 Training @ 489 epoch...
15:33:28.180   Training iter 50, batch loss 0.1671, batch acc 0.9514
15:33:28.664   Training iter 100, batch loss 0.1407, batch acc 0.9612
15:33:29.161   Training iter 150, batch loss 0.1465, batch acc 0.9544
15:33:29.647   Training iter 200, batch loss 0.1730, batch acc 0.9504
15:33:30.161   Training iter 250, batch loss 0.1603, batch acc 0.9520
15:33:30.677   Training iter 300, batch loss 0.1553, batch acc 0.9552
15:33:31.210   Training iter 350, batch loss 0.1772, batch acc 0.9478
15:33:31.784   Training iter 400, batch loss 0.1663, batch acc 0.9480
15:33:32.362   Training iter 450, batch loss 0.1491, batch acc 0.9574
15:33:32.932   Training iter 500, batch loss 0.1560, batch acc 0.9516
15:33:33.436   Training iter 550, batch loss 0.1525, batch acc 0.9572
15:33:33.944   Training iter 600, batch loss 0.1653, batch acc 0.9510
15:33:33.946 Training @ 490 epoch...
15:33:34.444   Training iter 50, batch loss 0.1493, batch acc 0.9522
15:33:34.923   Training iter 100, batch loss 0.1472, batch acc 0.9596
15:33:35.399   Training iter 150, batch loss 0.1368, batch acc 0.9574
15:33:35.887   Training iter 200, batch loss 0.1690, batch acc 0.9502
15:33:36.370   Training iter 250, batch loss 0.1654, batch acc 0.9520
15:33:36.852   Training iter 300, batch loss 0.1557, batch acc 0.9530
15:33:37.334   Training iter 350, batch loss 0.1647, batch acc 0.9506
15:33:37.843   Training iter 400, batch loss 0.1672, batch acc 0.9480
15:33:38.347   Training iter 450, batch loss 0.1622, batch acc 0.9530
15:33:38.850   Training iter 500, batch loss 0.1585, batch acc 0.9532
15:33:39.360   Training iter 550, batch loss 0.1682, batch acc 0.9518
15:33:39.833   Training iter 600, batch loss 0.1790, batch acc 0.9460
15:33:39.835 Testing @ 490 epoch...
15:33:39.878     Testing, total mean loss 0.23151, total acc 0.93160
15:33:39.878 Training @ 491 epoch...
15:33:40.352   Training iter 50, batch loss 0.1811, batch acc 0.9466
15:33:40.799   Training iter 100, batch loss 0.1567, batch acc 0.9556
15:33:41.258   Training iter 150, batch loss 0.1530, batch acc 0.9530
15:33:41.748   Training iter 200, batch loss 0.1616, batch acc 0.9524
15:33:42.261   Training iter 250, batch loss 0.1610, batch acc 0.9494
15:33:42.733   Training iter 300, batch loss 0.1419, batch acc 0.9560
15:33:43.243   Training iter 350, batch loss 0.1704, batch acc 0.9502
15:33:43.753   Training iter 400, batch loss 0.1658, batch acc 0.9496
15:33:44.266   Training iter 450, batch loss 0.1642, batch acc 0.9466
15:33:44.770   Training iter 500, batch loss 0.1628, batch acc 0.9502
15:33:45.276   Training iter 550, batch loss 0.1581, batch acc 0.9516
15:33:45.795   Training iter 600, batch loss 0.1562, batch acc 0.9510
15:33:45.797 Training @ 492 epoch...
15:33:46.314   Training iter 50, batch loss 0.1421, batch acc 0.9566
15:33:46.842   Training iter 100, batch loss 0.1756, batch acc 0.9486
15:33:47.318   Training iter 150, batch loss 0.1700, batch acc 0.9488
15:33:47.790   Training iter 200, batch loss 0.1607, batch acc 0.9508
15:33:48.272   Training iter 250, batch loss 0.1712, batch acc 0.9460
15:33:48.735   Training iter 300, batch loss 0.1583, batch acc 0.9534
15:33:49.214   Training iter 350, batch loss 0.1501, batch acc 0.9516
15:33:49.678   Training iter 400, batch loss 0.1555, batch acc 0.9542
15:33:50.153   Training iter 450, batch loss 0.1591, batch acc 0.9512
15:33:50.622   Training iter 500, batch loss 0.1471, batch acc 0.9550
15:33:51.079   Training iter 550, batch loss 0.1530, batch acc 0.9560
15:33:51.551   Training iter 600, batch loss 0.1597, batch acc 0.9542
15:33:51.553 Training @ 493 epoch...
15:33:52.022   Training iter 50, batch loss 0.1596, batch acc 0.9536
15:33:52.490   Training iter 100, batch loss 0.1633, batch acc 0.9508
15:33:52.956   Training iter 150, batch loss 0.1383, batch acc 0.9594
15:33:53.432   Training iter 200, batch loss 0.1623, batch acc 0.9478
15:33:53.907   Training iter 250, batch loss 0.1580, batch acc 0.9504
15:33:54.399   Training iter 300, batch loss 0.1689, batch acc 0.9500
15:33:54.889   Training iter 350, batch loss 0.1629, batch acc 0.9538
15:33:55.388   Training iter 400, batch loss 0.1620, batch acc 0.9512
15:33:55.912   Training iter 450, batch loss 0.1652, batch acc 0.9528
15:33:56.442   Training iter 500, batch loss 0.1447, batch acc 0.9572
15:33:56.966   Training iter 550, batch loss 0.1643, batch acc 0.9528
15:33:57.502   Training iter 600, batch loss 0.1593, batch acc 0.9482
15:33:57.504 Training @ 494 epoch...
15:33:58.050   Training iter 50, batch loss 0.1572, batch acc 0.9550
15:33:58.579   Training iter 100, batch loss 0.1568, batch acc 0.9508
15:33:59.077   Training iter 150, batch loss 0.1556, batch acc 0.9532
15:33:59.570   Training iter 200, batch loss 0.1569, batch acc 0.9578
15:34:00.071   Training iter 250, batch loss 0.1517, batch acc 0.9560
15:34:00.608   Training iter 300, batch loss 0.1645, batch acc 0.9506
15:34:01.139   Training iter 350, batch loss 0.1550, batch acc 0.9522
15:34:01.699   Training iter 400, batch loss 0.1499, batch acc 0.9570
15:34:02.278   Training iter 450, batch loss 0.1610, batch acc 0.9522
15:34:02.858   Training iter 500, batch loss 0.1518, batch acc 0.9554
15:34:03.448   Training iter 550, batch loss 0.1662, batch acc 0.9524
15:34:04.036   Training iter 600, batch loss 0.1614, batch acc 0.9534
15:34:04.038 Training @ 495 epoch...
15:34:04.609   Training iter 50, batch loss 0.1600, batch acc 0.9504
15:34:05.179   Training iter 100, batch loss 0.1563, batch acc 0.9532
15:34:05.737   Training iter 150, batch loss 0.1503, batch acc 0.9548
15:34:06.294   Training iter 200, batch loss 0.1720, batch acc 0.9490
15:34:06.833   Training iter 250, batch loss 0.1568, batch acc 0.9568
15:34:07.355   Training iter 300, batch loss 0.1454, batch acc 0.9570
15:34:07.889   Training iter 350, batch loss 0.1588, batch acc 0.9512
15:34:08.416   Training iter 400, batch loss 0.1478, batch acc 0.9540
15:34:08.944   Training iter 450, batch loss 0.1593, batch acc 0.9538
15:34:09.477   Training iter 500, batch loss 0.1602, batch acc 0.9526
15:34:10.008   Training iter 550, batch loss 0.1588, batch acc 0.9516
15:34:10.549   Training iter 600, batch loss 0.1811, batch acc 0.9470
15:34:10.551 Testing @ 495 epoch...
15:34:10.595     Testing, total mean loss 0.22422, total acc 0.93730
15:34:10.595 Training @ 496 epoch...
15:34:11.130   Training iter 50, batch loss 0.1548, batch acc 0.9554
15:34:11.659   Training iter 100, batch loss 0.1643, batch acc 0.9486
15:34:12.189   Training iter 150, batch loss 0.1654, batch acc 0.9534
15:34:12.715   Training iter 200, batch loss 0.1483, batch acc 0.9536
15:34:13.231   Training iter 250, batch loss 0.1548, batch acc 0.9504
15:34:13.738   Training iter 300, batch loss 0.1711, batch acc 0.9486
15:34:14.222   Training iter 350, batch loss 0.1581, batch acc 0.9500
15:34:14.689   Training iter 400, batch loss 0.1641, batch acc 0.9516
15:34:15.168   Training iter 450, batch loss 0.1741, batch acc 0.9494
15:34:15.662   Training iter 500, batch loss 0.1490, batch acc 0.9592
15:34:16.142   Training iter 550, batch loss 0.1655, batch acc 0.9510
15:34:16.625   Training iter 600, batch loss 0.1457, batch acc 0.9610
15:34:16.626 Training @ 497 epoch...
15:34:17.142   Training iter 50, batch loss 0.1774, batch acc 0.9438
15:34:17.653   Training iter 100, batch loss 0.1482, batch acc 0.9502
15:34:18.175   Training iter 150, batch loss 0.1532, batch acc 0.9560
15:34:18.686   Training iter 200, batch loss 0.1579, batch acc 0.9490
15:34:19.192   Training iter 250, batch loss 0.1702, batch acc 0.9516
15:34:19.680   Training iter 300, batch loss 0.1601, batch acc 0.9512
15:34:20.172   Training iter 350, batch loss 0.1583, batch acc 0.9534
15:34:20.652   Training iter 400, batch loss 0.1435, batch acc 0.9562
15:34:21.114   Training iter 450, batch loss 0.1689, batch acc 0.9502
15:34:21.590   Training iter 500, batch loss 0.1655, batch acc 0.9498
15:34:22.108   Training iter 550, batch loss 0.1494, batch acc 0.9522
15:34:22.629   Training iter 600, batch loss 0.1479, batch acc 0.9566
15:34:22.631 Training @ 498 epoch...
15:34:23.162   Training iter 50, batch loss 0.1328, batch acc 0.9600
15:34:23.693   Training iter 100, batch loss 0.1694, batch acc 0.9544
15:34:24.215   Training iter 150, batch loss 0.1771, batch acc 0.9446
15:34:24.746   Training iter 200, batch loss 0.1479, batch acc 0.9578
15:34:25.295   Training iter 250, batch loss 0.1618, batch acc 0.9544
15:34:25.820   Training iter 300, batch loss 0.1793, batch acc 0.9474
15:34:26.343   Training iter 350, batch loss 0.1634, batch acc 0.9494
15:34:26.834   Training iter 400, batch loss 0.1607, batch acc 0.9524
15:34:27.376   Training iter 450, batch loss 0.1472, batch acc 0.9566
15:34:27.960   Training iter 500, batch loss 0.1453, batch acc 0.9524
15:34:28.551   Training iter 550, batch loss 0.1562, batch acc 0.9506
15:34:29.115   Training iter 600, batch loss 0.1699, batch acc 0.9462
15:34:29.117 Training @ 499 epoch...
15:34:29.663   Training iter 50, batch loss 0.1610, batch acc 0.9528
15:34:30.202   Training iter 100, batch loss 0.1706, batch acc 0.9504
15:34:30.747   Training iter 150, batch loss 0.1600, batch acc 0.9520
15:34:31.296   Training iter 200, batch loss 0.1694, batch acc 0.9504
15:34:31.849   Training iter 250, batch loss 0.1683, batch acc 0.9558
15:34:32.387   Training iter 300, batch loss 0.1517, batch acc 0.9568
15:34:32.912   Training iter 350, batch loss 0.1453, batch acc 0.9554
15:34:33.431   Training iter 400, batch loss 0.1534, batch acc 0.9574
15:34:33.950   Training iter 450, batch loss 0.1631, batch acc 0.9502
15:34:34.484   Training iter 500, batch loss 0.1489, batch acc 0.9534
15:34:35.015   Training iter 550, batch loss 0.1525, batch acc 0.9556
15:34:35.535   Training iter 600, batch loss 0.1654, batch acc 0.9470
======================================================
15:34:35.536 Testing @ final epoch...
15:34:35.585     Testing, total mean loss 0.21292, total acc 0.93870
training time: 3142 seconds
