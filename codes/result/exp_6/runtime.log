======================================================
learning_rate: 0.1
weight_decay: 0.0001
momentum: 0.1
batch_size: 100
max_epoch: 500
disp_freq: 50
test_epoch: 5
plot_epoch: 100
network: Lin-784-10 Sigm Lin-10-10 Sigm
loss: Euclidean
result dir: ./result/exp_6
======================================================
13:49:51.411 Training @ 0 epoch...
13:49:51.961   Training iter 50, batch loss 1.2362, batch acc 0.1138
13:49:52.490   Training iter 100, batch loss 1.2176, batch acc 0.1110
13:49:53.022   Training iter 150, batch loss 1.1993, batch acc 0.1048
13:49:53.546   Training iter 200, batch loss 1.1810, batch acc 0.1084
13:49:54.045   Training iter 250, batch loss 1.1627, batch acc 0.1112
13:49:54.563   Training iter 300, batch loss 1.1444, batch acc 0.1152
13:49:55.094   Training iter 350, batch loss 1.1260, batch acc 0.1144
13:49:55.621   Training iter 400, batch loss 1.1075, batch acc 0.1134
13:49:56.085   Training iter 450, batch loss 1.0888, batch acc 0.1114
13:49:56.546   Training iter 500, batch loss 1.0697, batch acc 0.1238
13:49:57.019   Training iter 550, batch loss 1.0506, batch acc 0.1134
13:49:57.495   Training iter 600, batch loss 1.0313, batch acc 0.1076
13:49:57.497 Testing @ 0 epoch...
13:49:57.536     Testing, total mean loss 1.02124, total acc 0.11350
13:49:57.536 Plot @ 0 epoch...
13:49:57.536 Training @ 1 epoch...
13:49:58.034   Training iter 50, batch loss 1.0117, batch acc 0.1142
13:49:58.533   Training iter 100, batch loss 0.9920, batch acc 0.1122
13:49:59.023   Training iter 150, batch loss 0.9720, batch acc 0.1216
13:49:59.502   Training iter 200, batch loss 0.9523, batch acc 0.1112
13:50:00.021   Training iter 250, batch loss 0.9325, batch acc 0.1114
13:50:00.553   Training iter 300, batch loss 0.9128, batch acc 0.1054
13:50:01.088   Training iter 350, batch loss 0.8933, batch acc 0.1116
13:50:01.632   Training iter 400, batch loss 0.8742, batch acc 0.1108
13:50:02.193   Training iter 450, batch loss 0.8554, batch acc 0.1112
13:50:02.765   Training iter 500, batch loss 0.8370, batch acc 0.1106
13:50:03.317   Training iter 550, batch loss 0.8191, batch acc 0.1184
13:50:03.877   Training iter 600, batch loss 0.8020, batch acc 0.1098
13:50:03.879 Training @ 2 epoch...
13:50:04.423   Training iter 50, batch loss 0.7854, batch acc 0.1136
13:50:04.950   Training iter 100, batch loss 0.7693, batch acc 0.1144
13:50:05.490   Training iter 150, batch loss 0.7542, batch acc 0.1094
13:50:06.022   Training iter 200, batch loss 0.7397, batch acc 0.1074
13:50:06.545   Training iter 250, batch loss 0.7257, batch acc 0.1118
13:50:07.059   Training iter 300, batch loss 0.7125, batch acc 0.1116
13:50:07.542   Training iter 350, batch loss 0.6999, batch acc 0.1134
13:50:08.021   Training iter 400, batch loss 0.6882, batch acc 0.1078
13:50:08.496   Training iter 450, batch loss 0.6768, batch acc 0.1148
13:50:08.959   Training iter 500, batch loss 0.6662, batch acc 0.1068
13:50:09.412   Training iter 550, batch loss 0.6561, batch acc 0.1228
13:50:09.869   Training iter 600, batch loss 0.6467, batch acc 0.1146
13:50:09.871 Training @ 3 epoch...
13:50:10.345   Training iter 50, batch loss 0.6378, batch acc 0.1148
13:50:10.818   Training iter 100, batch loss 0.6293, batch acc 0.1164
13:50:11.286   Training iter 150, batch loss 0.6215, batch acc 0.1112
13:50:11.751   Training iter 200, batch loss 0.6139, batch acc 0.1064
13:50:12.217   Training iter 250, batch loss 0.6067, batch acc 0.1124
13:50:12.712   Training iter 300, batch loss 0.6002, batch acc 0.1084
13:50:13.231   Training iter 350, batch loss 0.5938, batch acc 0.1106
13:50:13.770   Training iter 400, batch loss 0.5878, batch acc 0.1136
13:50:14.309   Training iter 450, batch loss 0.5823, batch acc 0.1096
13:50:14.822   Training iter 500, batch loss 0.5768, batch acc 0.1206
13:50:15.316   Training iter 550, batch loss 0.5718, batch acc 0.1112
13:50:15.829   Training iter 600, batch loss 0.5670, batch acc 0.1132
13:50:15.831 Training @ 4 epoch...
13:50:16.361   Training iter 50, batch loss 0.5624, batch acc 0.1164
13:50:16.872   Training iter 100, batch loss 0.5581, batch acc 0.1132
13:50:17.375   Training iter 150, batch loss 0.5541, batch acc 0.1146
13:50:17.885   Training iter 200, batch loss 0.5504, batch acc 0.1066
13:50:18.362   Training iter 250, batch loss 0.5469, batch acc 0.1078
13:50:18.832   Training iter 300, batch loss 0.5433, batch acc 0.1064
13:50:19.293   Training iter 350, batch loss 0.5400, batch acc 0.1072
13:50:19.747   Training iter 400, batch loss 0.5368, batch acc 0.1090
13:50:20.210   Training iter 450, batch loss 0.5338, batch acc 0.1122
13:50:20.670   Training iter 500, batch loss 0.5310, batch acc 0.1146
13:50:21.137   Training iter 550, batch loss 0.5280, batch acc 0.1248
13:50:21.596   Training iter 600, batch loss 0.5255, batch acc 0.1156
13:50:21.598 Training @ 5 epoch...
13:50:22.058   Training iter 50, batch loss 0.5232, batch acc 0.1102
13:50:22.518   Training iter 100, batch loss 0.5207, batch acc 0.1148
13:50:22.982   Training iter 150, batch loss 0.5188, batch acc 0.1064
13:50:23.454   Training iter 200, batch loss 0.5164, batch acc 0.1154
13:50:23.925   Training iter 250, batch loss 0.5145, batch acc 0.1120
13:50:24.402   Training iter 300, batch loss 0.5124, batch acc 0.1168
13:50:24.876   Training iter 350, batch loss 0.5106, batch acc 0.1128
13:50:25.353   Training iter 400, batch loss 0.5088, batch acc 0.1130
13:50:25.829   Training iter 450, batch loss 0.5071, batch acc 0.1080
13:50:26.313   Training iter 500, batch loss 0.5054, batch acc 0.1116
13:50:26.782   Training iter 550, batch loss 0.5037, batch acc 0.1160
13:50:27.257   Training iter 600, batch loss 0.5023, batch acc 0.1114
13:50:27.258 Testing @ 5 epoch...
13:50:27.297     Testing, total mean loss 0.50154, total acc 0.11350
13:50:27.297 Training @ 6 epoch...
13:50:27.784   Training iter 50, batch loss 0.5010, batch acc 0.1016
13:50:28.285   Training iter 100, batch loss 0.4995, batch acc 0.1092
13:50:28.799   Training iter 150, batch loss 0.4981, batch acc 0.1080
13:50:29.328   Training iter 200, batch loss 0.4967, batch acc 0.1176
13:50:29.835   Training iter 250, batch loss 0.4957, batch acc 0.1094
13:50:30.379   Training iter 300, batch loss 0.4943, batch acc 0.1134
13:50:30.930   Training iter 350, batch loss 0.4933, batch acc 0.1122
13:50:31.482   Training iter 400, batch loss 0.4920, batch acc 0.1210
13:50:32.028   Training iter 450, batch loss 0.4910, batch acc 0.1132
13:50:32.572   Training iter 500, batch loss 0.4900, batch acc 0.1148
13:50:33.119   Training iter 550, batch loss 0.4889, batch acc 0.1180
13:50:33.664   Training iter 600, batch loss 0.4882, batch acc 0.1100
13:50:33.666 Training @ 7 epoch...
13:50:34.210   Training iter 50, batch loss 0.4872, batch acc 0.1102
13:50:34.719   Training iter 100, batch loss 0.4862, batch acc 0.1096
13:50:35.246   Training iter 150, batch loss 0.4854, batch acc 0.1152
13:50:35.758   Training iter 200, batch loss 0.4846, batch acc 0.1136
13:50:36.276   Training iter 250, batch loss 0.4839, batch acc 0.1022
13:50:36.786   Training iter 300, batch loss 0.4830, batch acc 0.1120
13:50:37.292   Training iter 350, batch loss 0.4823, batch acc 0.1112
13:50:37.801   Training iter 400, batch loss 0.4816, batch acc 0.1108
13:50:38.308   Training iter 450, batch loss 0.4807, batch acc 0.1168
13:50:38.818   Training iter 500, batch loss 0.4802, batch acc 0.1152
13:50:39.337   Training iter 550, batch loss 0.4795, batch acc 0.1180
13:50:39.850   Training iter 600, batch loss 0.4788, batch acc 0.1136
13:50:39.851 Training @ 8 epoch...
13:50:40.369   Training iter 50, batch loss 0.4781, batch acc 0.1190
13:50:40.869   Training iter 100, batch loss 0.4777, batch acc 0.1134
13:50:41.381   Training iter 150, batch loss 0.4772, batch acc 0.1034
13:50:41.898   Training iter 200, batch loss 0.4765, batch acc 0.1160
13:50:42.426   Training iter 250, batch loss 0.4760, batch acc 0.1080
13:50:42.934   Training iter 300, batch loss 0.4754, batch acc 0.1140
13:50:43.414   Training iter 350, batch loss 0.4751, batch acc 0.1086
13:50:43.884   Training iter 400, batch loss 0.4744, batch acc 0.1094
13:50:44.377   Training iter 450, batch loss 0.4740, batch acc 0.1136
13:50:44.892   Training iter 500, batch loss 0.4734, batch acc 0.1188
13:50:45.412   Training iter 550, batch loss 0.4730, batch acc 0.1122
13:50:45.914   Training iter 600, batch loss 0.4726, batch acc 0.1120
13:50:45.916 Training @ 9 epoch...
13:50:46.430   Training iter 50, batch loss 0.4722, batch acc 0.1150
13:50:46.954   Training iter 100, batch loss 0.4718, batch acc 0.1060
13:50:47.467   Training iter 150, batch loss 0.4714, batch acc 0.1078
13:50:47.998   Training iter 200, batch loss 0.4708, batch acc 0.1200
13:50:48.526   Training iter 250, batch loss 0.4706, batch acc 0.1094
13:50:49.046   Training iter 300, batch loss 0.4702, batch acc 0.1078
13:50:49.569   Training iter 350, batch loss 0.4698, batch acc 0.1170
13:50:50.113   Training iter 400, batch loss 0.4694, batch acc 0.1192
13:50:50.628   Training iter 450, batch loss 0.4690, batch acc 0.1154
13:50:51.117   Training iter 500, batch loss 0.4688, batch acc 0.1170
13:50:51.608   Training iter 550, batch loss 0.4685, batch acc 0.1026
13:50:52.098   Training iter 600, batch loss 0.4682, batch acc 0.1112
13:50:52.100 Training @ 10 epoch...
13:50:52.596   Training iter 50, batch loss 0.4678, batch acc 0.1154
13:50:53.092   Training iter 100, batch loss 0.4676, batch acc 0.1054
13:50:53.601   Training iter 150, batch loss 0.4672, batch acc 0.1122
13:50:54.099   Training iter 200, batch loss 0.4669, batch acc 0.1134
13:50:54.592   Training iter 250, batch loss 0.4667, batch acc 0.1140
13:50:55.099   Training iter 300, batch loss 0.4664, batch acc 0.1134
13:50:55.605   Training iter 350, batch loss 0.4661, batch acc 0.1148
13:50:56.106   Training iter 400, batch loss 0.4659, batch acc 0.1098
13:50:56.609   Training iter 450, batch loss 0.4656, batch acc 0.1102
13:50:57.102   Training iter 500, batch loss 0.4653, batch acc 0.1154
13:50:57.588   Training iter 550, batch loss 0.4651, batch acc 0.1130
13:50:58.079   Training iter 600, batch loss 0.4649, batch acc 0.1114
13:50:58.080 Testing @ 10 epoch...
13:50:58.119     Testing, total mean loss 0.46475, total acc 0.11350
13:50:58.119 Training @ 11 epoch...
13:50:58.631   Training iter 50, batch loss 0.4646, batch acc 0.1126
13:50:59.121   Training iter 100, batch loss 0.4645, batch acc 0.1068
13:50:59.580   Training iter 150, batch loss 0.4642, batch acc 0.1166
13:51:00.043   Training iter 200, batch loss 0.4640, batch acc 0.1130
13:51:00.533   Training iter 250, batch loss 0.4637, batch acc 0.1194
13:51:01.055   Training iter 300, batch loss 0.4635, batch acc 0.1154
13:51:01.618   Training iter 350, batch loss 0.4634, batch acc 0.1082
13:51:02.184   Training iter 400, batch loss 0.4631, batch acc 0.1138
13:51:02.770   Training iter 450, batch loss 0.4630, batch acc 0.1128
13:51:03.352   Training iter 500, batch loss 0.4629, batch acc 0.1060
13:51:03.924   Training iter 550, batch loss 0.4626, batch acc 0.1112
13:51:04.498   Training iter 600, batch loss 0.4624, batch acc 0.1126
13:51:04.500 Training @ 12 epoch...
13:51:05.068   Training iter 50, batch loss 0.4622, batch acc 0.1168
13:51:05.630   Training iter 100, batch loss 0.4621, batch acc 0.1106
13:51:06.182   Training iter 150, batch loss 0.4621, batch acc 0.1034
13:51:06.739   Training iter 200, batch loss 0.4618, batch acc 0.1170
13:51:07.282   Training iter 250, batch loss 0.4616, batch acc 0.1146
13:51:07.813   Training iter 300, batch loss 0.4614, batch acc 0.1112
13:51:08.350   Training iter 350, batch loss 0.4612, batch acc 0.1160
13:51:08.814   Training iter 400, batch loss 0.4612, batch acc 0.1096
13:51:09.297   Training iter 450, batch loss 0.4610, batch acc 0.1084
13:51:09.789   Training iter 500, batch loss 0.4608, batch acc 0.1176
13:51:10.308   Training iter 550, batch loss 0.4607, batch acc 0.1086
13:51:10.808   Training iter 600, batch loss 0.4606, batch acc 0.1146
13:51:10.810 Training @ 13 epoch...
13:51:11.321   Training iter 50, batch loss 0.4605, batch acc 0.1068
13:51:11.860   Training iter 100, batch loss 0.4602, batch acc 0.1222
13:51:12.402   Training iter 150, batch loss 0.4601, batch acc 0.1172
13:51:12.924   Training iter 200, batch loss 0.4601, batch acc 0.1072
13:51:13.456   Training iter 250, batch loss 0.4599, batch acc 0.1154
13:51:13.981   Training iter 300, batch loss 0.4598, batch acc 0.1142
13:51:14.508   Training iter 350, batch loss 0.4597, batch acc 0.1108
13:51:15.024   Training iter 400, batch loss 0.4595, batch acc 0.1168
13:51:15.550   Training iter 450, batch loss 0.4595, batch acc 0.1110
13:51:16.116   Training iter 500, batch loss 0.4594, batch acc 0.1080
13:51:16.656   Training iter 550, batch loss 0.4592, batch acc 0.1092
13:51:17.141   Training iter 600, batch loss 0.4591, batch acc 0.1096
13:51:17.143 Training @ 14 epoch...
13:51:17.656   Training iter 50, batch loss 0.4590, batch acc 0.1086
13:51:18.165   Training iter 100, batch loss 0.4588, batch acc 0.1122
13:51:18.688   Training iter 150, batch loss 0.4587, batch acc 0.1172
13:51:19.213   Training iter 200, batch loss 0.4587, batch acc 0.1148
13:51:19.746   Training iter 250, batch loss 0.4586, batch acc 0.1126
13:51:20.286   Training iter 300, batch loss 0.4585, batch acc 0.1156
13:51:20.825   Training iter 350, batch loss 0.4584, batch acc 0.1102
13:51:21.358   Training iter 400, batch loss 0.4583, batch acc 0.1102
13:51:21.893   Training iter 450, batch loss 0.4582, batch acc 0.1102
13:51:22.412   Training iter 500, batch loss 0.4581, batch acc 0.1094
13:51:22.936   Training iter 550, batch loss 0.4580, batch acc 0.1144
13:51:23.462   Training iter 600, batch loss 0.4579, batch acc 0.1130
13:51:23.463 Training @ 15 epoch...
13:51:23.951   Training iter 50, batch loss 0.4579, batch acc 0.1060
13:51:24.425   Training iter 100, batch loss 0.4578, batch acc 0.1096
13:51:24.888   Training iter 150, batch loss 0.4576, batch acc 0.1172
13:51:25.365   Training iter 200, batch loss 0.4577, batch acc 0.1044
13:51:25.839   Training iter 250, batch loss 0.4575, batch acc 0.1136
13:51:26.320   Training iter 300, batch loss 0.4574, batch acc 0.1168
13:51:26.794   Training iter 350, batch loss 0.4574, batch acc 0.1100
13:51:27.273   Training iter 400, batch loss 0.4573, batch acc 0.1100
13:51:27.767   Training iter 450, batch loss 0.4572, batch acc 0.1166
13:51:28.270   Training iter 500, batch loss 0.4571, batch acc 0.1164
13:51:28.755   Training iter 550, batch loss 0.4571, batch acc 0.1150
13:51:29.244   Training iter 600, batch loss 0.4570, batch acc 0.1128
13:51:29.246 Testing @ 15 epoch...
13:51:29.285     Testing, total mean loss 0.45696, total acc 0.11350
13:51:29.285 Training @ 16 epoch...
13:51:29.785   Training iter 50, batch loss 0.4569, batch acc 0.1192
13:51:30.277   Training iter 100, batch loss 0.4569, batch acc 0.1148
13:51:30.768   Training iter 150, batch loss 0.4568, batch acc 0.1054
13:51:31.299   Training iter 200, batch loss 0.4568, batch acc 0.1066
13:51:31.788   Training iter 250, batch loss 0.4567, batch acc 0.1040
13:51:32.250   Training iter 300, batch loss 0.4566, batch acc 0.1154
13:51:32.709   Training iter 350, batch loss 0.4566, batch acc 0.1104
13:51:33.184   Training iter 400, batch loss 0.4564, batch acc 0.1114
13:51:33.647   Training iter 450, batch loss 0.4564, batch acc 0.1156
13:51:34.148   Training iter 500, batch loss 0.4564, batch acc 0.1064
13:51:34.664   Training iter 550, batch loss 0.4563, batch acc 0.1146
13:51:35.176   Training iter 600, batch loss 0.4562, batch acc 0.1246
13:51:35.178 Training @ 17 epoch...
13:51:35.697   Training iter 50, batch loss 0.4562, batch acc 0.1096
13:51:36.213   Training iter 100, batch loss 0.4562, batch acc 0.1144
13:51:36.707   Training iter 150, batch loss 0.4561, batch acc 0.1154
13:51:37.206   Training iter 200, batch loss 0.4560, batch acc 0.1130
13:51:37.707   Training iter 250, batch loss 0.4559, batch acc 0.1156
13:51:38.219   Training iter 300, batch loss 0.4559, batch acc 0.1144
13:51:38.741   Training iter 350, batch loss 0.4559, batch acc 0.1098
13:51:39.251   Training iter 400, batch loss 0.4559, batch acc 0.1098
13:51:39.761   Training iter 450, batch loss 0.4557, batch acc 0.1146
13:51:40.249   Training iter 500, batch loss 0.4557, batch acc 0.1128
13:51:40.723   Training iter 550, batch loss 0.4557, batch acc 0.1084
13:51:41.185   Training iter 600, batch loss 0.4556, batch acc 0.1106
13:51:41.187 Training @ 18 epoch...
13:51:41.639   Training iter 50, batch loss 0.4556, batch acc 0.1130
13:51:42.100   Training iter 100, batch loss 0.4556, batch acc 0.1072
13:51:42.550   Training iter 150, batch loss 0.4556, batch acc 0.1034
13:51:43.009   Training iter 200, batch loss 0.4554, batch acc 0.1136
13:51:43.476   Training iter 250, batch loss 0.4554, batch acc 0.1196
13:51:43.913   Training iter 300, batch loss 0.4554, batch acc 0.1112
13:51:44.365   Training iter 350, batch loss 0.4553, batch acc 0.1156
13:51:44.850   Training iter 400, batch loss 0.4553, batch acc 0.1134
13:51:45.369   Training iter 450, batch loss 0.4552, batch acc 0.1086
13:51:45.866   Training iter 500, batch loss 0.4551, batch acc 0.1160
13:51:46.362   Training iter 550, batch loss 0.4551, batch acc 0.1152
13:51:46.843   Training iter 600, batch loss 0.4551, batch acc 0.1116
13:51:46.844 Training @ 19 epoch...
13:51:47.329   Training iter 50, batch loss 0.4551, batch acc 0.1084
13:51:47.826   Training iter 100, batch loss 0.4550, batch acc 0.1106
13:51:48.322   Training iter 150, batch loss 0.4549, batch acc 0.1174
13:51:48.786   Training iter 200, batch loss 0.4550, batch acc 0.1086
13:51:49.271   Training iter 250, batch loss 0.4549, batch acc 0.1186
13:51:49.779   Training iter 300, batch loss 0.4549, batch acc 0.1110
13:51:50.290   Training iter 350, batch loss 0.4549, batch acc 0.1102
13:51:50.800   Training iter 400, batch loss 0.4548, batch acc 0.1114
13:51:51.300   Training iter 450, batch loss 0.4548, batch acc 0.1102
13:51:51.784   Training iter 500, batch loss 0.4548, batch acc 0.1140
13:51:52.284   Training iter 550, batch loss 0.4547, batch acc 0.1144
13:51:52.787   Training iter 600, batch loss 0.4546, batch acc 0.1136
13:51:52.789 Training @ 20 epoch...
13:51:53.291   Training iter 50, batch loss 0.4547, batch acc 0.1084
13:51:53.778   Training iter 100, batch loss 0.4546, batch acc 0.1046
13:51:54.261   Training iter 150, batch loss 0.4546, batch acc 0.1106
13:51:54.743   Training iter 200, batch loss 0.4545, batch acc 0.1106
13:51:55.227   Training iter 250, batch loss 0.4546, batch acc 0.1060
13:51:55.704   Training iter 300, batch loss 0.4544, batch acc 0.1150
13:51:56.177   Training iter 350, batch loss 0.4544, batch acc 0.1170
13:51:56.646   Training iter 400, batch loss 0.4544, batch acc 0.1124
13:51:57.134   Training iter 450, batch loss 0.4543, batch acc 0.1164
13:51:57.614   Training iter 500, batch loss 0.4544, batch acc 0.1112
13:51:58.125   Training iter 550, batch loss 0.4543, batch acc 0.1134
13:51:58.625   Training iter 600, batch loss 0.4541, batch acc 0.1228
13:51:58.627 Testing @ 20 epoch...
13:51:58.666     Testing, total mean loss 0.45427, total acc 0.11350
13:51:58.666 Training @ 21 epoch...
13:51:59.188   Training iter 50, batch loss 0.4543, batch acc 0.1126
13:51:59.708   Training iter 100, batch loss 0.4542, batch acc 0.1186
13:52:00.234   Training iter 150, batch loss 0.4543, batch acc 0.1076
13:52:00.726   Training iter 200, batch loss 0.4542, batch acc 0.1072
13:52:01.211   Training iter 250, batch loss 0.4541, batch acc 0.1142
13:52:01.763   Training iter 300, batch loss 0.4542, batch acc 0.1064
13:52:02.279   Training iter 350, batch loss 0.4541, batch acc 0.1124
13:52:02.806   Training iter 400, batch loss 0.4541, batch acc 0.1138
13:52:03.330   Training iter 450, batch loss 0.4541, batch acc 0.1058
13:52:03.832   Training iter 500, batch loss 0.4541, batch acc 0.1100
13:52:04.354   Training iter 550, batch loss 0.4540, batch acc 0.1152
13:52:04.877   Training iter 600, batch loss 0.4539, batch acc 0.1246
13:52:04.879 Training @ 22 epoch...
13:52:05.413   Training iter 50, batch loss 0.4540, batch acc 0.1106
13:52:05.901   Training iter 100, batch loss 0.4539, batch acc 0.1178
13:52:06.385   Training iter 150, batch loss 0.4538, batch acc 0.1152
13:52:06.883   Training iter 200, batch loss 0.4539, batch acc 0.1136
13:52:07.384   Training iter 250, batch loss 0.4538, batch acc 0.1172
13:52:07.880   Training iter 300, batch loss 0.4538, batch acc 0.1176
13:52:08.384   Training iter 350, batch loss 0.4539, batch acc 0.1080
13:52:08.889   Training iter 400, batch loss 0.4539, batch acc 0.1052
13:52:09.385   Training iter 450, batch loss 0.4538, batch acc 0.1110
13:52:09.899   Training iter 500, batch loss 0.4538, batch acc 0.1088
13:52:10.441   Training iter 550, batch loss 0.4538, batch acc 0.1072
13:52:10.985   Training iter 600, batch loss 0.4537, batch acc 0.1162
13:52:10.986 Training @ 23 epoch...
13:52:11.519   Training iter 50, batch loss 0.4537, batch acc 0.1108
13:52:12.059   Training iter 100, batch loss 0.4536, batch acc 0.1180
13:52:12.603   Training iter 150, batch loss 0.4535, batch acc 0.1224
13:52:13.158   Training iter 200, batch loss 0.4536, batch acc 0.1150
13:52:13.717   Training iter 250, batch loss 0.4536, batch acc 0.1104
13:52:14.271   Training iter 300, batch loss 0.4536, batch acc 0.1168
13:52:14.815   Training iter 350, batch loss 0.4536, batch acc 0.1098
13:52:15.331   Training iter 400, batch loss 0.4536, batch acc 0.1112
13:52:15.844   Training iter 450, batch loss 0.4536, batch acc 0.1092
13:52:16.349   Training iter 500, batch loss 0.4535, batch acc 0.1104
13:52:16.861   Training iter 550, batch loss 0.4535, batch acc 0.1070
13:52:17.361   Training iter 600, batch loss 0.4536, batch acc 0.1074
13:52:17.362 Training @ 24 epoch...
13:52:17.872   Training iter 50, batch loss 0.4534, batch acc 0.1130
13:52:18.374   Training iter 100, batch loss 0.4534, batch acc 0.1192
13:52:18.878   Training iter 150, batch loss 0.4534, batch acc 0.1146
13:52:19.384   Training iter 200, batch loss 0.4534, batch acc 0.1106
13:52:19.874   Training iter 250, batch loss 0.4535, batch acc 0.1090
13:52:20.369   Training iter 300, batch loss 0.4534, batch acc 0.1086
13:52:20.847   Training iter 350, batch loss 0.4534, batch acc 0.1124
13:52:21.319   Training iter 400, batch loss 0.4533, batch acc 0.1106
13:52:21.821   Training iter 450, batch loss 0.4534, batch acc 0.1124
13:52:22.342   Training iter 500, batch loss 0.4534, batch acc 0.1100
13:52:22.864   Training iter 550, batch loss 0.4533, batch acc 0.1178
13:52:23.385   Training iter 600, batch loss 0.4533, batch acc 0.1102
13:52:23.387 Training @ 25 epoch...
13:52:23.910   Training iter 50, batch loss 0.4532, batch acc 0.1138
13:52:24.434   Training iter 100, batch loss 0.4533, batch acc 0.1132
13:52:24.962   Training iter 150, batch loss 0.4531, batch acc 0.1216
13:52:25.499   Training iter 200, batch loss 0.4532, batch acc 0.1086
13:52:26.030   Training iter 250, batch loss 0.4534, batch acc 0.1032
13:52:26.552   Training iter 300, batch loss 0.4532, batch acc 0.1162
13:52:27.085   Training iter 350, batch loss 0.4530, batch acc 0.1190
13:52:27.610   Training iter 400, batch loss 0.4531, batch acc 0.1130
13:52:28.115   Training iter 450, batch loss 0.4532, batch acc 0.1140
13:52:28.768   Training iter 500, batch loss 0.4532, batch acc 0.1048
13:52:29.298   Training iter 550, batch loss 0.4532, batch acc 0.1068
13:52:29.822   Training iter 600, batch loss 0.4531, batch acc 0.1142
13:52:29.823 Testing @ 25 epoch...
13:52:29.863     Testing, total mean loss 0.45310, total acc 0.11350
13:52:29.863 Training @ 26 epoch...
13:52:30.382   Training iter 50, batch loss 0.4531, batch acc 0.1184
13:52:30.896   Training iter 100, batch loss 0.4531, batch acc 0.1114
13:52:31.392   Training iter 150, batch loss 0.4531, batch acc 0.1140
13:52:31.895   Training iter 200, batch loss 0.4530, batch acc 0.1108
13:52:32.398   Training iter 250, batch loss 0.4531, batch acc 0.1130
13:52:32.901   Training iter 300, batch loss 0.4530, batch acc 0.1158
13:52:33.428   Training iter 350, batch loss 0.4531, batch acc 0.1062
13:52:33.940   Training iter 400, batch loss 0.4530, batch acc 0.1136
13:52:34.449   Training iter 450, batch loss 0.4531, batch acc 0.1064
13:52:34.968   Training iter 500, batch loss 0.4530, batch acc 0.1088
13:52:35.490   Training iter 550, batch loss 0.4530, batch acc 0.1126
13:52:36.009   Training iter 600, batch loss 0.4529, batch acc 0.1174
13:52:36.011 Training @ 27 epoch...
13:52:36.523   Training iter 50, batch loss 0.4529, batch acc 0.1146
13:52:37.035   Training iter 100, batch loss 0.4529, batch acc 0.1076
13:52:37.546   Training iter 150, batch loss 0.4529, batch acc 0.1142
13:52:38.107   Training iter 200, batch loss 0.4530, batch acc 0.1048
13:52:38.666   Training iter 250, batch loss 0.4528, batch acc 0.1162
13:52:39.229   Training iter 300, batch loss 0.4530, batch acc 0.1040
13:52:39.785   Training iter 350, batch loss 0.4528, batch acc 0.1238
13:52:40.344   Training iter 400, batch loss 0.4529, batch acc 0.1150
13:52:40.894   Training iter 450, batch loss 0.4529, batch acc 0.1092
13:52:41.451   Training iter 500, batch loss 0.4529, batch acc 0.1100
13:52:42.013   Training iter 550, batch loss 0.4528, batch acc 0.1156
13:52:42.575   Training iter 600, batch loss 0.4529, batch acc 0.1134
13:52:42.577 Training @ 28 epoch...
13:52:43.142   Training iter 50, batch loss 0.4528, batch acc 0.1108
13:52:43.709   Training iter 100, batch loss 0.4528, batch acc 0.1062
13:52:44.269   Training iter 150, batch loss 0.4528, batch acc 0.1142
13:52:44.819   Training iter 200, batch loss 0.4528, batch acc 0.1062
13:52:45.359   Training iter 250, batch loss 0.4528, batch acc 0.1126
13:52:45.909   Training iter 300, batch loss 0.4527, batch acc 0.1170
13:52:46.458   Training iter 350, batch loss 0.4528, batch acc 0.1124
13:52:47.010   Training iter 400, batch loss 0.4528, batch acc 0.1046
13:52:47.594   Training iter 450, batch loss 0.4527, batch acc 0.1160
13:52:48.168   Training iter 500, batch loss 0.4527, batch acc 0.1176
13:52:48.708   Training iter 550, batch loss 0.4527, batch acc 0.1114
13:52:49.233   Training iter 600, batch loss 0.4527, batch acc 0.1194
13:52:49.235 Training @ 29 epoch...
13:52:49.792   Training iter 50, batch loss 0.4528, batch acc 0.1080
13:52:50.335   Training iter 100, batch loss 0.4526, batch acc 0.1154
13:52:50.868   Training iter 150, batch loss 0.4527, batch acc 0.1078
13:52:51.397   Training iter 200, batch loss 0.4525, batch acc 0.1216
13:52:51.926   Training iter 250, batch loss 0.4526, batch acc 0.1108
13:52:52.469   Training iter 300, batch loss 0.4528, batch acc 0.1034
13:52:53.033   Training iter 350, batch loss 0.4526, batch acc 0.1140
13:52:53.580   Training iter 400, batch loss 0.4527, batch acc 0.1134
13:52:54.138   Training iter 450, batch loss 0.4527, batch acc 0.1120
13:52:54.708   Training iter 500, batch loss 0.4526, batch acc 0.1130
13:52:55.295   Training iter 550, batch loss 0.4526, batch acc 0.1146
13:52:55.887   Training iter 600, batch loss 0.4527, batch acc 0.1144
13:52:55.889 Training @ 30 epoch...
13:52:56.494   Training iter 50, batch loss 0.4526, batch acc 0.1104
13:52:57.090   Training iter 100, batch loss 0.4526, batch acc 0.1080
13:52:57.674   Training iter 150, batch loss 0.4526, batch acc 0.1122
13:52:58.293   Training iter 200, batch loss 0.4525, batch acc 0.1156
13:52:58.868   Training iter 250, batch loss 0.4527, batch acc 0.1070
13:52:59.453   Training iter 300, batch loss 0.4525, batch acc 0.1168
13:53:00.048   Training iter 350, batch loss 0.4526, batch acc 0.1148
13:53:00.614   Training iter 400, batch loss 0.4526, batch acc 0.1120
13:53:01.161   Training iter 450, batch loss 0.4525, batch acc 0.1154
13:53:01.813   Training iter 500, batch loss 0.4525, batch acc 0.1148
13:53:02.599   Training iter 550, batch loss 0.4526, batch acc 0.1066
13:53:03.373   Training iter 600, batch loss 0.4525, batch acc 0.1148
13:53:03.376 Testing @ 30 epoch...
13:53:03.439     Testing, total mean loss 0.45251, total acc 0.11350
13:53:03.439 Training @ 31 epoch...
13:53:04.223   Training iter 50, batch loss 0.4526, batch acc 0.1080
13:53:04.979   Training iter 100, batch loss 0.4525, batch acc 0.1154
13:53:05.741   Training iter 150, batch loss 0.4525, batch acc 0.1118
13:53:06.512   Training iter 200, batch loss 0.4525, batch acc 0.1076
13:53:07.128   Training iter 250, batch loss 0.4525, batch acc 0.1124
13:53:07.670   Training iter 300, batch loss 0.4525, batch acc 0.1160
13:53:08.219   Training iter 350, batch loss 0.4525, batch acc 0.1130
13:53:08.743   Training iter 400, batch loss 0.4524, batch acc 0.1144
13:53:09.262   Training iter 450, batch loss 0.4525, batch acc 0.1108
13:53:09.761   Training iter 500, batch loss 0.4524, batch acc 0.1158
13:53:10.268   Training iter 550, batch loss 0.4524, batch acc 0.1130
13:53:10.804   Training iter 600, batch loss 0.4525, batch acc 0.1102
13:53:10.806 Training @ 32 epoch...
13:53:11.364   Training iter 50, batch loss 0.4525, batch acc 0.1086
13:53:11.917   Training iter 100, batch loss 0.4526, batch acc 0.1036
13:53:12.659   Training iter 150, batch loss 0.4525, batch acc 0.1102
13:53:13.416   Training iter 200, batch loss 0.4523, batch acc 0.1234
13:53:13.984   Training iter 250, batch loss 0.4525, batch acc 0.1062
13:53:14.515   Training iter 300, batch loss 0.4524, batch acc 0.1096
13:53:15.027   Training iter 350, batch loss 0.4523, batch acc 0.1218
13:53:15.554   Training iter 400, batch loss 0.4523, batch acc 0.1216
13:53:16.096   Training iter 450, batch loss 0.4524, batch acc 0.1100
13:53:16.624   Training iter 500, batch loss 0.4524, batch acc 0.1154
13:53:17.107   Training iter 550, batch loss 0.4525, batch acc 0.1072
13:53:17.582   Training iter 600, batch loss 0.4524, batch acc 0.1108
13:53:17.584 Training @ 33 epoch...
13:53:18.071   Training iter 50, batch loss 0.4524, batch acc 0.1134
13:53:18.553   Training iter 100, batch loss 0.4523, batch acc 0.1178
13:53:19.045   Training iter 150, batch loss 0.4523, batch acc 0.1140
13:53:19.525   Training iter 200, batch loss 0.4524, batch acc 0.1104
13:53:20.025   Training iter 250, batch loss 0.4523, batch acc 0.1184
13:53:20.531   Training iter 300, batch loss 0.4524, batch acc 0.1130
13:53:21.020   Training iter 350, batch loss 0.4523, batch acc 0.1172
13:53:21.511   Training iter 400, batch loss 0.4524, batch acc 0.1094
13:53:22.009   Training iter 450, batch loss 0.4523, batch acc 0.1144
13:53:22.513   Training iter 500, batch loss 0.4524, batch acc 0.1028
13:53:23.015   Training iter 550, batch loss 0.4524, batch acc 0.1080
13:53:23.521   Training iter 600, batch loss 0.4523, batch acc 0.1096
13:53:23.523 Training @ 34 epoch...
13:53:24.037   Training iter 50, batch loss 0.4523, batch acc 0.1176
13:53:24.534   Training iter 100, batch loss 0.4523, batch acc 0.1070
13:53:25.061   Training iter 150, batch loss 0.4524, batch acc 0.1064
13:53:25.594   Training iter 200, batch loss 0.4524, batch acc 0.1004
13:53:26.107   Training iter 250, batch loss 0.4522, batch acc 0.1168
13:53:26.626   Training iter 300, batch loss 0.4523, batch acc 0.1154
13:53:27.181   Training iter 350, batch loss 0.4523, batch acc 0.1140
13:53:27.739   Training iter 400, batch loss 0.4522, batch acc 0.1130
13:53:28.288   Training iter 450, batch loss 0.4523, batch acc 0.1142
13:53:28.824   Training iter 500, batch loss 0.4522, batch acc 0.1184
13:53:29.368   Training iter 550, batch loss 0.4523, batch acc 0.1132
13:53:29.916   Training iter 600, batch loss 0.4523, batch acc 0.1120
13:53:29.918 Training @ 35 epoch...
13:53:30.468   Training iter 50, batch loss 0.4522, batch acc 0.1126
13:53:31.037   Training iter 100, batch loss 0.4522, batch acc 0.1142
13:53:31.607   Training iter 150, batch loss 0.4522, batch acc 0.1176
13:53:32.164   Training iter 200, batch loss 0.4522, batch acc 0.1202
13:53:32.714   Training iter 250, batch loss 0.4523, batch acc 0.1070
13:53:33.264   Training iter 300, batch loss 0.4522, batch acc 0.1134
13:53:33.789   Training iter 350, batch loss 0.4522, batch acc 0.1128
13:53:34.317   Training iter 400, batch loss 0.4523, batch acc 0.1142
13:53:34.862   Training iter 450, batch loss 0.4523, batch acc 0.1070
13:53:35.404   Training iter 500, batch loss 0.4523, batch acc 0.1104
13:53:35.944   Training iter 550, batch loss 0.4522, batch acc 0.1106
13:53:36.484   Training iter 600, batch loss 0.4522, batch acc 0.1084
13:53:36.486 Testing @ 35 epoch...
13:53:36.532     Testing, total mean loss 0.45220, total acc 0.11350
13:53:36.532 Training @ 36 epoch...
13:53:37.081   Training iter 50, batch loss 0.4523, batch acc 0.1082
13:53:37.637   Training iter 100, batch loss 0.4522, batch acc 0.1156
13:53:38.197   Training iter 150, batch loss 0.4522, batch acc 0.1150
13:53:38.748   Training iter 200, batch loss 0.4522, batch acc 0.1072
13:53:39.308   Training iter 250, batch loss 0.4522, batch acc 0.1082
13:53:39.875   Training iter 300, batch loss 0.4522, batch acc 0.1134
13:53:40.488   Training iter 350, batch loss 0.4522, batch acc 0.1072
13:53:41.050   Training iter 400, batch loss 0.4522, batch acc 0.1152
13:53:41.621   Training iter 450, batch loss 0.4521, batch acc 0.1188
13:53:42.216   Training iter 500, batch loss 0.4522, batch acc 0.1126
13:53:42.837   Training iter 550, batch loss 0.4522, batch acc 0.1120
13:53:43.443   Training iter 600, batch loss 0.4521, batch acc 0.1150
13:53:43.444 Training @ 37 epoch...
13:53:43.995   Training iter 50, batch loss 0.4522, batch acc 0.1126
13:53:44.549   Training iter 100, batch loss 0.4522, batch acc 0.1124
13:53:45.101   Training iter 150, batch loss 0.4522, batch acc 0.1062
13:53:45.695   Training iter 200, batch loss 0.4521, batch acc 0.1130
13:53:46.274   Training iter 250, batch loss 0.4522, batch acc 0.1074
13:53:46.858   Training iter 300, batch loss 0.4520, batch acc 0.1182
13:53:47.438   Training iter 350, batch loss 0.4522, batch acc 0.1096
13:53:48.031   Training iter 400, batch loss 0.4521, batch acc 0.1142
13:53:48.619   Training iter 450, batch loss 0.4523, batch acc 0.1086
13:53:49.169   Training iter 500, batch loss 0.4522, batch acc 0.1104
13:53:49.725   Training iter 550, batch loss 0.4521, batch acc 0.1164
13:53:50.296   Training iter 600, batch loss 0.4520, batch acc 0.1194
13:53:50.298 Training @ 38 epoch...
13:53:50.858   Training iter 50, batch loss 0.4521, batch acc 0.1100
13:53:51.427   Training iter 100, batch loss 0.4521, batch acc 0.1116
13:53:51.999   Training iter 150, batch loss 0.4521, batch acc 0.1156
13:53:52.570   Training iter 200, batch loss 0.4521, batch acc 0.1084
13:53:53.143   Training iter 250, batch loss 0.4521, batch acc 0.1136
13:53:53.665   Training iter 300, batch loss 0.4521, batch acc 0.1102
13:53:54.158   Training iter 350, batch loss 0.4522, batch acc 0.1138
13:53:54.642   Training iter 400, batch loss 0.4521, batch acc 0.1118
13:53:55.171   Training iter 450, batch loss 0.4521, batch acc 0.1182
13:53:55.678   Training iter 500, batch loss 0.4521, batch acc 0.1112
13:53:56.154   Training iter 550, batch loss 0.4521, batch acc 0.1096
13:53:56.618   Training iter 600, batch loss 0.4521, batch acc 0.1144
13:53:56.619 Training @ 39 epoch...
13:53:57.104   Training iter 50, batch loss 0.4521, batch acc 0.1082
13:53:57.582   Training iter 100, batch loss 0.4521, batch acc 0.1176
13:53:58.107   Training iter 150, batch loss 0.4521, batch acc 0.1154
13:53:58.587   Training iter 200, batch loss 0.4521, batch acc 0.1088
13:53:59.088   Training iter 250, batch loss 0.4521, batch acc 0.1074
13:53:59.618   Training iter 300, batch loss 0.4521, batch acc 0.1054
13:54:00.171   Training iter 350, batch loss 0.4521, batch acc 0.1116
13:54:00.738   Training iter 400, batch loss 0.4520, batch acc 0.1250
13:54:01.271   Training iter 450, batch loss 0.4521, batch acc 0.1094
13:54:01.831   Training iter 500, batch loss 0.4521, batch acc 0.1136
13:54:02.520   Training iter 550, batch loss 0.4520, batch acc 0.1198
13:54:03.189   Training iter 600, batch loss 0.4521, batch acc 0.1062
13:54:03.191 Training @ 40 epoch...
13:54:03.776   Training iter 50, batch loss 0.4521, batch acc 0.1104
13:54:04.337   Training iter 100, batch loss 0.4520, batch acc 0.1120
13:54:04.900   Training iter 150, batch loss 0.4521, batch acc 0.1108
13:54:05.439   Training iter 200, batch loss 0.4520, batch acc 0.1182
13:54:05.978   Training iter 250, batch loss 0.4521, batch acc 0.1148
13:54:06.519   Training iter 300, batch loss 0.4520, batch acc 0.1156
13:54:07.050   Training iter 350, batch loss 0.4520, batch acc 0.1116
13:54:07.572   Training iter 400, batch loss 0.4521, batch acc 0.1076
13:54:08.073   Training iter 450, batch loss 0.4520, batch acc 0.1148
13:54:08.592   Training iter 500, batch loss 0.4520, batch acc 0.1156
13:54:09.085   Training iter 550, batch loss 0.4522, batch acc 0.1006
13:54:09.576   Training iter 600, batch loss 0.4520, batch acc 0.1164
13:54:09.578 Testing @ 40 epoch...
13:54:09.620     Testing, total mean loss 0.45202, total acc 0.11350
13:54:09.620 Training @ 41 epoch...
13:54:10.138   Training iter 50, batch loss 0.4521, batch acc 0.1056
13:54:10.671   Training iter 100, batch loss 0.4520, batch acc 0.1156
13:54:11.174   Training iter 150, batch loss 0.4522, batch acc 0.1040
13:54:11.659   Training iter 200, batch loss 0.4520, batch acc 0.1144
13:54:12.138   Training iter 250, batch loss 0.4520, batch acc 0.1080
13:54:12.626   Training iter 300, batch loss 0.4519, batch acc 0.1212
13:54:13.121   Training iter 350, batch loss 0.4520, batch acc 0.1128
13:54:13.643   Training iter 400, batch loss 0.4521, batch acc 0.1082
13:54:14.137   Training iter 450, batch loss 0.4520, batch acc 0.1114
13:54:14.612   Training iter 500, batch loss 0.4519, batch acc 0.1242
13:54:15.095   Training iter 550, batch loss 0.4520, batch acc 0.1118
13:54:15.591   Training iter 600, batch loss 0.4520, batch acc 0.1112
13:54:15.593 Training @ 42 epoch...
13:54:16.133   Training iter 50, batch loss 0.4520, batch acc 0.1120
13:54:16.658   Training iter 100, batch loss 0.4520, batch acc 0.1178
13:54:17.194   Training iter 150, batch loss 0.4519, batch acc 0.1206
13:54:17.740   Training iter 200, batch loss 0.4521, batch acc 0.1130
13:54:18.284   Training iter 250, batch loss 0.4522, batch acc 0.1024
13:54:18.839   Training iter 300, batch loss 0.4520, batch acc 0.1126
13:54:19.393   Training iter 350, batch loss 0.4519, batch acc 0.1124
13:54:19.972   Training iter 400, batch loss 0.4521, batch acc 0.1028
13:54:20.536   Training iter 450, batch loss 0.4519, batch acc 0.1152
13:54:21.105   Training iter 500, batch loss 0.4519, batch acc 0.1190
13:54:21.670   Training iter 550, batch loss 0.4521, batch acc 0.1060
13:54:22.209   Training iter 600, batch loss 0.4519, batch acc 0.1146
13:54:22.211 Training @ 43 epoch...
13:54:22.748   Training iter 50, batch loss 0.4520, batch acc 0.1150
13:54:23.292   Training iter 100, batch loss 0.4520, batch acc 0.1142
13:54:23.829   Training iter 150, batch loss 0.4520, batch acc 0.1154
13:54:24.368   Training iter 200, batch loss 0.4519, batch acc 0.1170
13:54:24.923   Training iter 250, batch loss 0.4521, batch acc 0.1054
13:54:25.487   Training iter 300, batch loss 0.4519, batch acc 0.1200
13:54:26.015   Training iter 350, batch loss 0.4520, batch acc 0.1072
13:54:26.537   Training iter 400, batch loss 0.4519, batch acc 0.1156
13:54:27.090   Training iter 450, batch loss 0.4520, batch acc 0.1128
13:54:27.642   Training iter 500, batch loss 0.4520, batch acc 0.1108
13:54:28.188   Training iter 550, batch loss 0.4520, batch acc 0.1068
13:54:28.714   Training iter 600, batch loss 0.4520, batch acc 0.1082
13:54:28.716 Training @ 44 epoch...
13:54:29.248   Training iter 50, batch loss 0.4519, batch acc 0.1212
13:54:29.786   Training iter 100, batch loss 0.4520, batch acc 0.1104
13:54:30.320   Training iter 150, batch loss 0.4519, batch acc 0.1176
13:54:30.871   Training iter 200, batch loss 0.4520, batch acc 0.1132
13:54:31.429   Training iter 250, batch loss 0.4520, batch acc 0.1098
13:54:32.012   Training iter 300, batch loss 0.4520, batch acc 0.1112
13:54:32.597   Training iter 350, batch loss 0.4519, batch acc 0.1128
13:54:33.168   Training iter 400, batch loss 0.4520, batch acc 0.1144
13:54:33.739   Training iter 450, batch loss 0.4520, batch acc 0.1116
13:54:34.325   Training iter 500, batch loss 0.4520, batch acc 0.1078
13:54:34.924   Training iter 550, batch loss 0.4520, batch acc 0.1074
13:54:35.511   Training iter 600, batch loss 0.4519, batch acc 0.1110
13:54:35.512 Training @ 45 epoch...
13:54:36.097   Training iter 50, batch loss 0.4519, batch acc 0.1138
13:54:36.633   Training iter 100, batch loss 0.4520, batch acc 0.1142
13:54:37.159   Training iter 150, batch loss 0.4519, batch acc 0.1112
13:54:37.669   Training iter 200, batch loss 0.4520, batch acc 0.1136
13:54:38.190   Training iter 250, batch loss 0.4519, batch acc 0.1096
13:54:38.694   Training iter 300, batch loss 0.4519, batch acc 0.1146
13:54:39.185   Training iter 350, batch loss 0.4519, batch acc 0.1186
13:54:39.707   Training iter 400, batch loss 0.4520, batch acc 0.1110
13:54:40.252   Training iter 450, batch loss 0.4519, batch acc 0.1072
13:54:40.788   Training iter 500, batch loss 0.4519, batch acc 0.1070
13:54:41.343   Training iter 550, batch loss 0.4519, batch acc 0.1142
13:54:41.897   Training iter 600, batch loss 0.4520, batch acc 0.1134
13:54:41.899 Testing @ 45 epoch...
13:54:41.944     Testing, total mean loss 0.45192, total acc 0.11350
13:54:41.944 Training @ 46 epoch...
13:54:42.505   Training iter 50, batch loss 0.4519, batch acc 0.1168
13:54:43.059   Training iter 100, batch loss 0.4519, batch acc 0.1110
13:54:43.580   Training iter 150, batch loss 0.4520, batch acc 0.1054
13:54:44.109   Training iter 200, batch loss 0.4520, batch acc 0.1068
13:54:44.808   Training iter 250, batch loss 0.4519, batch acc 0.1172
13:54:45.332   Training iter 300, batch loss 0.4518, batch acc 0.1174
13:54:45.837   Training iter 350, batch loss 0.4519, batch acc 0.1152
13:54:46.322   Training iter 400, batch loss 0.4520, batch acc 0.1096
13:54:46.814   Training iter 450, batch loss 0.4519, batch acc 0.1112
13:54:47.294   Training iter 500, batch loss 0.4518, batch acc 0.1172
13:54:47.777   Training iter 550, batch loss 0.4519, batch acc 0.1174
13:54:48.268   Training iter 600, batch loss 0.4520, batch acc 0.1032
13:54:48.270 Training @ 47 epoch...
13:54:48.763   Training iter 50, batch loss 0.4519, batch acc 0.1090
13:54:49.258   Training iter 100, batch loss 0.4519, batch acc 0.1150
13:54:49.753   Training iter 150, batch loss 0.4520, batch acc 0.1024
13:54:50.250   Training iter 200, batch loss 0.4519, batch acc 0.1208
13:54:50.749   Training iter 250, batch loss 0.4520, batch acc 0.1072
13:54:51.258   Training iter 300, batch loss 0.4520, batch acc 0.1078
13:54:51.764   Training iter 350, batch loss 0.4519, batch acc 0.1170
13:54:52.284   Training iter 400, batch loss 0.4519, batch acc 0.1134
13:54:52.793   Training iter 450, batch loss 0.4519, batch acc 0.1148
13:54:53.303   Training iter 500, batch loss 0.4519, batch acc 0.1140
13:54:53.796   Training iter 550, batch loss 0.4518, batch acc 0.1144
13:54:54.298   Training iter 600, batch loss 0.4519, batch acc 0.1126
13:54:54.300 Training @ 48 epoch...
13:54:54.814   Training iter 50, batch loss 0.4519, batch acc 0.1120
13:54:55.337   Training iter 100, batch loss 0.4519, batch acc 0.1074
13:54:55.802   Training iter 150, batch loss 0.4519, batch acc 0.1128
13:54:56.274   Training iter 200, batch loss 0.4519, batch acc 0.1140
13:54:56.739   Training iter 250, batch loss 0.4518, batch acc 0.1130
13:54:57.225   Training iter 300, batch loss 0.4519, batch acc 0.1192
13:54:57.704   Training iter 350, batch loss 0.4519, batch acc 0.1124
13:54:58.223   Training iter 400, batch loss 0.4520, batch acc 0.1022
13:54:58.728   Training iter 450, batch loss 0.4518, batch acc 0.1202
13:54:59.241   Training iter 500, batch loss 0.4519, batch acc 0.1140
13:54:59.738   Training iter 550, batch loss 0.4519, batch acc 0.1054
13:55:00.251   Training iter 600, batch loss 0.4519, batch acc 0.1158
13:55:00.252 Training @ 49 epoch...
13:55:00.776   Training iter 50, batch loss 0.4519, batch acc 0.1058
13:55:01.295   Training iter 100, batch loss 0.4518, batch acc 0.1198
13:55:01.953   Training iter 150, batch loss 0.4519, batch acc 0.1100
13:55:02.696   Training iter 200, batch loss 0.4519, batch acc 0.1096
13:55:03.373   Training iter 250, batch loss 0.4519, batch acc 0.1116
13:55:03.918   Training iter 300, batch loss 0.4519, batch acc 0.1146
13:55:04.454   Training iter 350, batch loss 0.4519, batch acc 0.1130
13:55:04.982   Training iter 400, batch loss 0.4518, batch acc 0.1170
13:55:05.505   Training iter 450, batch loss 0.4519, batch acc 0.1086
13:55:06.040   Training iter 500, batch loss 0.4519, batch acc 0.1098
13:55:06.561   Training iter 550, batch loss 0.4519, batch acc 0.1166
13:55:07.111   Training iter 600, batch loss 0.4519, batch acc 0.1120
13:55:07.112 Training @ 50 epoch...
13:55:07.678   Training iter 50, batch loss 0.4519, batch acc 0.1160
13:55:08.197   Training iter 100, batch loss 0.4518, batch acc 0.1140
13:55:08.687   Training iter 150, batch loss 0.4518, batch acc 0.1216
13:55:09.169   Training iter 200, batch loss 0.4519, batch acc 0.1128
13:55:09.688   Training iter 250, batch loss 0.4520, batch acc 0.1060
13:55:10.193   Training iter 300, batch loss 0.4519, batch acc 0.1082
13:55:10.685   Training iter 350, batch loss 0.4518, batch acc 0.1114
13:55:11.178   Training iter 400, batch loss 0.4518, batch acc 0.1170
13:55:11.668   Training iter 450, batch loss 0.4518, batch acc 0.1160
13:55:12.188   Training iter 500, batch loss 0.4520, batch acc 0.1044
13:55:12.693   Training iter 550, batch loss 0.4518, batch acc 0.1140
13:55:13.208   Training iter 600, batch loss 0.4519, batch acc 0.1070
13:55:13.210 Testing @ 50 epoch...
13:55:13.250     Testing, total mean loss 0.45186, total acc 0.11350
13:55:13.250 Training @ 51 epoch...
13:55:13.758   Training iter 50, batch loss 0.4519, batch acc 0.1040
13:55:14.270   Training iter 100, batch loss 0.4518, batch acc 0.1182
13:55:14.784   Training iter 150, batch loss 0.4518, batch acc 0.1148
13:55:15.270   Training iter 200, batch loss 0.4519, batch acc 0.1158
13:55:15.749   Training iter 250, batch loss 0.4519, batch acc 0.1072
13:55:16.259   Training iter 300, batch loss 0.4519, batch acc 0.1102
13:55:16.796   Training iter 350, batch loss 0.4519, batch acc 0.1152
13:55:17.353   Training iter 400, batch loss 0.4518, batch acc 0.1110
13:55:17.912   Training iter 450, batch loss 0.4519, batch acc 0.1150
13:55:18.438   Training iter 500, batch loss 0.4519, batch acc 0.1044
13:55:18.890   Training iter 550, batch loss 0.4518, batch acc 0.1172
13:55:19.343   Training iter 600, batch loss 0.4518, batch acc 0.1154
13:55:19.345 Training @ 52 epoch...
13:55:19.804   Training iter 50, batch loss 0.4519, batch acc 0.1114
13:55:20.269   Training iter 100, batch loss 0.4518, batch acc 0.1150
13:55:20.793   Training iter 150, batch loss 0.4518, batch acc 0.1108
13:55:21.291   Training iter 200, batch loss 0.4518, batch acc 0.1150
13:55:21.772   Training iter 250, batch loss 0.4518, batch acc 0.1190
13:55:22.276   Training iter 300, batch loss 0.4518, batch acc 0.1170
13:55:22.800   Training iter 350, batch loss 0.4519, batch acc 0.1140
13:55:23.370   Training iter 400, batch loss 0.4519, batch acc 0.1070
13:55:23.978   Training iter 450, batch loss 0.4519, batch acc 0.1076
13:55:24.548   Training iter 500, batch loss 0.4519, batch acc 0.1178
13:55:25.133   Training iter 550, batch loss 0.4520, batch acc 0.1026
13:55:25.715   Training iter 600, batch loss 0.4518, batch acc 0.1112
13:55:25.717 Training @ 53 epoch...
13:55:26.310   Training iter 50, batch loss 0.4519, batch acc 0.1158
13:55:26.872   Training iter 100, batch loss 0.4518, batch acc 0.1104
13:55:27.456   Training iter 150, batch loss 0.4517, batch acc 0.1186
13:55:28.025   Training iter 200, batch loss 0.4518, batch acc 0.1130
13:55:28.625   Training iter 250, batch loss 0.4519, batch acc 0.1112
13:55:29.157   Training iter 300, batch loss 0.4518, batch acc 0.1172
13:55:29.687   Training iter 350, batch loss 0.4519, batch acc 0.1060
13:55:30.219   Training iter 400, batch loss 0.4518, batch acc 0.1100
13:55:30.723   Training iter 450, batch loss 0.4519, batch acc 0.1098
13:55:31.230   Training iter 500, batch loss 0.4519, batch acc 0.1090
13:55:31.725   Training iter 550, batch loss 0.4519, batch acc 0.1114
13:55:32.233   Training iter 600, batch loss 0.4518, batch acc 0.1160
13:55:32.235 Training @ 54 epoch...
13:55:32.736   Training iter 50, batch loss 0.4519, batch acc 0.1116
13:55:33.239   Training iter 100, batch loss 0.4518, batch acc 0.1178
13:55:33.754   Training iter 150, batch loss 0.4518, batch acc 0.1154
13:55:34.282   Training iter 200, batch loss 0.4518, batch acc 0.1144
13:55:34.803   Training iter 250, batch loss 0.4517, batch acc 0.1192
13:55:35.316   Training iter 300, batch loss 0.4518, batch acc 0.1152
13:55:35.784   Training iter 350, batch loss 0.4519, batch acc 0.1078
13:55:36.256   Training iter 400, batch loss 0.4519, batch acc 0.1106
13:55:36.723   Training iter 450, batch loss 0.4519, batch acc 0.1134
13:55:37.205   Training iter 500, batch loss 0.4519, batch acc 0.1060
13:55:37.672   Training iter 550, batch loss 0.4518, batch acc 0.1132
13:55:38.165   Training iter 600, batch loss 0.4519, batch acc 0.1038
13:55:38.167 Training @ 55 epoch...
13:55:38.666   Training iter 50, batch loss 0.4519, batch acc 0.1096
13:55:39.157   Training iter 100, batch loss 0.4518, batch acc 0.1128
13:55:39.645   Training iter 150, batch loss 0.4519, batch acc 0.1096
13:55:40.162   Training iter 200, batch loss 0.4518, batch acc 0.1094
13:55:40.657   Training iter 250, batch loss 0.4518, batch acc 0.1128
13:55:41.143   Training iter 300, batch loss 0.4518, batch acc 0.1164
13:55:41.632   Training iter 350, batch loss 0.4518, batch acc 0.1142
13:55:42.115   Training iter 400, batch loss 0.4518, batch acc 0.1110
13:55:42.589   Training iter 450, batch loss 0.4519, batch acc 0.1174
13:55:43.069   Training iter 500, batch loss 0.4519, batch acc 0.1108
13:55:43.549   Training iter 550, batch loss 0.4519, batch acc 0.1048
13:55:44.038   Training iter 600, batch loss 0.4518, batch acc 0.1196
13:55:44.039 Testing @ 55 epoch...
13:55:44.080     Testing, total mean loss 0.45182, total acc 0.11350
13:55:44.080 Training @ 56 epoch...
13:55:44.569   Training iter 50, batch loss 0.4518, batch acc 0.1170
13:55:45.067   Training iter 100, batch loss 0.4518, batch acc 0.1114
13:55:45.575   Training iter 150, batch loss 0.4518, batch acc 0.1160
13:55:46.075   Training iter 200, batch loss 0.4518, batch acc 0.1158
13:55:46.565   Training iter 250, batch loss 0.4519, batch acc 0.1084
13:55:47.046   Training iter 300, batch loss 0.4519, batch acc 0.1106
13:55:47.546   Training iter 350, batch loss 0.4518, batch acc 0.1108
13:55:48.033   Training iter 400, batch loss 0.4519, batch acc 0.1134
13:55:48.530   Training iter 450, batch loss 0.4519, batch acc 0.1108
13:55:49.008   Training iter 500, batch loss 0.4520, batch acc 0.1040
13:55:49.483   Training iter 550, batch loss 0.4518, batch acc 0.1182
13:55:49.972   Training iter 600, batch loss 0.4518, batch acc 0.1120
13:55:49.973 Training @ 57 epoch...
13:55:50.482   Training iter 50, batch loss 0.4518, batch acc 0.1112
13:55:50.976   Training iter 100, batch loss 0.4519, batch acc 0.1104
13:55:51.474   Training iter 150, batch loss 0.4518, batch acc 0.1148
13:55:51.981   Training iter 200, batch loss 0.4517, batch acc 0.1214
13:55:52.497   Training iter 250, batch loss 0.4519, batch acc 0.1116
13:55:53.004   Training iter 300, batch loss 0.4519, batch acc 0.1106
13:55:53.517   Training iter 350, batch loss 0.4518, batch acc 0.1148
13:55:54.020   Training iter 400, batch loss 0.4518, batch acc 0.1166
13:55:54.519   Training iter 450, batch loss 0.4518, batch acc 0.1110
13:55:55.014   Training iter 500, batch loss 0.4519, batch acc 0.1068
13:55:55.533   Training iter 550, batch loss 0.4518, batch acc 0.1142
13:55:56.061   Training iter 600, batch loss 0.4519, batch acc 0.1050
13:55:56.063 Training @ 58 epoch...
13:55:56.564   Training iter 50, batch loss 0.4519, batch acc 0.1110
13:55:57.067   Training iter 100, batch loss 0.4519, batch acc 0.1094
13:55:57.583   Training iter 150, batch loss 0.4518, batch acc 0.1148
13:55:58.091   Training iter 200, batch loss 0.4518, batch acc 0.1138
13:55:58.590   Training iter 250, batch loss 0.4518, batch acc 0.1128
13:55:59.090   Training iter 300, batch loss 0.4519, batch acc 0.1106
13:55:59.582   Training iter 350, batch loss 0.4518, batch acc 0.1178
13:56:00.078   Training iter 400, batch loss 0.4519, batch acc 0.1072
13:56:00.602   Training iter 450, batch loss 0.4518, batch acc 0.1100
13:56:01.109   Training iter 500, batch loss 0.4518, batch acc 0.1088
13:56:01.641   Training iter 550, batch loss 0.4518, batch acc 0.1140
13:56:02.209   Training iter 600, batch loss 0.4518, batch acc 0.1182
13:56:02.211 Training @ 59 epoch...
13:56:02.769   Training iter 50, batch loss 0.4518, batch acc 0.1110
13:56:03.324   Training iter 100, batch loss 0.4518, batch acc 0.1136
13:56:03.867   Training iter 150, batch loss 0.4518, batch acc 0.1070
13:56:04.406   Training iter 200, batch loss 0.4519, batch acc 0.1074
13:56:04.930   Training iter 250, batch loss 0.4518, batch acc 0.1098
13:56:05.466   Training iter 300, batch loss 0.4518, batch acc 0.1134
13:56:05.965   Training iter 350, batch loss 0.4517, batch acc 0.1182
13:56:06.504   Training iter 400, batch loss 0.4518, batch acc 0.1128
13:56:07.062   Training iter 450, batch loss 0.4518, batch acc 0.1138
13:56:07.575   Training iter 500, batch loss 0.4517, batch acc 0.1224
13:56:08.061   Training iter 550, batch loss 0.4519, batch acc 0.1068
13:56:08.558   Training iter 600, batch loss 0.4518, batch acc 0.1122
13:56:08.560 Training @ 60 epoch...
13:56:09.045   Training iter 50, batch loss 0.4517, batch acc 0.1218
13:56:09.531   Training iter 100, batch loss 0.4519, batch acc 0.1078
13:56:10.029   Training iter 150, batch loss 0.4518, batch acc 0.1140
13:56:10.544   Training iter 200, batch loss 0.4517, batch acc 0.1202
13:56:11.025   Training iter 250, batch loss 0.4519, batch acc 0.1086
13:56:11.516   Training iter 300, batch loss 0.4518, batch acc 0.1112
13:56:12.027   Training iter 350, batch loss 0.4518, batch acc 0.1140
13:56:12.568   Training iter 400, batch loss 0.4518, batch acc 0.1154
13:56:13.093   Training iter 450, batch loss 0.4519, batch acc 0.1084
13:56:13.619   Training iter 500, batch loss 0.4519, batch acc 0.1078
13:56:14.164   Training iter 550, batch loss 0.4519, batch acc 0.1072
13:56:14.736   Training iter 600, batch loss 0.4518, batch acc 0.1120
13:56:14.737 Testing @ 60 epoch...
13:56:14.780     Testing, total mean loss 0.45180, total acc 0.11350
13:56:14.780 Training @ 61 epoch...
13:56:15.325   Training iter 50, batch loss 0.4518, batch acc 0.1154
13:56:15.864   Training iter 100, batch loss 0.4518, batch acc 0.1146
13:56:16.405   Training iter 150, batch loss 0.4519, batch acc 0.1002
13:56:16.941   Training iter 200, batch loss 0.4518, batch acc 0.1120
13:56:17.474   Training iter 250, batch loss 0.4519, batch acc 0.1072
13:56:18.051   Training iter 300, batch loss 0.4518, batch acc 0.1142
13:56:18.573   Training iter 350, batch loss 0.4517, batch acc 0.1196
13:56:19.077   Training iter 400, batch loss 0.4517, batch acc 0.1144
13:56:19.585   Training iter 450, batch loss 0.4518, batch acc 0.1118
13:56:20.094   Training iter 500, batch loss 0.4518, batch acc 0.1128
13:56:20.595   Training iter 550, batch loss 0.4519, batch acc 0.1056
13:56:21.078   Training iter 600, batch loss 0.4518, batch acc 0.1206
13:56:21.080 Training @ 62 epoch...
13:56:21.564   Training iter 50, batch loss 0.4518, batch acc 0.1120
13:56:22.072   Training iter 100, batch loss 0.4519, batch acc 0.1038
13:56:22.608   Training iter 150, batch loss 0.4516, batch acc 0.1160
13:56:23.126   Training iter 200, batch loss 0.4518, batch acc 0.1160
13:56:23.655   Training iter 250, batch loss 0.4517, batch acc 0.1210
13:56:24.185   Training iter 300, batch loss 0.4518, batch acc 0.1166
13:56:24.727   Training iter 350, batch loss 0.4518, batch acc 0.1136
13:56:25.278   Training iter 400, batch loss 0.4518, batch acc 0.1118
13:56:25.801   Training iter 450, batch loss 0.4520, batch acc 0.1020
13:56:26.298   Training iter 500, batch loss 0.4518, batch acc 0.1136
13:56:26.783   Training iter 550, batch loss 0.4518, batch acc 0.1130
13:56:27.270   Training iter 600, batch loss 0.4519, batch acc 0.1090
13:56:27.272 Training @ 63 epoch...
13:56:27.793   Training iter 50, batch loss 0.4518, batch acc 0.1128
13:56:28.286   Training iter 100, batch loss 0.4518, batch acc 0.1072
13:56:28.774   Training iter 150, batch loss 0.4518, batch acc 0.1132
13:56:29.271   Training iter 200, batch loss 0.4518, batch acc 0.1132
13:56:29.764   Training iter 250, batch loss 0.4518, batch acc 0.1094
13:56:30.254   Training iter 300, batch loss 0.4518, batch acc 0.1140
13:56:30.776   Training iter 350, batch loss 0.4518, batch acc 0.1158
13:56:31.304   Training iter 400, batch loss 0.4518, batch acc 0.1184
13:56:31.828   Training iter 450, batch loss 0.4518, batch acc 0.1150
13:56:32.366   Training iter 500, batch loss 0.4519, batch acc 0.1070
13:56:32.901   Training iter 550, batch loss 0.4518, batch acc 0.1102
13:56:33.422   Training iter 600, batch loss 0.4518, batch acc 0.1122
13:56:33.424 Training @ 64 epoch...
13:56:33.950   Training iter 50, batch loss 0.4517, batch acc 0.1188
13:56:34.474   Training iter 100, batch loss 0.4519, batch acc 0.1044
13:56:34.984   Training iter 150, batch loss 0.4518, batch acc 0.1102
13:56:35.517   Training iter 200, batch loss 0.4518, batch acc 0.1126
13:56:36.055   Training iter 250, batch loss 0.4517, batch acc 0.1150
13:56:36.592   Training iter 300, batch loss 0.4518, batch acc 0.1124
13:56:37.115   Training iter 350, batch loss 0.4519, batch acc 0.1094
13:56:37.650   Training iter 400, batch loss 0.4519, batch acc 0.1124
13:56:38.179   Training iter 450, batch loss 0.4517, batch acc 0.1200
13:56:38.704   Training iter 500, batch loss 0.4518, batch acc 0.1098
13:56:39.234   Training iter 550, batch loss 0.4518, batch acc 0.1086
13:56:39.786   Training iter 600, batch loss 0.4518, batch acc 0.1148
13:56:39.787 Training @ 65 epoch...
13:56:40.341   Training iter 50, batch loss 0.4518, batch acc 0.1106
13:56:40.880   Training iter 100, batch loss 0.4518, batch acc 0.1082
13:56:41.404   Training iter 150, batch loss 0.4518, batch acc 0.1230
13:56:41.930   Training iter 200, batch loss 0.4518, batch acc 0.1074
13:56:42.458   Training iter 250, batch loss 0.4518, batch acc 0.1088
13:56:42.985   Training iter 300, batch loss 0.4518, batch acc 0.1136
13:56:43.514   Training iter 350, batch loss 0.4517, batch acc 0.1176
13:56:44.045   Training iter 400, batch loss 0.4520, batch acc 0.1044
13:56:44.582   Training iter 450, batch loss 0.4518, batch acc 0.1130
13:56:45.095   Training iter 500, batch loss 0.4518, batch acc 0.1130
13:56:45.615   Training iter 550, batch loss 0.4517, batch acc 0.1180
13:56:46.153   Training iter 600, batch loss 0.4518, batch acc 0.1108
13:56:46.154 Testing @ 65 epoch...
13:56:46.196     Testing, total mean loss 0.45178, total acc 0.11350
13:56:46.196 Training @ 66 epoch...
13:56:46.737   Training iter 50, batch loss 0.4518, batch acc 0.1088
13:56:47.274   Training iter 100, batch loss 0.4518, batch acc 0.1102
13:56:47.799   Training iter 150, batch loss 0.4517, batch acc 0.1146
13:56:48.322   Training iter 200, batch loss 0.4518, batch acc 0.1132
13:56:48.842   Training iter 250, batch loss 0.4518, batch acc 0.1136
13:56:49.358   Training iter 300, batch loss 0.4517, batch acc 0.1148
13:56:49.866   Training iter 350, batch loss 0.4517, batch acc 0.1170
13:56:50.374   Training iter 400, batch loss 0.4517, batch acc 0.1132
13:56:50.881   Training iter 450, batch loss 0.4520, batch acc 0.1062
13:56:51.384   Training iter 500, batch loss 0.4519, batch acc 0.1130
13:56:51.899   Training iter 550, batch loss 0.4518, batch acc 0.1126
13:56:52.427   Training iter 600, batch loss 0.4518, batch acc 0.1112
13:56:52.429 Training @ 67 epoch...
13:56:52.958   Training iter 50, batch loss 0.4518, batch acc 0.1128
13:56:53.484   Training iter 100, batch loss 0.4517, batch acc 0.1166
13:56:54.003   Training iter 150, batch loss 0.4519, batch acc 0.1040
13:56:54.526   Training iter 200, batch loss 0.4518, batch acc 0.1154
13:56:55.062   Training iter 250, batch loss 0.4518, batch acc 0.1120
13:56:55.601   Training iter 300, batch loss 0.4517, batch acc 0.1160
13:56:56.145   Training iter 350, batch loss 0.4518, batch acc 0.1110
13:56:56.678   Training iter 400, batch loss 0.4518, batch acc 0.1114
13:56:57.206   Training iter 450, batch loss 0.4518, batch acc 0.1188
13:56:57.749   Training iter 500, batch loss 0.4518, batch acc 0.1072
13:56:58.292   Training iter 550, batch loss 0.4518, batch acc 0.1104
13:56:58.816   Training iter 600, batch loss 0.4518, batch acc 0.1128
13:56:58.818 Training @ 68 epoch...
13:56:59.349   Training iter 50, batch loss 0.4518, batch acc 0.1072
13:56:59.876   Training iter 100, batch loss 0.4517, batch acc 0.1180
13:57:00.413   Training iter 150, batch loss 0.4518, batch acc 0.1208
13:57:00.928   Training iter 200, batch loss 0.4518, batch acc 0.1090
13:57:01.489   Training iter 250, batch loss 0.4518, batch acc 0.1140
13:57:02.045   Training iter 300, batch loss 0.4519, batch acc 0.1038
13:57:02.580   Training iter 350, batch loss 0.4518, batch acc 0.1168
13:57:03.116   Training iter 400, batch loss 0.4518, batch acc 0.1124
13:57:03.687   Training iter 450, batch loss 0.4517, batch acc 0.1158
13:57:04.255   Training iter 500, batch loss 0.4517, batch acc 0.1166
13:57:04.822   Training iter 550, batch loss 0.4520, batch acc 0.1018
13:57:05.333   Training iter 600, batch loss 0.4518, batch acc 0.1122
13:57:05.335 Training @ 69 epoch...
13:57:05.869   Training iter 50, batch loss 0.4517, batch acc 0.1136
13:57:06.399   Training iter 100, batch loss 0.4519, batch acc 0.1112
13:57:06.961   Training iter 150, batch loss 0.4518, batch acc 0.1148
13:57:07.509   Training iter 200, batch loss 0.4519, batch acc 0.1084
13:57:08.050   Training iter 250, batch loss 0.4518, batch acc 0.1090
13:57:08.568   Training iter 300, batch loss 0.4518, batch acc 0.1132
13:57:09.068   Training iter 350, batch loss 0.4518, batch acc 0.1062
13:57:09.591   Training iter 400, batch loss 0.4517, batch acc 0.1142
13:57:10.147   Training iter 450, batch loss 0.4517, batch acc 0.1172
13:57:10.676   Training iter 500, batch loss 0.4517, batch acc 0.1174
13:57:11.219   Training iter 550, batch loss 0.4518, batch acc 0.1116
13:57:11.743   Training iter 600, batch loss 0.4518, batch acc 0.1116
13:57:11.745 Training @ 70 epoch...
13:57:12.268   Training iter 50, batch loss 0.4518, batch acc 0.1132
13:57:12.790   Training iter 100, batch loss 0.4516, batch acc 0.1242
13:57:13.329   Training iter 150, batch loss 0.4519, batch acc 0.1088
13:57:13.864   Training iter 200, batch loss 0.4518, batch acc 0.1170
13:57:14.408   Training iter 250, batch loss 0.4517, batch acc 0.1136
13:57:14.943   Training iter 300, batch loss 0.4518, batch acc 0.1152
13:57:15.493   Training iter 350, batch loss 0.4518, batch acc 0.1102
13:57:16.038   Training iter 400, batch loss 0.4518, batch acc 0.1102
13:57:16.597   Training iter 450, batch loss 0.4517, batch acc 0.1180
13:57:17.142   Training iter 500, batch loss 0.4518, batch acc 0.1056
13:57:17.695   Training iter 550, batch loss 0.4519, batch acc 0.1052
13:57:18.186   Training iter 600, batch loss 0.4519, batch acc 0.1072
13:57:18.188 Testing @ 70 epoch...
13:57:18.227     Testing, total mean loss 0.45177, total acc 0.11350
13:57:18.227 Training @ 71 epoch...
13:57:18.700   Training iter 50, batch loss 0.4518, batch acc 0.1130
13:57:19.157   Training iter 100, batch loss 0.4517, batch acc 0.1190
13:57:19.625   Training iter 150, batch loss 0.4517, batch acc 0.1074
13:57:20.131   Training iter 200, batch loss 0.4518, batch acc 0.1130
13:57:20.627   Training iter 250, batch loss 0.4519, batch acc 0.1102
13:57:21.115   Training iter 300, batch loss 0.4518, batch acc 0.1082
13:57:21.598   Training iter 350, batch loss 0.4518, batch acc 0.1136
13:57:22.070   Training iter 400, batch loss 0.4518, batch acc 0.1124
13:57:22.547   Training iter 450, batch loss 0.4518, batch acc 0.1118
13:57:23.009   Training iter 500, batch loss 0.4518, batch acc 0.1140
13:57:23.481   Training iter 550, batch loss 0.4517, batch acc 0.1170
13:57:23.954   Training iter 600, batch loss 0.4518, batch acc 0.1088
13:57:23.956 Training @ 72 epoch...
13:57:24.444   Training iter 50, batch loss 0.4518, batch acc 0.1130
13:57:24.956   Training iter 100, batch loss 0.4518, batch acc 0.1122
13:57:25.472   Training iter 150, batch loss 0.4519, batch acc 0.1066
13:57:26.019   Training iter 200, batch loss 0.4518, batch acc 0.1168
13:57:26.550   Training iter 250, batch loss 0.4518, batch acc 0.1102
13:57:27.099   Training iter 300, batch loss 0.4518, batch acc 0.1106
13:57:27.687   Training iter 350, batch loss 0.4518, batch acc 0.1100
13:57:28.278   Training iter 400, batch loss 0.4518, batch acc 0.1124
13:57:28.873   Training iter 450, batch loss 0.4517, batch acc 0.1166
13:57:29.457   Training iter 500, batch loss 0.4518, batch acc 0.1138
13:57:30.038   Training iter 550, batch loss 0.4517, batch acc 0.1140
13:57:30.605   Training iter 600, batch loss 0.4518, batch acc 0.1122
13:57:30.607 Training @ 73 epoch...
13:57:31.181   Training iter 50, batch loss 0.4517, batch acc 0.1126
13:57:31.741   Training iter 100, batch loss 0.4517, batch acc 0.1166
13:57:32.255   Training iter 150, batch loss 0.4518, batch acc 0.1040
13:57:32.772   Training iter 200, batch loss 0.4518, batch acc 0.1074
13:57:33.297   Training iter 250, batch loss 0.4519, batch acc 0.1048
13:57:33.818   Training iter 300, batch loss 0.4518, batch acc 0.1176
13:57:34.359   Training iter 350, batch loss 0.4519, batch acc 0.1064
13:57:34.907   Training iter 400, batch loss 0.4517, batch acc 0.1186
13:57:35.481   Training iter 450, batch loss 0.4518, batch acc 0.1166
13:57:36.015   Training iter 500, batch loss 0.4518, batch acc 0.1170
13:57:36.554   Training iter 550, batch loss 0.4517, batch acc 0.1170
13:57:37.075   Training iter 600, batch loss 0.4518, batch acc 0.1098
13:57:37.077 Training @ 74 epoch...
13:57:37.628   Training iter 50, batch loss 0.4517, batch acc 0.1198
13:57:38.157   Training iter 100, batch loss 0.4518, batch acc 0.1126
13:57:38.683   Training iter 150, batch loss 0.4518, batch acc 0.1120
13:57:39.204   Training iter 200, batch loss 0.4518, batch acc 0.1138
13:57:39.729   Training iter 250, batch loss 0.4518, batch acc 0.1124
13:57:40.251   Training iter 300, batch loss 0.4518, batch acc 0.1076
13:57:40.761   Training iter 350, batch loss 0.4517, batch acc 0.1178
13:57:41.281   Training iter 400, batch loss 0.4518, batch acc 0.1136
13:57:41.820   Training iter 450, batch loss 0.4517, batch acc 0.1142
13:57:42.378   Training iter 500, batch loss 0.4518, batch acc 0.1090
13:57:42.928   Training iter 550, batch loss 0.4518, batch acc 0.1074
13:57:43.480   Training iter 600, batch loss 0.4518, batch acc 0.1082
13:57:43.482 Training @ 75 epoch...
13:57:44.035   Training iter 50, batch loss 0.4519, batch acc 0.1076
13:57:44.587   Training iter 100, batch loss 0.4518, batch acc 0.1084
13:57:45.125   Training iter 150, batch loss 0.4517, batch acc 0.1188
13:57:45.692   Training iter 200, batch loss 0.4518, batch acc 0.1120
13:57:46.229   Training iter 250, batch loss 0.4517, batch acc 0.1204
13:57:46.757   Training iter 300, batch loss 0.4517, batch acc 0.1174
13:57:47.291   Training iter 350, batch loss 0.4517, batch acc 0.1096
13:57:47.788   Training iter 400, batch loss 0.4518, batch acc 0.1134
13:57:48.297   Training iter 450, batch loss 0.4518, batch acc 0.1124
13:57:48.791   Training iter 500, batch loss 0.4518, batch acc 0.1068
13:57:49.286   Training iter 550, batch loss 0.4518, batch acc 0.1156
13:57:49.799   Training iter 600, batch loss 0.4518, batch acc 0.1060
13:57:49.801 Testing @ 75 epoch...
13:57:49.840     Testing, total mean loss 0.45177, total acc 0.11350
13:57:49.840 Training @ 76 epoch...
13:57:50.360   Training iter 50, batch loss 0.4518, batch acc 0.1170
13:57:50.850   Training iter 100, batch loss 0.4519, batch acc 0.1094
13:57:51.350   Training iter 150, batch loss 0.4518, batch acc 0.1062
13:57:51.859   Training iter 200, batch loss 0.4518, batch acc 0.1062
13:57:52.362   Training iter 250, batch loss 0.4518, batch acc 0.1112
13:57:52.852   Training iter 300, batch loss 0.4517, batch acc 0.1178
13:57:53.351   Training iter 350, batch loss 0.4517, batch acc 0.1186
13:57:53.837   Training iter 400, batch loss 0.4517, batch acc 0.1112
13:57:54.335   Training iter 450, batch loss 0.4518, batch acc 0.1120
13:57:54.838   Training iter 500, batch loss 0.4517, batch acc 0.1192
13:57:55.341   Training iter 550, batch loss 0.4518, batch acc 0.1068
13:57:55.831   Training iter 600, batch loss 0.4518, batch acc 0.1128
13:57:55.833 Training @ 77 epoch...
13:57:56.347   Training iter 50, batch loss 0.4518, batch acc 0.1096
13:57:56.832   Training iter 100, batch loss 0.4518, batch acc 0.1078
13:57:57.336   Training iter 150, batch loss 0.4517, batch acc 0.1208
13:57:57.868   Training iter 200, batch loss 0.4517, batch acc 0.1162
13:57:58.404   Training iter 250, batch loss 0.4518, batch acc 0.1128
13:57:58.934   Training iter 300, batch loss 0.4518, batch acc 0.1162
13:57:59.447   Training iter 350, batch loss 0.4518, batch acc 0.1122
13:57:59.971   Training iter 400, batch loss 0.4517, batch acc 0.1128
13:58:00.506   Training iter 450, batch loss 0.4518, batch acc 0.1142
13:58:01.022   Training iter 500, batch loss 0.4519, batch acc 0.1020
13:58:01.576   Training iter 550, batch loss 0.4518, batch acc 0.1130
13:58:02.142   Training iter 600, batch loss 0.4518, batch acc 0.1108
13:58:02.144 Training @ 78 epoch...
13:58:02.722   Training iter 50, batch loss 0.4518, batch acc 0.1144
13:58:03.289   Training iter 100, batch loss 0.4518, batch acc 0.1110
13:58:03.848   Training iter 150, batch loss 0.4517, batch acc 0.1182
13:58:04.394   Training iter 200, batch loss 0.4519, batch acc 0.1096
13:58:04.940   Training iter 250, batch loss 0.4518, batch acc 0.1052
13:58:05.488   Training iter 300, batch loss 0.4517, batch acc 0.1174
13:58:06.033   Training iter 350, batch loss 0.4518, batch acc 0.1064
13:58:06.575   Training iter 400, batch loss 0.4518, batch acc 0.1098
13:58:07.116   Training iter 450, batch loss 0.4518, batch acc 0.1124
13:58:07.652   Training iter 500, batch loss 0.4518, batch acc 0.1106
13:58:08.180   Training iter 550, batch loss 0.4517, batch acc 0.1228
13:58:08.699   Training iter 600, batch loss 0.4518, batch acc 0.1106
13:58:08.701 Training @ 79 epoch...
13:58:09.228   Training iter 50, batch loss 0.4517, batch acc 0.1104
13:58:09.752   Training iter 100, batch loss 0.4518, batch acc 0.1104
13:58:10.277   Training iter 150, batch loss 0.4519, batch acc 0.1064
13:58:10.819   Training iter 200, batch loss 0.4518, batch acc 0.1098
13:58:11.366   Training iter 250, batch loss 0.4518, batch acc 0.1160
13:58:11.895   Training iter 300, batch loss 0.4519, batch acc 0.1080
13:58:12.428   Training iter 350, batch loss 0.4518, batch acc 0.1132
13:58:12.986   Training iter 400, batch loss 0.4517, batch acc 0.1184
13:58:13.542   Training iter 450, batch loss 0.4517, batch acc 0.1172
13:58:14.105   Training iter 500, batch loss 0.4518, batch acc 0.1136
13:58:14.667   Training iter 550, batch loss 0.4517, batch acc 0.1130
13:58:15.226   Training iter 600, batch loss 0.4517, batch acc 0.1120
13:58:15.228 Training @ 80 epoch...
13:58:15.784   Training iter 50, batch loss 0.4517, batch acc 0.1078
13:58:16.353   Training iter 100, batch loss 0.4518, batch acc 0.1098
13:58:16.901   Training iter 150, batch loss 0.4518, batch acc 0.1060
13:58:17.459   Training iter 200, batch loss 0.4518, batch acc 0.1120
13:58:18.010   Training iter 250, batch loss 0.4517, batch acc 0.1166
13:58:18.559   Training iter 300, batch loss 0.4518, batch acc 0.1136
13:58:19.089   Training iter 350, batch loss 0.4517, batch acc 0.1170
13:58:19.626   Training iter 400, batch loss 0.4518, batch acc 0.1158
13:58:20.159   Training iter 450, batch loss 0.4518, batch acc 0.1094
13:58:20.666   Training iter 500, batch loss 0.4517, batch acc 0.1178
13:58:21.165   Training iter 550, batch loss 0.4518, batch acc 0.1128
13:58:21.677   Training iter 600, batch loss 0.4519, batch acc 0.1098
13:58:21.679 Testing @ 80 epoch...
13:58:21.719     Testing, total mean loss 0.45176, total acc 0.11350
13:58:21.719 Training @ 81 epoch...
13:58:22.252   Training iter 50, batch loss 0.4517, batch acc 0.1172
13:58:22.787   Training iter 100, batch loss 0.4517, batch acc 0.1122
13:58:23.316   Training iter 150, batch loss 0.4517, batch acc 0.1194
13:58:23.828   Training iter 200, batch loss 0.4519, batch acc 0.1062
13:58:24.344   Training iter 250, batch loss 0.4518, batch acc 0.1084
13:58:24.854   Training iter 300, batch loss 0.4518, batch acc 0.1114
13:58:25.381   Training iter 350, batch loss 0.4518, batch acc 0.1102
13:58:25.902   Training iter 400, batch loss 0.4517, batch acc 0.1228
13:58:26.415   Training iter 450, batch loss 0.4518, batch acc 0.1084
13:58:26.927   Training iter 500, batch loss 0.4518, batch acc 0.1138
13:58:27.433   Training iter 550, batch loss 0.4518, batch acc 0.1064
13:58:27.941   Training iter 600, batch loss 0.4518, batch acc 0.1120
13:58:27.942 Training @ 82 epoch...
13:58:28.450   Training iter 50, batch loss 0.4518, batch acc 0.1104
13:58:28.931   Training iter 100, batch loss 0.4517, batch acc 0.1152
13:58:29.391   Training iter 150, batch loss 0.4519, batch acc 0.1064
13:58:29.895   Training iter 200, batch loss 0.4517, batch acc 0.1148
13:58:30.413   Training iter 250, batch loss 0.4518, batch acc 0.1166
13:58:30.927   Training iter 300, batch loss 0.4517, batch acc 0.1156
13:58:31.474   Training iter 350, batch loss 0.4518, batch acc 0.1106
13:58:32.035   Training iter 400, batch loss 0.4518, batch acc 0.1100
13:58:32.590   Training iter 450, batch loss 0.4518, batch acc 0.1144
13:58:33.155   Training iter 500, batch loss 0.4518, batch acc 0.1072
13:58:33.715   Training iter 550, batch loss 0.4517, batch acc 0.1216
13:58:34.271   Training iter 600, batch loss 0.4519, batch acc 0.1056
13:58:34.273 Training @ 83 epoch...
13:58:34.858   Training iter 50, batch loss 0.4518, batch acc 0.1080
13:58:35.439   Training iter 100, batch loss 0.4518, batch acc 0.1092
13:58:35.903   Training iter 150, batch loss 0.4517, batch acc 0.1196
13:58:36.358   Training iter 200, batch loss 0.4517, batch acc 0.1118
13:58:36.821   Training iter 250, batch loss 0.4518, batch acc 0.1146
13:58:37.298   Training iter 300, batch loss 0.4518, batch acc 0.1040
13:58:37.799   Training iter 350, batch loss 0.4517, batch acc 0.1134
13:58:38.302   Training iter 400, batch loss 0.4517, batch acc 0.1236
13:58:38.801   Training iter 450, batch loss 0.4517, batch acc 0.1118
13:58:39.294   Training iter 500, batch loss 0.4518, batch acc 0.1130
13:58:39.802   Training iter 550, batch loss 0.4518, batch acc 0.1030
13:58:40.303   Training iter 600, batch loss 0.4518, batch acc 0.1164
13:58:40.304 Training @ 84 epoch...
13:58:40.811   Training iter 50, batch loss 0.4518, batch acc 0.1156
13:58:41.312   Training iter 100, batch loss 0.4518, batch acc 0.1088
13:58:41.825   Training iter 150, batch loss 0.4517, batch acc 0.1154
13:58:42.351   Training iter 200, batch loss 0.4518, batch acc 0.1120
13:58:42.880   Training iter 250, batch loss 0.4517, batch acc 0.1146
13:58:43.393   Training iter 300, batch loss 0.4518, batch acc 0.1050
13:58:43.896   Training iter 350, batch loss 0.4517, batch acc 0.1130
13:58:44.414   Training iter 400, batch loss 0.4517, batch acc 0.1214
13:58:44.934   Training iter 450, batch loss 0.4517, batch acc 0.1158
13:58:45.458   Training iter 500, batch loss 0.4519, batch acc 0.1068
13:58:45.998   Training iter 550, batch loss 0.4517, batch acc 0.1164
13:58:46.557   Training iter 600, batch loss 0.4519, batch acc 0.1036
13:58:46.558 Training @ 85 epoch...
13:58:47.118   Training iter 50, batch loss 0.4518, batch acc 0.1088
13:58:47.685   Training iter 100, batch loss 0.4517, batch acc 0.1164
13:58:48.264   Training iter 150, batch loss 0.4517, batch acc 0.1144
13:58:48.820   Training iter 200, batch loss 0.4517, batch acc 0.1176
13:58:49.404   Training iter 250, batch loss 0.4517, batch acc 0.1182
13:58:49.988   Training iter 300, batch loss 0.4519, batch acc 0.1082
13:58:50.571   Training iter 350, batch loss 0.4518, batch acc 0.1090
13:58:51.145   Training iter 400, batch loss 0.4518, batch acc 0.1078
13:58:51.683   Training iter 450, batch loss 0.4518, batch acc 0.1086
13:58:52.330   Training iter 500, batch loss 0.4518, batch acc 0.1084
13:58:53.043   Training iter 550, batch loss 0.4518, batch acc 0.1148
13:58:53.708   Training iter 600, batch loss 0.4518, batch acc 0.1162
13:58:53.710 Testing @ 85 epoch...
13:58:53.751     Testing, total mean loss 0.45176, total acc 0.11350
13:58:53.751 Training @ 86 epoch...
13:58:54.316   Training iter 50, batch loss 0.4517, batch acc 0.1156
13:58:54.877   Training iter 100, batch loss 0.4518, batch acc 0.1102
13:58:55.455   Training iter 150, batch loss 0.4518, batch acc 0.1086
13:58:55.982   Training iter 200, batch loss 0.4517, batch acc 0.1140
13:58:56.504   Training iter 250, batch loss 0.4519, batch acc 0.1054
13:58:57.018   Training iter 300, batch loss 0.4516, batch acc 0.1266
13:58:57.551   Training iter 350, batch loss 0.4519, batch acc 0.1030
13:58:58.043   Training iter 400, batch loss 0.4518, batch acc 0.1110
13:58:58.541   Training iter 450, batch loss 0.4518, batch acc 0.1134
13:58:59.039   Training iter 500, batch loss 0.4518, batch acc 0.1160
13:58:59.531   Training iter 550, batch loss 0.4518, batch acc 0.1106
13:59:00.016   Training iter 600, batch loss 0.4518, batch acc 0.1140
13:59:00.018 Training @ 87 epoch...
13:59:00.536   Training iter 50, batch loss 0.4517, batch acc 0.1156
13:59:01.059   Training iter 100, batch loss 0.4517, batch acc 0.1214
13:59:01.595   Training iter 150, batch loss 0.4517, batch acc 0.1110
13:59:02.173   Training iter 200, batch loss 0.4518, batch acc 0.1104
13:59:02.740   Training iter 250, batch loss 0.4518, batch acc 0.1108
13:59:03.303   Training iter 300, batch loss 0.4518, batch acc 0.1110
13:59:03.864   Training iter 350, batch loss 0.4517, batch acc 0.1162
13:59:04.431   Training iter 400, batch loss 0.4518, batch acc 0.1076
13:59:04.964   Training iter 450, batch loss 0.4518, batch acc 0.1124
13:59:05.533   Training iter 500, batch loss 0.4519, batch acc 0.1080
13:59:06.086   Training iter 550, batch loss 0.4517, batch acc 0.1126
13:59:06.638   Training iter 600, batch loss 0.4518, batch acc 0.1114
13:59:06.640 Training @ 88 epoch...
13:59:07.182   Training iter 50, batch loss 0.4517, batch acc 0.1148
13:59:07.730   Training iter 100, batch loss 0.4518, batch acc 0.1050
13:59:08.255   Training iter 150, batch loss 0.4518, batch acc 0.1140
13:59:08.779   Training iter 200, batch loss 0.4517, batch acc 0.1162
13:59:09.302   Training iter 250, batch loss 0.4518, batch acc 0.1114
13:59:09.828   Training iter 300, batch loss 0.4517, batch acc 0.1116
13:59:10.367   Training iter 350, batch loss 0.4517, batch acc 0.1128
13:59:10.881   Training iter 400, batch loss 0.4518, batch acc 0.1078
13:59:11.401   Training iter 450, batch loss 0.4518, batch acc 0.1086
13:59:11.927   Training iter 500, batch loss 0.4517, batch acc 0.1230
13:59:12.498   Training iter 550, batch loss 0.4518, batch acc 0.1116
13:59:13.038   Training iter 600, batch loss 0.4518, batch acc 0.1116
13:59:13.040 Training @ 89 epoch...
13:59:13.565   Training iter 50, batch loss 0.4518, batch acc 0.1114
13:59:14.092   Training iter 100, batch loss 0.4517, batch acc 0.1162
13:59:14.622   Training iter 150, batch loss 0.4518, batch acc 0.1102
13:59:15.137   Training iter 200, batch loss 0.4516, batch acc 0.1224
13:59:15.656   Training iter 250, batch loss 0.4518, batch acc 0.1094
13:59:16.189   Training iter 300, batch loss 0.4517, batch acc 0.1170
13:59:16.725   Training iter 350, batch loss 0.4518, batch acc 0.1172
13:59:17.252   Training iter 400, batch loss 0.4518, batch acc 0.1106
13:59:17.799   Training iter 450, batch loss 0.4518, batch acc 0.1058
13:59:18.350   Training iter 500, batch loss 0.4518, batch acc 0.1102
13:59:18.914   Training iter 550, batch loss 0.4517, batch acc 0.1124
13:59:19.457   Training iter 600, batch loss 0.4518, batch acc 0.1056
13:59:19.459 Training @ 90 epoch...
13:59:20.016   Training iter 50, batch loss 0.4519, batch acc 0.1038
13:59:20.577   Training iter 100, batch loss 0.4517, batch acc 0.1184
13:59:21.133   Training iter 150, batch loss 0.4517, batch acc 0.1174
13:59:21.691   Training iter 200, batch loss 0.4518, batch acc 0.1120
13:59:22.248   Training iter 250, batch loss 0.4517, batch acc 0.1076
13:59:22.832   Training iter 300, batch loss 0.4519, batch acc 0.1068
13:59:23.405   Training iter 350, batch loss 0.4518, batch acc 0.1134
13:59:23.946   Training iter 400, batch loss 0.4518, batch acc 0.1102
13:59:24.474   Training iter 450, batch loss 0.4518, batch acc 0.1120
13:59:25.007   Training iter 500, batch loss 0.4518, batch acc 0.1156
13:59:25.547   Training iter 550, batch loss 0.4517, batch acc 0.1210
13:59:26.067   Training iter 600, batch loss 0.4517, batch acc 0.1102
13:59:26.068 Testing @ 90 epoch...
13:59:26.109     Testing, total mean loss 0.45176, total acc 0.11350
13:59:26.109 Training @ 91 epoch...
13:59:26.654   Training iter 50, batch loss 0.4518, batch acc 0.1142
13:59:27.196   Training iter 100, batch loss 0.4518, batch acc 0.1052
13:59:27.725   Training iter 150, batch loss 0.4518, batch acc 0.1116
13:59:28.263   Training iter 200, batch loss 0.4517, batch acc 0.1128
13:59:28.785   Training iter 250, batch loss 0.4517, batch acc 0.1172
13:59:29.343   Training iter 300, batch loss 0.4518, batch acc 0.1132
13:59:29.867   Training iter 350, batch loss 0.4518, batch acc 0.1130
13:59:30.415   Training iter 400, batch loss 0.4518, batch acc 0.1116
13:59:30.931   Training iter 450, batch loss 0.4517, batch acc 0.1170
13:59:31.464   Training iter 500, batch loss 0.4517, batch acc 0.1116
13:59:31.983   Training iter 550, batch loss 0.4518, batch acc 0.1088
13:59:32.500   Training iter 600, batch loss 0.4518, batch acc 0.1122
13:59:32.502 Training @ 92 epoch...
13:59:33.032   Training iter 50, batch loss 0.4519, batch acc 0.1080
13:59:33.567   Training iter 100, batch loss 0.4517, batch acc 0.1184
13:59:34.122   Training iter 150, batch loss 0.4518, batch acc 0.1126
13:59:34.685   Training iter 200, batch loss 0.4517, batch acc 0.1130
13:59:35.286   Training iter 250, batch loss 0.4518, batch acc 0.1086
13:59:35.836   Training iter 300, batch loss 0.4519, batch acc 0.1102
13:59:36.356   Training iter 350, batch loss 0.4517, batch acc 0.1072
13:59:36.890   Training iter 400, batch loss 0.4517, batch acc 0.1100
13:59:37.416   Training iter 450, batch loss 0.4517, batch acc 0.1134
13:59:37.922   Training iter 500, batch loss 0.4517, batch acc 0.1118
13:59:38.438   Training iter 550, batch loss 0.4518, batch acc 0.1166
13:59:38.964   Training iter 600, batch loss 0.4518, batch acc 0.1186
13:59:38.966 Training @ 93 epoch...
13:59:39.492   Training iter 50, batch loss 0.4518, batch acc 0.1116
13:59:39.992   Training iter 100, batch loss 0.4517, batch acc 0.1124
13:59:40.488   Training iter 150, batch loss 0.4517, batch acc 0.1122
13:59:40.965   Training iter 200, batch loss 0.4518, batch acc 0.1122
13:59:41.421   Training iter 250, batch loss 0.4518, batch acc 0.1078
13:59:41.887   Training iter 300, batch loss 0.4517, batch acc 0.1158
13:59:42.362   Training iter 350, batch loss 0.4518, batch acc 0.1108
13:59:42.826   Training iter 400, batch loss 0.4519, batch acc 0.1062
13:59:43.301   Training iter 450, batch loss 0.4518, batch acc 0.1124
13:59:43.759   Training iter 500, batch loss 0.4517, batch acc 0.1168
13:59:44.262   Training iter 550, batch loss 0.4518, batch acc 0.1148
13:59:44.776   Training iter 600, batch loss 0.4517, batch acc 0.1154
13:59:44.777 Training @ 94 epoch...
13:59:45.284   Training iter 50, batch loss 0.4517, batch acc 0.1166
13:59:45.785   Training iter 100, batch loss 0.4518, batch acc 0.1144
13:59:46.295   Training iter 150, batch loss 0.4518, batch acc 0.1100
13:59:46.800   Training iter 200, batch loss 0.4517, batch acc 0.1110
13:59:47.314   Training iter 250, batch loss 0.4517, batch acc 0.1118
13:59:47.879   Training iter 300, batch loss 0.4518, batch acc 0.1082
13:59:48.421   Training iter 350, batch loss 0.4518, batch acc 0.1110
13:59:48.942   Training iter 400, batch loss 0.4518, batch acc 0.1156
13:59:49.472   Training iter 450, batch loss 0.4518, batch acc 0.1162
13:59:50.015   Training iter 500, batch loss 0.4518, batch acc 0.1124
13:59:50.564   Training iter 550, batch loss 0.4519, batch acc 0.1112
13:59:51.108   Training iter 600, batch loss 0.4518, batch acc 0.1100
13:59:51.109 Training @ 95 epoch...
13:59:51.662   Training iter 50, batch loss 0.4518, batch acc 0.1164
13:59:52.211   Training iter 100, batch loss 0.4518, batch acc 0.1108
13:59:52.758   Training iter 150, batch loss 0.4518, batch acc 0.1094
13:59:53.301   Training iter 200, batch loss 0.4517, batch acc 0.1092
13:59:53.828   Training iter 250, batch loss 0.4517, batch acc 0.1124
13:59:54.347   Training iter 300, batch loss 0.4519, batch acc 0.1044
13:59:54.879   Training iter 350, batch loss 0.4518, batch acc 0.1128
13:59:55.429   Training iter 400, batch loss 0.4518, batch acc 0.1114
13:59:55.969   Training iter 450, batch loss 0.4517, batch acc 0.1178
13:59:56.479   Training iter 500, batch loss 0.4518, batch acc 0.1078
13:59:56.994   Training iter 550, batch loss 0.4517, batch acc 0.1142
13:59:57.520   Training iter 600, batch loss 0.4517, batch acc 0.1218
13:59:57.522 Testing @ 95 epoch...
13:59:57.561     Testing, total mean loss 0.45176, total acc 0.11350
13:59:57.561 Training @ 96 epoch...
13:59:58.075   Training iter 50, batch loss 0.4517, batch acc 0.1168
13:59:58.572   Training iter 100, batch loss 0.4517, batch acc 0.1158
13:59:59.086   Training iter 150, batch loss 0.4517, batch acc 0.1110
13:59:59.598   Training iter 200, batch loss 0.4519, batch acc 0.1098
14:00:00.129   Training iter 250, batch loss 0.4519, batch acc 0.1080
14:00:00.667   Training iter 300, batch loss 0.4518, batch acc 0.1106
14:00:01.185   Training iter 350, batch loss 0.4517, batch acc 0.1174
14:00:01.767   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:00:02.353   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:00:02.890   Training iter 500, batch loss 0.4517, batch acc 0.1130
14:00:03.425   Training iter 550, batch loss 0.4517, batch acc 0.1116
14:00:03.967   Training iter 600, batch loss 0.4517, batch acc 0.1150
14:00:03.969 Training @ 97 epoch...
14:00:04.591   Training iter 50, batch loss 0.4517, batch acc 0.1160
14:00:05.241   Training iter 100, batch loss 0.4518, batch acc 0.1150
14:00:05.937   Training iter 150, batch loss 0.4519, batch acc 0.1056
14:00:06.539   Training iter 200, batch loss 0.4518, batch acc 0.1090
14:00:07.113   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:00:07.672   Training iter 300, batch loss 0.4518, batch acc 0.1092
14:00:08.243   Training iter 350, batch loss 0.4518, batch acc 0.1060
14:00:08.804   Training iter 400, batch loss 0.4518, batch acc 0.1118
14:00:09.313   Training iter 450, batch loss 0.4517, batch acc 0.1194
14:00:09.808   Training iter 500, batch loss 0.4517, batch acc 0.1162
14:00:10.385   Training iter 550, batch loss 0.4517, batch acc 0.1170
14:00:10.963   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:00:10.964 Training @ 98 epoch...
14:00:11.524   Training iter 50, batch loss 0.4518, batch acc 0.1132
14:00:12.119   Training iter 100, batch loss 0.4518, batch acc 0.1080
14:00:12.661   Training iter 150, batch loss 0.4518, batch acc 0.1146
14:00:13.243   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:00:13.867   Training iter 250, batch loss 0.4517, batch acc 0.1128
14:00:14.537   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:00:15.121   Training iter 350, batch loss 0.4518, batch acc 0.1086
14:00:15.688   Training iter 400, batch loss 0.4517, batch acc 0.1150
14:00:16.256   Training iter 450, batch loss 0.4518, batch acc 0.1062
14:00:16.822   Training iter 500, batch loss 0.4517, batch acc 0.1236
14:00:17.424   Training iter 550, batch loss 0.4517, batch acc 0.1116
14:00:18.018   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:00:18.020 Training @ 99 epoch...
14:00:18.589   Training iter 50, batch loss 0.4516, batch acc 0.1184
14:00:19.136   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:00:19.610   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:00:20.113   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:00:20.581   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:00:21.054   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:00:21.554   Training iter 350, batch loss 0.4518, batch acc 0.1162
14:00:22.058   Training iter 400, batch loss 0.4518, batch acc 0.1058
14:00:22.577   Training iter 450, batch loss 0.4518, batch acc 0.1080
14:00:23.099   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:00:23.635   Training iter 550, batch loss 0.4518, batch acc 0.1126
14:00:24.154   Training iter 600, batch loss 0.4517, batch acc 0.1200
14:00:24.156 Training @ 100 epoch...
14:00:24.696   Training iter 50, batch loss 0.4517, batch acc 0.1140
14:00:25.234   Training iter 100, batch loss 0.4516, batch acc 0.1212
14:00:25.773   Training iter 150, batch loss 0.4518, batch acc 0.1082
14:00:26.326   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:00:26.870   Training iter 250, batch loss 0.4518, batch acc 0.1128
14:00:27.424   Training iter 300, batch loss 0.4518, batch acc 0.1146
14:00:27.980   Training iter 350, batch loss 0.4518, batch acc 0.1138
14:00:28.561   Training iter 400, batch loss 0.4518, batch acc 0.1074
14:00:29.101   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:00:29.621   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:00:30.194   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:00:30.760   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:00:30.762 Testing @ 100 epoch...
14:00:30.800     Testing, total mean loss 0.45175, total acc 0.11350
14:00:30.800 Plot @ 100 epoch...
14:00:30.800 Training @ 101 epoch...
14:00:31.325   Training iter 50, batch loss 0.4519, batch acc 0.1000
14:00:31.902   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:00:32.430   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:00:32.965   Training iter 200, batch loss 0.4518, batch acc 0.1144
14:00:33.501   Training iter 250, batch loss 0.4519, batch acc 0.1054
14:00:34.042   Training iter 300, batch loss 0.4518, batch acc 0.1114
14:00:34.585   Training iter 350, batch loss 0.4516, batch acc 0.1162
14:00:35.127   Training iter 400, batch loss 0.4517, batch acc 0.1150
14:00:35.671   Training iter 450, batch loss 0.4517, batch acc 0.1184
14:00:36.188   Training iter 500, batch loss 0.4517, batch acc 0.1100
14:00:36.700   Training iter 550, batch loss 0.4518, batch acc 0.1126
14:00:37.224   Training iter 600, batch loss 0.4517, batch acc 0.1214
14:00:37.226 Training @ 102 epoch...
14:00:37.758   Training iter 50, batch loss 0.4518, batch acc 0.1098
14:00:38.315   Training iter 100, batch loss 0.4518, batch acc 0.1108
14:00:38.891   Training iter 150, batch loss 0.4517, batch acc 0.1158
14:00:39.458   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:00:40.017   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:00:40.622   Training iter 300, batch loss 0.4517, batch acc 0.1140
14:00:41.190   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:00:41.741   Training iter 400, batch loss 0.4517, batch acc 0.1172
14:00:42.306   Training iter 450, batch loss 0.4519, batch acc 0.1068
14:00:42.910   Training iter 500, batch loss 0.4517, batch acc 0.1138
14:00:43.466   Training iter 550, batch loss 0.4518, batch acc 0.1096
14:00:44.017   Training iter 600, batch loss 0.4517, batch acc 0.1156
14:00:44.019 Training @ 103 epoch...
14:00:44.616   Training iter 50, batch loss 0.4516, batch acc 0.1228
14:00:45.145   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:00:45.657   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:00:46.157   Training iter 200, batch loss 0.4518, batch acc 0.1040
14:00:46.657   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:00:47.171   Training iter 300, batch loss 0.4518, batch acc 0.1150
14:00:47.685   Training iter 350, batch loss 0.4518, batch acc 0.1148
14:00:48.184   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:00:48.694   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:00:49.203   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:00:49.709   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:00:50.246   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:00:50.248 Training @ 104 epoch...
14:00:50.800   Training iter 50, batch loss 0.4519, batch acc 0.1054
14:00:51.325   Training iter 100, batch loss 0.4517, batch acc 0.1204
14:00:51.872   Training iter 150, batch loss 0.4517, batch acc 0.1076
14:00:52.411   Training iter 200, batch loss 0.4518, batch acc 0.1122
14:00:52.981   Training iter 250, batch loss 0.4518, batch acc 0.1174
14:00:53.542   Training iter 300, batch loss 0.4518, batch acc 0.1132
14:00:54.075   Training iter 350, batch loss 0.4518, batch acc 0.1108
14:00:54.631   Training iter 400, batch loss 0.4519, batch acc 0.1088
14:00:55.213   Training iter 450, batch loss 0.4516, batch acc 0.1226
14:00:55.773   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:00:56.342   Training iter 550, batch loss 0.4518, batch acc 0.1108
14:00:56.900   Training iter 600, batch loss 0.4517, batch acc 0.1100
14:00:56.902 Training @ 105 epoch...
14:00:57.507   Training iter 50, batch loss 0.4518, batch acc 0.1148
14:00:58.080   Training iter 100, batch loss 0.4518, batch acc 0.1112
14:00:58.666   Training iter 150, batch loss 0.4518, batch acc 0.1132
14:00:59.207   Training iter 200, batch loss 0.4517, batch acc 0.1166
14:00:59.731   Training iter 250, batch loss 0.4518, batch acc 0.1100
14:01:00.280   Training iter 300, batch loss 0.4518, batch acc 0.1094
14:01:00.830   Training iter 350, batch loss 0.4517, batch acc 0.1186
14:01:01.376   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:01:01.959   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:01:02.511   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:01:03.068   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:01:03.615   Training iter 600, batch loss 0.4517, batch acc 0.1114
14:01:03.616 Testing @ 105 epoch...
14:01:03.656     Testing, total mean loss 0.45175, total acc 0.11350
14:01:03.656 Training @ 106 epoch...
14:01:04.211   Training iter 50, batch loss 0.4519, batch acc 0.1092
14:01:04.745   Training iter 100, batch loss 0.4518, batch acc 0.1070
14:01:05.266   Training iter 150, batch loss 0.4518, batch acc 0.1134
14:01:05.800   Training iter 200, batch loss 0.4518, batch acc 0.1148
14:01:06.344   Training iter 250, batch loss 0.4518, batch acc 0.1084
14:01:06.848   Training iter 300, batch loss 0.4517, batch acc 0.1100
14:01:07.348   Training iter 350, batch loss 0.4517, batch acc 0.1132
14:01:07.843   Training iter 400, batch loss 0.4517, batch acc 0.1106
14:01:08.350   Training iter 450, batch loss 0.4517, batch acc 0.1150
14:01:08.847   Training iter 500, batch loss 0.4518, batch acc 0.1146
14:01:09.362   Training iter 550, batch loss 0.4517, batch acc 0.1178
14:01:09.891   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:01:09.893 Training @ 107 epoch...
14:01:10.426   Training iter 50, batch loss 0.4518, batch acc 0.1104
14:01:10.951   Training iter 100, batch loss 0.4516, batch acc 0.1194
14:01:11.494   Training iter 150, batch loss 0.4518, batch acc 0.1082
14:01:12.038   Training iter 200, batch loss 0.4517, batch acc 0.1118
14:01:12.597   Training iter 250, batch loss 0.4518, batch acc 0.1152
14:01:13.164   Training iter 300, batch loss 0.4518, batch acc 0.1134
14:01:13.706   Training iter 350, batch loss 0.4518, batch acc 0.1098
14:01:14.257   Training iter 400, batch loss 0.4517, batch acc 0.1114
14:01:14.824   Training iter 450, batch loss 0.4518, batch acc 0.1160
14:01:15.389   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:01:15.933   Training iter 550, batch loss 0.4517, batch acc 0.1160
14:01:16.491   Training iter 600, batch loss 0.4518, batch acc 0.1070
14:01:16.492 Training @ 108 epoch...
14:01:17.045   Training iter 50, batch loss 0.4518, batch acc 0.1152
14:01:17.546   Training iter 100, batch loss 0.4517, batch acc 0.1196
14:01:18.059   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:01:18.571   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:01:19.073   Training iter 250, batch loss 0.4517, batch acc 0.1134
14:01:19.584   Training iter 300, batch loss 0.4517, batch acc 0.1124
14:01:20.114   Training iter 350, batch loss 0.4519, batch acc 0.1082
14:01:20.659   Training iter 400, batch loss 0.4517, batch acc 0.1176
14:01:21.193   Training iter 450, batch loss 0.4517, batch acc 0.1118
14:01:21.723   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:01:22.266   Training iter 550, batch loss 0.4518, batch acc 0.1092
14:01:22.823   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:01:22.825 Training @ 109 epoch...
14:01:23.394   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:01:23.937   Training iter 100, batch loss 0.4517, batch acc 0.1194
14:01:24.474   Training iter 150, batch loss 0.4517, batch acc 0.1166
14:01:24.999   Training iter 200, batch loss 0.4518, batch acc 0.1130
14:01:25.530   Training iter 250, batch loss 0.4518, batch acc 0.1064
14:01:26.063   Training iter 300, batch loss 0.4518, batch acc 0.1100
14:01:26.571   Training iter 350, batch loss 0.4518, batch acc 0.1162
14:01:27.084   Training iter 400, batch loss 0.4518, batch acc 0.1060
14:01:27.630   Training iter 450, batch loss 0.4518, batch acc 0.1084
14:01:28.180   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:01:28.718   Training iter 550, batch loss 0.4517, batch acc 0.1206
14:01:29.247   Training iter 600, batch loss 0.4518, batch acc 0.1102
14:01:29.249 Training @ 110 epoch...
14:01:29.792   Training iter 50, batch loss 0.4518, batch acc 0.1148
14:01:30.342   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:01:30.876   Training iter 150, batch loss 0.4519, batch acc 0.1076
14:01:31.390   Training iter 200, batch loss 0.4518, batch acc 0.1030
14:01:31.923   Training iter 250, batch loss 0.4517, batch acc 0.1154
14:01:32.463   Training iter 300, batch loss 0.4518, batch acc 0.1070
14:01:32.994   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:01:33.522   Training iter 400, batch loss 0.4518, batch acc 0.1138
14:01:34.036   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:01:34.552   Training iter 500, batch loss 0.4517, batch acc 0.1172
14:01:35.076   Training iter 550, batch loss 0.4517, batch acc 0.1170
14:01:35.598   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:01:35.599 Testing @ 110 epoch...
14:01:35.639     Testing, total mean loss 0.45175, total acc 0.11350
14:01:35.639 Training @ 111 epoch...
14:01:36.166   Training iter 50, batch loss 0.4518, batch acc 0.1086
14:01:36.675   Training iter 100, batch loss 0.4518, batch acc 0.1136
14:01:37.137   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:01:37.604   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:01:38.098   Training iter 250, batch loss 0.4517, batch acc 0.1120
14:01:38.616   Training iter 300, batch loss 0.4518, batch acc 0.1092
14:01:39.091   Training iter 350, batch loss 0.4517, batch acc 0.1180
14:01:39.566   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:01:40.052   Training iter 450, batch loss 0.4518, batch acc 0.1044
14:01:40.535   Training iter 500, batch loss 0.4517, batch acc 0.1188
14:01:41.010   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:01:41.493   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:01:41.494 Training @ 112 epoch...
14:01:41.974   Training iter 50, batch loss 0.4517, batch acc 0.1102
14:01:42.485   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:01:42.976   Training iter 150, batch loss 0.4518, batch acc 0.1136
14:01:43.483   Training iter 200, batch loss 0.4518, batch acc 0.1090
14:01:44.030   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:01:44.585   Training iter 300, batch loss 0.4519, batch acc 0.1048
14:01:45.146   Training iter 350, batch loss 0.4517, batch acc 0.1136
14:01:45.709   Training iter 400, batch loss 0.4517, batch acc 0.1142
14:01:46.268   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:01:46.824   Training iter 500, batch loss 0.4518, batch acc 0.1130
14:01:47.377   Training iter 550, batch loss 0.4517, batch acc 0.1174
14:01:47.920   Training iter 600, batch loss 0.4518, batch acc 0.1152
14:01:47.922 Training @ 113 epoch...
14:01:48.482   Training iter 50, batch loss 0.4517, batch acc 0.1128
14:01:49.026   Training iter 100, batch loss 0.4518, batch acc 0.1108
14:01:49.560   Training iter 150, batch loss 0.4518, batch acc 0.1086
14:01:50.073   Training iter 200, batch loss 0.4518, batch acc 0.1106
14:01:50.596   Training iter 250, batch loss 0.4517, batch acc 0.1174
14:01:51.116   Training iter 300, batch loss 0.4518, batch acc 0.1086
14:01:51.648   Training iter 350, batch loss 0.4517, batch acc 0.1144
14:01:52.169   Training iter 400, batch loss 0.4518, batch acc 0.1120
14:01:52.685   Training iter 450, batch loss 0.4518, batch acc 0.1062
14:01:53.205   Training iter 500, batch loss 0.4518, batch acc 0.1136
14:01:53.723   Training iter 550, batch loss 0.4518, batch acc 0.1140
14:01:54.211   Training iter 600, batch loss 0.4517, batch acc 0.1194
14:01:54.213 Training @ 114 epoch...
14:01:54.683   Training iter 50, batch loss 0.4518, batch acc 0.1052
14:01:55.147   Training iter 100, batch loss 0.4517, batch acc 0.1196
14:01:55.625   Training iter 150, batch loss 0.4518, batch acc 0.1104
14:01:56.103   Training iter 200, batch loss 0.4517, batch acc 0.1224
14:01:56.597   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:01:57.065   Training iter 300, batch loss 0.4518, batch acc 0.1110
14:01:57.540   Training iter 350, batch loss 0.4518, batch acc 0.1068
14:01:58.019   Training iter 400, batch loss 0.4518, batch acc 0.1136
14:01:58.496   Training iter 450, batch loss 0.4517, batch acc 0.1212
14:01:58.973   Training iter 500, batch loss 0.4518, batch acc 0.1102
14:01:59.449   Training iter 550, batch loss 0.4518, batch acc 0.1060
14:01:59.924   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:01:59.926 Training @ 115 epoch...
14:02:00.430   Training iter 50, batch loss 0.4517, batch acc 0.1158
14:02:00.934   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:02:01.478   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:02:02.010   Training iter 200, batch loss 0.4518, batch acc 0.1130
14:02:02.494   Training iter 250, batch loss 0.4518, batch acc 0.1070
14:02:03.021   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:02:03.526   Training iter 350, batch loss 0.4517, batch acc 0.1150
14:02:04.030   Training iter 400, batch loss 0.4518, batch acc 0.1086
14:02:04.525   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:02:05.033   Training iter 500, batch loss 0.4518, batch acc 0.1132
14:02:05.533   Training iter 550, batch loss 0.4518, batch acc 0.1130
14:02:06.026   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:02:06.028 Testing @ 115 epoch...
14:02:06.067     Testing, total mean loss 0.45175, total acc 0.11350
14:02:06.067 Training @ 116 epoch...
14:02:06.583   Training iter 50, batch loss 0.4518, batch acc 0.1168
14:02:07.120   Training iter 100, batch loss 0.4516, batch acc 0.1196
14:02:07.646   Training iter 150, batch loss 0.4518, batch acc 0.1138
14:02:08.170   Training iter 200, batch loss 0.4517, batch acc 0.1176
14:02:08.679   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:02:09.192   Training iter 300, batch loss 0.4517, batch acc 0.1226
14:02:09.700   Training iter 350, batch loss 0.4518, batch acc 0.1072
14:02:10.199   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:02:10.708   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:02:11.202   Training iter 500, batch loss 0.4518, batch acc 0.1076
14:02:11.690   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:02:12.217   Training iter 600, batch loss 0.4519, batch acc 0.1040
14:02:12.220 Training @ 117 epoch...
14:02:12.947   Training iter 50, batch loss 0.4518, batch acc 0.1172
14:02:13.656   Training iter 100, batch loss 0.4517, batch acc 0.1198
14:02:14.340   Training iter 150, batch loss 0.4517, batch acc 0.1122
14:02:14.882   Training iter 200, batch loss 0.4517, batch acc 0.1102
14:02:15.438   Training iter 250, batch loss 0.4517, batch acc 0.1152
14:02:16.003   Training iter 300, batch loss 0.4519, batch acc 0.1076
14:02:16.550   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:02:17.077   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:02:17.602   Training iter 450, batch loss 0.4518, batch acc 0.1044
14:02:18.119   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:02:18.663   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:02:19.164   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:02:19.165 Training @ 118 epoch...
14:02:19.678   Training iter 50, batch loss 0.4518, batch acc 0.1128
14:02:20.193   Training iter 100, batch loss 0.4516, batch acc 0.1188
14:02:20.717   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:02:21.214   Training iter 200, batch loss 0.4518, batch acc 0.1102
14:02:21.708   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:02:22.213   Training iter 300, batch loss 0.4517, batch acc 0.1116
14:02:22.735   Training iter 350, batch loss 0.4518, batch acc 0.1100
14:02:23.249   Training iter 400, batch loss 0.4518, batch acc 0.1188
14:02:23.741   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:02:24.252   Training iter 500, batch loss 0.4517, batch acc 0.1164
14:02:24.786   Training iter 550, batch loss 0.4518, batch acc 0.1068
14:02:25.307   Training iter 600, batch loss 0.4518, batch acc 0.1134
14:02:25.309 Training @ 119 epoch...
14:02:25.823   Training iter 50, batch loss 0.4517, batch acc 0.1174
14:02:26.339   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:02:26.880   Training iter 150, batch loss 0.4519, batch acc 0.1032
14:02:27.415   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:02:27.913   Training iter 250, batch loss 0.4518, batch acc 0.1124
14:02:28.415   Training iter 300, batch loss 0.4517, batch acc 0.1102
14:02:28.924   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:02:29.459   Training iter 400, batch loss 0.4517, batch acc 0.1164
14:02:29.968   Training iter 450, batch loss 0.4517, batch acc 0.1122
14:02:30.483   Training iter 500, batch loss 0.4518, batch acc 0.1082
14:02:30.994   Training iter 550, batch loss 0.4518, batch acc 0.1180
14:02:31.541   Training iter 600, batch loss 0.4518, batch acc 0.1134
14:02:31.543 Training @ 120 epoch...
14:02:32.084   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:02:32.621   Training iter 100, batch loss 0.4517, batch acc 0.1194
14:02:33.156   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:02:33.693   Training iter 200, batch loss 0.4517, batch acc 0.1170
14:02:34.226   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:02:34.768   Training iter 300, batch loss 0.4518, batch acc 0.1132
14:02:35.319   Training iter 350, batch loss 0.4519, batch acc 0.1052
14:02:35.869   Training iter 400, batch loss 0.4517, batch acc 0.1142
14:02:36.422   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:02:36.954   Training iter 500, batch loss 0.4519, batch acc 0.1106
14:02:37.487   Training iter 550, batch loss 0.4517, batch acc 0.1186
14:02:38.007   Training iter 600, batch loss 0.4518, batch acc 0.1052
14:02:38.009 Testing @ 120 epoch...
14:02:38.048     Testing, total mean loss 0.45175, total acc 0.11350
14:02:38.048 Training @ 121 epoch...
14:02:38.603   Training iter 50, batch loss 0.4517, batch acc 0.1156
14:02:39.122   Training iter 100, batch loss 0.4518, batch acc 0.1072
14:02:39.655   Training iter 150, batch loss 0.4518, batch acc 0.1078
14:02:40.192   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:02:40.717   Training iter 250, batch loss 0.4518, batch acc 0.1154
14:02:41.234   Training iter 300, batch loss 0.4518, batch acc 0.1122
14:02:41.734   Training iter 350, batch loss 0.4517, batch acc 0.1178
14:02:42.253   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:02:42.796   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:02:43.328   Training iter 500, batch loss 0.4518, batch acc 0.1114
14:02:43.838   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:02:44.363   Training iter 600, batch loss 0.4517, batch acc 0.1118
14:02:44.365 Training @ 122 epoch...
14:02:44.900   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:02:45.423   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:02:45.933   Training iter 150, batch loss 0.4517, batch acc 0.1164
14:02:46.433   Training iter 200, batch loss 0.4517, batch acc 0.1188
14:02:46.941   Training iter 250, batch loss 0.4518, batch acc 0.1066
14:02:47.483   Training iter 300, batch loss 0.4518, batch acc 0.1140
14:02:48.034   Training iter 350, batch loss 0.4518, batch acc 0.1138
14:02:48.576   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:02:49.112   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:02:49.674   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:02:50.236   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:02:50.785   Training iter 600, batch loss 0.4517, batch acc 0.1146
14:02:50.787 Training @ 123 epoch...
14:02:51.348   Training iter 50, batch loss 0.4518, batch acc 0.1052
14:02:51.904   Training iter 100, batch loss 0.4518, batch acc 0.1072
14:02:52.456   Training iter 150, batch loss 0.4516, batch acc 0.1200
14:02:53.034   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:02:53.602   Training iter 250, batch loss 0.4517, batch acc 0.1164
14:02:54.134   Training iter 300, batch loss 0.4517, batch acc 0.1158
14:02:54.676   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:02:55.235   Training iter 400, batch loss 0.4517, batch acc 0.1124
14:02:55.781   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:02:56.319   Training iter 500, batch loss 0.4518, batch acc 0.1074
14:02:56.857   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:02:57.379   Training iter 600, batch loss 0.4517, batch acc 0.1182
14:02:57.381 Training @ 124 epoch...
14:02:57.904   Training iter 50, batch loss 0.4515, batch acc 0.1242
14:02:58.429   Training iter 100, batch loss 0.4519, batch acc 0.1042
14:02:58.929   Training iter 150, batch loss 0.4517, batch acc 0.1154
14:02:59.439   Training iter 200, batch loss 0.4518, batch acc 0.1106
14:02:59.955   Training iter 250, batch loss 0.4518, batch acc 0.1110
14:03:00.469   Training iter 300, batch loss 0.4518, batch acc 0.1104
14:03:00.992   Training iter 350, batch loss 0.4518, batch acc 0.1118
14:03:01.504   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:03:02.063   Training iter 450, batch loss 0.4518, batch acc 0.1132
14:03:02.598   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:03:03.146   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:03:03.690   Training iter 600, batch loss 0.4517, batch acc 0.1156
14:03:03.692 Training @ 125 epoch...
14:03:04.249   Training iter 50, batch loss 0.4519, batch acc 0.1066
14:03:04.816   Training iter 100, batch loss 0.4517, batch acc 0.1142
14:03:05.403   Training iter 150, batch loss 0.4518, batch acc 0.1128
14:03:05.992   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:03:06.554   Training iter 250, batch loss 0.4518, batch acc 0.1156
14:03:07.105   Training iter 300, batch loss 0.4517, batch acc 0.1110
14:03:07.668   Training iter 350, batch loss 0.4519, batch acc 0.1074
14:03:08.208   Training iter 400, batch loss 0.4518, batch acc 0.1094
14:03:08.747   Training iter 450, batch loss 0.4517, batch acc 0.1162
14:03:09.294   Training iter 500, batch loss 0.4516, batch acc 0.1208
14:03:09.787   Training iter 550, batch loss 0.4518, batch acc 0.1122
14:03:10.285   Training iter 600, batch loss 0.4517, batch acc 0.1128
14:03:10.286 Testing @ 125 epoch...
14:03:10.325     Testing, total mean loss 0.45175, total acc 0.11350
14:03:10.325 Training @ 126 epoch...
14:03:10.824   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:03:11.318   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:03:11.814   Training iter 150, batch loss 0.4517, batch acc 0.1136
14:03:12.322   Training iter 200, batch loss 0.4518, batch acc 0.1174
14:03:12.845   Training iter 250, batch loss 0.4518, batch acc 0.1092
14:03:13.347   Training iter 300, batch loss 0.4517, batch acc 0.1144
14:03:13.842   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:03:14.334   Training iter 400, batch loss 0.4516, batch acc 0.1154
14:03:14.825   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:03:15.306   Training iter 500, batch loss 0.4518, batch acc 0.1058
14:03:15.789   Training iter 550, batch loss 0.4518, batch acc 0.1116
14:03:16.278   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:03:16.280 Training @ 127 epoch...
14:03:16.785   Training iter 50, batch loss 0.4517, batch acc 0.1090
14:03:17.273   Training iter 100, batch loss 0.4516, batch acc 0.1224
14:03:17.763   Training iter 150, batch loss 0.4517, batch acc 0.1164
14:03:18.285   Training iter 200, batch loss 0.4518, batch acc 0.1060
14:03:18.791   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:03:19.291   Training iter 300, batch loss 0.4519, batch acc 0.1038
14:03:19.821   Training iter 350, batch loss 0.4518, batch acc 0.1146
14:03:20.376   Training iter 400, batch loss 0.4517, batch acc 0.1128
14:03:20.933   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:03:21.480   Training iter 500, batch loss 0.4517, batch acc 0.1174
14:03:22.029   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:03:22.572   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:03:22.573 Training @ 128 epoch...
14:03:23.120   Training iter 50, batch loss 0.4518, batch acc 0.1072
14:03:23.673   Training iter 100, batch loss 0.4518, batch acc 0.1128
14:03:24.211   Training iter 150, batch loss 0.4519, batch acc 0.1012
14:03:24.742   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:03:25.284   Training iter 250, batch loss 0.4517, batch acc 0.1160
14:03:25.777   Training iter 300, batch loss 0.4517, batch acc 0.1158
14:03:26.271   Training iter 350, batch loss 0.4517, batch acc 0.1190
14:03:26.775   Training iter 400, batch loss 0.4518, batch acc 0.1104
14:03:27.271   Training iter 450, batch loss 0.4517, batch acc 0.1162
14:03:27.749   Training iter 500, batch loss 0.4517, batch acc 0.1106
14:03:28.254   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:03:28.747   Training iter 600, batch loss 0.4518, batch acc 0.1112
14:03:28.749 Training @ 129 epoch...
14:03:29.243   Training iter 50, batch loss 0.4517, batch acc 0.1114
14:03:29.726   Training iter 100, batch loss 0.4518, batch acc 0.1074
14:03:30.200   Training iter 150, batch loss 0.4518, batch acc 0.1052
14:03:30.656   Training iter 200, batch loss 0.4518, batch acc 0.1062
14:03:31.135   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:03:31.642   Training iter 300, batch loss 0.4517, batch acc 0.1152
14:03:32.130   Training iter 350, batch loss 0.4517, batch acc 0.1192
14:03:32.606   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:03:33.096   Training iter 450, batch loss 0.4517, batch acc 0.1174
14:03:33.601   Training iter 500, batch loss 0.4518, batch acc 0.1116
14:03:34.082   Training iter 550, batch loss 0.4518, batch acc 0.1146
14:03:34.586   Training iter 600, batch loss 0.4517, batch acc 0.1168
14:03:34.587 Training @ 130 epoch...
14:03:35.111   Training iter 50, batch loss 0.4518, batch acc 0.1080
14:03:35.635   Training iter 100, batch loss 0.4518, batch acc 0.1134
14:03:36.141   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:03:36.649   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:03:37.157   Training iter 250, batch loss 0.4517, batch acc 0.1112
14:03:37.663   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:03:38.186   Training iter 350, batch loss 0.4518, batch acc 0.1104
14:03:38.725   Training iter 400, batch loss 0.4518, batch acc 0.1138
14:03:39.241   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:03:39.751   Training iter 500, batch loss 0.4517, batch acc 0.1108
14:03:40.282   Training iter 550, batch loss 0.4516, batch acc 0.1224
14:03:40.811   Training iter 600, batch loss 0.4518, batch acc 0.1148
14:03:40.812 Testing @ 130 epoch...
14:03:40.853     Testing, total mean loss 0.45175, total acc 0.11350
14:03:40.853 Training @ 131 epoch...
14:03:41.395   Training iter 50, batch loss 0.4517, batch acc 0.1168
14:03:41.928   Training iter 100, batch loss 0.4517, batch acc 0.1192
14:03:42.457   Training iter 150, batch loss 0.4517, batch acc 0.1200
14:03:42.993   Training iter 200, batch loss 0.4518, batch acc 0.1076
14:03:43.516   Training iter 250, batch loss 0.4516, batch acc 0.1244
14:03:44.027   Training iter 300, batch loss 0.4519, batch acc 0.1048
14:03:44.530   Training iter 350, batch loss 0.4517, batch acc 0.1094
14:03:45.034   Training iter 400, batch loss 0.4520, batch acc 0.1002
14:03:45.555   Training iter 450, batch loss 0.4517, batch acc 0.1154
14:03:46.083   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:03:46.583   Training iter 550, batch loss 0.4519, batch acc 0.1058
14:03:47.071   Training iter 600, batch loss 0.4517, batch acc 0.1136
14:03:47.073 Training @ 132 epoch...
14:03:47.533   Training iter 50, batch loss 0.4518, batch acc 0.1146
14:03:47.990   Training iter 100, batch loss 0.4518, batch acc 0.1070
14:03:48.455   Training iter 150, batch loss 0.4517, batch acc 0.1092
14:03:48.912   Training iter 200, batch loss 0.4517, batch acc 0.1114
14:03:49.364   Training iter 250, batch loss 0.4518, batch acc 0.1156
14:03:49.829   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:03:50.291   Training iter 350, batch loss 0.4518, batch acc 0.1190
14:03:50.739   Training iter 400, batch loss 0.4519, batch acc 0.1070
14:03:51.208   Training iter 450, batch loss 0.4518, batch acc 0.1070
14:03:51.688   Training iter 500, batch loss 0.4517, batch acc 0.1126
14:03:52.173   Training iter 550, batch loss 0.4517, batch acc 0.1192
14:03:52.711   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:03:52.713 Training @ 133 epoch...
14:03:53.242   Training iter 50, batch loss 0.4517, batch acc 0.1142
14:03:53.826   Training iter 100, batch loss 0.4518, batch acc 0.1060
14:03:54.399   Training iter 150, batch loss 0.4518, batch acc 0.1104
14:03:54.975   Training iter 200, batch loss 0.4517, batch acc 0.1138
14:03:55.491   Training iter 250, batch loss 0.4518, batch acc 0.1128
14:03:55.982   Training iter 300, batch loss 0.4518, batch acc 0.1134
14:03:56.487   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:03:56.991   Training iter 400, batch loss 0.4518, batch acc 0.1146
14:03:57.517   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:03:58.017   Training iter 500, batch loss 0.4517, batch acc 0.1138
14:03:58.508   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:03:58.991   Training iter 600, batch loss 0.4518, batch acc 0.1120
14:03:58.993 Training @ 134 epoch...
14:03:59.493   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:04:00.005   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:04:00.515   Training iter 150, batch loss 0.4519, batch acc 0.1066
14:04:01.011   Training iter 200, batch loss 0.4517, batch acc 0.1120
14:04:01.545   Training iter 250, batch loss 0.4516, batch acc 0.1196
14:04:02.097   Training iter 300, batch loss 0.4518, batch acc 0.1162
14:04:02.614   Training iter 350, batch loss 0.4518, batch acc 0.1068
14:04:03.142   Training iter 400, batch loss 0.4518, batch acc 0.1124
14:04:03.657   Training iter 450, batch loss 0.4518, batch acc 0.1046
14:04:04.182   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:04:04.724   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:04:05.269   Training iter 600, batch loss 0.4518, batch acc 0.1156
14:04:05.271 Training @ 135 epoch...
14:04:05.761   Training iter 50, batch loss 0.4518, batch acc 0.1112
14:04:06.249   Training iter 100, batch loss 0.4518, batch acc 0.1060
14:04:06.725   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:04:07.229   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:04:07.780   Training iter 250, batch loss 0.4518, batch acc 0.1126
14:04:08.309   Training iter 300, batch loss 0.4517, batch acc 0.1168
14:04:08.827   Training iter 350, batch loss 0.4518, batch acc 0.1114
14:04:09.354   Training iter 400, batch loss 0.4517, batch acc 0.1122
14:04:09.893   Training iter 450, batch loss 0.4519, batch acc 0.1064
14:04:10.444   Training iter 500, batch loss 0.4518, batch acc 0.1138
14:04:10.975   Training iter 550, batch loss 0.4516, batch acc 0.1184
14:04:11.532   Training iter 600, batch loss 0.4518, batch acc 0.1088
14:04:11.534 Testing @ 135 epoch...
14:04:11.574     Testing, total mean loss 0.45175, total acc 0.11350
14:04:11.574 Training @ 136 epoch...
14:04:12.140   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:04:12.692   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:04:13.282   Training iter 150, batch loss 0.4517, batch acc 0.1058
14:04:13.797   Training iter 200, batch loss 0.4517, batch acc 0.1104
14:04:14.301   Training iter 250, batch loss 0.4518, batch acc 0.1128
14:04:14.798   Training iter 300, batch loss 0.4517, batch acc 0.1114
14:04:15.301   Training iter 350, batch loss 0.4517, batch acc 0.1190
14:04:15.786   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:04:16.289   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:04:16.838   Training iter 500, batch loss 0.4519, batch acc 0.1056
14:04:17.411   Training iter 550, batch loss 0.4517, batch acc 0.1204
14:04:17.922   Training iter 600, batch loss 0.4519, batch acc 0.1112
14:04:17.924 Training @ 137 epoch...
14:04:18.467   Training iter 50, batch loss 0.4517, batch acc 0.1144
14:04:18.997   Training iter 100, batch loss 0.4517, batch acc 0.1182
14:04:19.528   Training iter 150, batch loss 0.4518, batch acc 0.1142
14:04:20.059   Training iter 200, batch loss 0.4518, batch acc 0.1082
14:04:20.602   Training iter 250, batch loss 0.4517, batch acc 0.1152
14:04:21.123   Training iter 300, batch loss 0.4517, batch acc 0.1168
14:04:21.647   Training iter 350, batch loss 0.4517, batch acc 0.1118
14:04:22.213   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:04:22.777   Training iter 450, batch loss 0.4519, batch acc 0.1086
14:04:23.357   Training iter 500, batch loss 0.4517, batch acc 0.1138
14:04:23.923   Training iter 550, batch loss 0.4517, batch acc 0.1074
14:04:24.466   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:04:24.468 Training @ 138 epoch...
14:04:25.018   Training iter 50, batch loss 0.4518, batch acc 0.1110
14:04:25.580   Training iter 100, batch loss 0.4517, batch acc 0.1136
14:04:26.123   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:04:26.667   Training iter 200, batch loss 0.4517, batch acc 0.1196
14:04:27.231   Training iter 250, batch loss 0.4518, batch acc 0.1078
14:04:27.813   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:04:28.395   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:04:28.967   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:04:29.526   Training iter 450, batch loss 0.4518, batch acc 0.1166
14:04:30.072   Training iter 500, batch loss 0.4518, batch acc 0.1108
14:04:30.636   Training iter 550, batch loss 0.4518, batch acc 0.1042
14:04:31.213   Training iter 600, batch loss 0.4517, batch acc 0.1162
14:04:31.215 Training @ 139 epoch...
14:04:31.773   Training iter 50, batch loss 0.4518, batch acc 0.1100
14:04:32.330   Training iter 100, batch loss 0.4518, batch acc 0.1062
14:04:32.876   Training iter 150, batch loss 0.4518, batch acc 0.1118
14:04:33.431   Training iter 200, batch loss 0.4517, batch acc 0.1196
14:04:33.961   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:04:34.493   Training iter 300, batch loss 0.4518, batch acc 0.1140
14:04:35.033   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:04:35.573   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:04:36.121   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:04:36.662   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:04:37.206   Training iter 550, batch loss 0.4518, batch acc 0.1118
14:04:37.747   Training iter 600, batch loss 0.4517, batch acc 0.1136
14:04:37.749 Training @ 140 epoch...
14:04:38.291   Training iter 50, batch loss 0.4517, batch acc 0.1144
14:04:38.823   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:04:39.360   Training iter 150, batch loss 0.4516, batch acc 0.1262
14:04:39.929   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:04:40.520   Training iter 250, batch loss 0.4518, batch acc 0.1148
14:04:41.088   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:04:41.648   Training iter 350, batch loss 0.4518, batch acc 0.1078
14:04:42.233   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:04:42.808   Training iter 450, batch loss 0.4519, batch acc 0.1028
14:04:43.385   Training iter 500, batch loss 0.4517, batch acc 0.1158
14:04:43.922   Training iter 550, batch loss 0.4517, batch acc 0.1122
14:04:44.455   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:04:44.457 Testing @ 140 epoch...
14:04:44.496     Testing, total mean loss 0.45175, total acc 0.11350
14:04:44.496 Training @ 141 epoch...
14:04:45.036   Training iter 50, batch loss 0.4518, batch acc 0.1120
14:04:45.540   Training iter 100, batch loss 0.4518, batch acc 0.1100
14:04:46.053   Training iter 150, batch loss 0.4517, batch acc 0.1166
14:04:46.578   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:04:47.158   Training iter 250, batch loss 0.4517, batch acc 0.1104
14:04:47.723   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:04:48.268   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:04:48.729   Training iter 400, batch loss 0.4518, batch acc 0.1056
14:04:49.197   Training iter 450, batch loss 0.4517, batch acc 0.1182
14:04:49.704   Training iter 500, batch loss 0.4518, batch acc 0.1150
14:04:50.246   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:04:50.779   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:04:50.780 Training @ 142 epoch...
14:04:51.294   Training iter 50, batch loss 0.4518, batch acc 0.1174
14:04:51.788   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:04:52.265   Training iter 150, batch loss 0.4517, batch acc 0.1154
14:04:52.745   Training iter 200, batch loss 0.4519, batch acc 0.1046
14:04:53.236   Training iter 250, batch loss 0.4517, batch acc 0.1194
14:04:53.716   Training iter 300, batch loss 0.4518, batch acc 0.1118
14:04:54.188   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:04:54.702   Training iter 400, batch loss 0.4518, batch acc 0.1088
14:04:55.207   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:04:55.690   Training iter 500, batch loss 0.4518, batch acc 0.1082
14:04:56.167   Training iter 550, batch loss 0.4517, batch acc 0.1130
14:04:56.642   Training iter 600, batch loss 0.4518, batch acc 0.1114
14:04:56.643 Training @ 143 epoch...
14:04:57.138   Training iter 50, batch loss 0.4517, batch acc 0.1144
14:04:57.637   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:04:58.139   Training iter 150, batch loss 0.4518, batch acc 0.1052
14:04:58.638   Training iter 200, batch loss 0.4518, batch acc 0.1114
14:04:59.142   Training iter 250, batch loss 0.4516, batch acc 0.1224
14:04:59.627   Training iter 300, batch loss 0.4518, batch acc 0.1148
14:05:00.127   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:05:00.620   Training iter 400, batch loss 0.4517, batch acc 0.1130
14:05:01.128   Training iter 450, batch loss 0.4519, batch acc 0.1070
14:05:01.653   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:05:02.219   Training iter 550, batch loss 0.4517, batch acc 0.1166
14:05:02.791   Training iter 600, batch loss 0.4517, batch acc 0.1122
14:05:02.793 Training @ 144 epoch...
14:05:03.346   Training iter 50, batch loss 0.4517, batch acc 0.1172
14:05:03.873   Training iter 100, batch loss 0.4517, batch acc 0.1182
14:05:04.397   Training iter 150, batch loss 0.4519, batch acc 0.1078
14:05:04.929   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:05:05.451   Training iter 250, batch loss 0.4519, batch acc 0.1062
14:05:05.978   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:05:06.510   Training iter 350, batch loss 0.4518, batch acc 0.1166
14:05:07.026   Training iter 400, batch loss 0.4516, batch acc 0.1178
14:05:07.541   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:05:08.061   Training iter 500, batch loss 0.4517, batch acc 0.1132
14:05:08.584   Training iter 550, batch loss 0.4518, batch acc 0.1068
14:05:09.105   Training iter 600, batch loss 0.4518, batch acc 0.1064
14:05:09.107 Training @ 145 epoch...
14:05:09.622   Training iter 50, batch loss 0.4517, batch acc 0.1120
14:05:10.132   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:05:10.613   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:05:11.095   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:05:11.581   Training iter 250, batch loss 0.4517, batch acc 0.1146
14:05:12.088   Training iter 300, batch loss 0.4517, batch acc 0.1214
14:05:12.617   Training iter 350, batch loss 0.4519, batch acc 0.1040
14:05:13.141   Training iter 400, batch loss 0.4518, batch acc 0.1124
14:05:13.658   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:05:14.182   Training iter 500, batch loss 0.4516, batch acc 0.1236
14:05:14.705   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:05:15.223   Training iter 600, batch loss 0.4518, batch acc 0.1044
14:05:15.225 Testing @ 145 epoch...
14:05:15.264     Testing, total mean loss 0.45175, total acc 0.11350
14:05:15.264 Training @ 146 epoch...
14:05:15.803   Training iter 50, batch loss 0.4518, batch acc 0.1156
14:05:16.327   Training iter 100, batch loss 0.4517, batch acc 0.1168
14:05:16.853   Training iter 150, batch loss 0.4517, batch acc 0.1144
14:05:17.370   Training iter 200, batch loss 0.4518, batch acc 0.1088
14:05:17.911   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:05:18.441   Training iter 300, batch loss 0.4517, batch acc 0.1180
14:05:18.958   Training iter 350, batch loss 0.4517, batch acc 0.1110
14:05:19.485   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:05:20.020   Training iter 450, batch loss 0.4517, batch acc 0.1148
14:05:20.551   Training iter 500, batch loss 0.4517, batch acc 0.1122
14:05:21.078   Training iter 550, batch loss 0.4518, batch acc 0.1042
14:05:21.608   Training iter 600, batch loss 0.4519, batch acc 0.1066
14:05:21.610 Training @ 147 epoch...
14:05:22.145   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:05:22.683   Training iter 100, batch loss 0.4518, batch acc 0.1128
14:05:23.217   Training iter 150, batch loss 0.4519, batch acc 0.1060
14:05:23.747   Training iter 200, batch loss 0.4518, batch acc 0.1146
14:05:24.329   Training iter 250, batch loss 0.4517, batch acc 0.1126
14:05:24.869   Training iter 300, batch loss 0.4516, batch acc 0.1220
14:05:25.425   Training iter 350, batch loss 0.4517, batch acc 0.1084
14:05:25.980   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:05:26.536   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:05:27.059   Training iter 500, batch loss 0.4518, batch acc 0.1134
14:05:27.610   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:05:28.178   Training iter 600, batch loss 0.4517, batch acc 0.1194
14:05:28.180 Training @ 148 epoch...
14:05:28.746   Training iter 50, batch loss 0.4517, batch acc 0.1184
14:05:29.313   Training iter 100, batch loss 0.4518, batch acc 0.1064
14:05:29.864   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:05:30.413   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:05:30.946   Training iter 250, batch loss 0.4516, batch acc 0.1270
14:05:31.487   Training iter 300, batch loss 0.4518, batch acc 0.1068
14:05:32.030   Training iter 350, batch loss 0.4519, batch acc 0.1104
14:05:32.569   Training iter 400, batch loss 0.4518, batch acc 0.1064
14:05:33.121   Training iter 450, batch loss 0.4517, batch acc 0.1168
14:05:33.648   Training iter 500, batch loss 0.4519, batch acc 0.1072
14:05:34.171   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:05:34.698   Training iter 600, batch loss 0.4517, batch acc 0.1094
14:05:34.700 Training @ 149 epoch...
14:05:35.243   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:05:35.772   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:05:36.302   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:05:36.822   Training iter 200, batch loss 0.4517, batch acc 0.1172
14:05:37.347   Training iter 250, batch loss 0.4518, batch acc 0.1034
14:05:37.882   Training iter 300, batch loss 0.4517, batch acc 0.1152
14:05:38.425   Training iter 350, batch loss 0.4519, batch acc 0.1086
14:05:38.951   Training iter 400, batch loss 0.4517, batch acc 0.1190
14:05:39.476   Training iter 450, batch loss 0.4517, batch acc 0.1170
14:05:40.013   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:05:40.527   Training iter 550, batch loss 0.4518, batch acc 0.1084
14:05:41.036   Training iter 600, batch loss 0.4517, batch acc 0.1158
14:05:41.038 Training @ 150 epoch...
14:05:41.557   Training iter 50, batch loss 0.4517, batch acc 0.1140
14:05:42.071   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:05:42.598   Training iter 150, batch loss 0.4518, batch acc 0.1114
14:05:43.128   Training iter 200, batch loss 0.4517, batch acc 0.1110
14:05:43.657   Training iter 250, batch loss 0.4517, batch acc 0.1134
14:05:44.177   Training iter 300, batch loss 0.4517, batch acc 0.1170
14:05:44.697   Training iter 350, batch loss 0.4518, batch acc 0.1090
14:05:45.213   Training iter 400, batch loss 0.4519, batch acc 0.1086
14:05:45.738   Training iter 450, batch loss 0.4518, batch acc 0.1120
14:05:46.286   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:05:46.819   Training iter 550, batch loss 0.4517, batch acc 0.1174
14:05:47.356   Training iter 600, batch loss 0.4518, batch acc 0.1074
14:05:47.358 Testing @ 150 epoch...
14:05:47.400     Testing, total mean loss 0.45175, total acc 0.11350
14:05:47.400 Training @ 151 epoch...
14:05:47.947   Training iter 50, batch loss 0.4517, batch acc 0.1150
14:05:48.515   Training iter 100, batch loss 0.4517, batch acc 0.1154
14:05:49.049   Training iter 150, batch loss 0.4518, batch acc 0.1102
14:05:49.586   Training iter 200, batch loss 0.4517, batch acc 0.1152
14:05:50.159   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:05:50.722   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:05:51.260   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:05:51.807   Training iter 400, batch loss 0.4517, batch acc 0.1104
14:05:52.343   Training iter 450, batch loss 0.4519, batch acc 0.1054
14:05:52.895   Training iter 500, batch loss 0.4517, batch acc 0.1122
14:05:53.438   Training iter 550, batch loss 0.4517, batch acc 0.1132
14:05:53.939   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:05:53.940 Training @ 152 epoch...
14:05:54.445   Training iter 50, batch loss 0.4518, batch acc 0.1080
14:05:54.951   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:05:55.446   Training iter 150, batch loss 0.4518, batch acc 0.1084
14:05:55.922   Training iter 200, batch loss 0.4517, batch acc 0.1130
14:05:56.389   Training iter 250, batch loss 0.4518, batch acc 0.1072
14:05:56.846   Training iter 300, batch loss 0.4517, batch acc 0.1116
14:05:57.309   Training iter 350, batch loss 0.4516, batch acc 0.1212
14:05:57.775   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:05:58.251   Training iter 450, batch loss 0.4518, batch acc 0.1122
14:05:58.732   Training iter 500, batch loss 0.4517, batch acc 0.1108
14:05:59.196   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:05:59.648   Training iter 600, batch loss 0.4518, batch acc 0.1138
14:05:59.649 Training @ 153 epoch...
14:06:00.115   Training iter 50, batch loss 0.4519, batch acc 0.1092
14:06:00.596   Training iter 100, batch loss 0.4517, batch acc 0.1124
14:06:01.051   Training iter 150, batch loss 0.4517, batch acc 0.1130
14:06:01.599   Training iter 200, batch loss 0.4518, batch acc 0.1120
14:06:02.137   Training iter 250, batch loss 0.4518, batch acc 0.1136
14:06:02.641   Training iter 300, batch loss 0.4519, batch acc 0.1028
14:06:03.178   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:06:03.696   Training iter 400, batch loss 0.4516, batch acc 0.1198
14:06:04.206   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:06:04.711   Training iter 500, batch loss 0.4517, batch acc 0.1136
14:06:05.208   Training iter 550, batch loss 0.4518, batch acc 0.1156
14:06:05.725   Training iter 600, batch loss 0.4517, batch acc 0.1156
14:06:05.727 Training @ 154 epoch...
14:06:06.227   Training iter 50, batch loss 0.4519, batch acc 0.1098
14:06:06.740   Training iter 100, batch loss 0.4517, batch acc 0.1174
14:06:07.220   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:06:07.696   Training iter 200, batch loss 0.4517, batch acc 0.1114
14:06:08.185   Training iter 250, batch loss 0.4516, batch acc 0.1184
14:06:08.682   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:06:09.152   Training iter 350, batch loss 0.4518, batch acc 0.1130
14:06:09.657   Training iter 400, batch loss 0.4517, batch acc 0.1146
14:06:10.192   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:06:10.721   Training iter 500, batch loss 0.4518, batch acc 0.1084
14:06:11.227   Training iter 550, batch loss 0.4517, batch acc 0.1140
14:06:11.725   Training iter 600, batch loss 0.4517, batch acc 0.1138
14:06:11.726 Training @ 155 epoch...
14:06:12.255   Training iter 50, batch loss 0.4518, batch acc 0.1046
14:06:12.786   Training iter 100, batch loss 0.4516, batch acc 0.1226
14:06:13.369   Training iter 150, batch loss 0.4517, batch acc 0.1166
14:06:13.906   Training iter 200, batch loss 0.4518, batch acc 0.1072
14:06:14.467   Training iter 250, batch loss 0.4518, batch acc 0.1086
14:06:15.001   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:06:15.546   Training iter 350, batch loss 0.4518, batch acc 0.1100
14:06:16.070   Training iter 400, batch loss 0.4518, batch acc 0.1104
14:06:16.591   Training iter 450, batch loss 0.4517, batch acc 0.1146
14:06:17.120   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:06:17.636   Training iter 550, batch loss 0.4519, batch acc 0.1070
14:06:18.147   Training iter 600, batch loss 0.4516, batch acc 0.1206
14:06:18.148 Testing @ 155 epoch...
14:06:18.188     Testing, total mean loss 0.45175, total acc 0.11350
14:06:18.188 Training @ 156 epoch...
14:06:18.721   Training iter 50, batch loss 0.4518, batch acc 0.1136
14:06:19.233   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:06:19.744   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:06:20.263   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:06:20.777   Training iter 250, batch loss 0.4517, batch acc 0.1118
14:06:21.301   Training iter 300, batch loss 0.4519, batch acc 0.1060
14:06:21.805   Training iter 350, batch loss 0.4517, batch acc 0.1130
14:06:22.302   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:06:22.799   Training iter 450, batch loss 0.4518, batch acc 0.1112
14:06:23.315   Training iter 500, batch loss 0.4517, batch acc 0.1184
14:06:23.790   Training iter 550, batch loss 0.4517, batch acc 0.1174
14:06:24.256   Training iter 600, batch loss 0.4517, batch acc 0.1128
14:06:24.257 Training @ 157 epoch...
14:06:24.767   Training iter 50, batch loss 0.4517, batch acc 0.1154
14:06:25.286   Training iter 100, batch loss 0.4517, batch acc 0.1132
14:06:25.811   Training iter 150, batch loss 0.4518, batch acc 0.1114
14:06:26.323   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:06:26.829   Training iter 250, batch loss 0.4517, batch acc 0.1188
14:06:27.336   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:06:27.850   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:06:28.357   Training iter 400, batch loss 0.4518, batch acc 0.1076
14:06:28.852   Training iter 450, batch loss 0.4518, batch acc 0.1158
14:06:29.375   Training iter 500, batch loss 0.4518, batch acc 0.1096
14:06:29.886   Training iter 550, batch loss 0.4518, batch acc 0.1110
14:06:30.396   Training iter 600, batch loss 0.4517, batch acc 0.1134
14:06:30.398 Training @ 158 epoch...
14:06:30.900   Training iter 50, batch loss 0.4517, batch acc 0.1162
14:06:31.395   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:06:31.910   Training iter 150, batch loss 0.4518, batch acc 0.1138
14:06:32.416   Training iter 200, batch loss 0.4519, batch acc 0.1040
14:06:32.924   Training iter 250, batch loss 0.4518, batch acc 0.1146
14:06:33.433   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:06:33.932   Training iter 350, batch loss 0.4518, batch acc 0.1128
14:06:34.438   Training iter 400, batch loss 0.4517, batch acc 0.1142
14:06:34.965   Training iter 450, batch loss 0.4518, batch acc 0.1130
14:06:35.487   Training iter 500, batch loss 0.4517, batch acc 0.1112
14:06:36.005   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:06:36.519   Training iter 600, batch loss 0.4517, batch acc 0.1128
14:06:36.521 Training @ 159 epoch...
14:06:37.042   Training iter 50, batch loss 0.4517, batch acc 0.1174
14:06:37.557   Training iter 100, batch loss 0.4517, batch acc 0.1106
14:06:38.077   Training iter 150, batch loss 0.4517, batch acc 0.1178
14:06:38.595   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:06:39.114   Training iter 250, batch loss 0.4518, batch acc 0.1174
14:06:39.634   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:06:40.161   Training iter 350, batch loss 0.4517, batch acc 0.1156
14:06:40.688   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:06:41.220   Training iter 450, batch loss 0.4518, batch acc 0.1034
14:06:41.739   Training iter 500, batch loss 0.4518, batch acc 0.1152
14:06:42.261   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:06:42.784   Training iter 600, batch loss 0.4518, batch acc 0.1064
14:06:42.785 Training @ 160 epoch...
14:06:43.319   Training iter 50, batch loss 0.4518, batch acc 0.1100
14:06:43.833   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:06:44.377   Training iter 150, batch loss 0.4517, batch acc 0.1178
14:06:44.914   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:06:45.473   Training iter 250, batch loss 0.4517, batch acc 0.1138
14:06:46.013   Training iter 300, batch loss 0.4517, batch acc 0.1120
14:06:46.558   Training iter 350, batch loss 0.4518, batch acc 0.1178
14:06:47.115   Training iter 400, batch loss 0.4518, batch acc 0.1146
14:06:47.675   Training iter 450, batch loss 0.4518, batch acc 0.1132
14:06:48.258   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:06:48.831   Training iter 550, batch loss 0.4517, batch acc 0.1118
14:06:49.395   Training iter 600, batch loss 0.4518, batch acc 0.1076
14:06:49.397 Testing @ 160 epoch...
14:06:49.439     Testing, total mean loss 0.45175, total acc 0.11350
14:06:49.439 Training @ 161 epoch...
14:06:50.017   Training iter 50, batch loss 0.4518, batch acc 0.1058
14:06:50.602   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:06:51.160   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:06:51.711   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:06:52.280   Training iter 250, batch loss 0.4517, batch acc 0.1160
14:06:52.855   Training iter 300, batch loss 0.4518, batch acc 0.1118
14:06:53.396   Training iter 350, batch loss 0.4518, batch acc 0.1116
14:06:53.930   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:06:54.460   Training iter 450, batch loss 0.4517, batch acc 0.1098
14:06:55.007   Training iter 500, batch loss 0.4517, batch acc 0.1180
14:06:55.575   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:06:56.105   Training iter 600, batch loss 0.4518, batch acc 0.1126
14:06:56.106 Training @ 162 epoch...
14:06:56.629   Training iter 50, batch loss 0.4517, batch acc 0.1138
14:06:57.164   Training iter 100, batch loss 0.4517, batch acc 0.1168
14:06:57.724   Training iter 150, batch loss 0.4518, batch acc 0.1088
14:06:58.256   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:06:58.779   Training iter 250, batch loss 0.4517, batch acc 0.1096
14:06:59.293   Training iter 300, batch loss 0.4518, batch acc 0.1074
14:06:59.809   Training iter 350, batch loss 0.4518, batch acc 0.1166
14:07:00.340   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:07:00.862   Training iter 450, batch loss 0.4518, batch acc 0.1076
14:07:01.433   Training iter 500, batch loss 0.4518, batch acc 0.1114
14:07:01.993   Training iter 550, batch loss 0.4518, batch acc 0.1160
14:07:02.545   Training iter 600, batch loss 0.4518, batch acc 0.1126
14:07:02.547 Training @ 163 epoch...
14:07:03.123   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:07:03.689   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:07:04.249   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:07:04.803   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:07:05.354   Training iter 250, batch loss 0.4518, batch acc 0.1128
14:07:05.893   Training iter 300, batch loss 0.4517, batch acc 0.1116
14:07:06.431   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:07:06.946   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:07:07.446   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:07:07.946   Training iter 500, batch loss 0.4517, batch acc 0.1200
14:07:08.456   Training iter 550, batch loss 0.4518, batch acc 0.1116
14:07:08.952   Training iter 600, batch loss 0.4517, batch acc 0.1196
14:07:08.953 Training @ 164 epoch...
14:07:09.459   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:07:09.958   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:07:10.463   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:07:10.951   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:07:11.444   Training iter 250, batch loss 0.4516, batch acc 0.1202
14:07:11.947   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:07:12.463   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:07:12.995   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:07:13.573   Training iter 450, batch loss 0.4518, batch acc 0.1070
14:07:14.149   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:07:14.695   Training iter 550, batch loss 0.4518, batch acc 0.1076
14:07:15.194   Training iter 600, batch loss 0.4519, batch acc 0.1040
14:07:15.196 Training @ 165 epoch...
14:07:15.727   Training iter 50, batch loss 0.4517, batch acc 0.1160
14:07:16.237   Training iter 100, batch loss 0.4517, batch acc 0.1222
14:07:16.767   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:07:17.310   Training iter 200, batch loss 0.4518, batch acc 0.1076
14:07:17.838   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:07:18.342   Training iter 300, batch loss 0.4518, batch acc 0.1122
14:07:18.859   Training iter 350, batch loss 0.4517, batch acc 0.1180
14:07:19.371   Training iter 400, batch loss 0.4517, batch acc 0.1106
14:07:19.877   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:07:20.405   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:07:20.935   Training iter 550, batch loss 0.4518, batch acc 0.1070
14:07:21.467   Training iter 600, batch loss 0.4518, batch acc 0.1126
14:07:21.469 Testing @ 165 epoch...
14:07:21.509     Testing, total mean loss 0.45175, total acc 0.11350
14:07:21.509 Training @ 166 epoch...
14:07:22.048   Training iter 50, batch loss 0.4517, batch acc 0.1170
14:07:22.591   Training iter 100, batch loss 0.4517, batch acc 0.1178
14:07:23.132   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:07:23.675   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:07:24.218   Training iter 250, batch loss 0.4519, batch acc 0.1026
14:07:24.765   Training iter 300, batch loss 0.4517, batch acc 0.1170
14:07:25.313   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:07:25.846   Training iter 400, batch loss 0.4517, batch acc 0.1190
14:07:26.376   Training iter 450, batch loss 0.4518, batch acc 0.1050
14:07:26.900   Training iter 500, batch loss 0.4518, batch acc 0.1108
14:07:27.423   Training iter 550, batch loss 0.4518, batch acc 0.1132
14:07:27.946   Training iter 600, batch loss 0.4518, batch acc 0.1094
14:07:27.948 Training @ 167 epoch...
14:07:28.479   Training iter 50, batch loss 0.4518, batch acc 0.1110
14:07:29.012   Training iter 100, batch loss 0.4517, batch acc 0.1132
14:07:29.545   Training iter 150, batch loss 0.4517, batch acc 0.1126
14:07:30.081   Training iter 200, batch loss 0.4518, batch acc 0.1056
14:07:30.613   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:07:31.141   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:07:31.660   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:07:32.175   Training iter 400, batch loss 0.4518, batch acc 0.1120
14:07:32.692   Training iter 450, batch loss 0.4518, batch acc 0.1122
14:07:33.228   Training iter 500, batch loss 0.4517, batch acc 0.1148
14:07:33.731   Training iter 550, batch loss 0.4517, batch acc 0.1170
14:07:34.240   Training iter 600, batch loss 0.4518, batch acc 0.1138
14:07:34.242 Training @ 168 epoch...
14:07:34.753   Training iter 50, batch loss 0.4518, batch acc 0.1078
14:07:35.244   Training iter 100, batch loss 0.4517, batch acc 0.1108
14:07:35.716   Training iter 150, batch loss 0.4518, batch acc 0.1072
14:07:36.183   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:07:36.655   Training iter 250, batch loss 0.4517, batch acc 0.1154
14:07:37.122   Training iter 300, batch loss 0.4517, batch acc 0.1140
14:07:37.631   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:07:38.082   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:07:38.556   Training iter 450, batch loss 0.4516, batch acc 0.1230
14:07:39.034   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:07:39.508   Training iter 550, batch loss 0.4518, batch acc 0.1090
14:07:39.991   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:07:39.993 Training @ 169 epoch...
14:07:40.471   Training iter 50, batch loss 0.4519, batch acc 0.1052
14:07:40.929   Training iter 100, batch loss 0.4517, batch acc 0.1142
14:07:41.401   Training iter 150, batch loss 0.4517, batch acc 0.1220
14:07:41.872   Training iter 200, batch loss 0.4518, batch acc 0.1054
14:07:42.343   Training iter 250, batch loss 0.4518, batch acc 0.1138
14:07:42.824   Training iter 300, batch loss 0.4517, batch acc 0.1172
14:07:43.450   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:07:43.952   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:07:44.425   Training iter 450, batch loss 0.4517, batch acc 0.1128
14:07:44.904   Training iter 500, batch loss 0.4517, batch acc 0.1154
14:07:45.372   Training iter 550, batch loss 0.4517, batch acc 0.1104
14:07:45.840   Training iter 600, batch loss 0.4519, batch acc 0.1020
14:07:45.842 Training @ 170 epoch...
14:07:46.329   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:07:46.798   Training iter 100, batch loss 0.4517, batch acc 0.1120
14:07:47.261   Training iter 150, batch loss 0.4518, batch acc 0.1038
14:07:47.732   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:07:48.201   Training iter 250, batch loss 0.4518, batch acc 0.1146
14:07:48.661   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:07:49.125   Training iter 350, batch loss 0.4518, batch acc 0.1166
14:07:49.590   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:07:50.062   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:07:50.533   Training iter 500, batch loss 0.4518, batch acc 0.1114
14:07:51.012   Training iter 550, batch loss 0.4519, batch acc 0.1102
14:07:51.484   Training iter 600, batch loss 0.4517, batch acc 0.1180
14:07:51.485 Testing @ 170 epoch...
14:07:51.524     Testing, total mean loss 0.45175, total acc 0.11350
14:07:51.525 Training @ 171 epoch...
14:07:52.010   Training iter 50, batch loss 0.4517, batch acc 0.1128
14:07:52.490   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:07:52.974   Training iter 150, batch loss 0.4517, batch acc 0.1082
14:07:53.460   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:07:53.978   Training iter 250, batch loss 0.4517, batch acc 0.1130
14:07:54.499   Training iter 300, batch loss 0.4518, batch acc 0.1118
14:07:55.045   Training iter 350, batch loss 0.4518, batch acc 0.1138
14:07:55.586   Training iter 400, batch loss 0.4517, batch acc 0.1160
14:07:56.135   Training iter 450, batch loss 0.4518, batch acc 0.1074
14:07:56.691   Training iter 500, batch loss 0.4517, batch acc 0.1102
14:07:57.252   Training iter 550, batch loss 0.4518, batch acc 0.1190
14:07:57.810   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:07:57.812 Training @ 172 epoch...
14:07:58.363   Training iter 50, batch loss 0.4518, batch acc 0.1134
14:07:58.905   Training iter 100, batch loss 0.4517, batch acc 0.1142
14:07:59.431   Training iter 150, batch loss 0.4519, batch acc 0.1096
14:07:59.947   Training iter 200, batch loss 0.4517, batch acc 0.1124
14:08:00.467   Training iter 250, batch loss 0.4518, batch acc 0.1092
14:08:00.975   Training iter 300, batch loss 0.4517, batch acc 0.1082
14:08:01.505   Training iter 350, batch loss 0.4518, batch acc 0.1084
14:08:02.060   Training iter 400, batch loss 0.4517, batch acc 0.1152
14:08:02.612   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:08:03.167   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:08:03.727   Training iter 550, batch loss 0.4517, batch acc 0.1146
14:08:04.282   Training iter 600, batch loss 0.4518, batch acc 0.1170
14:08:04.283 Training @ 173 epoch...
14:08:04.851   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:08:05.406   Training iter 100, batch loss 0.4519, batch acc 0.1092
14:08:05.973   Training iter 150, batch loss 0.4517, batch acc 0.1094
14:08:06.521   Training iter 200, batch loss 0.4518, batch acc 0.1130
14:08:07.075   Training iter 250, batch loss 0.4518, batch acc 0.1042
14:08:07.600   Training iter 300, batch loss 0.4517, batch acc 0.1188
14:08:08.133   Training iter 350, batch loss 0.4518, batch acc 0.1124
14:08:08.656   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:08:09.167   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:08:09.686   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:08:10.212   Training iter 550, batch loss 0.4517, batch acc 0.1172
14:08:10.784   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:08:10.786 Training @ 174 epoch...
14:08:11.372   Training iter 50, batch loss 0.4517, batch acc 0.1094
14:08:11.971   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:08:12.515   Training iter 150, batch loss 0.4518, batch acc 0.1104
14:08:13.021   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:08:13.540   Training iter 250, batch loss 0.4517, batch acc 0.1130
14:08:14.050   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:08:14.552   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:08:15.057   Training iter 400, batch loss 0.4518, batch acc 0.1152
14:08:15.570   Training iter 450, batch loss 0.4518, batch acc 0.1126
14:08:16.127   Training iter 500, batch loss 0.4517, batch acc 0.1124
14:08:17.122   Training iter 550, batch loss 0.4517, batch acc 0.1150
14:08:17.656   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:08:17.658 Training @ 175 epoch...
14:08:18.165   Training iter 50, batch loss 0.4516, batch acc 0.1200
14:08:18.687   Training iter 100, batch loss 0.4518, batch acc 0.1088
14:08:19.184   Training iter 150, batch loss 0.4518, batch acc 0.1160
14:08:19.685   Training iter 200, batch loss 0.4517, batch acc 0.1156
14:08:20.202   Training iter 250, batch loss 0.4517, batch acc 0.1176
14:08:20.729   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:08:21.281   Training iter 350, batch loss 0.4518, batch acc 0.1106
14:08:21.796   Training iter 400, batch loss 0.4518, batch acc 0.1118
14:08:22.318   Training iter 450, batch loss 0.4518, batch acc 0.1072
14:08:22.832   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:08:23.344   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:08:23.854   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:08:23.856 Testing @ 175 epoch...
14:08:23.894     Testing, total mean loss 0.45174, total acc 0.11350
14:08:23.894 Training @ 176 epoch...
14:08:24.439   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:08:24.967   Training iter 100, batch loss 0.4518, batch acc 0.1120
14:08:25.487   Training iter 150, batch loss 0.4518, batch acc 0.1076
14:08:25.991   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:08:26.500   Training iter 250, batch loss 0.4517, batch acc 0.1132
14:08:27.010   Training iter 300, batch loss 0.4518, batch acc 0.1072
14:08:27.528   Training iter 350, batch loss 0.4518, batch acc 0.1152
14:08:28.049   Training iter 400, batch loss 0.4516, batch acc 0.1216
14:08:28.555   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:08:29.059   Training iter 500, batch loss 0.4519, batch acc 0.1062
14:08:29.585   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:08:30.081   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:08:30.083 Training @ 177 epoch...
14:08:30.592   Training iter 50, batch loss 0.4518, batch acc 0.1142
14:08:31.070   Training iter 100, batch loss 0.4517, batch acc 0.1188
14:08:31.537   Training iter 150, batch loss 0.4518, batch acc 0.1066
14:08:31.990   Training iter 200, batch loss 0.4518, batch acc 0.1082
14:08:32.437   Training iter 250, batch loss 0.4516, batch acc 0.1158
14:08:32.907   Training iter 300, batch loss 0.4518, batch acc 0.1120
14:08:33.394   Training iter 350, batch loss 0.4518, batch acc 0.1168
14:08:33.869   Training iter 400, batch loss 0.4517, batch acc 0.1122
14:08:34.333   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:08:34.819   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:08:35.292   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:08:35.763   Training iter 600, batch loss 0.4517, batch acc 0.1098
14:08:35.765 Training @ 178 epoch...
14:08:36.256   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:08:36.749   Training iter 100, batch loss 0.4517, batch acc 0.1168
14:08:37.245   Training iter 150, batch loss 0.4517, batch acc 0.1184
14:08:37.753   Training iter 200, batch loss 0.4518, batch acc 0.1040
14:08:38.259   Training iter 250, batch loss 0.4518, batch acc 0.1126
14:08:38.751   Training iter 300, batch loss 0.4517, batch acc 0.1166
14:08:39.238   Training iter 350, batch loss 0.4518, batch acc 0.1064
14:08:39.735   Training iter 400, batch loss 0.4518, batch acc 0.1078
14:08:40.240   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:08:40.742   Training iter 500, batch loss 0.4518, batch acc 0.1096
14:08:41.262   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:08:41.770   Training iter 600, batch loss 0.4517, batch acc 0.1210
14:08:41.771 Training @ 179 epoch...
14:08:42.302   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:08:42.845   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:08:43.385   Training iter 150, batch loss 0.4518, batch acc 0.1074
14:08:43.905   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:08:44.450   Training iter 250, batch loss 0.4517, batch acc 0.1164
14:08:45.001   Training iter 300, batch loss 0.4516, batch acc 0.1234
14:08:45.543   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:08:46.079   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:08:46.564   Training iter 450, batch loss 0.4518, batch acc 0.1090
14:08:47.059   Training iter 500, batch loss 0.4519, batch acc 0.1038
14:08:47.561   Training iter 550, batch loss 0.4517, batch acc 0.1194
14:08:48.078   Training iter 600, batch loss 0.4519, batch acc 0.1114
14:08:48.080 Training @ 180 epoch...
14:08:48.607   Training iter 50, batch loss 0.4518, batch acc 0.1114
14:08:49.109   Training iter 100, batch loss 0.4517, batch acc 0.1186
14:08:49.613   Training iter 150, batch loss 0.4517, batch acc 0.1110
14:08:50.120   Training iter 200, batch loss 0.4518, batch acc 0.1116
14:08:50.623   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:08:51.120   Training iter 300, batch loss 0.4517, batch acc 0.1148
14:08:51.635   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:08:52.140   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:08:52.655   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:08:53.166   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:08:53.678   Training iter 550, batch loss 0.4518, batch acc 0.1082
14:08:54.178   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:08:54.180 Testing @ 180 epoch...
14:08:54.219     Testing, total mean loss 0.45174, total acc 0.11350
14:08:54.219 Training @ 181 epoch...
14:08:54.736   Training iter 50, batch loss 0.4517, batch acc 0.1158
14:08:55.269   Training iter 100, batch loss 0.4518, batch acc 0.1164
14:08:55.808   Training iter 150, batch loss 0.4518, batch acc 0.1118
14:08:56.326   Training iter 200, batch loss 0.4517, batch acc 0.1174
14:08:56.832   Training iter 250, batch loss 0.4519, batch acc 0.1062
14:08:57.337   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:08:57.859   Training iter 350, batch loss 0.4517, batch acc 0.1116
14:08:58.385   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:08:58.901   Training iter 450, batch loss 0.4517, batch acc 0.1182
14:08:59.416   Training iter 500, batch loss 0.4518, batch acc 0.1090
14:08:59.935   Training iter 550, batch loss 0.4518, batch acc 0.1074
14:09:00.452   Training iter 600, batch loss 0.4517, batch acc 0.1142
14:09:00.453 Training @ 182 epoch...
14:09:00.968   Training iter 50, batch loss 0.4519, batch acc 0.1030
14:09:01.471   Training iter 100, batch loss 0.4517, batch acc 0.1100
14:09:02.029   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:09:02.533   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:09:03.027   Training iter 250, batch loss 0.4517, batch acc 0.1232
14:09:03.517   Training iter 300, batch loss 0.4518, batch acc 0.1160
14:09:04.014   Training iter 350, batch loss 0.4517, batch acc 0.1142
14:09:04.516   Training iter 400, batch loss 0.4518, batch acc 0.1060
14:09:05.022   Training iter 450, batch loss 0.4516, batch acc 0.1154
14:09:05.522   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:09:06.027   Training iter 550, batch loss 0.4517, batch acc 0.1156
14:09:06.512   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:09:06.513 Training @ 183 epoch...
14:09:07.024   Training iter 50, batch loss 0.4517, batch acc 0.1168
14:09:07.509   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:09:08.003   Training iter 150, batch loss 0.4517, batch acc 0.1142
14:09:08.484   Training iter 200, batch loss 0.4518, batch acc 0.1118
14:09:08.976   Training iter 250, batch loss 0.4517, batch acc 0.1088
14:09:09.470   Training iter 300, batch loss 0.4517, batch acc 0.1178
14:09:09.984   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:09:10.512   Training iter 400, batch loss 0.4517, batch acc 0.1124
14:09:11.041   Training iter 450, batch loss 0.4518, batch acc 0.1142
14:09:11.554   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:09:12.069   Training iter 550, batch loss 0.4518, batch acc 0.1096
14:09:12.588   Training iter 600, batch loss 0.4518, batch acc 0.1076
14:09:12.589 Training @ 184 epoch...
14:09:13.103   Training iter 50, batch loss 0.4517, batch acc 0.1180
14:09:13.627   Training iter 100, batch loss 0.4517, batch acc 0.1126
14:09:14.139   Training iter 150, batch loss 0.4518, batch acc 0.1084
14:09:14.649   Training iter 200, batch loss 0.4517, batch acc 0.1188
14:09:15.150   Training iter 250, batch loss 0.4517, batch acc 0.1132
14:09:15.652   Training iter 300, batch loss 0.4517, batch acc 0.1096
14:09:16.170   Training iter 350, batch loss 0.4519, batch acc 0.1042
14:09:16.696   Training iter 400, batch loss 0.4517, batch acc 0.1174
14:09:17.213   Training iter 450, batch loss 0.4518, batch acc 0.1140
14:09:17.727   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:09:18.246   Training iter 550, batch loss 0.4518, batch acc 0.1138
14:09:18.771   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:09:18.773 Training @ 185 epoch...
14:09:19.289   Training iter 50, batch loss 0.4517, batch acc 0.1136
14:09:19.818   Training iter 100, batch loss 0.4519, batch acc 0.1076
14:09:20.343   Training iter 150, batch loss 0.4516, batch acc 0.1122
14:09:20.863   Training iter 200, batch loss 0.4517, batch acc 0.1186
14:09:21.369   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:09:21.881   Training iter 300, batch loss 0.4518, batch acc 0.1106
14:09:22.389   Training iter 350, batch loss 0.4517, batch acc 0.1150
14:09:22.905   Training iter 400, batch loss 0.4517, batch acc 0.1186
14:09:23.427   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:09:23.928   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:09:24.435   Training iter 550, batch loss 0.4519, batch acc 0.1048
14:09:24.955   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:09:24.957 Testing @ 185 epoch...
14:09:24.996     Testing, total mean loss 0.45174, total acc 0.11350
14:09:24.996 Training @ 186 epoch...
14:09:25.540   Training iter 50, batch loss 0.4517, batch acc 0.1146
14:09:26.055   Training iter 100, batch loss 0.4516, batch acc 0.1224
14:09:26.541   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:09:27.028   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:09:27.521   Training iter 250, batch loss 0.4517, batch acc 0.1126
14:09:28.030   Training iter 300, batch loss 0.4518, batch acc 0.1142
14:09:28.526   Training iter 350, batch loss 0.4517, batch acc 0.1150
14:09:29.028   Training iter 400, batch loss 0.4517, batch acc 0.1156
14:09:29.511   Training iter 450, batch loss 0.4518, batch acc 0.1040
14:09:30.021   Training iter 500, batch loss 0.4517, batch acc 0.1126
14:09:30.550   Training iter 550, batch loss 0.4517, batch acc 0.1140
14:09:31.076   Training iter 600, batch loss 0.4519, batch acc 0.1052
14:09:31.078 Training @ 187 epoch...
14:09:31.605   Training iter 50, batch loss 0.4518, batch acc 0.1100
14:09:32.121   Training iter 100, batch loss 0.4518, batch acc 0.1080
14:09:32.643   Training iter 150, batch loss 0.4518, batch acc 0.1090
14:09:33.170   Training iter 200, batch loss 0.4518, batch acc 0.1090
14:09:33.687   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:09:34.189   Training iter 300, batch loss 0.4517, batch acc 0.1174
14:09:34.696   Training iter 350, batch loss 0.4518, batch acc 0.1150
14:09:35.190   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:09:35.652   Training iter 450, batch loss 0.4517, batch acc 0.1110
14:09:36.156   Training iter 500, batch loss 0.4516, batch acc 0.1198
14:09:36.657   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:09:37.173   Training iter 600, batch loss 0.4517, batch acc 0.1096
14:09:37.174 Training @ 188 epoch...
14:09:37.685   Training iter 50, batch loss 0.4517, batch acc 0.1216
14:09:38.193   Training iter 100, batch loss 0.4518, batch acc 0.1100
14:09:38.691   Training iter 150, batch loss 0.4518, batch acc 0.1022
14:09:39.189   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:09:39.695   Training iter 250, batch loss 0.4517, batch acc 0.1152
14:09:40.215   Training iter 300, batch loss 0.4518, batch acc 0.1068
14:09:40.719   Training iter 350, batch loss 0.4518, batch acc 0.1100
14:09:41.230   Training iter 400, batch loss 0.4518, batch acc 0.1094
14:09:41.731   Training iter 450, batch loss 0.4517, batch acc 0.1156
14:09:42.240   Training iter 500, batch loss 0.4517, batch acc 0.1120
14:09:42.740   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:09:43.252   Training iter 600, batch loss 0.4517, batch acc 0.1186
14:09:43.253 Training @ 189 epoch...
14:09:43.790   Training iter 50, batch loss 0.4518, batch acc 0.1130
14:09:44.328   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:09:44.864   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:09:45.410   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:09:45.951   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:09:46.473   Training iter 300, batch loss 0.4517, batch acc 0.1178
14:09:46.995   Training iter 350, batch loss 0.4516, batch acc 0.1168
14:09:47.504   Training iter 400, batch loss 0.4518, batch acc 0.1082
14:09:48.021   Training iter 450, batch loss 0.4517, batch acc 0.1174
14:09:48.546   Training iter 500, batch loss 0.4518, batch acc 0.1068
14:09:49.073   Training iter 550, batch loss 0.4518, batch acc 0.1148
14:09:49.577   Training iter 600, batch loss 0.4517, batch acc 0.1120
14:09:49.579 Training @ 190 epoch...
14:09:50.078   Training iter 50, batch loss 0.4517, batch acc 0.1166
14:09:50.574   Training iter 100, batch loss 0.4518, batch acc 0.1108
14:09:51.064   Training iter 150, batch loss 0.4518, batch acc 0.1024
14:09:51.562   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:09:52.061   Training iter 250, batch loss 0.4517, batch acc 0.1184
14:09:52.583   Training iter 300, batch loss 0.4517, batch acc 0.1120
14:09:53.117   Training iter 350, batch loss 0.4518, batch acc 0.1116
14:09:53.643   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:09:54.157   Training iter 450, batch loss 0.4518, batch acc 0.1166
14:09:54.673   Training iter 500, batch loss 0.4517, batch acc 0.1150
14:09:55.206   Training iter 550, batch loss 0.4517, batch acc 0.1142
14:09:55.727   Training iter 600, batch loss 0.4518, batch acc 0.1122
14:09:55.729 Testing @ 190 epoch...
14:09:55.767     Testing, total mean loss 0.45174, total acc 0.11350
14:09:55.767 Training @ 191 epoch...
14:09:56.292   Training iter 50, batch loss 0.4519, batch acc 0.1058
14:09:56.798   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:09:57.328   Training iter 150, batch loss 0.4518, batch acc 0.1146
14:09:57.909   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:09:58.439   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:09:58.991   Training iter 300, batch loss 0.4516, batch acc 0.1208
14:09:59.562   Training iter 350, batch loss 0.4517, batch acc 0.1136
14:10:00.167   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:10:00.783   Training iter 450, batch loss 0.4517, batch acc 0.1182
14:10:01.391   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:10:02.057   Training iter 550, batch loss 0.4518, batch acc 0.1066
14:10:02.734   Training iter 600, batch loss 0.4517, batch acc 0.1148
14:10:02.736 Training @ 192 epoch...
14:10:03.317   Training iter 50, batch loss 0.4518, batch acc 0.1112
14:10:03.883   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:10:04.489   Training iter 150, batch loss 0.4517, batch acc 0.1200
14:10:05.047   Training iter 200, batch loss 0.4517, batch acc 0.1116
14:10:05.606   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:10:06.163   Training iter 300, batch loss 0.4518, batch acc 0.1020
14:10:06.689   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:10:07.189   Training iter 400, batch loss 0.4517, batch acc 0.1144
14:10:07.675   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:10:08.193   Training iter 500, batch loss 0.4518, batch acc 0.1140
14:10:08.731   Training iter 550, batch loss 0.4517, batch acc 0.1122
14:10:09.259   Training iter 600, batch loss 0.4518, batch acc 0.1062
14:10:09.260 Training @ 193 epoch...
14:10:09.764   Training iter 50, batch loss 0.4517, batch acc 0.1162
14:10:10.271   Training iter 100, batch loss 0.4518, batch acc 0.1120
14:10:10.771   Training iter 150, batch loss 0.4518, batch acc 0.1170
14:10:11.253   Training iter 200, batch loss 0.4517, batch acc 0.1138
14:10:11.730   Training iter 250, batch loss 0.4518, batch acc 0.1122
14:10:12.240   Training iter 300, batch loss 0.4517, batch acc 0.1180
14:10:12.750   Training iter 350, batch loss 0.4518, batch acc 0.1050
14:10:13.292   Training iter 400, batch loss 0.4517, batch acc 0.1130
14:10:13.837   Training iter 450, batch loss 0.4518, batch acc 0.1062
14:10:14.354   Training iter 500, batch loss 0.4517, batch acc 0.1148
14:10:14.867   Training iter 550, batch loss 0.4519, batch acc 0.1042
14:10:15.385   Training iter 600, batch loss 0.4516, batch acc 0.1160
14:10:15.387 Training @ 194 epoch...
14:10:15.917   Training iter 50, batch loss 0.4517, batch acc 0.1146
14:10:16.437   Training iter 100, batch loss 0.4518, batch acc 0.1056
14:10:16.959   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:10:17.480   Training iter 200, batch loss 0.4518, batch acc 0.1060
14:10:17.957   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:10:18.423   Training iter 300, batch loss 0.4518, batch acc 0.1110
14:10:18.892   Training iter 350, batch loss 0.4516, batch acc 0.1174
14:10:19.390   Training iter 400, batch loss 0.4517, batch acc 0.1104
14:10:19.880   Training iter 450, batch loss 0.4518, batch acc 0.1150
14:10:20.366   Training iter 500, batch loss 0.4518, batch acc 0.1158
14:10:20.843   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:10:21.308   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:10:21.310 Training @ 195 epoch...
14:10:21.789   Training iter 50, batch loss 0.4518, batch acc 0.1134
14:10:22.274   Training iter 100, batch loss 0.4518, batch acc 0.1094
14:10:22.750   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:10:23.241   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:10:23.734   Training iter 250, batch loss 0.4518, batch acc 0.1072
14:10:24.240   Training iter 300, batch loss 0.4517, batch acc 0.1170
14:10:24.754   Training iter 350, batch loss 0.4517, batch acc 0.1212
14:10:25.281   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:10:25.779   Training iter 450, batch loss 0.4518, batch acc 0.1090
14:10:26.284   Training iter 500, batch loss 0.4518, batch acc 0.1158
14:10:26.780   Training iter 550, batch loss 0.4517, batch acc 0.1086
14:10:27.299   Training iter 600, batch loss 0.4518, batch acc 0.1122
14:10:27.301 Testing @ 195 epoch...
14:10:27.340     Testing, total mean loss 0.45174, total acc 0.11350
14:10:27.341 Training @ 196 epoch...
14:10:27.871   Training iter 50, batch loss 0.4516, batch acc 0.1164
14:10:28.370   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:10:28.889   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:10:29.423   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:10:29.994   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:10:30.566   Training iter 300, batch loss 0.4517, batch acc 0.1178
14:10:31.133   Training iter 350, batch loss 0.4517, batch acc 0.1116
14:10:31.708   Training iter 400, batch loss 0.4518, batch acc 0.1152
14:10:32.293   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:10:32.891   Training iter 500, batch loss 0.4518, batch acc 0.1082
14:10:33.493   Training iter 550, batch loss 0.4519, batch acc 0.1072
14:10:34.084   Training iter 600, batch loss 0.4517, batch acc 0.1182
14:10:34.086 Training @ 197 epoch...
14:10:34.694   Training iter 50, batch loss 0.4518, batch acc 0.1056
14:10:35.233   Training iter 100, batch loss 0.4517, batch acc 0.1164
14:10:35.766   Training iter 150, batch loss 0.4518, batch acc 0.1074
14:10:36.286   Training iter 200, batch loss 0.4517, batch acc 0.1142
14:10:36.813   Training iter 250, batch loss 0.4517, batch acc 0.1160
14:10:37.334   Training iter 300, batch loss 0.4518, batch acc 0.1126
14:10:37.857   Training iter 350, batch loss 0.4517, batch acc 0.1142
14:10:38.360   Training iter 400, batch loss 0.4517, batch acc 0.1110
14:10:38.859   Training iter 450, batch loss 0.4517, batch acc 0.1194
14:10:39.353   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:10:39.850   Training iter 550, batch loss 0.4518, batch acc 0.1082
14:10:40.362   Training iter 600, batch loss 0.4518, batch acc 0.1122
14:10:40.364 Training @ 198 epoch...
14:10:40.870   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:10:41.386   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:10:41.891   Training iter 150, batch loss 0.4517, batch acc 0.1174
14:10:42.391   Training iter 200, batch loss 0.4518, batch acc 0.1074
14:10:42.901   Training iter 250, batch loss 0.4517, batch acc 0.1128
14:10:43.440   Training iter 300, batch loss 0.4519, batch acc 0.1046
14:10:44.009   Training iter 350, batch loss 0.4518, batch acc 0.1088
14:10:44.570   Training iter 400, batch loss 0.4518, batch acc 0.1130
14:10:45.120   Training iter 450, batch loss 0.4518, batch acc 0.1076
14:10:45.628   Training iter 500, batch loss 0.4517, batch acc 0.1210
14:10:46.162   Training iter 550, batch loss 0.4518, batch acc 0.1154
14:10:46.666   Training iter 600, batch loss 0.4517, batch acc 0.1156
14:10:46.668 Training @ 199 epoch...
14:10:47.184   Training iter 50, batch loss 0.4517, batch acc 0.1154
14:10:47.708   Training iter 100, batch loss 0.4517, batch acc 0.1106
14:10:48.271   Training iter 150, batch loss 0.4518, batch acc 0.1090
14:10:48.831   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:10:49.381   Training iter 250, batch loss 0.4518, batch acc 0.1100
14:10:49.935   Training iter 300, batch loss 0.4518, batch acc 0.1154
14:10:50.478   Training iter 350, batch loss 0.4518, batch acc 0.1106
14:10:51.003   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:10:51.521   Training iter 450, batch loss 0.4517, batch acc 0.1148
14:10:52.050   Training iter 500, batch loss 0.4518, batch acc 0.1110
14:10:52.577   Training iter 550, batch loss 0.4516, batch acc 0.1216
14:10:53.116   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:10:53.118 Training @ 200 epoch...
14:10:53.653   Training iter 50, batch loss 0.4518, batch acc 0.1130
14:10:54.141   Training iter 100, batch loss 0.4517, batch acc 0.1088
14:10:54.628   Training iter 150, batch loss 0.4517, batch acc 0.1174
14:10:55.123   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:10:55.637   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:10:56.119   Training iter 300, batch loss 0.4519, batch acc 0.1046
14:10:56.610   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:10:57.079   Training iter 400, batch loss 0.4517, batch acc 0.1088
14:10:57.561   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:10:58.052   Training iter 500, batch loss 0.4517, batch acc 0.1168
14:10:58.537   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:10:59.012   Training iter 600, batch loss 0.4516, batch acc 0.1228
14:10:59.014 Testing @ 200 epoch...
14:10:59.053     Testing, total mean loss 0.45174, total acc 0.11350
14:10:59.053 Plot @ 200 epoch...
14:10:59.053 Training @ 201 epoch...
14:10:59.525   Training iter 50, batch loss 0.4518, batch acc 0.1090
14:10:59.995   Training iter 100, batch loss 0.4518, batch acc 0.1134
14:11:00.470   Training iter 150, batch loss 0.4517, batch acc 0.1114
14:11:00.957   Training iter 200, batch loss 0.4518, batch acc 0.1138
14:11:01.468   Training iter 250, batch loss 0.4517, batch acc 0.1122
14:11:01.984   Training iter 300, batch loss 0.4518, batch acc 0.1098
14:11:02.517   Training iter 350, batch loss 0.4517, batch acc 0.1190
14:11:03.050   Training iter 400, batch loss 0.4518, batch acc 0.1134
14:11:03.565   Training iter 450, batch loss 0.4518, batch acc 0.1132
14:11:04.116   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:11:04.660   Training iter 550, batch loss 0.4517, batch acc 0.1170
14:11:05.202   Training iter 600, batch loss 0.4518, batch acc 0.1100
14:11:05.203 Training @ 202 epoch...
14:11:05.753   Training iter 50, batch loss 0.4518, batch acc 0.1110
14:11:06.299   Training iter 100, batch loss 0.4518, batch acc 0.1076
14:11:06.832   Training iter 150, batch loss 0.4517, batch acc 0.1170
14:11:07.366   Training iter 200, batch loss 0.4517, batch acc 0.1206
14:11:07.906   Training iter 250, batch loss 0.4518, batch acc 0.1040
14:11:08.451   Training iter 300, batch loss 0.4517, batch acc 0.1120
14:11:08.993   Training iter 350, batch loss 0.4518, batch acc 0.1154
14:11:09.539   Training iter 400, batch loss 0.4518, batch acc 0.1088
14:11:10.069   Training iter 450, batch loss 0.4518, batch acc 0.1118
14:11:10.594   Training iter 500, batch loss 0.4517, batch acc 0.1162
14:11:11.121   Training iter 550, batch loss 0.4518, batch acc 0.1096
14:11:11.634   Training iter 600, batch loss 0.4518, batch acc 0.1144
14:11:11.636 Training @ 203 epoch...
14:11:12.162   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:11:12.689   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:11:13.227   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:11:13.733   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:11:14.211   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:11:14.684   Training iter 300, batch loss 0.4517, batch acc 0.1114
14:11:15.189   Training iter 350, batch loss 0.4517, batch acc 0.1124
14:11:15.720   Training iter 400, batch loss 0.4518, batch acc 0.1136
14:11:16.245   Training iter 450, batch loss 0.4516, batch acc 0.1216
14:11:16.768   Training iter 500, batch loss 0.4518, batch acc 0.1034
14:11:17.293   Training iter 550, batch loss 0.4519, batch acc 0.1086
14:11:17.834   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:11:17.836 Training @ 204 epoch...
14:11:18.393   Training iter 50, batch loss 0.4517, batch acc 0.1112
14:11:18.915   Training iter 100, batch loss 0.4516, batch acc 0.1206
14:11:19.424   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:11:19.954   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:11:20.508   Training iter 250, batch loss 0.4518, batch acc 0.1072
14:11:21.053   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:11:21.598   Training iter 350, batch loss 0.4517, batch acc 0.1156
14:11:22.153   Training iter 400, batch loss 0.4516, batch acc 0.1204
14:11:22.728   Training iter 450, batch loss 0.4519, batch acc 0.1044
14:11:23.303   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:11:23.886   Training iter 550, batch loss 0.4519, batch acc 0.1006
14:11:24.478   Training iter 600, batch loss 0.4517, batch acc 0.1164
14:11:24.480 Training @ 205 epoch...
14:11:25.086   Training iter 50, batch loss 0.4517, batch acc 0.1106
14:11:25.692   Training iter 100, batch loss 0.4518, batch acc 0.1128
14:11:26.266   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:11:26.819   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:11:27.395   Training iter 250, batch loss 0.4517, batch acc 0.1188
14:11:27.976   Training iter 300, batch loss 0.4517, batch acc 0.1164
14:11:28.516   Training iter 350, batch loss 0.4519, batch acc 0.1048
14:11:29.053   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:11:29.582   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:11:30.124   Training iter 500, batch loss 0.4518, batch acc 0.1072
14:11:30.664   Training iter 550, batch loss 0.4518, batch acc 0.1128
14:11:31.195   Training iter 600, batch loss 0.4517, batch acc 0.1126
14:11:31.197 Testing @ 205 epoch...
14:11:31.236     Testing, total mean loss 0.45174, total acc 0.11350
14:11:31.236 Training @ 206 epoch...
14:11:31.776   Training iter 50, batch loss 0.4519, batch acc 0.1098
14:11:32.299   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:11:32.827   Training iter 150, batch loss 0.4517, batch acc 0.1110
14:11:33.378   Training iter 200, batch loss 0.4519, batch acc 0.1024
14:11:33.951   Training iter 250, batch loss 0.4518, batch acc 0.1150
14:11:34.496   Training iter 300, batch loss 0.4517, batch acc 0.1164
14:11:35.044   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:11:35.578   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:11:36.129   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:11:36.677   Training iter 500, batch loss 0.4518, batch acc 0.1108
14:11:37.201   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:11:37.727   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:11:37.729 Training @ 207 epoch...
14:11:38.265   Training iter 50, batch loss 0.4517, batch acc 0.1186
14:11:38.774   Training iter 100, batch loss 0.4517, batch acc 0.1110
14:11:39.277   Training iter 150, batch loss 0.4517, batch acc 0.1122
14:11:39.785   Training iter 200, batch loss 0.4518, batch acc 0.1126
14:11:40.311   Training iter 250, batch loss 0.4518, batch acc 0.1062
14:11:40.833   Training iter 300, batch loss 0.4518, batch acc 0.1086
14:11:41.352   Training iter 350, batch loss 0.4517, batch acc 0.1142
14:11:41.857   Training iter 400, batch loss 0.4517, batch acc 0.1170
14:11:42.370   Training iter 450, batch loss 0.4517, batch acc 0.1124
14:11:42.887   Training iter 500, batch loss 0.4518, batch acc 0.1158
14:11:43.378   Training iter 550, batch loss 0.4518, batch acc 0.1102
14:11:43.886   Training iter 600, batch loss 0.4518, batch acc 0.1096
14:11:43.888 Training @ 208 epoch...
14:11:44.394   Training iter 50, batch loss 0.4518, batch acc 0.1078
14:11:44.902   Training iter 100, batch loss 0.4517, batch acc 0.1146
14:11:45.395   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:11:45.873   Training iter 200, batch loss 0.4517, batch acc 0.1152
14:11:46.356   Training iter 250, batch loss 0.4517, batch acc 0.1110
14:11:46.855   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:11:47.348   Training iter 350, batch loss 0.4516, batch acc 0.1210
14:11:47.856   Training iter 400, batch loss 0.4518, batch acc 0.1112
14:11:48.400   Training iter 450, batch loss 0.4516, batch acc 0.1214
14:11:48.946   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:11:49.461   Training iter 550, batch loss 0.4518, batch acc 0.1058
14:11:49.994   Training iter 600, batch loss 0.4519, batch acc 0.1060
14:11:49.996 Training @ 209 epoch...
14:11:50.526   Training iter 50, batch loss 0.4518, batch acc 0.1102
14:11:51.063   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:11:51.581   Training iter 150, batch loss 0.4518, batch acc 0.1160
14:11:52.103   Training iter 200, batch loss 0.4516, batch acc 0.1162
14:11:52.630   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:11:53.151   Training iter 300, batch loss 0.4517, batch acc 0.1128
14:11:53.694   Training iter 350, batch loss 0.4518, batch acc 0.1156
14:11:54.204   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:11:54.721   Training iter 450, batch loss 0.4518, batch acc 0.1108
14:11:55.242   Training iter 500, batch loss 0.4518, batch acc 0.1118
14:11:55.768   Training iter 550, batch loss 0.4518, batch acc 0.1098
14:11:56.318   Training iter 600, batch loss 0.4517, batch acc 0.1142
14:11:56.320 Training @ 210 epoch...
14:11:56.816   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:11:57.301   Training iter 100, batch loss 0.4518, batch acc 0.1058
14:11:57.791   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:11:58.281   Training iter 200, batch loss 0.4516, batch acc 0.1232
14:11:58.771   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:11:59.247   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:11:59.731   Training iter 350, batch loss 0.4518, batch acc 0.1130
14:12:00.235   Training iter 400, batch loss 0.4517, batch acc 0.1100
14:12:00.731   Training iter 450, batch loss 0.4518, batch acc 0.1112
14:12:01.215   Training iter 500, batch loss 0.4518, batch acc 0.1118
14:12:01.733   Training iter 550, batch loss 0.4517, batch acc 0.1108
14:12:02.277   Training iter 600, batch loss 0.4518, batch acc 0.1100
14:12:02.279 Testing @ 210 epoch...
14:12:02.318     Testing, total mean loss 0.45174, total acc 0.11350
14:12:02.319 Training @ 211 epoch...
14:12:02.845   Training iter 50, batch loss 0.4518, batch acc 0.1112
14:12:03.387   Training iter 100, batch loss 0.4518, batch acc 0.1100
14:12:03.912   Training iter 150, batch loss 0.4517, batch acc 0.1170
14:12:04.429   Training iter 200, batch loss 0.4519, batch acc 0.1058
14:12:04.942   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:12:05.454   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:12:05.983   Training iter 350, batch loss 0.4517, batch acc 0.1106
14:12:06.578   Training iter 400, batch loss 0.4518, batch acc 0.1146
14:12:07.181   Training iter 450, batch loss 0.4517, batch acc 0.1150
14:12:07.771   Training iter 500, batch loss 0.4518, batch acc 0.1108
14:12:08.320   Training iter 550, batch loss 0.4516, batch acc 0.1204
14:12:08.837   Training iter 600, batch loss 0.4517, batch acc 0.1158
14:12:08.839 Training @ 212 epoch...
14:12:09.362   Training iter 50, batch loss 0.4517, batch acc 0.1124
14:12:09.879   Training iter 100, batch loss 0.4519, batch acc 0.1054
14:12:10.402   Training iter 150, batch loss 0.4517, batch acc 0.1114
14:12:10.916   Training iter 200, batch loss 0.4517, batch acc 0.1190
14:12:11.435   Training iter 250, batch loss 0.4516, batch acc 0.1182
14:12:11.959   Training iter 300, batch loss 0.4518, batch acc 0.1098
14:12:12.489   Training iter 350, batch loss 0.4518, batch acc 0.1128
14:12:13.024   Training iter 400, batch loss 0.4518, batch acc 0.1154
14:12:13.568   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:12:14.130   Training iter 500, batch loss 0.4517, batch acc 0.1088
14:12:14.664   Training iter 550, batch loss 0.4517, batch acc 0.1152
14:12:15.192   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:12:15.193 Training @ 213 epoch...
14:12:15.762   Training iter 50, batch loss 0.4519, batch acc 0.1024
14:12:16.295   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:12:16.834   Training iter 150, batch loss 0.4518, batch acc 0.1140
14:12:17.359   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:12:17.887   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:12:18.434   Training iter 300, batch loss 0.4517, batch acc 0.1144
14:12:18.966   Training iter 350, batch loss 0.4518, batch acc 0.1064
14:12:19.485   Training iter 400, batch loss 0.4517, batch acc 0.1142
14:12:20.023   Training iter 450, batch loss 0.4517, batch acc 0.1114
14:12:20.556   Training iter 500, batch loss 0.4516, batch acc 0.1212
14:12:21.087   Training iter 550, batch loss 0.4518, batch acc 0.1128
14:12:21.618   Training iter 600, batch loss 0.4518, batch acc 0.1156
14:12:21.619 Training @ 214 epoch...
14:12:22.159   Training iter 50, batch loss 0.4518, batch acc 0.1068
14:12:22.695   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:12:23.227   Training iter 150, batch loss 0.4518, batch acc 0.1064
14:12:23.759   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:12:24.319   Training iter 250, batch loss 0.4517, batch acc 0.1106
14:12:24.878   Training iter 300, batch loss 0.4518, batch acc 0.1140
14:12:25.438   Training iter 350, batch loss 0.4517, batch acc 0.1180
14:12:25.995   Training iter 400, batch loss 0.4517, batch acc 0.1122
14:12:26.536   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:12:27.108   Training iter 500, batch loss 0.4517, batch acc 0.1158
14:12:27.660   Training iter 550, batch loss 0.4517, batch acc 0.1184
14:12:28.245   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:12:28.247 Training @ 215 epoch...
14:12:28.791   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:12:29.377   Training iter 100, batch loss 0.4518, batch acc 0.1094
14:12:29.952   Training iter 150, batch loss 0.4518, batch acc 0.1062
14:12:30.511   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:12:31.091   Training iter 250, batch loss 0.4518, batch acc 0.1082
14:12:31.665   Training iter 300, batch loss 0.4517, batch acc 0.1224
14:12:32.221   Training iter 350, batch loss 0.4519, batch acc 0.1046
14:12:32.742   Training iter 400, batch loss 0.4516, batch acc 0.1200
14:12:33.276   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:12:33.802   Training iter 500, batch loss 0.4518, batch acc 0.1088
14:12:34.333   Training iter 550, batch loss 0.4518, batch acc 0.1148
14:12:34.860   Training iter 600, batch loss 0.4518, batch acc 0.1144
14:12:34.862 Testing @ 215 epoch...
14:12:34.901     Testing, total mean loss 0.45174, total acc 0.11350
14:12:34.901 Training @ 216 epoch...
14:12:35.420   Training iter 50, batch loss 0.4518, batch acc 0.1078
14:12:35.930   Training iter 100, batch loss 0.4517, batch acc 0.1078
14:12:36.447   Training iter 150, batch loss 0.4517, batch acc 0.1166
14:12:36.954   Training iter 200, batch loss 0.4519, batch acc 0.1090
14:12:37.454   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:12:37.963   Training iter 300, batch loss 0.4517, batch acc 0.1168
14:12:38.463   Training iter 350, batch loss 0.4518, batch acc 0.1136
14:12:39.022   Training iter 400, batch loss 0.4518, batch acc 0.1070
14:12:39.559   Training iter 450, batch loss 0.4517, batch acc 0.1130
14:12:40.108   Training iter 500, batch loss 0.4517, batch acc 0.1174
14:12:40.654   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:12:41.204   Training iter 600, batch loss 0.4517, batch acc 0.1142
14:12:41.206 Training @ 217 epoch...
14:12:41.749   Training iter 50, batch loss 0.4517, batch acc 0.1150
14:12:42.294   Training iter 100, batch loss 0.4518, batch acc 0.1166
14:12:42.845   Training iter 150, batch loss 0.4519, batch acc 0.1042
14:12:43.383   Training iter 200, batch loss 0.4518, batch acc 0.1130
14:12:43.927   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:12:44.467   Training iter 300, batch loss 0.4518, batch acc 0.1140
14:12:45.016   Training iter 350, batch loss 0.4518, batch acc 0.1104
14:12:45.537   Training iter 400, batch loss 0.4519, batch acc 0.1064
14:12:46.069   Training iter 450, batch loss 0.4517, batch acc 0.1154
14:12:46.596   Training iter 500, batch loss 0.4517, batch acc 0.1098
14:12:47.114   Training iter 550, batch loss 0.4517, batch acc 0.1124
14:12:47.625   Training iter 600, batch loss 0.4516, batch acc 0.1200
14:12:47.626 Training @ 218 epoch...
14:12:48.170   Training iter 50, batch loss 0.4517, batch acc 0.1166
14:12:48.687   Training iter 100, batch loss 0.4518, batch acc 0.1162
14:12:49.207   Training iter 150, batch loss 0.4516, batch acc 0.1210
14:12:49.732   Training iter 200, batch loss 0.4517, batch acc 0.1180
14:12:50.254   Training iter 250, batch loss 0.4519, batch acc 0.1030
14:12:50.776   Training iter 300, batch loss 0.4518, batch acc 0.1154
14:12:51.302   Training iter 350, batch loss 0.4517, batch acc 0.1162
14:12:51.828   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:12:52.372   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:12:52.902   Training iter 500, batch loss 0.4518, batch acc 0.1106
14:12:53.417   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:12:53.932   Training iter 600, batch loss 0.4518, batch acc 0.1026
14:12:53.934 Training @ 219 epoch...
14:12:54.454   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:12:54.963   Training iter 100, batch loss 0.4517, batch acc 0.1146
14:12:55.515   Training iter 150, batch loss 0.4517, batch acc 0.1184
14:12:56.065   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:12:56.614   Training iter 250, batch loss 0.4517, batch acc 0.1194
14:12:57.159   Training iter 300, batch loss 0.4518, batch acc 0.1096
14:12:57.707   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:12:58.265   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:12:58.820   Training iter 450, batch loss 0.4517, batch acc 0.1080
14:12:59.390   Training iter 500, batch loss 0.4517, batch acc 0.1122
14:12:59.963   Training iter 550, batch loss 0.4518, batch acc 0.1118
14:13:00.530   Training iter 600, batch loss 0.4519, batch acc 0.1078
14:13:00.532 Training @ 220 epoch...
14:13:01.097   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:13:01.685   Training iter 100, batch loss 0.4516, batch acc 0.1212
14:13:02.276   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:13:02.821   Training iter 200, batch loss 0.4519, batch acc 0.1054
14:13:03.347   Training iter 250, batch loss 0.4517, batch acc 0.1102
14:13:03.884   Training iter 300, batch loss 0.4518, batch acc 0.1128
14:13:04.419   Training iter 350, batch loss 0.4519, batch acc 0.1006
14:13:04.959   Training iter 400, batch loss 0.4517, batch acc 0.1156
14:13:05.490   Training iter 450, batch loss 0.4517, batch acc 0.1120
14:13:06.033   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:13:06.561   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:13:07.101   Training iter 600, batch loss 0.4517, batch acc 0.1200
14:13:07.103 Testing @ 220 epoch...
14:13:07.142     Testing, total mean loss 0.45174, total acc 0.11350
14:13:07.142 Training @ 221 epoch...
14:13:07.673   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:13:08.184   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:13:08.691   Training iter 150, batch loss 0.4518, batch acc 0.1136
14:13:09.190   Training iter 200, batch loss 0.4517, batch acc 0.1112
14:13:09.676   Training iter 250, batch loss 0.4517, batch acc 0.1104
14:13:10.188   Training iter 300, batch loss 0.4518, batch acc 0.1160
14:13:10.680   Training iter 350, batch loss 0.4516, batch acc 0.1200
14:13:11.195   Training iter 400, batch loss 0.4517, batch acc 0.1156
14:13:11.728   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:13:12.263   Training iter 500, batch loss 0.4518, batch acc 0.1050
14:13:12.792   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:13:13.326   Training iter 600, batch loss 0.4518, batch acc 0.1102
14:13:13.328 Training @ 222 epoch...
14:13:13.870   Training iter 50, batch loss 0.4517, batch acc 0.1102
14:13:14.385   Training iter 100, batch loss 0.4517, batch acc 0.1154
14:13:14.906   Training iter 150, batch loss 0.4518, batch acc 0.1056
14:13:15.432   Training iter 200, batch loss 0.4518, batch acc 0.1080
14:13:15.948   Training iter 250, batch loss 0.4517, batch acc 0.1132
14:13:16.475   Training iter 300, batch loss 0.4517, batch acc 0.1128
14:13:17.015   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:13:17.532   Training iter 400, batch loss 0.4516, batch acc 0.1130
14:13:18.037   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:13:18.553   Training iter 500, batch loss 0.4518, batch acc 0.1166
14:13:19.055   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:13:19.569   Training iter 600, batch loss 0.4518, batch acc 0.1188
14:13:19.571 Training @ 223 epoch...
14:13:20.089   Training iter 50, batch loss 0.4518, batch acc 0.1124
14:13:20.611   Training iter 100, batch loss 0.4516, batch acc 0.1134
14:13:21.142   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:13:21.664   Training iter 200, batch loss 0.4518, batch acc 0.1106
14:13:22.180   Training iter 250, batch loss 0.4517, batch acc 0.1184
14:13:22.667   Training iter 300, batch loss 0.4519, batch acc 0.1060
14:13:23.142   Training iter 350, batch loss 0.4517, batch acc 0.1170
14:13:23.618   Training iter 400, batch loss 0.4518, batch acc 0.1118
14:13:24.081   Training iter 450, batch loss 0.4517, batch acc 0.1184
14:13:24.573   Training iter 500, batch loss 0.4518, batch acc 0.1136
14:13:25.052   Training iter 550, batch loss 0.4519, batch acc 0.1038
14:13:25.542   Training iter 600, batch loss 0.4518, batch acc 0.1102
14:13:25.544 Training @ 224 epoch...
14:13:26.011   Training iter 50, batch loss 0.4518, batch acc 0.1080
14:13:26.479   Training iter 100, batch loss 0.4518, batch acc 0.1094
14:13:26.947   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:13:27.439   Training iter 200, batch loss 0.4517, batch acc 0.1124
14:13:27.978   Training iter 250, batch loss 0.4517, batch acc 0.1130
14:13:28.548   Training iter 300, batch loss 0.4517, batch acc 0.1156
14:13:29.122   Training iter 350, batch loss 0.4518, batch acc 0.1050
14:13:29.679   Training iter 400, batch loss 0.4518, batch acc 0.1082
14:13:30.213   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:13:30.747   Training iter 500, batch loss 0.4517, batch acc 0.1188
14:13:31.303   Training iter 550, batch loss 0.4518, batch acc 0.1144
14:13:31.852   Training iter 600, batch loss 0.4517, batch acc 0.1172
14:13:31.854 Training @ 225 epoch...
14:13:32.399   Training iter 50, batch loss 0.4518, batch acc 0.1144
14:13:32.950   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:13:33.479   Training iter 150, batch loss 0.4517, batch acc 0.1142
14:13:33.988   Training iter 200, batch loss 0.4518, batch acc 0.1102
14:13:34.498   Training iter 250, batch loss 0.4518, batch acc 0.1082
14:13:35.011   Training iter 300, batch loss 0.4518, batch acc 0.1094
14:13:35.514   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:13:36.031   Training iter 400, batch loss 0.4518, batch acc 0.1076
14:13:36.526   Training iter 450, batch loss 0.4517, batch acc 0.1130
14:13:37.032   Training iter 500, batch loss 0.4517, batch acc 0.1116
14:13:37.539   Training iter 550, batch loss 0.4518, batch acc 0.1142
14:13:38.050   Training iter 600, batch loss 0.4517, batch acc 0.1174
14:13:38.052 Testing @ 225 epoch...
14:13:38.092     Testing, total mean loss 0.45174, total acc 0.11350
14:13:38.092 Training @ 226 epoch...
14:13:38.592   Training iter 50, batch loss 0.4517, batch acc 0.1136
14:13:39.074   Training iter 100, batch loss 0.4517, batch acc 0.1146
14:13:39.541   Training iter 150, batch loss 0.4518, batch acc 0.1106
14:13:40.013   Training iter 200, batch loss 0.4517, batch acc 0.1142
14:13:40.531   Training iter 250, batch loss 0.4519, batch acc 0.1074
14:13:41.058   Training iter 300, batch loss 0.4517, batch acc 0.1184
14:13:41.552   Training iter 350, batch loss 0.4516, batch acc 0.1186
14:13:42.054   Training iter 400, batch loss 0.4517, batch acc 0.1144
14:13:42.560   Training iter 450, batch loss 0.4518, batch acc 0.1118
14:13:43.068   Training iter 500, batch loss 0.4519, batch acc 0.1052
14:13:43.579   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:13:44.098   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:13:44.100 Training @ 227 epoch...
14:13:44.618   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:13:45.136   Training iter 100, batch loss 0.4517, batch acc 0.1156
14:13:45.659   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:13:46.188   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:13:46.720   Training iter 250, batch loss 0.4517, batch acc 0.1132
14:13:47.235   Training iter 300, batch loss 0.4517, batch acc 0.1174
14:13:47.753   Training iter 350, batch loss 0.4518, batch acc 0.1042
14:13:48.306   Training iter 400, batch loss 0.4519, batch acc 0.1052
14:13:48.861   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:13:49.409   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:13:49.927   Training iter 550, batch loss 0.4517, batch acc 0.1118
14:13:50.446   Training iter 600, batch loss 0.4516, batch acc 0.1202
14:13:50.447 Training @ 228 epoch...
14:13:50.967   Training iter 50, batch loss 0.4518, batch acc 0.1110
14:13:51.493   Training iter 100, batch loss 0.4517, batch acc 0.1132
14:13:52.060   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:13:52.574   Training iter 200, batch loss 0.4517, batch acc 0.1118
14:13:53.096   Training iter 250, batch loss 0.4518, batch acc 0.1104
14:13:53.612   Training iter 300, batch loss 0.4517, batch acc 0.1182
14:13:54.122   Training iter 350, batch loss 0.4517, batch acc 0.1072
14:13:54.625   Training iter 400, batch loss 0.4517, batch acc 0.1168
14:13:55.143   Training iter 450, batch loss 0.4517, batch acc 0.1182
14:13:55.655   Training iter 500, batch loss 0.4518, batch acc 0.1146
14:13:56.173   Training iter 550, batch loss 0.4519, batch acc 0.1070
14:13:56.683   Training iter 600, batch loss 0.4518, batch acc 0.1078
14:13:56.684 Training @ 229 epoch...
14:13:57.218   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:13:57.747   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:13:58.271   Training iter 150, batch loss 0.4517, batch acc 0.1134
14:13:58.786   Training iter 200, batch loss 0.4517, batch acc 0.1192
14:13:59.306   Training iter 250, batch loss 0.4517, batch acc 0.1090
14:13:59.861   Training iter 300, batch loss 0.4518, batch acc 0.1178
14:14:00.430   Training iter 350, batch loss 0.4518, batch acc 0.1104
14:14:00.986   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:14:01.541   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:14:02.135   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:14:02.716   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:14:03.329   Training iter 600, batch loss 0.4517, batch acc 0.1136
14:14:03.330 Training @ 230 epoch...
14:14:03.912   Training iter 50, batch loss 0.4517, batch acc 0.1124
14:14:04.493   Training iter 100, batch loss 0.4517, batch acc 0.1208
14:14:05.062   Training iter 150, batch loss 0.4518, batch acc 0.1084
14:14:05.622   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:14:06.163   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:14:06.716   Training iter 300, batch loss 0.4517, batch acc 0.1160
14:14:07.253   Training iter 350, batch loss 0.4518, batch acc 0.1018
14:14:07.783   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:14:08.302   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:14:08.798   Training iter 500, batch loss 0.4517, batch acc 0.1154
14:14:09.297   Training iter 550, batch loss 0.4518, batch acc 0.1102
14:14:09.780   Training iter 600, batch loss 0.4518, batch acc 0.1114
14:14:09.782 Testing @ 230 epoch...
14:14:09.821     Testing, total mean loss 0.45174, total acc 0.11350
14:14:09.821 Training @ 231 epoch...
14:14:10.329   Training iter 50, batch loss 0.4517, batch acc 0.1056
14:14:10.784   Training iter 100, batch loss 0.4516, batch acc 0.1168
14:14:11.265   Training iter 150, batch loss 0.4518, batch acc 0.1110
14:14:11.727   Training iter 200, batch loss 0.4517, batch acc 0.1146
14:14:12.209   Training iter 250, batch loss 0.4517, batch acc 0.1192
14:14:12.676   Training iter 300, batch loss 0.4518, batch acc 0.1114
14:14:13.163   Training iter 350, batch loss 0.4518, batch acc 0.1066
14:14:13.639   Training iter 400, batch loss 0.4517, batch acc 0.1182
14:14:14.125   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:14:14.593   Training iter 500, batch loss 0.4518, batch acc 0.1170
14:14:15.063   Training iter 550, batch loss 0.4519, batch acc 0.1092
14:14:15.530   Training iter 600, batch loss 0.4517, batch acc 0.1102
14:14:15.532 Training @ 232 epoch...
14:14:16.056   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:14:16.571   Training iter 100, batch loss 0.4517, batch acc 0.1124
14:14:17.085   Training iter 150, batch loss 0.4519, batch acc 0.1080
14:14:17.595   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:14:18.126   Training iter 250, batch loss 0.4517, batch acc 0.1144
14:14:18.640   Training iter 300, batch loss 0.4518, batch acc 0.1054
14:14:19.156   Training iter 350, batch loss 0.4518, batch acc 0.1080
14:14:19.681   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:14:20.213   Training iter 450, batch loss 0.4518, batch acc 0.1130
14:14:20.748   Training iter 500, batch loss 0.4518, batch acc 0.1110
14:14:21.279   Training iter 550, batch loss 0.4517, batch acc 0.1206
14:14:21.811   Training iter 600, batch loss 0.4517, batch acc 0.1112
14:14:21.813 Training @ 233 epoch...
14:14:22.341   Training iter 50, batch loss 0.4518, batch acc 0.1090
14:14:22.872   Training iter 100, batch loss 0.4518, batch acc 0.1110
14:14:23.404   Training iter 150, batch loss 0.4517, batch acc 0.1182
14:14:23.940   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:14:24.472   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:14:25.000   Training iter 300, batch loss 0.4518, batch acc 0.1096
14:14:25.513   Training iter 350, batch loss 0.4517, batch acc 0.1124
14:14:26.010   Training iter 400, batch loss 0.4518, batch acc 0.1126
14:14:26.505   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:14:26.988   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:14:27.538   Training iter 550, batch loss 0.4517, batch acc 0.1118
14:14:28.101   Training iter 600, batch loss 0.4517, batch acc 0.1120
14:14:28.103 Training @ 234 epoch...
14:14:28.666   Training iter 50, batch loss 0.4517, batch acc 0.1104
14:14:29.177   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:14:29.650   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:14:30.140   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:14:30.652   Training iter 250, batch loss 0.4519, batch acc 0.0994
14:14:31.164   Training iter 300, batch loss 0.4517, batch acc 0.1158
14:14:31.707   Training iter 350, batch loss 0.4517, batch acc 0.1128
14:14:32.265   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:14:32.811   Training iter 450, batch loss 0.4518, batch acc 0.1170
14:14:33.361   Training iter 500, batch loss 0.4517, batch acc 0.1128
14:14:33.909   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:14:34.475   Training iter 600, batch loss 0.4518, batch acc 0.1102
14:14:34.477 Training @ 235 epoch...
14:14:35.029   Training iter 50, batch loss 0.4518, batch acc 0.1034
14:14:35.573   Training iter 100, batch loss 0.4518, batch acc 0.1148
14:14:36.125   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:14:36.664   Training iter 200, batch loss 0.4518, batch acc 0.1110
14:14:37.216   Training iter 250, batch loss 0.4517, batch acc 0.1154
14:14:37.734   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:14:38.269   Training iter 350, batch loss 0.4517, batch acc 0.1190
14:14:38.786   Training iter 400, batch loss 0.4518, batch acc 0.1128
14:14:39.295   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:14:39.803   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:14:40.329   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:14:40.850   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:14:40.852 Testing @ 235 epoch...
14:14:40.890     Testing, total mean loss 0.45174, total acc 0.11350
14:14:40.890 Training @ 236 epoch...
14:14:41.406   Training iter 50, batch loss 0.4517, batch acc 0.1108
14:14:41.927   Training iter 100, batch loss 0.4518, batch acc 0.1066
14:14:42.446   Training iter 150, batch loss 0.4516, batch acc 0.1178
14:14:42.972   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:14:43.514   Training iter 250, batch loss 0.4518, batch acc 0.1140
14:14:44.050   Training iter 300, batch loss 0.4517, batch acc 0.1170
14:14:44.561   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:14:45.088   Training iter 400, batch loss 0.4518, batch acc 0.1130
14:14:45.629   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:14:46.154   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:14:46.675   Training iter 550, batch loss 0.4518, batch acc 0.1074
14:14:47.192   Training iter 600, batch loss 0.4518, batch acc 0.1114
14:14:47.194 Training @ 237 epoch...
14:14:47.722   Training iter 50, batch loss 0.4518, batch acc 0.1136
14:14:48.240   Training iter 100, batch loss 0.4518, batch acc 0.1130
14:14:48.753   Training iter 150, batch loss 0.4518, batch acc 0.1144
14:14:49.270   Training iter 200, batch loss 0.4518, batch acc 0.1134
14:14:49.773   Training iter 250, batch loss 0.4517, batch acc 0.1134
14:14:50.287   Training iter 300, batch loss 0.4517, batch acc 0.1104
14:14:50.803   Training iter 350, batch loss 0.4517, batch acc 0.1090
14:14:51.345   Training iter 400, batch loss 0.4517, batch acc 0.1128
14:14:51.872   Training iter 450, batch loss 0.4518, batch acc 0.1078
14:14:52.403   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:14:52.928   Training iter 550, batch loss 0.4517, batch acc 0.1166
14:14:53.488   Training iter 600, batch loss 0.4518, batch acc 0.1122
14:14:53.490 Training @ 238 epoch...
14:14:54.036   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:14:54.577   Training iter 100, batch loss 0.4517, batch acc 0.1124
14:14:55.129   Training iter 150, batch loss 0.4517, batch acc 0.1126
14:14:55.667   Training iter 200, batch loss 0.4518, batch acc 0.1090
14:14:56.212   Training iter 250, batch loss 0.4517, batch acc 0.1162
14:14:56.756   Training iter 300, batch loss 0.4518, batch acc 0.1120
14:14:57.276   Training iter 350, batch loss 0.4518, batch acc 0.1048
14:14:57.789   Training iter 400, batch loss 0.4517, batch acc 0.1176
14:14:58.311   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:14:58.838   Training iter 500, batch loss 0.4517, batch acc 0.1134
14:14:59.358   Training iter 550, batch loss 0.4518, batch acc 0.1110
14:14:59.874   Training iter 600, batch loss 0.4517, batch acc 0.1166
14:14:59.876 Training @ 239 epoch...
14:15:00.421   Training iter 50, batch loss 0.4517, batch acc 0.1170
14:15:00.951   Training iter 100, batch loss 0.4517, batch acc 0.1138
14:15:01.495   Training iter 150, batch loss 0.4517, batch acc 0.1162
14:15:02.074   Training iter 200, batch loss 0.4518, batch acc 0.1090
14:15:02.666   Training iter 250, batch loss 0.4518, batch acc 0.1124
14:15:03.230   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:15:03.801   Training iter 350, batch loss 0.4518, batch acc 0.1090
14:15:04.368   Training iter 400, batch loss 0.4517, batch acc 0.1244
14:15:04.938   Training iter 450, batch loss 0.4518, batch acc 0.1068
14:15:05.506   Training iter 500, batch loss 0.4517, batch acc 0.1070
14:15:06.024   Training iter 550, batch loss 0.4519, batch acc 0.1080
14:15:06.534   Training iter 600, batch loss 0.4517, batch acc 0.1136
14:15:06.536 Training @ 240 epoch...
14:15:07.089   Training iter 50, batch loss 0.4517, batch acc 0.1138
14:15:07.649   Training iter 100, batch loss 0.4517, batch acc 0.1204
14:15:08.190   Training iter 150, batch loss 0.4517, batch acc 0.1100
14:15:08.710   Training iter 200, batch loss 0.4518, batch acc 0.1118
14:15:09.234   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:15:09.758   Training iter 300, batch loss 0.4519, batch acc 0.1036
14:15:10.258   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:15:10.751   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:15:11.253   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:15:11.749   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:15:12.239   Training iter 550, batch loss 0.4517, batch acc 0.1164
14:15:12.720   Training iter 600, batch loss 0.4516, batch acc 0.1162
14:15:12.722 Testing @ 240 epoch...
14:15:12.761     Testing, total mean loss 0.45174, total acc 0.11350
14:15:12.761 Training @ 241 epoch...
14:15:13.283   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:15:13.808   Training iter 100, batch loss 0.4517, batch acc 0.1138
14:15:14.365   Training iter 150, batch loss 0.4518, batch acc 0.1118
14:15:14.940   Training iter 200, batch loss 0.4518, batch acc 0.1152
14:15:15.516   Training iter 250, batch loss 0.4518, batch acc 0.1054
14:15:16.097   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:15:16.632   Training iter 350, batch loss 0.4517, batch acc 0.1212
14:15:17.154   Training iter 400, batch loss 0.4518, batch acc 0.1148
14:15:17.675   Training iter 450, batch loss 0.4518, batch acc 0.1098
14:15:18.207   Training iter 500, batch loss 0.4518, batch acc 0.1074
14:15:18.733   Training iter 550, batch loss 0.4517, batch acc 0.1162
14:15:19.262   Training iter 600, batch loss 0.4518, batch acc 0.1110
14:15:19.264 Training @ 242 epoch...
14:15:19.783   Training iter 50, batch loss 0.4517, batch acc 0.1192
14:15:20.334   Training iter 100, batch loss 0.4518, batch acc 0.1092
14:15:20.880   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:15:21.425   Training iter 200, batch loss 0.4517, batch acc 0.1166
14:15:21.981   Training iter 250, batch loss 0.4519, batch acc 0.1064
14:15:22.545   Training iter 300, batch loss 0.4518, batch acc 0.1122
14:15:23.107   Training iter 350, batch loss 0.4517, batch acc 0.1124
14:15:23.673   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:15:24.240   Training iter 450, batch loss 0.4519, batch acc 0.1052
14:15:24.797   Training iter 500, batch loss 0.4517, batch acc 0.1090
14:15:25.357   Training iter 550, batch loss 0.4518, batch acc 0.1124
14:15:25.917   Training iter 600, batch loss 0.4516, batch acc 0.1208
14:15:25.919 Training @ 243 epoch...
14:15:26.478   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:15:27.017   Training iter 100, batch loss 0.4517, batch acc 0.1104
14:15:27.553   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:15:28.089   Training iter 200, batch loss 0.4518, batch acc 0.1116
14:15:28.650   Training iter 250, batch loss 0.4517, batch acc 0.1178
14:15:29.200   Training iter 300, batch loss 0.4517, batch acc 0.1190
14:15:29.737   Training iter 350, batch loss 0.4518, batch acc 0.1116
14:15:30.279   Training iter 400, batch loss 0.4518, batch acc 0.1156
14:15:30.828   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:15:31.365   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:15:31.889   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:15:32.396   Training iter 600, batch loss 0.4518, batch acc 0.1046
14:15:32.398 Training @ 244 epoch...
14:15:32.985   Training iter 50, batch loss 0.4517, batch acc 0.1180
14:15:33.641   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:15:34.213   Training iter 150, batch loss 0.4518, batch acc 0.1086
14:15:34.730   Training iter 200, batch loss 0.4518, batch acc 0.1042
14:15:35.233   Training iter 250, batch loss 0.4518, batch acc 0.1146
14:15:35.739   Training iter 300, batch loss 0.4518, batch acc 0.1072
14:15:36.252   Training iter 350, batch loss 0.4518, batch acc 0.1062
14:15:36.777   Training iter 400, batch loss 0.4517, batch acc 0.1170
14:15:37.305   Training iter 450, batch loss 0.4516, batch acc 0.1180
14:15:37.842   Training iter 500, batch loss 0.4517, batch acc 0.1202
14:15:38.354   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:15:38.861   Training iter 600, batch loss 0.4518, batch acc 0.1106
14:15:38.862 Training @ 245 epoch...
14:15:39.388   Training iter 50, batch loss 0.4518, batch acc 0.1136
14:15:39.900   Training iter 100, batch loss 0.4517, batch acc 0.1114
14:15:40.411   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:15:40.921   Training iter 200, batch loss 0.4519, batch acc 0.1056
14:15:41.440   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:15:41.962   Training iter 300, batch loss 0.4517, batch acc 0.1144
14:15:42.465   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:15:42.973   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:15:43.485   Training iter 450, batch loss 0.4516, batch acc 0.1198
14:15:43.998   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:15:44.508   Training iter 550, batch loss 0.4518, batch acc 0.1074
14:15:45.022   Training iter 600, batch loss 0.4517, batch acc 0.1182
14:15:45.023 Testing @ 245 epoch...
14:15:45.062     Testing, total mean loss 0.45174, total acc 0.11350
14:15:45.062 Training @ 246 epoch...
14:15:45.524   Training iter 50, batch loss 0.4517, batch acc 0.1190
14:15:45.991   Training iter 100, batch loss 0.4517, batch acc 0.1138
14:15:46.485   Training iter 150, batch loss 0.4517, batch acc 0.1078
14:15:46.962   Training iter 200, batch loss 0.4517, batch acc 0.1138
14:15:47.441   Training iter 250, batch loss 0.4518, batch acc 0.1156
14:15:47.921   Training iter 300, batch loss 0.4518, batch acc 0.1094
14:15:48.405   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:15:48.881   Training iter 400, batch loss 0.4518, batch acc 0.1108
14:15:49.351   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:15:49.824   Training iter 500, batch loss 0.4519, batch acc 0.1040
14:15:50.311   Training iter 550, batch loss 0.4517, batch acc 0.1150
14:15:50.836   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:15:50.838 Training @ 247 epoch...
14:15:51.395   Training iter 50, batch loss 0.4517, batch acc 0.1142
14:15:51.964   Training iter 100, batch loss 0.4518, batch acc 0.1050
14:15:52.521   Training iter 150, batch loss 0.4518, batch acc 0.1128
14:15:53.079   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:15:53.641   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:15:54.199   Training iter 300, batch loss 0.4518, batch acc 0.1106
14:15:54.761   Training iter 350, batch loss 0.4518, batch acc 0.1022
14:15:55.320   Training iter 400, batch loss 0.4517, batch acc 0.1218
14:15:55.873   Training iter 450, batch loss 0.4519, batch acc 0.1090
14:15:56.415   Training iter 500, batch loss 0.4516, batch acc 0.1168
14:15:56.961   Training iter 550, batch loss 0.4517, batch acc 0.1156
14:15:57.504   Training iter 600, batch loss 0.4518, batch acc 0.1146
14:15:57.506 Training @ 248 epoch...
14:15:58.052   Training iter 50, batch loss 0.4517, batch acc 0.1166
14:15:58.561   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:15:59.081   Training iter 150, batch loss 0.4519, batch acc 0.1082
14:15:59.600   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:16:00.113   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:16:00.633   Training iter 300, batch loss 0.4517, batch acc 0.1140
14:16:01.148   Training iter 350, batch loss 0.4518, batch acc 0.1088
14:16:01.669   Training iter 400, batch loss 0.4517, batch acc 0.1184
14:16:02.176   Training iter 450, batch loss 0.4518, batch acc 0.1168
14:16:02.736   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:16:03.389   Training iter 550, batch loss 0.4517, batch acc 0.1106
14:16:04.015   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:16:04.017 Training @ 249 epoch...
14:16:04.540   Training iter 50, batch loss 0.4517, batch acc 0.1180
14:16:05.083   Training iter 100, batch loss 0.4519, batch acc 0.1064
14:16:05.630   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:16:06.198   Training iter 200, batch loss 0.4517, batch acc 0.1142
14:16:06.701   Training iter 250, batch loss 0.4517, batch acc 0.1144
14:16:07.223   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:16:07.772   Training iter 350, batch loss 0.4518, batch acc 0.1108
14:16:08.326   Training iter 400, batch loss 0.4517, batch acc 0.1180
14:16:08.870   Training iter 450, batch loss 0.4518, batch acc 0.1066
14:16:09.435   Training iter 500, batch loss 0.4517, batch acc 0.1130
14:16:09.993   Training iter 550, batch loss 0.4517, batch acc 0.1138
14:16:10.559   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:16:10.561 Training @ 250 epoch...
14:16:11.124   Training iter 50, batch loss 0.4518, batch acc 0.1076
14:16:11.679   Training iter 100, batch loss 0.4517, batch acc 0.1180
14:16:12.240   Training iter 150, batch loss 0.4518, batch acc 0.1144
14:16:12.798   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:16:13.357   Training iter 250, batch loss 0.4519, batch acc 0.1080
14:16:13.901   Training iter 300, batch loss 0.4517, batch acc 0.1138
14:16:14.448   Training iter 350, batch loss 0.4517, batch acc 0.1206
14:16:14.966   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:16:15.498   Training iter 450, batch loss 0.4517, batch acc 0.1188
14:16:16.026   Training iter 500, batch loss 0.4518, batch acc 0.1072
14:16:16.545   Training iter 550, batch loss 0.4517, batch acc 0.1080
14:16:17.076   Training iter 600, batch loss 0.4518, batch acc 0.1072
14:16:17.078 Testing @ 250 epoch...
14:16:17.117     Testing, total mean loss 0.45174, total acc 0.11350
14:16:17.117 Training @ 251 epoch...
14:16:17.658   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:16:18.214   Training iter 100, batch loss 0.4517, batch acc 0.1136
14:16:18.761   Training iter 150, batch loss 0.4517, batch acc 0.1100
14:16:19.301   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:16:19.839   Training iter 250, batch loss 0.4517, batch acc 0.1146
14:16:20.376   Training iter 300, batch loss 0.4517, batch acc 0.1102
14:16:20.892   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:16:21.412   Training iter 400, batch loss 0.4518, batch acc 0.1074
14:16:21.927   Training iter 450, batch loss 0.4517, batch acc 0.1190
14:16:22.462   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:16:22.981   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:16:23.497   Training iter 600, batch loss 0.4516, batch acc 0.1222
14:16:23.499 Training @ 252 epoch...
14:16:24.032   Training iter 50, batch loss 0.4517, batch acc 0.1178
14:16:24.550   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:16:25.084   Training iter 150, batch loss 0.4517, batch acc 0.1142
14:16:25.605   Training iter 200, batch loss 0.4516, batch acc 0.1164
14:16:26.143   Training iter 250, batch loss 0.4519, batch acc 0.1064
14:16:26.671   Training iter 300, batch loss 0.4516, batch acc 0.1180
14:16:27.204   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:16:27.753   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:16:28.298   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:16:28.853   Training iter 500, batch loss 0.4518, batch acc 0.1116
14:16:29.416   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:16:29.977   Training iter 600, batch loss 0.4518, batch acc 0.1078
14:16:29.979 Training @ 253 epoch...
14:16:30.526   Training iter 50, batch loss 0.4517, batch acc 0.1156
14:16:31.046   Training iter 100, batch loss 0.4516, batch acc 0.1184
14:16:31.562   Training iter 150, batch loss 0.4519, batch acc 0.1052
14:16:32.081   Training iter 200, batch loss 0.4517, batch acc 0.1160
14:16:32.578   Training iter 250, batch loss 0.4517, batch acc 0.1112
14:16:33.097   Training iter 300, batch loss 0.4519, batch acc 0.1074
14:16:33.598   Training iter 350, batch loss 0.4517, batch acc 0.1114
14:16:34.111   Training iter 400, batch loss 0.4519, batch acc 0.1006
14:16:34.628   Training iter 450, batch loss 0.4518, batch acc 0.1122
14:16:35.137   Training iter 500, batch loss 0.4518, batch acc 0.1156
14:16:35.680   Training iter 550, batch loss 0.4517, batch acc 0.1192
14:16:36.230   Training iter 600, batch loss 0.4517, batch acc 0.1156
14:16:36.232 Training @ 254 epoch...
14:16:36.780   Training iter 50, batch loss 0.4517, batch acc 0.1150
14:16:37.315   Training iter 100, batch loss 0.4519, batch acc 0.1080
14:16:37.862   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:16:38.397   Training iter 200, batch loss 0.4518, batch acc 0.1080
14:16:38.911   Training iter 250, batch loss 0.4517, batch acc 0.1138
14:16:39.443   Training iter 300, batch loss 0.4517, batch acc 0.1106
14:16:39.976   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:16:40.541   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:16:41.089   Training iter 450, batch loss 0.4518, batch acc 0.1108
14:16:41.634   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:16:42.183   Training iter 550, batch loss 0.4518, batch acc 0.1116
14:16:42.753   Training iter 600, batch loss 0.4516, batch acc 0.1238
14:16:42.755 Training @ 255 epoch...
14:16:43.305   Training iter 50, batch loss 0.4519, batch acc 0.1026
14:16:43.847   Training iter 100, batch loss 0.4518, batch acc 0.1148
14:16:44.395   Training iter 150, batch loss 0.4517, batch acc 0.1082
14:16:44.963   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:16:45.525   Training iter 250, batch loss 0.4517, batch acc 0.1162
14:16:46.077   Training iter 300, batch loss 0.4515, batch acc 0.1250
14:16:46.587   Training iter 350, batch loss 0.4518, batch acc 0.1116
14:16:47.090   Training iter 400, batch loss 0.4518, batch acc 0.1074
14:16:47.613   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:16:48.145   Training iter 500, batch loss 0.4518, batch acc 0.1164
14:16:48.670   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:16:49.179   Training iter 600, batch loss 0.4517, batch acc 0.1128
14:16:49.181 Testing @ 255 epoch...
14:16:49.221     Testing, total mean loss 0.45174, total acc 0.11350
14:16:49.221 Training @ 256 epoch...
14:16:49.764   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:16:50.300   Training iter 100, batch loss 0.4517, batch acc 0.1148
14:16:50.831   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:16:51.367   Training iter 200, batch loss 0.4517, batch acc 0.1172
14:16:51.917   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:16:52.449   Training iter 300, batch loss 0.4517, batch acc 0.1134
14:16:52.986   Training iter 350, batch loss 0.4518, batch acc 0.1072
14:16:53.626   Training iter 400, batch loss 0.4518, batch acc 0.1130
14:16:54.342   Training iter 450, batch loss 0.4518, batch acc 0.1078
14:16:54.907   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:16:55.437   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:16:55.952   Training iter 600, batch loss 0.4517, batch acc 0.1224
14:16:55.953 Training @ 257 epoch...
14:16:56.510   Training iter 50, batch loss 0.4516, batch acc 0.1210
14:16:57.090   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:16:57.658   Training iter 150, batch loss 0.4518, batch acc 0.1130
14:16:58.258   Training iter 200, batch loss 0.4519, batch acc 0.1042
14:16:58.831   Training iter 250, batch loss 0.4518, batch acc 0.1090
14:16:59.415   Training iter 300, batch loss 0.4517, batch acc 0.1170
14:16:59.998   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:17:00.582   Training iter 400, batch loss 0.4518, batch acc 0.1078
14:17:01.155   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:17:01.747   Training iter 500, batch loss 0.4517, batch acc 0.1100
14:17:02.332   Training iter 550, batch loss 0.4517, batch acc 0.1206
14:17:02.856   Training iter 600, batch loss 0.4517, batch acc 0.1154
14:17:02.857 Training @ 258 epoch...
14:17:03.369   Training iter 50, batch loss 0.4517, batch acc 0.1140
14:17:03.907   Training iter 100, batch loss 0.4518, batch acc 0.1108
14:17:04.453   Training iter 150, batch loss 0.4517, batch acc 0.1114
14:17:05.005   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:17:05.556   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:17:06.086   Training iter 300, batch loss 0.4518, batch acc 0.1136
14:17:06.581   Training iter 350, batch loss 0.4518, batch acc 0.1100
14:17:07.096   Training iter 400, batch loss 0.4518, batch acc 0.1152
14:17:07.620   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:17:08.140   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:17:08.663   Training iter 550, batch loss 0.4517, batch acc 0.1124
14:17:09.179   Training iter 600, batch loss 0.4517, batch acc 0.1116
14:17:09.181 Training @ 259 epoch...
14:17:09.694   Training iter 50, batch loss 0.4518, batch acc 0.1038
14:17:10.211   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:17:10.728   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:17:11.242   Training iter 200, batch loss 0.4517, batch acc 0.1128
14:17:11.760   Training iter 250, batch loss 0.4519, batch acc 0.1078
14:17:12.279   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:17:12.838   Training iter 350, batch loss 0.4518, batch acc 0.1062
14:17:13.399   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:17:13.947   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:17:14.487   Training iter 500, batch loss 0.4517, batch acc 0.1202
14:17:15.029   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:17:15.572   Training iter 600, batch loss 0.4517, batch acc 0.1184
14:17:15.574 Training @ 260 epoch...
14:17:16.131   Training iter 50, batch loss 0.4517, batch acc 0.1150
14:17:16.681   Training iter 100, batch loss 0.4517, batch acc 0.1216
14:17:17.232   Training iter 150, batch loss 0.4518, batch acc 0.1114
14:17:17.777   Training iter 200, batch loss 0.4517, batch acc 0.1168
14:17:18.311   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:17:18.823   Training iter 300, batch loss 0.4517, batch acc 0.1136
14:17:19.314   Training iter 350, batch loss 0.4516, batch acc 0.1208
14:17:19.814   Training iter 400, batch loss 0.4519, batch acc 0.1056
14:17:20.340   Training iter 450, batch loss 0.4518, batch acc 0.1076
14:17:20.852   Training iter 500, batch loss 0.4519, batch acc 0.1076
14:17:21.367   Training iter 550, batch loss 0.4518, batch acc 0.1116
14:17:21.883   Training iter 600, batch loss 0.4517, batch acc 0.1094
14:17:21.885 Testing @ 260 epoch...
14:17:21.924     Testing, total mean loss 0.45174, total acc 0.11350
14:17:21.924 Training @ 261 epoch...
14:17:22.470   Training iter 50, batch loss 0.4519, batch acc 0.1028
14:17:23.002   Training iter 100, batch loss 0.4517, batch acc 0.1202
14:17:23.526   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:17:24.048   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:17:24.573   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:17:25.127   Training iter 300, batch loss 0.4517, batch acc 0.1124
14:17:25.639   Training iter 350, batch loss 0.4517, batch acc 0.1132
14:17:26.171   Training iter 400, batch loss 0.4518, batch acc 0.1088
14:17:26.693   Training iter 450, batch loss 0.4517, batch acc 0.1106
14:17:27.233   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:17:27.717   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:17:28.218   Training iter 600, batch loss 0.4517, batch acc 0.1192
14:17:28.220 Training @ 262 epoch...
14:17:28.707   Training iter 50, batch loss 0.4519, batch acc 0.1068
14:17:29.240   Training iter 100, batch loss 0.4517, batch acc 0.1130
14:17:29.772   Training iter 150, batch loss 0.4516, batch acc 0.1204
14:17:30.303   Training iter 200, batch loss 0.4518, batch acc 0.1114
14:17:30.849   Training iter 250, batch loss 0.4517, batch acc 0.1166
14:17:31.396   Training iter 300, batch loss 0.4518, batch acc 0.1080
14:17:31.954   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:17:32.509   Training iter 400, batch loss 0.4518, batch acc 0.1130
14:17:33.062   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:17:33.611   Training iter 500, batch loss 0.4517, batch acc 0.1156
14:17:34.158   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:17:34.718   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:17:34.719 Training @ 263 epoch...
14:17:35.265   Training iter 50, batch loss 0.4518, batch acc 0.1150
14:17:35.785   Training iter 100, batch loss 0.4517, batch acc 0.1044
14:17:36.297   Training iter 150, batch loss 0.4519, batch acc 0.1024
14:17:36.781   Training iter 200, batch loss 0.4517, batch acc 0.1212
14:17:37.306   Training iter 250, batch loss 0.4518, batch acc 0.1152
14:17:37.840   Training iter 300, batch loss 0.4517, batch acc 0.1168
14:17:38.366   Training iter 350, batch loss 0.4517, batch acc 0.1202
14:17:38.896   Training iter 400, batch loss 0.4519, batch acc 0.1012
14:17:39.424   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:17:39.960   Training iter 500, batch loss 0.4518, batch acc 0.1076
14:17:40.480   Training iter 550, batch loss 0.4517, batch acc 0.1142
14:17:40.983   Training iter 600, batch loss 0.4517, batch acc 0.1160
14:17:40.984 Training @ 264 epoch...
14:17:41.494   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:17:42.005   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:17:42.521   Training iter 150, batch loss 0.4519, batch acc 0.1058
14:17:43.025   Training iter 200, batch loss 0.4517, batch acc 0.1168
14:17:43.523   Training iter 250, batch loss 0.4518, batch acc 0.1086
14:17:44.020   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:17:44.535   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:17:45.071   Training iter 400, batch loss 0.4518, batch acc 0.1144
14:17:45.589   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:17:46.116   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:17:46.637   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:17:47.208   Training iter 600, batch loss 0.4516, batch acc 0.1212
14:17:47.210 Training @ 265 epoch...
14:17:47.788   Training iter 50, batch loss 0.4518, batch acc 0.1138
14:17:48.364   Training iter 100, batch loss 0.4517, batch acc 0.1088
14:17:48.861   Training iter 150, batch loss 0.4518, batch acc 0.1056
14:17:49.365   Training iter 200, batch loss 0.4517, batch acc 0.1120
14:17:49.888   Training iter 250, batch loss 0.4518, batch acc 0.1144
14:17:50.416   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:17:50.923   Training iter 350, batch loss 0.4519, batch acc 0.1088
14:17:51.438   Training iter 400, batch loss 0.4518, batch acc 0.1084
14:17:51.929   Training iter 450, batch loss 0.4516, batch acc 0.1170
14:17:52.418   Training iter 500, batch loss 0.4517, batch acc 0.1192
14:17:52.903   Training iter 550, batch loss 0.4518, batch acc 0.1108
14:17:53.391   Training iter 600, batch loss 0.4517, batch acc 0.1150
14:17:53.393 Testing @ 265 epoch...
14:17:53.432     Testing, total mean loss 0.45174, total acc 0.11350
14:17:53.432 Training @ 266 epoch...
14:17:53.914   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:17:54.400   Training iter 100, batch loss 0.4517, batch acc 0.1074
14:17:54.887   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:17:55.344   Training iter 200, batch loss 0.4517, batch acc 0.1142
14:17:55.804   Training iter 250, batch loss 0.4517, batch acc 0.1106
14:17:56.275   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:17:56.749   Training iter 350, batch loss 0.4518, batch acc 0.1136
14:17:57.276   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:17:57.787   Training iter 450, batch loss 0.4517, batch acc 0.1130
14:17:58.288   Training iter 500, batch loss 0.4517, batch acc 0.1190
14:17:58.780   Training iter 550, batch loss 0.4518, batch acc 0.1116
14:17:59.284   Training iter 600, batch loss 0.4518, batch acc 0.1168
14:17:59.286 Training @ 267 epoch...
14:17:59.798   Training iter 50, batch loss 0.4517, batch acc 0.1158
14:18:00.346   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:18:00.868   Training iter 150, batch loss 0.4518, batch acc 0.1110
14:18:01.384   Training iter 200, batch loss 0.4518, batch acc 0.1140
14:18:01.961   Training iter 250, batch loss 0.4517, batch acc 0.1128
14:18:02.538   Training iter 300, batch loss 0.4516, batch acc 0.1204
14:18:03.090   Training iter 350, batch loss 0.4518, batch acc 0.1136
14:18:03.648   Training iter 400, batch loss 0.4517, batch acc 0.1144
14:18:04.213   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:18:04.771   Training iter 500, batch loss 0.4518, batch acc 0.1120
14:18:05.309   Training iter 550, batch loss 0.4518, batch acc 0.1052
14:18:05.853   Training iter 600, batch loss 0.4519, batch acc 0.1078
14:18:05.854 Training @ 268 epoch...
14:18:06.395   Training iter 50, batch loss 0.4517, batch acc 0.1118
14:18:06.948   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:18:07.500   Training iter 150, batch loss 0.4517, batch acc 0.1126
14:18:08.041   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:18:08.588   Training iter 250, batch loss 0.4517, batch acc 0.1142
14:18:09.112   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:18:09.628   Training iter 350, batch loss 0.4519, batch acc 0.1092
14:18:10.175   Training iter 400, batch loss 0.4517, batch acc 0.1096
14:18:10.738   Training iter 450, batch loss 0.4518, batch acc 0.1146
14:18:11.299   Training iter 500, batch loss 0.4517, batch acc 0.1106
14:18:11.839   Training iter 550, batch loss 0.4517, batch acc 0.1132
14:18:12.378   Training iter 600, batch loss 0.4517, batch acc 0.1202
14:18:12.379 Training @ 269 epoch...
14:18:12.939   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:18:13.499   Training iter 100, batch loss 0.4518, batch acc 0.1154
14:18:14.049   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:18:14.587   Training iter 200, batch loss 0.4517, batch acc 0.1120
14:18:15.147   Training iter 250, batch loss 0.4518, batch acc 0.1144
14:18:15.692   Training iter 300, batch loss 0.4518, batch acc 0.1048
14:18:16.227   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:18:16.756   Training iter 400, batch loss 0.4517, batch acc 0.1194
14:18:17.310   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:18:17.866   Training iter 500, batch loss 0.4517, batch acc 0.1144
14:18:18.408   Training iter 550, batch loss 0.4517, batch acc 0.1130
14:18:18.935   Training iter 600, batch loss 0.4517, batch acc 0.1138
14:18:18.937 Training @ 270 epoch...
14:18:19.468   Training iter 50, batch loss 0.4518, batch acc 0.1096
14:18:20.001   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:18:20.537   Training iter 150, batch loss 0.4517, batch acc 0.1120
14:18:21.065   Training iter 200, batch loss 0.4517, batch acc 0.1096
14:18:21.581   Training iter 250, batch loss 0.4517, batch acc 0.1154
14:18:22.098   Training iter 300, batch loss 0.4519, batch acc 0.1034
14:18:22.632   Training iter 350, batch loss 0.4518, batch acc 0.1070
14:18:23.162   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:18:23.687   Training iter 450, batch loss 0.4517, batch acc 0.1172
14:18:24.206   Training iter 500, batch loss 0.4517, batch acc 0.1190
14:18:24.725   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:18:25.259   Training iter 600, batch loss 0.4518, batch acc 0.1132
14:18:25.261 Testing @ 270 epoch...
14:18:25.301     Testing, total mean loss 0.45174, total acc 0.11350
14:18:25.301 Training @ 271 epoch...
14:18:25.844   Training iter 50, batch loss 0.4518, batch acc 0.1086
14:18:26.379   Training iter 100, batch loss 0.4518, batch acc 0.1146
14:18:26.926   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:18:27.518   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:18:28.122   Training iter 250, batch loss 0.4517, batch acc 0.1212
14:18:28.656   Training iter 300, batch loss 0.4517, batch acc 0.1140
14:18:29.192   Training iter 350, batch loss 0.4518, batch acc 0.1106
14:18:29.725   Training iter 400, batch loss 0.4518, batch acc 0.1102
14:18:30.266   Training iter 450, batch loss 0.4517, batch acc 0.1112
14:18:30.816   Training iter 500, batch loss 0.4517, batch acc 0.1144
14:18:31.358   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:18:31.890   Training iter 600, batch loss 0.4517, batch acc 0.1126
14:18:31.891 Training @ 272 epoch...
14:18:32.431   Training iter 50, batch loss 0.4518, batch acc 0.1102
14:18:32.975   Training iter 100, batch loss 0.4518, batch acc 0.1068
14:18:33.477   Training iter 150, batch loss 0.4518, batch acc 0.1160
14:18:33.967   Training iter 200, batch loss 0.4517, batch acc 0.1184
14:18:34.462   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:18:34.970   Training iter 300, batch loss 0.4517, batch acc 0.1152
14:18:35.489   Training iter 350, batch loss 0.4518, batch acc 0.1068
14:18:35.980   Training iter 400, batch loss 0.4517, batch acc 0.1144
14:18:36.482   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:18:36.986   Training iter 500, batch loss 0.4518, batch acc 0.1090
14:18:37.508   Training iter 550, batch loss 0.4518, batch acc 0.1130
14:18:38.028   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:18:38.030 Training @ 273 epoch...
14:18:38.555   Training iter 50, batch loss 0.4518, batch acc 0.1124
14:18:39.046   Training iter 100, batch loss 0.4518, batch acc 0.1154
14:18:39.525   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:18:40.016   Training iter 200, batch loss 0.4518, batch acc 0.1138
14:18:40.524   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:18:41.006   Training iter 300, batch loss 0.4517, batch acc 0.1148
14:18:41.483   Training iter 350, batch loss 0.4517, batch acc 0.1120
14:18:41.962   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:18:42.449   Training iter 450, batch loss 0.4518, batch acc 0.1094
14:18:42.940   Training iter 500, batch loss 0.4517, batch acc 0.1144
14:18:43.411   Training iter 550, batch loss 0.4518, batch acc 0.1068
14:18:43.863   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:18:43.864 Training @ 274 epoch...
14:18:44.381   Training iter 50, batch loss 0.4519, batch acc 0.1012
14:18:44.903   Training iter 100, batch loss 0.4518, batch acc 0.1088
14:18:45.444   Training iter 150, batch loss 0.4517, batch acc 0.1160
14:18:45.945   Training iter 200, batch loss 0.4517, batch acc 0.1152
14:18:46.427   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:18:46.922   Training iter 300, batch loss 0.4518, batch acc 0.1094
14:18:47.420   Training iter 350, batch loss 0.4517, batch acc 0.1176
14:18:47.919   Training iter 400, batch loss 0.4517, batch acc 0.1098
14:18:48.423   Training iter 450, batch loss 0.4518, batch acc 0.1090
14:18:48.916   Training iter 500, batch loss 0.4518, batch acc 0.1148
14:18:49.410   Training iter 550, batch loss 0.4517, batch acc 0.1176
14:18:49.916   Training iter 600, batch loss 0.4517, batch acc 0.1216
14:18:49.918 Training @ 275 epoch...
14:18:50.433   Training iter 50, batch loss 0.4519, batch acc 0.0992
14:18:50.942   Training iter 100, batch loss 0.4517, batch acc 0.1212
14:18:51.429   Training iter 150, batch loss 0.4517, batch acc 0.1164
14:18:51.886   Training iter 200, batch loss 0.4518, batch acc 0.1068
14:18:52.348   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:18:52.843   Training iter 300, batch loss 0.4518, batch acc 0.1082
14:18:53.374   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:18:53.900   Training iter 400, batch loss 0.4516, batch acc 0.1214
14:18:54.416   Training iter 450, batch loss 0.4518, batch acc 0.1140
14:18:54.937   Training iter 500, batch loss 0.4518, batch acc 0.1140
14:18:55.464   Training iter 550, batch loss 0.4517, batch acc 0.1102
14:18:55.975   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:18:55.977 Testing @ 275 epoch...
14:18:56.021     Testing, total mean loss 0.45174, total acc 0.11350
14:18:56.021 Training @ 276 epoch...
14:18:56.533   Training iter 50, batch loss 0.4518, batch acc 0.1056
14:18:57.048   Training iter 100, batch loss 0.4517, batch acc 0.1160
14:18:57.565   Training iter 150, batch loss 0.4516, batch acc 0.1208
14:18:58.097   Training iter 200, batch loss 0.4518, batch acc 0.1058
14:18:58.599   Training iter 250, batch loss 0.4518, batch acc 0.1162
14:18:59.097   Training iter 300, batch loss 0.4517, batch acc 0.1144
14:18:59.586   Training iter 350, batch loss 0.4519, batch acc 0.1052
14:19:00.069   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:19:00.550   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:19:01.023   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:19:01.494   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:19:02.018   Training iter 600, batch loss 0.4517, batch acc 0.1168
14:19:02.019 Training @ 277 epoch...
14:19:02.564   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:19:03.117   Training iter 100, batch loss 0.4518, batch acc 0.1158
14:19:03.649   Training iter 150, batch loss 0.4517, batch acc 0.1158
14:19:04.183   Training iter 200, batch loss 0.4518, batch acc 0.1140
14:19:04.751   Training iter 250, batch loss 0.4517, batch acc 0.1154
14:19:05.320   Training iter 300, batch loss 0.4517, batch acc 0.1192
14:19:05.899   Training iter 350, batch loss 0.4517, batch acc 0.1074
14:19:06.456   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:19:07.012   Training iter 450, batch loss 0.4517, batch acc 0.1166
14:19:07.542   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:19:08.064   Training iter 550, batch loss 0.4518, batch acc 0.1058
14:19:08.557   Training iter 600, batch loss 0.4518, batch acc 0.1072
14:19:08.558 Training @ 278 epoch...
14:19:09.052   Training iter 50, batch loss 0.4518, batch acc 0.1014
14:19:09.539   Training iter 100, batch loss 0.4518, batch acc 0.1138
14:19:10.045   Training iter 150, batch loss 0.4517, batch acc 0.1110
14:19:10.562   Training iter 200, batch loss 0.4518, batch acc 0.1142
14:19:11.011   Training iter 250, batch loss 0.4517, batch acc 0.1124
14:19:11.479   Training iter 300, batch loss 0.4517, batch acc 0.1180
14:19:11.932   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:19:12.401   Training iter 400, batch loss 0.4518, batch acc 0.1124
14:19:12.888   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:19:13.377   Training iter 500, batch loss 0.4518, batch acc 0.1110
14:19:13.842   Training iter 550, batch loss 0.4517, batch acc 0.1150
14:19:14.312   Training iter 600, batch loss 0.4518, batch acc 0.1084
14:19:14.313 Training @ 279 epoch...
14:19:14.787   Training iter 50, batch loss 0.4518, batch acc 0.1074
14:19:15.267   Training iter 100, batch loss 0.4517, batch acc 0.1080
14:19:15.747   Training iter 150, batch loss 0.4517, batch acc 0.1116
14:19:16.226   Training iter 200, batch loss 0.4517, batch acc 0.1210
14:19:16.702   Training iter 250, batch loss 0.4517, batch acc 0.1170
14:19:17.180   Training iter 300, batch loss 0.4517, batch acc 0.1110
14:19:17.696   Training iter 350, batch loss 0.4517, batch acc 0.1110
14:19:18.222   Training iter 400, batch loss 0.4517, batch acc 0.1156
14:19:18.745   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:19:19.253   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:19:19.765   Training iter 550, batch loss 0.4518, batch acc 0.1064
14:19:20.287   Training iter 600, batch loss 0.4517, batch acc 0.1158
14:19:20.289 Training @ 280 epoch...
14:19:20.834   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:19:21.377   Training iter 100, batch loss 0.4518, batch acc 0.1156
14:19:21.925   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:19:22.445   Training iter 200, batch loss 0.4517, batch acc 0.1110
14:19:22.961   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:19:23.482   Training iter 300, batch loss 0.4518, batch acc 0.1132
14:19:23.994   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:19:24.511   Training iter 400, batch loss 0.4517, batch acc 0.1168
14:19:25.039   Training iter 450, batch loss 0.4517, batch acc 0.1168
14:19:25.571   Training iter 500, batch loss 0.4517, batch acc 0.1094
14:19:26.098   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:19:26.608   Training iter 600, batch loss 0.4518, batch acc 0.1110
14:19:26.609 Testing @ 280 epoch...
14:19:26.648     Testing, total mean loss 0.45174, total acc 0.11350
14:19:26.648 Training @ 281 epoch...
14:19:27.148   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:19:27.651   Training iter 100, batch loss 0.4518, batch acc 0.1086
14:19:28.162   Training iter 150, batch loss 0.4517, batch acc 0.1110
14:19:28.656   Training iter 200, batch loss 0.4518, batch acc 0.1136
14:19:29.149   Training iter 250, batch loss 0.4517, batch acc 0.1166
14:19:29.630   Training iter 300, batch loss 0.4518, batch acc 0.1074
14:19:30.159   Training iter 350, batch loss 0.4517, batch acc 0.1210
14:19:30.693   Training iter 400, batch loss 0.4518, batch acc 0.1102
14:19:31.221   Training iter 450, batch loss 0.4516, batch acc 0.1214
14:19:31.743   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:19:32.265   Training iter 550, batch loss 0.4519, batch acc 0.0998
14:19:32.792   Training iter 600, batch loss 0.4517, batch acc 0.1140
14:19:32.793 Training @ 282 epoch...
14:19:33.335   Training iter 50, batch loss 0.4518, batch acc 0.1104
14:19:33.854   Training iter 100, batch loss 0.4516, batch acc 0.1170
14:19:34.376   Training iter 150, batch loss 0.4518, batch acc 0.1182
14:19:34.912   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:19:35.440   Training iter 250, batch loss 0.4519, batch acc 0.1054
14:19:35.954   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:19:36.463   Training iter 350, batch loss 0.4518, batch acc 0.1080
14:19:37.003   Training iter 400, batch loss 0.4517, batch acc 0.1128
14:19:37.562   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:19:38.114   Training iter 500, batch loss 0.4518, batch acc 0.1084
14:19:38.669   Training iter 550, batch loss 0.4517, batch acc 0.1166
14:19:39.211   Training iter 600, batch loss 0.4518, batch acc 0.1138
14:19:39.213 Training @ 283 epoch...
14:19:39.768   Training iter 50, batch loss 0.4518, batch acc 0.1086
14:19:40.316   Training iter 100, batch loss 0.4517, batch acc 0.1146
14:19:40.858   Training iter 150, batch loss 0.4518, batch acc 0.1082
14:19:41.397   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:19:41.941   Training iter 250, batch loss 0.4518, batch acc 0.1076
14:19:42.486   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:19:43.038   Training iter 350, batch loss 0.4518, batch acc 0.1102
14:19:43.556   Training iter 400, batch loss 0.4517, batch acc 0.1148
14:19:44.060   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:19:44.584   Training iter 500, batch loss 0.4517, batch acc 0.1148
14:19:45.108   Training iter 550, batch loss 0.4517, batch acc 0.1156
14:19:45.619   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:19:45.620 Training @ 284 epoch...
14:19:46.139   Training iter 50, batch loss 0.4518, batch acc 0.1110
14:19:46.653   Training iter 100, batch loss 0.4517, batch acc 0.1120
14:19:47.162   Training iter 150, batch loss 0.4517, batch acc 0.1084
14:19:47.664   Training iter 200, batch loss 0.4518, batch acc 0.1168
14:19:48.172   Training iter 250, batch loss 0.4517, batch acc 0.1068
14:19:48.669   Training iter 300, batch loss 0.4518, batch acc 0.1134
14:19:49.179   Training iter 350, batch loss 0.4519, batch acc 0.1068
14:19:49.678   Training iter 400, batch loss 0.4517, batch acc 0.1182
14:19:50.190   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:19:50.681   Training iter 500, batch loss 0.4516, batch acc 0.1202
14:19:51.157   Training iter 550, batch loss 0.4517, batch acc 0.1150
14:19:51.645   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:19:51.647 Training @ 285 epoch...
14:19:52.131   Training iter 50, batch loss 0.4517, batch acc 0.1182
14:19:52.610   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:19:53.109   Training iter 150, batch loss 0.4518, batch acc 0.1088
14:19:53.633   Training iter 200, batch loss 0.4518, batch acc 0.1102
14:19:54.146   Training iter 250, batch loss 0.4516, batch acc 0.1210
14:19:54.649   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:19:55.172   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:19:55.691   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:19:56.217   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:19:56.746   Training iter 500, batch loss 0.4518, batch acc 0.1152
14:19:57.282   Training iter 550, batch loss 0.4518, batch acc 0.1074
14:19:57.812   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:19:57.814 Testing @ 285 epoch...
14:19:57.855     Testing, total mean loss 0.45174, total acc 0.11350
14:19:57.855 Training @ 286 epoch...
14:19:58.387   Training iter 50, batch loss 0.4519, batch acc 0.1112
14:19:58.895   Training iter 100, batch loss 0.4517, batch acc 0.1174
14:19:59.383   Training iter 150, batch loss 0.4518, batch acc 0.1084
14:19:59.894   Training iter 200, batch loss 0.4516, batch acc 0.1228
14:20:00.438   Training iter 250, batch loss 0.4517, batch acc 0.1144
14:20:00.956   Training iter 300, batch loss 0.4519, batch acc 0.1032
14:20:01.462   Training iter 350, batch loss 0.4519, batch acc 0.1088
14:20:01.982   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:20:02.539   Training iter 450, batch loss 0.4518, batch acc 0.1102
14:20:03.081   Training iter 500, batch loss 0.4517, batch acc 0.1158
14:20:03.609   Training iter 550, batch loss 0.4517, batch acc 0.1162
14:20:04.124   Training iter 600, batch loss 0.4518, batch acc 0.1038
14:20:04.126 Training @ 287 epoch...
14:20:04.667   Training iter 50, batch loss 0.4518, batch acc 0.1070
14:20:05.212   Training iter 100, batch loss 0.4517, batch acc 0.1170
14:20:05.757   Training iter 150, batch loss 0.4518, batch acc 0.1054
14:20:06.282   Training iter 200, batch loss 0.4517, batch acc 0.1176
14:20:06.799   Training iter 250, batch loss 0.4518, batch acc 0.1068
14:20:07.308   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:20:07.819   Training iter 350, batch loss 0.4517, batch acc 0.1176
14:20:08.321   Training iter 400, batch loss 0.4518, batch acc 0.1050
14:20:08.788   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:20:09.293   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:20:09.793   Training iter 550, batch loss 0.4517, batch acc 0.1182
14:20:10.295   Training iter 600, batch loss 0.4518, batch acc 0.1088
14:20:10.297 Training @ 288 epoch...
14:20:10.797   Training iter 50, batch loss 0.4518, batch acc 0.1080
14:20:11.295   Training iter 100, batch loss 0.4517, batch acc 0.1142
14:20:11.835   Training iter 150, batch loss 0.4517, batch acc 0.1146
14:20:12.370   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:20:12.875   Training iter 250, batch loss 0.4517, batch acc 0.1120
14:20:13.391   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:20:13.904   Training iter 350, batch loss 0.4517, batch acc 0.1198
14:20:14.403   Training iter 400, batch loss 0.4518, batch acc 0.1146
14:20:14.890   Training iter 450, batch loss 0.4518, batch acc 0.1030
14:20:15.360   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:20:15.810   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:20:16.275   Training iter 600, batch loss 0.4517, batch acc 0.1124
14:20:16.277 Training @ 289 epoch...
14:20:16.723   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:20:17.170   Training iter 100, batch loss 0.4517, batch acc 0.1122
14:20:17.639   Training iter 150, batch loss 0.4518, batch acc 0.1066
14:20:18.138   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:20:18.651   Training iter 250, batch loss 0.4518, batch acc 0.1110
14:20:19.142   Training iter 300, batch loss 0.4518, batch acc 0.1118
14:20:19.630   Training iter 350, batch loss 0.4518, batch acc 0.1142
14:20:20.125   Training iter 400, batch loss 0.4517, batch acc 0.1124
14:20:20.618   Training iter 450, batch loss 0.4518, batch acc 0.1158
14:20:21.115   Training iter 500, batch loss 0.4518, batch acc 0.1120
14:20:21.604   Training iter 550, batch loss 0.4517, batch acc 0.1096
14:20:22.100   Training iter 600, batch loss 0.4516, batch acc 0.1204
14:20:22.102 Training @ 290 epoch...
14:20:22.602   Training iter 50, batch loss 0.4517, batch acc 0.1206
14:20:23.100   Training iter 100, batch loss 0.4517, batch acc 0.1156
14:20:23.596   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:20:24.091   Training iter 200, batch loss 0.4517, batch acc 0.1174
14:20:24.595   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:20:25.119   Training iter 300, batch loss 0.4518, batch acc 0.1104
14:20:25.633   Training iter 350, batch loss 0.4518, batch acc 0.1140
14:20:26.144   Training iter 400, batch loss 0.4517, batch acc 0.1158
14:20:26.654   Training iter 450, batch loss 0.4517, batch acc 0.1120
14:20:27.165   Training iter 500, batch loss 0.4518, batch acc 0.1076
14:20:27.686   Training iter 550, batch loss 0.4518, batch acc 0.1004
14:20:28.211   Training iter 600, batch loss 0.4517, batch acc 0.1146
14:20:28.213 Testing @ 290 epoch...
14:20:28.252     Testing, total mean loss 0.45174, total acc 0.11350
14:20:28.252 Training @ 291 epoch...
14:20:28.771   Training iter 50, batch loss 0.4517, batch acc 0.1170
14:20:29.305   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:20:29.834   Training iter 150, batch loss 0.4518, batch acc 0.1060
14:20:30.355   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:20:30.872   Training iter 250, batch loss 0.4517, batch acc 0.1220
14:20:31.394   Training iter 300, batch loss 0.4517, batch acc 0.1094
14:20:31.914   Training iter 350, batch loss 0.4517, batch acc 0.1108
14:20:32.441   Training iter 400, batch loss 0.4518, batch acc 0.1052
14:20:32.983   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:20:33.532   Training iter 500, batch loss 0.4517, batch acc 0.1186
14:20:34.078   Training iter 550, batch loss 0.4519, batch acc 0.1100
14:20:34.638   Training iter 600, batch loss 0.4517, batch acc 0.1108
14:20:34.640 Training @ 292 epoch...
14:20:35.178   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:20:35.711   Training iter 100, batch loss 0.4517, batch acc 0.1178
14:20:36.241   Training iter 150, batch loss 0.4516, batch acc 0.1206
14:20:36.765   Training iter 200, batch loss 0.4518, batch acc 0.1062
14:20:37.298   Training iter 250, batch loss 0.4519, batch acc 0.1068
14:20:37.828   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:20:38.374   Training iter 350, batch loss 0.4517, batch acc 0.1130
14:20:38.904   Training iter 400, batch loss 0.4518, batch acc 0.1106
14:20:39.392   Training iter 450, batch loss 0.4518, batch acc 0.1052
14:20:39.888   Training iter 500, batch loss 0.4517, batch acc 0.1194
14:20:40.439   Training iter 550, batch loss 0.4517, batch acc 0.1114
14:20:40.997   Training iter 600, batch loss 0.4517, batch acc 0.1188
14:20:40.999 Training @ 293 epoch...
14:20:41.554   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:20:42.097   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:20:42.652   Training iter 150, batch loss 0.4518, batch acc 0.1124
14:20:43.205   Training iter 200, batch loss 0.4518, batch acc 0.1022
14:20:43.750   Training iter 250, batch loss 0.4517, batch acc 0.1162
14:20:44.298   Training iter 300, batch loss 0.4519, batch acc 0.1078
14:20:44.853   Training iter 350, batch loss 0.4517, batch acc 0.1126
14:20:45.406   Training iter 400, batch loss 0.4518, batch acc 0.1104
14:20:45.958   Training iter 450, batch loss 0.4518, batch acc 0.1134
14:20:46.515   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:20:47.063   Training iter 550, batch loss 0.4517, batch acc 0.1186
14:20:47.592   Training iter 600, batch loss 0.4517, batch acc 0.1148
14:20:47.593 Training @ 294 epoch...
14:20:48.117   Training iter 50, batch loss 0.4518, batch acc 0.1074
14:20:48.638   Training iter 100, batch loss 0.4518, batch acc 0.1090
14:20:49.152   Training iter 150, batch loss 0.4516, batch acc 0.1168
14:20:49.667   Training iter 200, batch loss 0.4518, batch acc 0.1102
14:20:50.202   Training iter 250, batch loss 0.4518, batch acc 0.1140
14:20:50.720   Training iter 300, batch loss 0.4517, batch acc 0.1144
14:20:51.235   Training iter 350, batch loss 0.4518, batch acc 0.1130
14:20:51.736   Training iter 400, batch loss 0.4517, batch acc 0.1168
14:20:52.242   Training iter 450, batch loss 0.4517, batch acc 0.1140
14:20:52.748   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:20:53.267   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:20:53.798   Training iter 600, batch loss 0.4517, batch acc 0.1130
14:20:53.800 Training @ 295 epoch...
14:20:54.340   Training iter 50, batch loss 0.4518, batch acc 0.1068
14:20:54.872   Training iter 100, batch loss 0.4518, batch acc 0.1086
14:20:55.439   Training iter 150, batch loss 0.4517, batch acc 0.1194
14:20:56.011   Training iter 200, batch loss 0.4518, batch acc 0.1164
14:20:56.580   Training iter 250, batch loss 0.4517, batch acc 0.1126
14:20:57.149   Training iter 300, batch loss 0.4518, batch acc 0.1134
14:20:57.713   Training iter 350, batch loss 0.4518, batch acc 0.1078
14:20:58.289   Training iter 400, batch loss 0.4518, batch acc 0.1140
14:20:58.843   Training iter 450, batch loss 0.4517, batch acc 0.1198
14:20:59.356   Training iter 500, batch loss 0.4518, batch acc 0.1106
14:20:59.874   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:21:00.397   Training iter 600, batch loss 0.4518, batch acc 0.1042
14:21:00.399 Testing @ 295 epoch...
14:21:00.437     Testing, total mean loss 0.45174, total acc 0.11350
14:21:00.437 Training @ 296 epoch...
14:21:00.877   Training iter 50, batch loss 0.4518, batch acc 0.1130
14:21:01.360   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:21:01.891   Training iter 150, batch loss 0.4517, batch acc 0.1110
14:21:02.435   Training iter 200, batch loss 0.4518, batch acc 0.1078
14:21:02.967   Training iter 250, batch loss 0.4518, batch acc 0.1114
14:21:03.522   Training iter 300, batch loss 0.4517, batch acc 0.1192
14:21:04.043   Training iter 350, batch loss 0.4517, batch acc 0.1150
14:21:04.568   Training iter 400, batch loss 0.4517, batch acc 0.1146
14:21:05.101   Training iter 450, batch loss 0.4518, batch acc 0.1094
14:21:05.625   Training iter 500, batch loss 0.4518, batch acc 0.1090
14:21:06.177   Training iter 550, batch loss 0.4518, batch acc 0.1152
14:21:06.716   Training iter 600, batch loss 0.4518, batch acc 0.1076
14:21:06.717 Training @ 297 epoch...
14:21:07.238   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:21:07.746   Training iter 100, batch loss 0.4518, batch acc 0.1096
14:21:08.254   Training iter 150, batch loss 0.4517, batch acc 0.1124
14:21:08.757   Training iter 200, batch loss 0.4517, batch acc 0.1134
14:21:09.263   Training iter 250, batch loss 0.4517, batch acc 0.1150
14:21:09.763   Training iter 300, batch loss 0.4519, batch acc 0.1088
14:21:10.284   Training iter 350, batch loss 0.4518, batch acc 0.1072
14:21:10.792   Training iter 400, batch loss 0.4518, batch acc 0.1068
14:21:11.297   Training iter 450, batch loss 0.4517, batch acc 0.1154
14:21:11.798   Training iter 500, batch loss 0.4518, batch acc 0.1150
14:21:12.305   Training iter 550, batch loss 0.4518, batch acc 0.1096
14:21:12.813   Training iter 600, batch loss 0.4517, batch acc 0.1236
14:21:12.815 Training @ 298 epoch...
14:21:13.370   Training iter 50, batch loss 0.4516, batch acc 0.1198
14:21:13.907   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:21:14.452   Training iter 150, batch loss 0.4518, batch acc 0.1070
14:21:14.995   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:21:15.536   Training iter 250, batch loss 0.4518, batch acc 0.1032
14:21:16.082   Training iter 300, batch loss 0.4519, batch acc 0.1054
14:21:16.618   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:21:17.162   Training iter 400, batch loss 0.4518, batch acc 0.1120
14:21:17.758   Training iter 450, batch loss 0.4517, batch acc 0.1122
14:21:18.418   Training iter 500, batch loss 0.4517, batch acc 0.1150
14:21:19.094   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:21:19.557   Training iter 600, batch loss 0.4517, batch acc 0.1172
14:21:19.558 Training @ 299 epoch...
14:21:20.017   Training iter 50, batch loss 0.4517, batch acc 0.1104
14:21:20.472   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:21:20.932   Training iter 150, batch loss 0.4518, batch acc 0.1076
14:21:21.384   Training iter 200, batch loss 0.4518, batch acc 0.1126
14:21:21.836   Training iter 250, batch loss 0.4516, batch acc 0.1212
14:21:22.297   Training iter 300, batch loss 0.4517, batch acc 0.1134
14:21:22.755   Training iter 350, batch loss 0.4516, batch acc 0.1146
14:21:23.235   Training iter 400, batch loss 0.4518, batch acc 0.1062
14:21:23.730   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:21:24.258   Training iter 500, batch loss 0.4518, batch acc 0.1140
14:21:24.799   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:21:25.358   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:21:25.359 Training @ 300 epoch...
14:21:25.905   Training iter 50, batch loss 0.4518, batch acc 0.1138
14:21:26.423   Training iter 100, batch loss 0.4517, batch acc 0.1206
14:21:26.918   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:21:27.425   Training iter 200, batch loss 0.4517, batch acc 0.1096
14:21:27.940   Training iter 250, batch loss 0.4517, batch acc 0.1122
14:21:28.446   Training iter 300, batch loss 0.4517, batch acc 0.1190
14:21:28.918   Training iter 350, batch loss 0.4517, batch acc 0.1126
14:21:29.393   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:21:29.869   Training iter 450, batch loss 0.4517, batch acc 0.1088
14:21:30.382   Training iter 500, batch loss 0.4517, batch acc 0.1136
14:21:30.887   Training iter 550, batch loss 0.4518, batch acc 0.1108
14:21:31.376   Training iter 600, batch loss 0.4518, batch acc 0.1076
14:21:31.378 Testing @ 300 epoch...
14:21:31.416     Testing, total mean loss 0.45174, total acc 0.11350
14:21:31.416 Plot @ 300 epoch...
14:21:31.416 Training @ 301 epoch...
14:21:31.931   Training iter 50, batch loss 0.4519, batch acc 0.1070
14:21:32.457   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:21:32.996   Training iter 150, batch loss 0.4518, batch acc 0.1054
14:21:33.533   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:21:34.051   Training iter 250, batch loss 0.4517, batch acc 0.1106
14:21:34.572   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:21:35.102   Training iter 350, batch loss 0.4518, batch acc 0.1130
14:21:35.607   Training iter 400, batch loss 0.4517, batch acc 0.1208
14:21:36.102   Training iter 450, batch loss 0.4516, batch acc 0.1200
14:21:36.580   Training iter 500, batch loss 0.4517, batch acc 0.1128
14:21:37.046   Training iter 550, batch loss 0.4518, batch acc 0.1114
14:21:37.511   Training iter 600, batch loss 0.4518, batch acc 0.1074
14:21:37.513 Training @ 302 epoch...
14:21:38.009   Training iter 50, batch loss 0.4517, batch acc 0.1112
14:21:38.527   Training iter 100, batch loss 0.4516, batch acc 0.1180
14:21:39.040   Training iter 150, batch loss 0.4519, batch acc 0.1086
14:21:39.550   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:21:40.068   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:21:40.565   Training iter 300, batch loss 0.4518, batch acc 0.1100
14:21:41.062   Training iter 350, batch loss 0.4517, batch acc 0.1148
14:21:41.566   Training iter 400, batch loss 0.4517, batch acc 0.1130
14:21:42.081   Training iter 450, batch loss 0.4518, batch acc 0.1148
14:21:42.575   Training iter 500, batch loss 0.4518, batch acc 0.1126
14:21:43.080   Training iter 550, batch loss 0.4517, batch acc 0.1090
14:21:43.575   Training iter 600, batch loss 0.4517, batch acc 0.1146
14:21:43.576 Training @ 303 epoch...
14:21:44.070   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:21:44.544   Training iter 100, batch loss 0.4517, batch acc 0.1166
14:21:45.038   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:21:45.534   Training iter 200, batch loss 0.4519, batch acc 0.1074
14:21:46.017   Training iter 250, batch loss 0.4517, batch acc 0.1180
14:21:46.515   Training iter 300, batch loss 0.4518, batch acc 0.1114
14:21:47.021   Training iter 350, batch loss 0.4518, batch acc 0.1114
14:21:47.521   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:21:48.010   Training iter 450, batch loss 0.4517, batch acc 0.1092
14:21:48.500   Training iter 500, batch loss 0.4517, batch acc 0.1150
14:21:49.002   Training iter 550, batch loss 0.4518, batch acc 0.1042
14:21:49.501   Training iter 600, batch loss 0.4518, batch acc 0.1134
14:21:49.503 Training @ 304 epoch...
14:21:50.011   Training iter 50, batch loss 0.4518, batch acc 0.1084
14:21:50.507   Training iter 100, batch loss 0.4518, batch acc 0.1082
14:21:50.996   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:21:51.488   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:21:51.977   Training iter 250, batch loss 0.4518, batch acc 0.1144
14:21:52.460   Training iter 300, batch loss 0.4519, batch acc 0.1030
14:21:52.949   Training iter 350, batch loss 0.4517, batch acc 0.1188
14:21:53.466   Training iter 400, batch loss 0.4517, batch acc 0.1190
14:21:53.928   Training iter 450, batch loss 0.4518, batch acc 0.1056
14:21:54.399   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:21:54.856   Training iter 550, batch loss 0.4516, batch acc 0.1222
14:21:55.344   Training iter 600, batch loss 0.4517, batch acc 0.1102
14:21:55.346 Training @ 305 epoch...
14:21:55.814   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:21:56.284   Training iter 100, batch loss 0.4517, batch acc 0.1168
14:21:56.749   Training iter 150, batch loss 0.4518, batch acc 0.1062
14:21:57.235   Training iter 200, batch loss 0.4517, batch acc 0.1162
14:21:57.698   Training iter 250, batch loss 0.4518, batch acc 0.1084
14:21:58.167   Training iter 300, batch loss 0.4518, batch acc 0.1160
14:21:58.620   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:21:59.091   Training iter 400, batch loss 0.4517, batch acc 0.1106
14:21:59.554   Training iter 450, batch loss 0.4518, batch acc 0.1080
14:22:00.030   Training iter 500, batch loss 0.4518, batch acc 0.1076
14:22:00.518   Training iter 550, batch loss 0.4517, batch acc 0.1152
14:22:00.974   Training iter 600, batch loss 0.4517, batch acc 0.1188
14:22:00.976 Testing @ 305 epoch...
14:22:01.016     Testing, total mean loss 0.45174, total acc 0.11350
14:22:01.016 Training @ 306 epoch...
14:22:01.517   Training iter 50, batch loss 0.4517, batch acc 0.1140
14:22:02.029   Training iter 100, batch loss 0.4517, batch acc 0.1094
14:22:02.560   Training iter 150, batch loss 0.4518, batch acc 0.1114
14:22:03.097   Training iter 200, batch loss 0.4518, batch acc 0.1052
14:22:03.622   Training iter 250, batch loss 0.4516, batch acc 0.1248
14:22:04.144   Training iter 300, batch loss 0.4519, batch acc 0.1068
14:22:04.675   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:22:05.214   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:22:05.736   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:22:06.267   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:22:06.807   Training iter 550, batch loss 0.4518, batch acc 0.1084
14:22:07.345   Training iter 600, batch loss 0.4517, batch acc 0.1178
14:22:07.346 Training @ 307 epoch...
14:22:07.870   Training iter 50, batch loss 0.4517, batch acc 0.1168
14:22:08.406   Training iter 100, batch loss 0.4517, batch acc 0.1126
14:22:08.958   Training iter 150, batch loss 0.4517, batch acc 0.1174
14:22:09.526   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:22:10.096   Training iter 250, batch loss 0.4517, batch acc 0.1204
14:22:10.645   Training iter 300, batch loss 0.4518, batch acc 0.1054
14:22:11.145   Training iter 350, batch loss 0.4518, batch acc 0.1048
14:22:11.650   Training iter 400, batch loss 0.4518, batch acc 0.1102
14:22:12.163   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:22:12.667   Training iter 500, batch loss 0.4518, batch acc 0.1132
14:22:13.188   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:22:13.700   Training iter 600, batch loss 0.4518, batch acc 0.1094
14:22:13.701 Training @ 308 epoch...
14:22:14.207   Training iter 50, batch loss 0.4517, batch acc 0.1150
14:22:14.701   Training iter 100, batch loss 0.4517, batch acc 0.1128
14:22:15.215   Training iter 150, batch loss 0.4517, batch acc 0.1106
14:22:15.717   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:22:16.217   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:22:16.723   Training iter 300, batch loss 0.4518, batch acc 0.1084
14:22:17.229   Training iter 350, batch loss 0.4517, batch acc 0.1162
14:22:17.742   Training iter 400, batch loss 0.4518, batch acc 0.1078
14:22:18.243   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:22:18.744   Training iter 500, batch loss 0.4517, batch acc 0.1148
14:22:19.252   Training iter 550, batch loss 0.4517, batch acc 0.1132
14:22:19.748   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:22:19.749 Training @ 309 epoch...
14:22:20.266   Training iter 50, batch loss 0.4518, batch acc 0.1102
14:22:20.767   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:22:21.267   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:22:21.761   Training iter 200, batch loss 0.4519, batch acc 0.0980
14:22:22.242   Training iter 250, batch loss 0.4517, batch acc 0.1158
14:22:22.726   Training iter 300, batch loss 0.4517, batch acc 0.1174
14:22:23.230   Training iter 350, batch loss 0.4518, batch acc 0.1106
14:22:23.738   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:22:24.242   Training iter 450, batch loss 0.4518, batch acc 0.1108
14:22:24.741   Training iter 500, batch loss 0.4516, batch acc 0.1200
14:22:25.254   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:22:25.758   Training iter 600, batch loss 0.4518, batch acc 0.1126
14:22:25.760 Training @ 310 epoch...
14:22:26.272   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:22:26.754   Training iter 100, batch loss 0.4517, batch acc 0.1096
14:22:27.242   Training iter 150, batch loss 0.4518, batch acc 0.1098
14:22:27.714   Training iter 200, batch loss 0.4517, batch acc 0.1098
14:22:28.184   Training iter 250, batch loss 0.4518, batch acc 0.1052
14:22:28.647   Training iter 300, batch loss 0.4518, batch acc 0.1154
14:22:29.102   Training iter 350, batch loss 0.4517, batch acc 0.1180
14:22:29.563   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:22:30.054   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:22:30.574   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:22:31.073   Training iter 550, batch loss 0.4517, batch acc 0.1178
14:22:31.571   Training iter 600, batch loss 0.4518, batch acc 0.1126
14:22:31.572 Testing @ 310 epoch...
14:22:31.611     Testing, total mean loss 0.45174, total acc 0.11350
14:22:31.611 Training @ 311 epoch...
14:22:32.112   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:22:32.599   Training iter 100, batch loss 0.4519, batch acc 0.1092
14:22:33.105   Training iter 150, batch loss 0.4517, batch acc 0.1090
14:22:33.605   Training iter 200, batch loss 0.4516, batch acc 0.1174
14:22:34.086   Training iter 250, batch loss 0.4517, batch acc 0.1184
14:22:34.558   Training iter 300, batch loss 0.4518, batch acc 0.1158
14:22:35.022   Training iter 350, batch loss 0.4517, batch acc 0.1110
14:22:35.497   Training iter 400, batch loss 0.4518, batch acc 0.1110
14:22:35.960   Training iter 450, batch loss 0.4518, batch acc 0.1120
14:22:36.436   Training iter 500, batch loss 0.4517, batch acc 0.1162
14:22:36.899   Training iter 550, batch loss 0.4518, batch acc 0.1128
14:22:37.367   Training iter 600, batch loss 0.4518, batch acc 0.1050
14:22:37.369 Training @ 312 epoch...
14:22:37.841   Training iter 50, batch loss 0.4517, batch acc 0.1116
14:22:38.306   Training iter 100, batch loss 0.4518, batch acc 0.1042
14:22:38.763   Training iter 150, batch loss 0.4519, batch acc 0.1052
14:22:39.226   Training iter 200, batch loss 0.4517, batch acc 0.1182
14:22:39.677   Training iter 250, batch loss 0.4517, batch acc 0.1204
14:22:40.148   Training iter 300, batch loss 0.4518, batch acc 0.1074
14:22:40.640   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:22:41.143   Training iter 400, batch loss 0.4517, batch acc 0.1126
14:22:41.649   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:22:42.138   Training iter 500, batch loss 0.4518, batch acc 0.1104
14:22:42.621   Training iter 550, batch loss 0.4518, batch acc 0.1068
14:22:43.101   Training iter 600, batch loss 0.4517, batch acc 0.1220
14:22:43.103 Training @ 313 epoch...
14:22:43.572   Training iter 50, batch loss 0.4517, batch acc 0.1168
14:22:44.014   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:22:44.457   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:22:44.914   Training iter 200, batch loss 0.4518, batch acc 0.1138
14:22:45.373   Training iter 250, batch loss 0.4518, batch acc 0.1136
14:22:45.808   Training iter 300, batch loss 0.4518, batch acc 0.1086
14:22:46.267   Training iter 350, batch loss 0.4517, batch acc 0.1156
14:22:46.719   Training iter 400, batch loss 0.4517, batch acc 0.1130
14:22:47.173   Training iter 450, batch loss 0.4518, batch acc 0.1044
14:22:47.619   Training iter 500, batch loss 0.4518, batch acc 0.1138
14:22:48.082   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:22:48.539   Training iter 600, batch loss 0.4518, batch acc 0.1094
14:22:48.541 Training @ 314 epoch...
14:22:49.021   Training iter 50, batch loss 0.4517, batch acc 0.1096
14:22:49.516   Training iter 100, batch loss 0.4517, batch acc 0.1162
14:22:50.007   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:22:50.502   Training iter 200, batch loss 0.4518, batch acc 0.1046
14:22:50.992   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:22:51.483   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:22:51.989   Training iter 350, batch loss 0.4519, batch acc 0.1026
14:22:52.482   Training iter 400, batch loss 0.4517, batch acc 0.1186
14:22:52.966   Training iter 450, batch loss 0.4517, batch acc 0.1182
14:22:53.463   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:22:53.953   Training iter 550, batch loss 0.4517, batch acc 0.1188
14:22:54.440   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:22:54.442 Training @ 315 epoch...
14:22:54.928   Training iter 50, batch loss 0.4518, batch acc 0.1062
14:22:55.408   Training iter 100, batch loss 0.4517, batch acc 0.1190
14:22:55.880   Training iter 150, batch loss 0.4517, batch acc 0.1158
14:22:56.360   Training iter 200, batch loss 0.4518, batch acc 0.1088
14:22:56.857   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:22:57.351   Training iter 300, batch loss 0.4517, batch acc 0.1128
14:22:57.849   Training iter 350, batch loss 0.4517, batch acc 0.1068
14:22:58.329   Training iter 400, batch loss 0.4518, batch acc 0.1154
14:22:58.813   Training iter 450, batch loss 0.4517, batch acc 0.1162
14:22:59.303   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:22:59.793   Training iter 550, batch loss 0.4517, batch acc 0.1132
14:23:00.289   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:23:00.290 Testing @ 315 epoch...
14:23:00.328     Testing, total mean loss 0.45174, total acc 0.11350
14:23:00.329 Training @ 316 epoch...
14:23:00.829   Training iter 50, batch loss 0.4516, batch acc 0.1192
14:23:01.318   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:23:01.879   Training iter 150, batch loss 0.4518, batch acc 0.1060
14:23:02.464   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:23:03.054   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:23:03.639   Training iter 300, batch loss 0.4517, batch acc 0.1182
14:23:04.166   Training iter 350, batch loss 0.4518, batch acc 0.1146
14:23:04.666   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:23:05.199   Training iter 450, batch loss 0.4519, batch acc 0.1058
14:23:05.755   Training iter 500, batch loss 0.4518, batch acc 0.1116
14:23:06.306   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:23:06.818   Training iter 600, batch loss 0.4517, batch acc 0.1178
14:23:06.820 Training @ 317 epoch...
14:23:07.322   Training iter 50, batch loss 0.4518, batch acc 0.1084
14:23:07.803   Training iter 100, batch loss 0.4517, batch acc 0.1134
14:23:08.293   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:23:08.817   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:23:09.350   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:23:09.847   Training iter 300, batch loss 0.4518, batch acc 0.1138
14:23:10.364   Training iter 350, batch loss 0.4518, batch acc 0.1124
14:23:10.856   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:23:11.337   Training iter 450, batch loss 0.4517, batch acc 0.1130
14:23:11.809   Training iter 500, batch loss 0.4518, batch acc 0.1082
14:23:12.283   Training iter 550, batch loss 0.4517, batch acc 0.1146
14:23:12.797   Training iter 600, batch loss 0.4518, batch acc 0.1144
14:23:12.799 Training @ 318 epoch...
14:23:13.301   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:23:13.808   Training iter 100, batch loss 0.4518, batch acc 0.1092
14:23:14.319   Training iter 150, batch loss 0.4518, batch acc 0.1152
14:23:14.810   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:23:15.304   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:23:15.788   Training iter 300, batch loss 0.4517, batch acc 0.1094
14:23:16.259   Training iter 350, batch loss 0.4518, batch acc 0.1090
14:23:16.732   Training iter 400, batch loss 0.4518, batch acc 0.1124
14:23:17.209   Training iter 450, batch loss 0.4518, batch acc 0.1108
14:23:17.705   Training iter 500, batch loss 0.4517, batch acc 0.1132
14:23:18.183   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:23:18.670   Training iter 600, batch loss 0.4517, batch acc 0.1198
14:23:18.672 Training @ 319 epoch...
14:23:19.149   Training iter 50, batch loss 0.4516, batch acc 0.1230
14:23:19.611   Training iter 100, batch loss 0.4519, batch acc 0.1104
14:23:20.101   Training iter 150, batch loss 0.4517, batch acc 0.1144
14:23:20.591   Training iter 200, batch loss 0.4517, batch acc 0.1160
14:23:21.058   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:23:21.512   Training iter 300, batch loss 0.4519, batch acc 0.1034
14:23:21.969   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:23:22.434   Training iter 400, batch loss 0.4517, batch acc 0.1110
14:23:22.905   Training iter 450, batch loss 0.4518, batch acc 0.1118
14:23:23.377   Training iter 500, batch loss 0.4518, batch acc 0.1064
14:23:23.839   Training iter 550, batch loss 0.4518, batch acc 0.1118
14:23:24.291   Training iter 600, batch loss 0.4517, batch acc 0.1124
14:23:24.293 Training @ 320 epoch...
14:23:24.776   Training iter 50, batch loss 0.4517, batch acc 0.1108
14:23:25.267   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:23:25.742   Training iter 150, batch loss 0.4518, batch acc 0.1080
14:23:26.229   Training iter 200, batch loss 0.4517, batch acc 0.1136
14:23:26.694   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:23:27.174   Training iter 300, batch loss 0.4518, batch acc 0.1114
14:23:27.664   Training iter 350, batch loss 0.4517, batch acc 0.1164
14:23:28.165   Training iter 400, batch loss 0.4517, batch acc 0.1204
14:23:28.651   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:23:29.138   Training iter 500, batch loss 0.4518, batch acc 0.1060
14:23:29.619   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:23:30.110   Training iter 600, batch loss 0.4517, batch acc 0.1166
14:23:30.111 Testing @ 320 epoch...
14:23:30.150     Testing, total mean loss 0.45174, total acc 0.11350
14:23:30.150 Training @ 321 epoch...
14:23:30.664   Training iter 50, batch loss 0.4517, batch acc 0.1220
14:23:31.153   Training iter 100, batch loss 0.4518, batch acc 0.1060
14:23:31.660   Training iter 150, batch loss 0.4517, batch acc 0.1146
14:23:32.161   Training iter 200, batch loss 0.4519, batch acc 0.1096
14:23:32.671   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:23:33.192   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:23:33.679   Training iter 350, batch loss 0.4517, batch acc 0.1190
14:23:34.164   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:23:34.654   Training iter 450, batch loss 0.4517, batch acc 0.1114
14:23:35.142   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:23:35.623   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:23:36.106   Training iter 600, batch loss 0.4518, batch acc 0.1080
14:23:36.107 Training @ 322 epoch...
14:23:36.593   Training iter 50, batch loss 0.4518, batch acc 0.1156
14:23:37.083   Training iter 100, batch loss 0.4517, batch acc 0.1182
14:23:37.581   Training iter 150, batch loss 0.4517, batch acc 0.1170
14:23:38.084   Training iter 200, batch loss 0.4517, batch acc 0.1106
14:23:38.588   Training iter 250, batch loss 0.4518, batch acc 0.1116
14:23:39.082   Training iter 300, batch loss 0.4516, batch acc 0.1180
14:23:39.570   Training iter 350, batch loss 0.4519, batch acc 0.1082
14:23:40.070   Training iter 400, batch loss 0.4518, batch acc 0.1060
14:23:40.566   Training iter 450, batch loss 0.4518, batch acc 0.1132
14:23:41.051   Training iter 500, batch loss 0.4517, batch acc 0.1168
14:23:41.535   Training iter 550, batch loss 0.4517, batch acc 0.1096
14:23:42.027   Training iter 600, batch loss 0.4519, batch acc 0.1036
14:23:42.029 Training @ 323 epoch...
14:23:42.537   Training iter 50, batch loss 0.4518, batch acc 0.1120
14:23:43.046   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:23:43.560   Training iter 150, batch loss 0.4518, batch acc 0.1128
14:23:44.055   Training iter 200, batch loss 0.4517, batch acc 0.1156
14:23:44.549   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:23:45.045   Training iter 300, batch loss 0.4518, batch acc 0.1138
14:23:45.553   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:23:46.052   Training iter 400, batch loss 0.4518, batch acc 0.1086
14:23:46.554   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:23:47.061   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:23:47.556   Training iter 550, batch loss 0.4517, batch acc 0.1146
14:23:48.064   Training iter 600, batch loss 0.4517, batch acc 0.1090
14:23:48.066 Training @ 324 epoch...
14:23:48.583   Training iter 50, batch loss 0.4517, batch acc 0.1106
14:23:49.098   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:23:49.602   Training iter 150, batch loss 0.4517, batch acc 0.1116
14:23:50.119   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:23:50.645   Training iter 250, batch loss 0.4518, batch acc 0.1072
14:23:51.157   Training iter 300, batch loss 0.4518, batch acc 0.1190
14:23:51.681   Training iter 350, batch loss 0.4517, batch acc 0.1224
14:23:52.186   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:23:52.686   Training iter 450, batch loss 0.4518, batch acc 0.1048
14:23:53.208   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:23:53.731   Training iter 550, batch loss 0.4518, batch acc 0.1114
14:23:54.236   Training iter 600, batch loss 0.4518, batch acc 0.1120
14:23:54.238 Training @ 325 epoch...
14:23:54.758   Training iter 50, batch loss 0.4517, batch acc 0.1142
14:23:55.282   Training iter 100, batch loss 0.4519, batch acc 0.1070
14:23:55.796   Training iter 150, batch loss 0.4517, batch acc 0.1150
14:23:56.313   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:23:56.818   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:23:57.348   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:23:57.857   Training iter 350, batch loss 0.4517, batch acc 0.1164
14:23:58.362   Training iter 400, batch loss 0.4517, batch acc 0.1078
14:23:58.917   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:23:59.474   Training iter 500, batch loss 0.4517, batch acc 0.1092
14:24:00.021   Training iter 550, batch loss 0.4517, batch acc 0.1152
14:24:00.523   Training iter 600, batch loss 0.4517, batch acc 0.1196
14:24:00.525 Testing @ 325 epoch...
14:24:00.563     Testing, total mean loss 0.45174, total acc 0.11350
14:24:00.563 Training @ 326 epoch...
14:24:01.070   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:24:01.604   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:24:02.170   Training iter 150, batch loss 0.4517, batch acc 0.1182
14:24:02.692   Training iter 200, batch loss 0.4517, batch acc 0.1126
14:24:03.235   Training iter 250, batch loss 0.4517, batch acc 0.1150
14:24:03.767   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:24:04.308   Training iter 350, batch loss 0.4517, batch acc 0.1196
14:24:04.860   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:24:05.400   Training iter 450, batch loss 0.4518, batch acc 0.1094
14:24:05.937   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:24:06.480   Training iter 550, batch loss 0.4518, batch acc 0.1072
14:24:07.030   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:24:07.032 Training @ 327 epoch...
14:24:07.558   Training iter 50, batch loss 0.4517, batch acc 0.1132
14:24:08.080   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:24:08.601   Training iter 150, batch loss 0.4518, batch acc 0.1066
14:24:09.142   Training iter 200, batch loss 0.4517, batch acc 0.1120
14:24:09.666   Training iter 250, batch loss 0.4517, batch acc 0.1186
14:24:10.202   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:24:10.716   Training iter 350, batch loss 0.4518, batch acc 0.1098
14:24:11.230   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:24:11.728   Training iter 450, batch loss 0.4517, batch acc 0.1116
14:24:12.236   Training iter 500, batch loss 0.4517, batch acc 0.1184
14:24:12.734   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:24:13.244   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:24:13.246 Training @ 328 epoch...
14:24:13.758   Training iter 50, batch loss 0.4517, batch acc 0.1122
14:24:14.260   Training iter 100, batch loss 0.4518, batch acc 0.1130
14:24:14.749   Training iter 150, batch loss 0.4517, batch acc 0.1138
14:24:15.254   Training iter 200, batch loss 0.4519, batch acc 0.1122
14:24:15.756   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:24:16.280   Training iter 300, batch loss 0.4518, batch acc 0.1048
14:24:16.791   Training iter 350, batch loss 0.4518, batch acc 0.1142
14:24:17.309   Training iter 400, batch loss 0.4517, batch acc 0.1146
14:24:17.850   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:24:18.377   Training iter 500, batch loss 0.4518, batch acc 0.1114
14:24:18.898   Training iter 550, batch loss 0.4516, batch acc 0.1182
14:24:19.415   Training iter 600, batch loss 0.4517, batch acc 0.1110
14:24:19.417 Training @ 329 epoch...
14:24:19.951   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:24:20.481   Training iter 100, batch loss 0.4517, batch acc 0.1166
14:24:21.011   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:24:21.538   Training iter 200, batch loss 0.4518, batch acc 0.1116
14:24:22.066   Training iter 250, batch loss 0.4517, batch acc 0.1174
14:24:22.593   Training iter 300, batch loss 0.4519, batch acc 0.1050
14:24:23.126   Training iter 350, batch loss 0.4518, batch acc 0.1134
14:24:23.650   Training iter 400, batch loss 0.4517, batch acc 0.1096
14:24:24.173   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:24:24.731   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:24:25.295   Training iter 550, batch loss 0.4517, batch acc 0.1112
14:24:25.838   Training iter 600, batch loss 0.4516, batch acc 0.1186
14:24:25.840 Training @ 330 epoch...
14:24:26.396   Training iter 50, batch loss 0.4518, batch acc 0.1116
14:24:26.935   Training iter 100, batch loss 0.4517, batch acc 0.1126
14:24:27.484   Training iter 150, batch loss 0.4516, batch acc 0.1230
14:24:28.039   Training iter 200, batch loss 0.4518, batch acc 0.1062
14:24:28.583   Training iter 250, batch loss 0.4516, batch acc 0.1198
14:24:29.128   Training iter 300, batch loss 0.4519, batch acc 0.1040
14:24:29.663   Training iter 350, batch loss 0.4518, batch acc 0.1104
14:24:30.201   Training iter 400, batch loss 0.4516, batch acc 0.1190
14:24:30.715   Training iter 450, batch loss 0.4518, batch acc 0.1060
14:24:31.234   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:24:31.756   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:24:32.257   Training iter 600, batch loss 0.4517, batch acc 0.1078
14:24:32.259 Testing @ 330 epoch...
14:24:32.297     Testing, total mean loss 0.45174, total acc 0.11350
14:24:32.297 Training @ 331 epoch...
14:24:32.816   Training iter 50, batch loss 0.4518, batch acc 0.1090
14:24:33.343   Training iter 100, batch loss 0.4518, batch acc 0.1114
14:24:33.851   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:24:34.323   Training iter 200, batch loss 0.4515, batch acc 0.1226
14:24:34.806   Training iter 250, batch loss 0.4517, batch acc 0.1130
14:24:35.293   Training iter 300, batch loss 0.4517, batch acc 0.1136
14:24:35.766   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:24:36.242   Training iter 400, batch loss 0.4517, batch acc 0.1196
14:24:36.696   Training iter 450, batch loss 0.4518, batch acc 0.1144
14:24:37.152   Training iter 500, batch loss 0.4518, batch acc 0.1048
14:24:37.621   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:24:38.089   Training iter 600, batch loss 0.4520, batch acc 0.1022
14:24:38.091 Training @ 332 epoch...
14:24:38.585   Training iter 50, batch loss 0.4519, batch acc 0.1084
14:24:39.067   Training iter 100, batch loss 0.4517, batch acc 0.1114
14:24:39.537   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:24:40.007   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:24:40.498   Training iter 250, batch loss 0.4517, batch acc 0.1112
14:24:40.985   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:24:41.484   Training iter 350, batch loss 0.4517, batch acc 0.1174
14:24:41.982   Training iter 400, batch loss 0.4518, batch acc 0.1164
14:24:42.486   Training iter 450, batch loss 0.4518, batch acc 0.1072
14:24:42.995   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:24:43.532   Training iter 550, batch loss 0.4517, batch acc 0.1106
14:24:44.056   Training iter 600, batch loss 0.4517, batch acc 0.1102
14:24:44.058 Training @ 333 epoch...
14:24:44.581   Training iter 50, batch loss 0.4517, batch acc 0.1180
14:24:45.110   Training iter 100, batch loss 0.4517, batch acc 0.1176
14:24:45.639   Training iter 150, batch loss 0.4516, batch acc 0.1142
14:24:46.170   Training iter 200, batch loss 0.4519, batch acc 0.1014
14:24:46.690   Training iter 250, batch loss 0.4517, batch acc 0.1200
14:24:47.220   Training iter 300, batch loss 0.4518, batch acc 0.1144
14:24:47.711   Training iter 350, batch loss 0.4518, batch acc 0.1082
14:24:48.220   Training iter 400, batch loss 0.4518, batch acc 0.1126
14:24:48.747   Training iter 450, batch loss 0.4518, batch acc 0.1112
14:24:49.313   Training iter 500, batch loss 0.4518, batch acc 0.1078
14:24:49.832   Training iter 550, batch loss 0.4518, batch acc 0.1098
14:24:50.363   Training iter 600, batch loss 0.4517, batch acc 0.1132
14:24:50.364 Training @ 334 epoch...
14:24:50.873   Training iter 50, batch loss 0.4518, batch acc 0.1114
14:24:51.383   Training iter 100, batch loss 0.4517, batch acc 0.1152
14:24:51.891   Training iter 150, batch loss 0.4517, batch acc 0.1142
14:24:52.416   Training iter 200, batch loss 0.4517, batch acc 0.1156
14:24:52.939   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:24:53.464   Training iter 300, batch loss 0.4518, batch acc 0.1084
14:24:53.981   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:24:54.495   Training iter 400, batch loss 0.4517, batch acc 0.1176
14:24:55.011   Training iter 450, batch loss 0.4519, batch acc 0.1062
14:24:55.534   Training iter 500, batch loss 0.4519, batch acc 0.1050
14:24:56.052   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:24:56.607   Training iter 600, batch loss 0.4516, batch acc 0.1196
14:24:56.609 Training @ 335 epoch...
14:24:57.207   Training iter 50, batch loss 0.4516, batch acc 0.1192
14:24:57.814   Training iter 100, batch loss 0.4518, batch acc 0.1068
14:24:58.403   Training iter 150, batch loss 0.4517, batch acc 0.1168
14:24:58.979   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:24:59.493   Training iter 250, batch loss 0.4518, batch acc 0.1066
14:25:00.032   Training iter 300, batch loss 0.4518, batch acc 0.1132
14:25:00.566   Training iter 350, batch loss 0.4518, batch acc 0.1180
14:25:01.133   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:25:01.696   Training iter 450, batch loss 0.4519, batch acc 0.1056
14:25:02.276   Training iter 500, batch loss 0.4517, batch acc 0.1120
14:25:02.822   Training iter 550, batch loss 0.4517, batch acc 0.1176
14:25:03.397   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:25:03.399 Testing @ 335 epoch...
14:25:03.442     Testing, total mean loss 0.45174, total acc 0.11350
14:25:03.442 Training @ 336 epoch...
14:25:04.005   Training iter 50, batch loss 0.4517, batch acc 0.1120
14:25:04.571   Training iter 100, batch loss 0.4518, batch acc 0.1110
14:25:05.113   Training iter 150, batch loss 0.4517, batch acc 0.1226
14:25:05.604   Training iter 200, batch loss 0.4518, batch acc 0.1066
14:25:06.119   Training iter 250, batch loss 0.4517, batch acc 0.1136
14:25:06.645   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:25:07.176   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:25:07.705   Training iter 400, batch loss 0.4518, batch acc 0.1076
14:25:08.219   Training iter 450, batch loss 0.4517, batch acc 0.1150
14:25:08.736   Training iter 500, batch loss 0.4516, batch acc 0.1202
14:25:09.273   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:25:09.813   Training iter 600, batch loss 0.4517, batch acc 0.1088
14:25:09.815 Training @ 337 epoch...
14:25:10.418   Training iter 50, batch loss 0.4517, batch acc 0.1172
14:25:10.935   Training iter 100, batch loss 0.4518, batch acc 0.1098
14:25:11.480   Training iter 150, batch loss 0.4517, batch acc 0.1156
14:25:12.028   Training iter 200, batch loss 0.4518, batch acc 0.1062
14:25:12.600   Training iter 250, batch loss 0.4518, batch acc 0.1140
14:25:13.166   Training iter 300, batch loss 0.4518, batch acc 0.1038
14:25:13.712   Training iter 350, batch loss 0.4518, batch acc 0.1060
14:25:14.243   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:25:14.774   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:25:15.320   Training iter 500, batch loss 0.4517, batch acc 0.1176
14:25:15.873   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:25:16.424   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:25:16.426 Training @ 338 epoch...
14:25:16.978   Training iter 50, batch loss 0.4517, batch acc 0.1186
14:25:17.537   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:25:18.128   Training iter 150, batch loss 0.4516, batch acc 0.1202
14:25:18.669   Training iter 200, batch loss 0.4518, batch acc 0.1078
14:25:19.200   Training iter 250, batch loss 0.4518, batch acc 0.1148
14:25:19.736   Training iter 300, batch loss 0.4517, batch acc 0.1134
14:25:20.265   Training iter 350, batch loss 0.4517, batch acc 0.1164
14:25:20.789   Training iter 400, batch loss 0.4517, batch acc 0.1114
14:25:21.316   Training iter 450, batch loss 0.4519, batch acc 0.1082
14:25:21.846   Training iter 500, batch loss 0.4519, batch acc 0.0982
14:25:22.374   Training iter 550, batch loss 0.4517, batch acc 0.1174
14:25:22.912   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:25:22.914 Training @ 339 epoch...
14:25:23.461   Training iter 50, batch loss 0.4518, batch acc 0.1104
14:25:24.004   Training iter 100, batch loss 0.4518, batch acc 0.1120
14:25:24.550   Training iter 150, batch loss 0.4517, batch acc 0.1130
14:25:25.102   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:25:25.654   Training iter 250, batch loss 0.4517, batch acc 0.1170
14:25:26.205   Training iter 300, batch loss 0.4517, batch acc 0.1188
14:25:26.762   Training iter 350, batch loss 0.4518, batch acc 0.1128
14:25:27.317   Training iter 400, batch loss 0.4517, batch acc 0.1102
14:25:27.895   Training iter 450, batch loss 0.4517, batch acc 0.1114
14:25:28.458   Training iter 500, batch loss 0.4518, batch acc 0.1138
14:25:29.021   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:25:29.582   Training iter 600, batch loss 0.4518, batch acc 0.1112
14:25:29.584 Training @ 340 epoch...
14:25:30.154   Training iter 50, batch loss 0.4518, batch acc 0.1094
14:25:30.727   Training iter 100, batch loss 0.4517, batch acc 0.1154
14:25:31.298   Training iter 150, batch loss 0.4517, batch acc 0.1086
14:25:31.871   Training iter 200, batch loss 0.4518, batch acc 0.1082
14:25:32.452   Training iter 250, batch loss 0.4516, batch acc 0.1208
14:25:33.032   Training iter 300, batch loss 0.4517, batch acc 0.1174
14:25:33.606   Training iter 350, batch loss 0.4518, batch acc 0.1122
14:25:34.154   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:25:34.678   Training iter 450, batch loss 0.4518, batch acc 0.1142
14:25:35.171   Training iter 500, batch loss 0.4518, batch acc 0.1050
14:25:35.676   Training iter 550, batch loss 0.4517, batch acc 0.1160
14:25:36.205   Training iter 600, batch loss 0.4518, batch acc 0.1098
14:25:36.207 Testing @ 340 epoch...
14:25:36.252     Testing, total mean loss 0.45174, total acc 0.11350
14:25:36.252 Training @ 341 epoch...
14:25:36.758   Training iter 50, batch loss 0.4518, batch acc 0.1056
14:25:37.282   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:25:37.823   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:25:38.359   Training iter 200, batch loss 0.4519, batch acc 0.1040
14:25:38.897   Training iter 250, batch loss 0.4517, batch acc 0.1142
14:25:39.433   Training iter 300, batch loss 0.4516, batch acc 0.1212
14:25:39.964   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:25:40.513   Training iter 400, batch loss 0.4517, batch acc 0.1106
14:25:41.032   Training iter 450, batch loss 0.4518, batch acc 0.1120
14:25:41.554   Training iter 500, batch loss 0.4518, batch acc 0.1172
14:25:42.099   Training iter 550, batch loss 0.4518, batch acc 0.1090
14:25:42.611   Training iter 600, batch loss 0.4517, batch acc 0.1190
14:25:42.613 Training @ 342 epoch...
14:25:43.136   Training iter 50, batch loss 0.4518, batch acc 0.1154
14:25:43.644   Training iter 100, batch loss 0.4517, batch acc 0.1104
14:25:44.153   Training iter 150, batch loss 0.4517, batch acc 0.1116
14:25:44.657   Training iter 200, batch loss 0.4517, batch acc 0.1144
14:25:45.169   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:25:45.661   Training iter 300, batch loss 0.4517, batch acc 0.1140
14:25:46.164   Training iter 350, batch loss 0.4517, batch acc 0.1200
14:25:46.679   Training iter 400, batch loss 0.4517, batch acc 0.1202
14:25:47.174   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:25:47.696   Training iter 500, batch loss 0.4518, batch acc 0.1052
14:25:48.231   Training iter 550, batch loss 0.4518, batch acc 0.1140
14:25:48.748   Training iter 600, batch loss 0.4519, batch acc 0.1038
14:25:48.750 Training @ 343 epoch...
14:25:49.272   Training iter 50, batch loss 0.4518, batch acc 0.1114
14:25:49.807   Training iter 100, batch loss 0.4517, batch acc 0.1124
14:25:50.336   Training iter 150, batch loss 0.4518, batch acc 0.1122
14:25:50.856   Training iter 200, batch loss 0.4518, batch acc 0.1114
14:25:51.448   Training iter 250, batch loss 0.4518, batch acc 0.1110
14:25:51.996   Training iter 300, batch loss 0.4517, batch acc 0.1146
14:25:52.606   Training iter 350, batch loss 0.4516, batch acc 0.1174
14:25:53.292   Training iter 400, batch loss 0.4518, batch acc 0.1120
14:25:53.957   Training iter 450, batch loss 0.4517, batch acc 0.1214
14:25:54.509   Training iter 500, batch loss 0.4517, batch acc 0.1126
14:25:55.062   Training iter 550, batch loss 0.4518, batch acc 0.1044
14:25:55.653   Training iter 600, batch loss 0.4517, batch acc 0.1076
14:25:55.655 Training @ 344 epoch...
14:25:56.255   Training iter 50, batch loss 0.4515, batch acc 0.1294
14:25:56.789   Training iter 100, batch loss 0.4517, batch acc 0.1122
14:25:57.326   Training iter 150, batch loss 0.4518, batch acc 0.1102
14:25:57.864   Training iter 200, batch loss 0.4518, batch acc 0.1118
14:25:58.400   Training iter 250, batch loss 0.4518, batch acc 0.1068
14:25:58.913   Training iter 300, batch loss 0.4518, batch acc 0.1040
14:25:59.418   Training iter 350, batch loss 0.4518, batch acc 0.1066
14:25:59.926   Training iter 400, batch loss 0.4518, batch acc 0.1144
14:26:00.459   Training iter 450, batch loss 0.4517, batch acc 0.1148
14:26:00.994   Training iter 500, batch loss 0.4518, batch acc 0.1148
14:26:01.529   Training iter 550, batch loss 0.4517, batch acc 0.1126
14:26:02.076   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:26:02.078 Training @ 345 epoch...
14:26:02.617   Training iter 50, batch loss 0.4517, batch acc 0.1172
14:26:03.191   Training iter 100, batch loss 0.4517, batch acc 0.1088
14:26:03.771   Training iter 150, batch loss 0.4517, batch acc 0.1122
14:26:04.340   Training iter 200, batch loss 0.4518, batch acc 0.1060
14:26:04.903   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:26:05.461   Training iter 300, batch loss 0.4517, batch acc 0.1134
14:26:06.030   Training iter 350, batch loss 0.4517, batch acc 0.1090
14:26:06.590   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:26:07.118   Training iter 450, batch loss 0.4517, batch acc 0.1146
14:26:07.602   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:26:08.174   Training iter 550, batch loss 0.4518, batch acc 0.1130
14:26:08.885   Training iter 600, batch loss 0.4518, batch acc 0.1130
14:26:08.887 Testing @ 345 epoch...
14:26:08.953     Testing, total mean loss 0.45174, total acc 0.11350
14:26:08.953 Training @ 346 epoch...
14:26:09.493   Training iter 50, batch loss 0.4518, batch acc 0.1102
14:26:09.980   Training iter 100, batch loss 0.4518, batch acc 0.1096
14:26:10.503   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:26:10.999   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:26:11.503   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:26:12.004   Training iter 300, batch loss 0.4518, batch acc 0.1070
14:26:12.496   Training iter 350, batch loss 0.4516, batch acc 0.1234
14:26:13.002   Training iter 400, batch loss 0.4518, batch acc 0.1070
14:26:13.516   Training iter 450, batch loss 0.4517, batch acc 0.1092
14:26:14.032   Training iter 500, batch loss 0.4518, batch acc 0.1102
14:26:14.546   Training iter 550, batch loss 0.4517, batch acc 0.1182
14:26:15.047   Training iter 600, batch loss 0.4517, batch acc 0.1170
14:26:15.049 Training @ 347 epoch...
14:26:15.572   Training iter 50, batch loss 0.4517, batch acc 0.1196
14:26:16.102   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:26:16.656   Training iter 150, batch loss 0.4518, batch acc 0.1052
14:26:17.222   Training iter 200, batch loss 0.4518, batch acc 0.1076
14:26:17.773   Training iter 250, batch loss 0.4517, batch acc 0.1176
14:26:18.344   Training iter 300, batch loss 0.4517, batch acc 0.1134
14:26:18.923   Training iter 350, batch loss 0.4517, batch acc 0.1104
14:26:19.489   Training iter 400, batch loss 0.4516, batch acc 0.1214
14:26:20.035   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:26:20.580   Training iter 500, batch loss 0.4519, batch acc 0.1046
14:26:21.126   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:26:21.680   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:26:21.682 Training @ 348 epoch...
14:26:22.242   Training iter 50, batch loss 0.4517, batch acc 0.1174
14:26:22.769   Training iter 100, batch loss 0.4519, batch acc 0.1068
14:26:23.302   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:26:23.824   Training iter 200, batch loss 0.4518, batch acc 0.1104
14:26:24.340   Training iter 250, batch loss 0.4518, batch acc 0.1140
14:26:24.851   Training iter 300, batch loss 0.4517, batch acc 0.1124
14:26:25.370   Training iter 350, batch loss 0.4517, batch acc 0.1166
14:26:25.901   Training iter 400, batch loss 0.4517, batch acc 0.1148
14:26:26.421   Training iter 450, batch loss 0.4518, batch acc 0.1054
14:26:26.937   Training iter 500, batch loss 0.4518, batch acc 0.1110
14:26:27.447   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:26:27.970   Training iter 600, batch loss 0.4518, batch acc 0.1140
14:26:27.971 Training @ 349 epoch...
14:26:28.510   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:26:29.050   Training iter 100, batch loss 0.4518, batch acc 0.1090
14:26:29.573   Training iter 150, batch loss 0.4517, batch acc 0.1144
14:26:30.108   Training iter 200, batch loss 0.4518, batch acc 0.1114
14:26:30.619   Training iter 250, batch loss 0.4517, batch acc 0.1132
14:26:31.110   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:26:31.622   Training iter 350, batch loss 0.4517, batch acc 0.1124
14:26:32.106   Training iter 400, batch loss 0.4517, batch acc 0.1216
14:26:32.605   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:26:33.129   Training iter 500, batch loss 0.4519, batch acc 0.1060
14:26:33.662   Training iter 550, batch loss 0.4518, batch acc 0.1098
14:26:34.184   Training iter 600, batch loss 0.4518, batch acc 0.1132
14:26:34.186 Training @ 350 epoch...
14:26:34.740   Training iter 50, batch loss 0.4518, batch acc 0.1116
14:26:35.296   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:26:35.859   Training iter 150, batch loss 0.4517, batch acc 0.1126
14:26:36.406   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:26:36.903   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:26:37.400   Training iter 300, batch loss 0.4518, batch acc 0.1118
14:26:37.902   Training iter 350, batch loss 0.4517, batch acc 0.1170
14:26:38.412   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:26:38.891   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:26:39.369   Training iter 500, batch loss 0.4517, batch acc 0.1144
14:26:39.845   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:26:40.340   Training iter 600, batch loss 0.4517, batch acc 0.1102
14:26:40.341 Testing @ 350 epoch...
14:26:40.380     Testing, total mean loss 0.45174, total acc 0.11350
14:26:40.380 Training @ 351 epoch...
14:26:40.885   Training iter 50, batch loss 0.4518, batch acc 0.1084
14:26:41.410   Training iter 100, batch loss 0.4517, batch acc 0.1160
14:26:41.956   Training iter 150, batch loss 0.4518, batch acc 0.1156
14:26:42.504   Training iter 200, batch loss 0.4518, batch acc 0.1060
14:26:43.050   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:26:43.542   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:26:44.024   Training iter 350, batch loss 0.4518, batch acc 0.1134
14:26:44.498   Training iter 400, batch loss 0.4517, batch acc 0.1126
14:26:44.978   Training iter 450, batch loss 0.4517, batch acc 0.1146
14:26:45.443   Training iter 500, batch loss 0.4517, batch acc 0.1168
14:26:45.897   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:26:46.367   Training iter 600, batch loss 0.4517, batch acc 0.1128
14:26:46.369 Training @ 352 epoch...
14:26:46.847   Training iter 50, batch loss 0.4518, batch acc 0.1092
14:26:47.327   Training iter 100, batch loss 0.4517, batch acc 0.1072
14:26:47.800   Training iter 150, batch loss 0.4518, batch acc 0.1136
14:26:48.276   Training iter 200, batch loss 0.4517, batch acc 0.1122
14:26:48.765   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:26:49.262   Training iter 300, batch loss 0.4518, batch acc 0.1082
14:26:49.781   Training iter 350, batch loss 0.4517, batch acc 0.1156
14:26:50.298   Training iter 400, batch loss 0.4517, batch acc 0.1116
14:26:50.835   Training iter 450, batch loss 0.4517, batch acc 0.1092
14:26:51.341   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:26:51.859   Training iter 550, batch loss 0.4518, batch acc 0.1166
14:26:52.386   Training iter 600, batch loss 0.4518, batch acc 0.1136
14:26:52.388 Training @ 353 epoch...
14:26:52.883   Training iter 50, batch loss 0.4518, batch acc 0.1124
14:26:53.371   Training iter 100, batch loss 0.4517, batch acc 0.1126
14:26:53.864   Training iter 150, batch loss 0.4518, batch acc 0.1144
14:26:54.382   Training iter 200, batch loss 0.4517, batch acc 0.1120
14:26:54.866   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:26:55.363   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:26:55.859   Training iter 350, batch loss 0.4517, batch acc 0.1128
14:26:56.341   Training iter 400, batch loss 0.4517, batch acc 0.1090
14:26:56.824   Training iter 450, batch loss 0.4517, batch acc 0.1144
14:26:57.307   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:26:57.806   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:26:58.336   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:26:58.338 Training @ 354 epoch...
14:26:58.888   Training iter 50, batch loss 0.4518, batch acc 0.1116
14:26:59.430   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:26:59.957   Training iter 150, batch loss 0.4518, batch acc 0.1060
14:27:00.482   Training iter 200, batch loss 0.4517, batch acc 0.1178
14:27:00.999   Training iter 250, batch loss 0.4516, batch acc 0.1212
14:27:01.569   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:27:02.233   Training iter 350, batch loss 0.4518, batch acc 0.1162
14:27:02.759   Training iter 400, batch loss 0.4517, batch acc 0.1170
14:27:03.236   Training iter 450, batch loss 0.4516, batch acc 0.1168
14:27:03.708   Training iter 500, batch loss 0.4519, batch acc 0.1026
14:27:04.194   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:27:04.710   Training iter 600, batch loss 0.4518, batch acc 0.1132
14:27:04.711 Training @ 355 epoch...
14:27:05.255   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:27:05.781   Training iter 100, batch loss 0.4518, batch acc 0.1086
14:27:06.317   Training iter 150, batch loss 0.4519, batch acc 0.1076
14:27:06.847   Training iter 200, batch loss 0.4518, batch acc 0.1118
14:27:07.379   Training iter 250, batch loss 0.4517, batch acc 0.1134
14:27:07.900   Training iter 300, batch loss 0.4518, batch acc 0.1142
14:27:08.410   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:27:08.941   Training iter 400, batch loss 0.4517, batch acc 0.1120
14:27:09.471   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:27:10.012   Training iter 500, batch loss 0.4517, batch acc 0.1196
14:27:10.538   Training iter 550, batch loss 0.4518, batch acc 0.1052
14:27:11.054   Training iter 600, batch loss 0.4518, batch acc 0.1140
14:27:11.056 Testing @ 355 epoch...
14:27:11.095     Testing, total mean loss 0.45174, total acc 0.11350
14:27:11.095 Training @ 356 epoch...
14:27:11.614   Training iter 50, batch loss 0.4518, batch acc 0.1104
14:27:12.125   Training iter 100, batch loss 0.4518, batch acc 0.1088
14:27:12.628   Training iter 150, batch loss 0.4517, batch acc 0.1188
14:27:13.142   Training iter 200, batch loss 0.4517, batch acc 0.1130
14:27:13.651   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:27:14.149   Training iter 300, batch loss 0.4517, batch acc 0.1130
14:27:14.646   Training iter 350, batch loss 0.4517, batch acc 0.1094
14:27:15.141   Training iter 400, batch loss 0.4517, batch acc 0.1214
14:27:15.649   Training iter 450, batch loss 0.4519, batch acc 0.1044
14:27:16.169   Training iter 500, batch loss 0.4517, batch acc 0.1090
14:27:16.674   Training iter 550, batch loss 0.4517, batch acc 0.1168
14:27:17.168   Training iter 600, batch loss 0.4517, batch acc 0.1122
14:27:17.170 Training @ 357 epoch...
14:27:17.740   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:27:18.303   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:27:18.852   Training iter 150, batch loss 0.4517, batch acc 0.1158
14:27:19.302   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:27:19.766   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:27:20.241   Training iter 300, batch loss 0.4517, batch acc 0.1130
14:27:20.710   Training iter 350, batch loss 0.4518, batch acc 0.1082
14:27:21.178   Training iter 400, batch loss 0.4517, batch acc 0.1130
14:27:21.632   Training iter 450, batch loss 0.4517, batch acc 0.1146
14:27:22.095   Training iter 500, batch loss 0.4517, batch acc 0.1126
14:27:22.562   Training iter 550, batch loss 0.4519, batch acc 0.1112
14:27:23.061   Training iter 600, batch loss 0.4517, batch acc 0.1150
14:27:23.062 Training @ 358 epoch...
14:27:23.552   Training iter 50, batch loss 0.4518, batch acc 0.1094
14:27:24.034   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:27:24.538   Training iter 150, batch loss 0.4518, batch acc 0.1046
14:27:25.064   Training iter 200, batch loss 0.4517, batch acc 0.1122
14:27:25.558   Training iter 250, batch loss 0.4517, batch acc 0.1186
14:27:26.059   Training iter 300, batch loss 0.4519, batch acc 0.1078
14:27:26.540   Training iter 350, batch loss 0.4518, batch acc 0.1108
14:27:26.985   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:27:27.452   Training iter 450, batch loss 0.4518, batch acc 0.1116
14:27:27.922   Training iter 500, batch loss 0.4517, batch acc 0.1154
14:27:28.426   Training iter 550, batch loss 0.4518, batch acc 0.1130
14:27:28.927   Training iter 600, batch loss 0.4517, batch acc 0.1168
14:27:28.928 Training @ 359 epoch...
14:27:29.427   Training iter 50, batch loss 0.4517, batch acc 0.1180
14:27:29.921   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:27:30.419   Training iter 150, batch loss 0.4518, batch acc 0.1058
14:27:30.897   Training iter 200, batch loss 0.4517, batch acc 0.1134
14:27:31.396   Training iter 250, batch loss 0.4517, batch acc 0.1114
14:27:31.893   Training iter 300, batch loss 0.4518, batch acc 0.1068
14:27:32.398   Training iter 350, batch loss 0.4517, batch acc 0.1112
14:27:32.922   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:27:33.444   Training iter 450, batch loss 0.4517, batch acc 0.1200
14:27:33.958   Training iter 500, batch loss 0.4517, batch acc 0.1154
14:27:34.479   Training iter 550, batch loss 0.4517, batch acc 0.1126
14:27:35.014   Training iter 600, batch loss 0.4518, batch acc 0.1080
14:27:35.015 Training @ 360 epoch...
14:27:35.559   Training iter 50, batch loss 0.4518, batch acc 0.1114
14:27:36.091   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:27:36.620   Training iter 150, batch loss 0.4517, batch acc 0.1126
14:27:37.155   Training iter 200, batch loss 0.4518, batch acc 0.1160
14:27:37.694   Training iter 250, batch loss 0.4517, batch acc 0.1134
14:27:38.244   Training iter 300, batch loss 0.4518, batch acc 0.1092
14:27:38.777   Training iter 350, batch loss 0.4518, batch acc 0.1154
14:27:39.307   Training iter 400, batch loss 0.4518, batch acc 0.1078
14:27:39.834   Training iter 450, batch loss 0.4517, batch acc 0.1198
14:27:40.386   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:27:40.949   Training iter 550, batch loss 0.4517, batch acc 0.1140
14:27:41.511   Training iter 600, batch loss 0.4518, batch acc 0.1110
14:27:41.513 Testing @ 360 epoch...
14:27:41.554     Testing, total mean loss 0.45174, total acc 0.11350
14:27:41.554 Training @ 361 epoch...
14:27:42.121   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:27:42.679   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:27:43.231   Training iter 150, batch loss 0.4516, batch acc 0.1270
14:27:43.762   Training iter 200, batch loss 0.4518, batch acc 0.1122
14:27:44.290   Training iter 250, batch loss 0.4518, batch acc 0.1114
14:27:44.830   Training iter 300, batch loss 0.4517, batch acc 0.1116
14:27:45.366   Training iter 350, batch loss 0.4517, batch acc 0.1184
14:27:45.902   Training iter 400, batch loss 0.4519, batch acc 0.1054
14:27:46.442   Training iter 450, batch loss 0.4518, batch acc 0.1098
14:27:46.978   Training iter 500, batch loss 0.4517, batch acc 0.1136
14:27:47.516   Training iter 550, batch loss 0.4517, batch acc 0.1096
14:27:48.054   Training iter 600, batch loss 0.4519, batch acc 0.1058
14:27:48.056 Training @ 362 epoch...
14:27:48.588   Training iter 50, batch loss 0.4518, batch acc 0.1138
14:27:49.093   Training iter 100, batch loss 0.4517, batch acc 0.1128
14:27:49.590   Training iter 150, batch loss 0.4517, batch acc 0.1134
14:27:50.118   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:27:50.633   Training iter 250, batch loss 0.4517, batch acc 0.1100
14:27:51.142   Training iter 300, batch loss 0.4518, batch acc 0.1132
14:27:51.642   Training iter 350, batch loss 0.4518, batch acc 0.1074
14:27:52.147   Training iter 400, batch loss 0.4518, batch acc 0.1046
14:27:52.654   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:27:53.176   Training iter 500, batch loss 0.4518, batch acc 0.1164
14:27:53.701   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:27:54.220   Training iter 600, batch loss 0.4517, batch acc 0.1172
14:27:54.222 Training @ 363 epoch...
14:27:54.744   Training iter 50, batch loss 0.4518, batch acc 0.1070
14:27:55.273   Training iter 100, batch loss 0.4517, batch acc 0.1198
14:27:55.786   Training iter 150, batch loss 0.4518, batch acc 0.1062
14:27:56.306   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:27:56.808   Training iter 250, batch loss 0.4518, batch acc 0.1132
14:27:57.324   Training iter 300, batch loss 0.4517, batch acc 0.1094
14:27:57.860   Training iter 350, batch loss 0.4516, batch acc 0.1194
14:27:58.387   Training iter 400, batch loss 0.4518, batch acc 0.1032
14:27:58.898   Training iter 450, batch loss 0.4518, batch acc 0.1142
14:27:59.414   Training iter 500, batch loss 0.4518, batch acc 0.1130
14:27:59.959   Training iter 550, batch loss 0.4518, batch acc 0.1122
14:28:00.505   Training iter 600, batch loss 0.4516, batch acc 0.1176
14:28:00.506 Training @ 364 epoch...
14:28:01.112   Training iter 50, batch loss 0.4518, batch acc 0.1148
14:28:01.778   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:28:02.531   Training iter 150, batch loss 0.4518, batch acc 0.1124
14:28:03.258   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:28:03.787   Training iter 250, batch loss 0.4517, batch acc 0.1072
14:28:04.305   Training iter 300, batch loss 0.4518, batch acc 0.1194
14:28:04.834   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:28:05.343   Training iter 400, batch loss 0.4518, batch acc 0.1138
14:28:05.867   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:28:06.377   Training iter 500, batch loss 0.4518, batch acc 0.1102
14:28:06.920   Training iter 550, batch loss 0.4517, batch acc 0.1116
14:28:07.448   Training iter 600, batch loss 0.4517, batch acc 0.1108
14:28:07.450 Training @ 365 epoch...
14:28:07.962   Training iter 50, batch loss 0.4517, batch acc 0.1098
14:28:08.473   Training iter 100, batch loss 0.4517, batch acc 0.1162
14:28:09.011   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:28:09.558   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:28:10.112   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:28:10.664   Training iter 300, batch loss 0.4517, batch acc 0.1162
14:28:11.207   Training iter 350, batch loss 0.4517, batch acc 0.1166
14:28:11.752   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:28:12.305   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:28:12.850   Training iter 500, batch loss 0.4517, batch acc 0.1192
14:28:13.390   Training iter 550, batch loss 0.4518, batch acc 0.1102
14:28:13.924   Training iter 600, batch loss 0.4519, batch acc 0.1110
14:28:13.925 Testing @ 365 epoch...
14:28:13.964     Testing, total mean loss 0.45174, total acc 0.11350
14:28:13.964 Training @ 366 epoch...
14:28:14.520   Training iter 50, batch loss 0.4517, batch acc 0.1174
14:28:15.061   Training iter 100, batch loss 0.4518, batch acc 0.1128
14:28:15.585   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:28:16.103   Training iter 200, batch loss 0.4517, batch acc 0.1112
14:28:16.625   Training iter 250, batch loss 0.4519, batch acc 0.1092
14:28:17.102   Training iter 300, batch loss 0.4517, batch acc 0.1118
14:28:17.589   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:28:18.065   Training iter 400, batch loss 0.4517, batch acc 0.1168
14:28:18.567   Training iter 450, batch loss 0.4518, batch acc 0.1154
14:28:19.048   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:28:19.529   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:28:20.021   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:28:20.023 Training @ 367 epoch...
14:28:20.510   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:28:20.986   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:28:21.471   Training iter 150, batch loss 0.4518, batch acc 0.1060
14:28:21.940   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:28:22.430   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:28:22.938   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:28:23.445   Training iter 350, batch loss 0.4516, batch acc 0.1220
14:28:23.963   Training iter 400, batch loss 0.4517, batch acc 0.1102
14:28:24.473   Training iter 450, batch loss 0.4516, batch acc 0.1188
14:28:24.995   Training iter 500, batch loss 0.4519, batch acc 0.1058
14:28:25.545   Training iter 550, batch loss 0.4517, batch acc 0.1110
14:28:26.097   Training iter 600, batch loss 0.4518, batch acc 0.1090
14:28:26.099 Training @ 368 epoch...
14:28:26.647   Training iter 50, batch loss 0.4516, batch acc 0.1144
14:28:27.192   Training iter 100, batch loss 0.4518, batch acc 0.1072
14:28:27.737   Training iter 150, batch loss 0.4518, batch acc 0.1088
14:28:28.283   Training iter 200, batch loss 0.4518, batch acc 0.1116
14:28:28.802   Training iter 250, batch loss 0.4519, batch acc 0.1088
14:28:29.335   Training iter 300, batch loss 0.4517, batch acc 0.1136
14:28:29.852   Training iter 350, batch loss 0.4517, batch acc 0.1132
14:28:30.394   Training iter 400, batch loss 0.4518, batch acc 0.1132
14:28:30.934   Training iter 450, batch loss 0.4518, batch acc 0.1122
14:28:31.448   Training iter 500, batch loss 0.4518, batch acc 0.1160
14:28:31.946   Training iter 550, batch loss 0.4517, batch acc 0.1184
14:28:32.453   Training iter 600, batch loss 0.4518, batch acc 0.1110
14:28:32.455 Training @ 369 epoch...
14:28:32.961   Training iter 50, batch loss 0.4517, batch acc 0.1156
14:28:33.452   Training iter 100, batch loss 0.4518, batch acc 0.1050
14:28:33.940   Training iter 150, batch loss 0.4518, batch acc 0.1132
14:28:34.430   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:28:34.881   Training iter 250, batch loss 0.4517, batch acc 0.1188
14:28:35.339   Training iter 300, batch loss 0.4518, batch acc 0.1078
14:28:35.791   Training iter 350, batch loss 0.4518, batch acc 0.1088
14:28:36.263   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:28:36.745   Training iter 450, batch loss 0.4517, batch acc 0.1154
14:28:37.220   Training iter 500, batch loss 0.4518, batch acc 0.1078
14:28:37.691   Training iter 550, batch loss 0.4517, batch acc 0.1152
14:28:38.164   Training iter 600, batch loss 0.4517, batch acc 0.1180
14:28:38.165 Training @ 370 epoch...
14:28:38.657   Training iter 50, batch loss 0.4518, batch acc 0.1058
14:28:39.145   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:28:39.625   Training iter 150, batch loss 0.4518, batch acc 0.1098
14:28:40.117   Training iter 200, batch loss 0.4518, batch acc 0.1126
14:28:40.608   Training iter 250, batch loss 0.4517, batch acc 0.1122
14:28:41.113   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:28:41.615   Training iter 350, batch loss 0.4517, batch acc 0.1202
14:28:42.112   Training iter 400, batch loss 0.4517, batch acc 0.1176
14:28:42.575   Training iter 450, batch loss 0.4517, batch acc 0.1124
14:28:43.067   Training iter 500, batch loss 0.4518, batch acc 0.1066
14:28:43.557   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:28:44.041   Training iter 600, batch loss 0.4517, batch acc 0.1106
14:28:44.042 Testing @ 370 epoch...
14:28:44.081     Testing, total mean loss 0.45174, total acc 0.11350
14:28:44.081 Training @ 371 epoch...
14:28:44.576   Training iter 50, batch loss 0.4517, batch acc 0.1156
14:28:45.061   Training iter 100, batch loss 0.4517, batch acc 0.1132
14:28:45.555   Training iter 150, batch loss 0.4518, batch acc 0.1150
14:28:46.047   Training iter 200, batch loss 0.4518, batch acc 0.1024
14:28:46.548   Training iter 250, batch loss 0.4516, batch acc 0.1194
14:28:47.041   Training iter 300, batch loss 0.4519, batch acc 0.1094
14:28:47.529   Training iter 350, batch loss 0.4518, batch acc 0.1100
14:28:48.021   Training iter 400, batch loss 0.4517, batch acc 0.1146
14:28:48.515   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:28:49.007   Training iter 500, batch loss 0.4518, batch acc 0.1106
14:28:49.510   Training iter 550, batch loss 0.4517, batch acc 0.1122
14:28:49.994   Training iter 600, batch loss 0.4517, batch acc 0.1160
14:28:49.996 Training @ 372 epoch...
14:28:50.492   Training iter 50, batch loss 0.4518, batch acc 0.1100
14:28:50.978   Training iter 100, batch loss 0.4518, batch acc 0.1086
14:28:51.488   Training iter 150, batch loss 0.4517, batch acc 0.1102
14:28:51.982   Training iter 200, batch loss 0.4516, batch acc 0.1234
14:28:52.502   Training iter 250, batch loss 0.4518, batch acc 0.1136
14:28:53.009   Training iter 300, batch loss 0.4518, batch acc 0.1090
14:28:53.512   Training iter 350, batch loss 0.4517, batch acc 0.1180
14:28:54.004   Training iter 400, batch loss 0.4519, batch acc 0.1058
14:28:54.506   Training iter 450, batch loss 0.4518, batch acc 0.1116
14:28:55.009   Training iter 500, batch loss 0.4516, batch acc 0.1190
14:28:55.494   Training iter 550, batch loss 0.4517, batch acc 0.1114
14:28:55.980   Training iter 600, batch loss 0.4518, batch acc 0.1078
14:28:55.981 Training @ 373 epoch...
14:28:56.484   Training iter 50, batch loss 0.4518, batch acc 0.1086
14:28:56.970   Training iter 100, batch loss 0.4517, batch acc 0.1126
14:28:57.458   Training iter 150, batch loss 0.4517, batch acc 0.1196
14:28:57.945   Training iter 200, batch loss 0.4517, batch acc 0.1128
14:28:58.439   Training iter 250, batch loss 0.4517, batch acc 0.1150
14:28:58.919   Training iter 300, batch loss 0.4518, batch acc 0.1058
14:28:59.396   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:28:59.889   Training iter 400, batch loss 0.4518, batch acc 0.1144
14:29:00.399   Training iter 450, batch loss 0.4517, batch acc 0.1084
14:29:00.897   Training iter 500, batch loss 0.4518, batch acc 0.1084
14:29:01.402   Training iter 550, batch loss 0.4517, batch acc 0.1162
14:29:01.941   Training iter 600, batch loss 0.4518, batch acc 0.1132
14:29:01.943 Training @ 374 epoch...
14:29:02.472   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:29:02.969   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:29:03.483   Training iter 150, batch loss 0.4518, batch acc 0.1050
14:29:03.993   Training iter 200, batch loss 0.4517, batch acc 0.1150
14:29:04.503   Training iter 250, batch loss 0.4518, batch acc 0.1032
14:29:05.006   Training iter 300, batch loss 0.4517, batch acc 0.1138
14:29:05.509   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:29:06.017   Training iter 400, batch loss 0.4517, batch acc 0.1158
14:29:06.505   Training iter 450, batch loss 0.4518, batch acc 0.1188
14:29:07.041   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:29:07.503   Training iter 550, batch loss 0.4518, batch acc 0.1156
14:29:07.951   Training iter 600, batch loss 0.4518, batch acc 0.1096
14:29:07.953 Training @ 375 epoch...
14:29:08.408   Training iter 50, batch loss 0.4518, batch acc 0.1094
14:29:08.865   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:29:09.329   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:29:09.788   Training iter 200, batch loss 0.4517, batch acc 0.1170
14:29:10.255   Training iter 250, batch loss 0.4518, batch acc 0.1122
14:29:10.747   Training iter 300, batch loss 0.4518, batch acc 0.1106
14:29:11.246   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:29:11.740   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:29:12.231   Training iter 450, batch loss 0.4516, batch acc 0.1232
14:29:12.758   Training iter 500, batch loss 0.4518, batch acc 0.1138
14:29:13.333   Training iter 550, batch loss 0.4518, batch acc 0.1070
14:29:13.908   Training iter 600, batch loss 0.4518, batch acc 0.1100
14:29:13.909 Testing @ 375 epoch...
14:29:13.949     Testing, total mean loss 0.45174, total acc 0.11350
14:29:13.949 Training @ 376 epoch...
14:29:14.524   Training iter 50, batch loss 0.4518, batch acc 0.1138
14:29:15.028   Training iter 100, batch loss 0.4518, batch acc 0.1092
14:29:15.534   Training iter 150, batch loss 0.4518, batch acc 0.1062
14:29:16.057   Training iter 200, batch loss 0.4516, batch acc 0.1256
14:29:16.602   Training iter 250, batch loss 0.4518, batch acc 0.1072
14:29:17.176   Training iter 300, batch loss 0.4518, batch acc 0.1094
14:29:17.736   Training iter 350, batch loss 0.4518, batch acc 0.1062
14:29:18.294   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:29:18.812   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:29:19.327   Training iter 500, batch loss 0.4517, batch acc 0.1200
14:29:19.852   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:29:20.392   Training iter 600, batch loss 0.4517, batch acc 0.1094
14:29:20.393 Training @ 377 epoch...
14:29:20.943   Training iter 50, batch loss 0.4518, batch acc 0.1052
14:29:21.473   Training iter 100, batch loss 0.4517, batch acc 0.1206
14:29:22.001   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:29:22.538   Training iter 200, batch loss 0.4518, batch acc 0.1084
14:29:23.082   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:29:23.626   Training iter 300, batch loss 0.4517, batch acc 0.1110
14:29:24.150   Training iter 350, batch loss 0.4516, batch acc 0.1182
14:29:24.690   Training iter 400, batch loss 0.4518, batch acc 0.1112
14:29:25.241   Training iter 450, batch loss 0.4517, batch acc 0.1112
14:29:25.769   Training iter 500, batch loss 0.4518, batch acc 0.1108
14:29:26.279   Training iter 550, batch loss 0.4518, batch acc 0.1126
14:29:26.818   Training iter 600, batch loss 0.4517, batch acc 0.1138
14:29:26.820 Training @ 378 epoch...
14:29:27.369   Training iter 50, batch loss 0.4518, batch acc 0.1130
14:29:28.017   Training iter 100, batch loss 0.4518, batch acc 0.1068
14:29:28.589   Training iter 150, batch loss 0.4518, batch acc 0.1082
14:29:29.228   Training iter 200, batch loss 0.4517, batch acc 0.1172
14:29:29.754   Training iter 250, batch loss 0.4517, batch acc 0.1160
14:29:30.364   Training iter 300, batch loss 0.4517, batch acc 0.1188
14:29:30.894   Training iter 350, batch loss 0.4517, batch acc 0.1136
14:29:31.406   Training iter 400, batch loss 0.4518, batch acc 0.1060
14:29:31.921   Training iter 450, batch loss 0.4517, batch acc 0.1154
14:29:32.447   Training iter 500, batch loss 0.4517, batch acc 0.1138
14:29:32.983   Training iter 550, batch loss 0.4518, batch acc 0.1122
14:29:33.522   Training iter 600, batch loss 0.4518, batch acc 0.1074
14:29:33.523 Training @ 379 epoch...
14:29:34.066   Training iter 50, batch loss 0.4517, batch acc 0.1172
14:29:34.600   Training iter 100, batch loss 0.4516, batch acc 0.1216
14:29:35.098   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:29:35.612   Training iter 200, batch loss 0.4517, batch acc 0.1116
14:29:36.131   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:29:36.582   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:29:37.029   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:29:37.470   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:29:37.932   Training iter 450, batch loss 0.4518, batch acc 0.1078
14:29:38.388   Training iter 500, batch loss 0.4518, batch acc 0.1102
14:29:38.850   Training iter 550, batch loss 0.4519, batch acc 0.1068
14:29:39.324   Training iter 600, batch loss 0.4517, batch acc 0.1114
14:29:39.326 Training @ 380 epoch...
14:29:39.795   Training iter 50, batch loss 0.4518, batch acc 0.1116
14:29:40.282   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:29:40.760   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:29:41.230   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:29:41.698   Training iter 250, batch loss 0.4517, batch acc 0.1220
14:29:42.170   Training iter 300, batch loss 0.4518, batch acc 0.1050
14:29:42.636   Training iter 350, batch loss 0.4516, batch acc 0.1168
14:29:43.105   Training iter 400, batch loss 0.4517, batch acc 0.1118
14:29:43.568   Training iter 450, batch loss 0.4517, batch acc 0.1150
14:29:44.045   Training iter 500, batch loss 0.4518, batch acc 0.1098
14:29:44.526   Training iter 550, batch loss 0.4517, batch acc 0.1150
14:29:45.024   Training iter 600, batch loss 0.4518, batch acc 0.1074
14:29:45.025 Testing @ 380 epoch...
14:29:45.064     Testing, total mean loss 0.45174, total acc 0.11350
14:29:45.064 Training @ 381 epoch...
14:29:45.568   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:29:46.050   Training iter 100, batch loss 0.4517, batch acc 0.1148
14:29:46.527   Training iter 150, batch loss 0.4517, batch acc 0.1134
14:29:47.060   Training iter 200, batch loss 0.4518, batch acc 0.1124
14:29:47.612   Training iter 250, batch loss 0.4518, batch acc 0.1134
14:29:48.149   Training iter 300, batch loss 0.4517, batch acc 0.1112
14:29:48.704   Training iter 350, batch loss 0.4516, batch acc 0.1130
14:29:49.254   Training iter 400, batch loss 0.4517, batch acc 0.1202
14:29:49.796   Training iter 450, batch loss 0.4519, batch acc 0.1056
14:29:50.325   Training iter 500, batch loss 0.4518, batch acc 0.1120
14:29:50.824   Training iter 550, batch loss 0.4519, batch acc 0.1024
14:29:51.316   Training iter 600, batch loss 0.4517, batch acc 0.1170
14:29:51.318 Training @ 382 epoch...
14:29:51.821   Training iter 50, batch loss 0.4517, batch acc 0.1166
14:29:52.324   Training iter 100, batch loss 0.4517, batch acc 0.1138
14:29:52.833   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:29:53.343   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:29:53.865   Training iter 250, batch loss 0.4519, batch acc 0.1100
14:29:54.379   Training iter 300, batch loss 0.4517, batch acc 0.1114
14:29:54.876   Training iter 350, batch loss 0.4518, batch acc 0.1082
14:29:55.387   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:29:55.897   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:29:56.416   Training iter 500, batch loss 0.4517, batch acc 0.1194
14:29:56.925   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:29:57.456   Training iter 600, batch loss 0.4518, batch acc 0.1070
14:29:57.458 Training @ 383 epoch...
14:29:58.009   Training iter 50, batch loss 0.4517, batch acc 0.1108
14:29:58.567   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:29:59.110   Training iter 150, batch loss 0.4517, batch acc 0.1124
14:29:59.658   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:30:00.213   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:30:00.787   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:30:01.395   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:30:02.025   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:30:02.620   Training iter 450, batch loss 0.4517, batch acc 0.1126
14:30:03.217   Training iter 500, batch loss 0.4517, batch acc 0.1174
14:30:03.803   Training iter 550, batch loss 0.4518, batch acc 0.1094
14:30:04.378   Training iter 600, batch loss 0.4518, batch acc 0.1062
14:30:04.380 Training @ 384 epoch...
14:30:04.919   Training iter 50, batch loss 0.4517, batch acc 0.1136
14:30:05.450   Training iter 100, batch loss 0.4517, batch acc 0.1138
14:30:05.951   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:30:06.466   Training iter 200, batch loss 0.4518, batch acc 0.1094
14:30:06.967   Training iter 250, batch loss 0.4518, batch acc 0.1130
14:30:07.474   Training iter 300, batch loss 0.4518, batch acc 0.1064
14:30:07.968   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:30:08.465   Training iter 400, batch loss 0.4518, batch acc 0.1094
14:30:08.966   Training iter 450, batch loss 0.4518, batch acc 0.1140
14:30:09.501   Training iter 500, batch loss 0.4518, batch acc 0.1128
14:30:10.072   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:30:10.642   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:30:10.644 Training @ 385 epoch...
14:30:11.206   Training iter 50, batch loss 0.4519, batch acc 0.1074
14:30:11.703   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:30:12.215   Training iter 150, batch loss 0.4517, batch acc 0.1174
14:30:12.724   Training iter 200, batch loss 0.4517, batch acc 0.1146
14:30:13.249   Training iter 250, batch loss 0.4517, batch acc 0.1158
14:30:13.771   Training iter 300, batch loss 0.4516, batch acc 0.1136
14:30:14.306   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:30:14.808   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:30:15.308   Training iter 450, batch loss 0.4518, batch acc 0.1116
14:30:15.822   Training iter 500, batch loss 0.4519, batch acc 0.1080
14:30:16.353   Training iter 550, batch loss 0.4518, batch acc 0.1126
14:30:16.882   Training iter 600, batch loss 0.4516, batch acc 0.1184
14:30:16.884 Testing @ 385 epoch...
14:30:16.923     Testing, total mean loss 0.45174, total acc 0.11350
14:30:16.923 Training @ 386 epoch...
14:30:17.466   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:30:18.015   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:30:18.555   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:30:19.092   Training iter 200, batch loss 0.4517, batch acc 0.1142
14:30:19.645   Training iter 250, batch loss 0.4518, batch acc 0.1064
14:30:20.201   Training iter 300, batch loss 0.4518, batch acc 0.1158
14:30:20.747   Training iter 350, batch loss 0.4517, batch acc 0.1128
14:30:21.288   Training iter 400, batch loss 0.4518, batch acc 0.1072
14:30:21.832   Training iter 450, batch loss 0.4517, batch acc 0.1166
14:30:22.374   Training iter 500, batch loss 0.4518, batch acc 0.1132
14:30:22.893   Training iter 550, batch loss 0.4518, batch acc 0.1128
14:30:23.400   Training iter 600, batch loss 0.4517, batch acc 0.1138
14:30:23.402 Training @ 387 epoch...
14:30:23.922   Training iter 50, batch loss 0.4517, batch acc 0.1170
14:30:24.441   Training iter 100, batch loss 0.4518, batch acc 0.1108
14:30:24.979   Training iter 150, batch loss 0.4518, batch acc 0.1114
14:30:25.503   Training iter 200, batch loss 0.4517, batch acc 0.1186
14:30:26.014   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:30:26.528   Training iter 300, batch loss 0.4518, batch acc 0.1142
14:30:27.040   Training iter 350, batch loss 0.4518, batch acc 0.1118
14:30:27.557   Training iter 400, batch loss 0.4517, batch acc 0.1144
14:30:28.074   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:30:28.613   Training iter 500, batch loss 0.4517, batch acc 0.1094
14:30:29.157   Training iter 550, batch loss 0.4518, batch acc 0.1106
14:30:29.693   Training iter 600, batch loss 0.4517, batch acc 0.1124
14:30:29.695 Training @ 388 epoch...
14:30:30.223   Training iter 50, batch loss 0.4517, batch acc 0.1146
14:30:30.762   Training iter 100, batch loss 0.4517, batch acc 0.1122
14:30:31.271   Training iter 150, batch loss 0.4517, batch acc 0.1106
14:30:31.775   Training iter 200, batch loss 0.4518, batch acc 0.1056
14:30:32.300   Training iter 250, batch loss 0.4517, batch acc 0.1152
14:30:32.802   Training iter 300, batch loss 0.4517, batch acc 0.1164
14:30:33.312   Training iter 350, batch loss 0.4518, batch acc 0.1090
14:30:33.811   Training iter 400, batch loss 0.4517, batch acc 0.1202
14:30:34.310   Training iter 450, batch loss 0.4518, batch acc 0.1146
14:30:34.833   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:30:35.346   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:30:35.850   Training iter 600, batch loss 0.4517, batch acc 0.1126
14:30:35.852 Training @ 389 epoch...
14:30:36.366   Training iter 50, batch loss 0.4517, batch acc 0.1174
14:30:36.850   Training iter 100, batch loss 0.4518, batch acc 0.1096
14:30:37.328   Training iter 150, batch loss 0.4518, batch acc 0.1106
14:30:37.828   Training iter 200, batch loss 0.4518, batch acc 0.1064
14:30:38.343   Training iter 250, batch loss 0.4518, batch acc 0.1076
14:30:38.832   Training iter 300, batch loss 0.4518, batch acc 0.1120
14:30:39.328   Training iter 350, batch loss 0.4517, batch acc 0.1112
14:30:39.825   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:30:40.348   Training iter 450, batch loss 0.4517, batch acc 0.1184
14:30:40.850   Training iter 500, batch loss 0.4517, batch acc 0.1182
14:30:41.363   Training iter 550, batch loss 0.4519, batch acc 0.1050
14:30:41.891   Training iter 600, batch loss 0.4516, batch acc 0.1188
14:30:41.893 Training @ 390 epoch...
14:30:42.434   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:30:42.962   Training iter 100, batch loss 0.4517, batch acc 0.1168
14:30:43.499   Training iter 150, batch loss 0.4519, batch acc 0.1052
14:30:44.027   Training iter 200, batch loss 0.4518, batch acc 0.1074
14:30:44.550   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:30:45.070   Training iter 300, batch loss 0.4518, batch acc 0.1070
14:30:45.587   Training iter 350, batch loss 0.4518, batch acc 0.1140
14:30:46.112   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:30:46.623   Training iter 450, batch loss 0.4516, batch acc 0.1224
14:30:47.131   Training iter 500, batch loss 0.4518, batch acc 0.1078
14:30:47.643   Training iter 550, batch loss 0.4517, batch acc 0.1138
14:30:48.163   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:30:48.164 Testing @ 390 epoch...
14:30:48.203     Testing, total mean loss 0.45174, total acc 0.11350
14:30:48.204 Training @ 391 epoch...
14:30:48.732   Training iter 50, batch loss 0.4518, batch acc 0.1096
14:30:49.270   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:30:49.836   Training iter 150, batch loss 0.4517, batch acc 0.1182
14:30:50.412   Training iter 200, batch loss 0.4518, batch acc 0.1078
14:30:50.975   Training iter 250, batch loss 0.4518, batch acc 0.1138
14:30:51.536   Training iter 300, batch loss 0.4517, batch acc 0.1110
14:30:52.115   Training iter 350, batch loss 0.4518, batch acc 0.1112
14:30:52.689   Training iter 400, batch loss 0.4517, batch acc 0.1120
14:30:53.253   Training iter 450, batch loss 0.4518, batch acc 0.1156
14:30:53.818   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:30:54.380   Training iter 550, batch loss 0.4517, batch acc 0.1106
14:30:54.923   Training iter 600, batch loss 0.4518, batch acc 0.1106
14:30:54.925 Training @ 392 epoch...
14:30:55.481   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:30:56.011   Training iter 100, batch loss 0.4518, batch acc 0.1112
14:30:56.545   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:30:57.073   Training iter 200, batch loss 0.4517, batch acc 0.1128
14:30:57.602   Training iter 250, batch loss 0.4517, batch acc 0.1156
14:30:58.127   Training iter 300, batch loss 0.4519, batch acc 0.1084
14:30:58.642   Training iter 350, batch loss 0.4518, batch acc 0.1142
14:30:59.169   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:30:59.685   Training iter 450, batch loss 0.4517, batch acc 0.1118
14:31:00.219   Training iter 500, batch loss 0.4518, batch acc 0.1134
14:31:00.726   Training iter 550, batch loss 0.4518, batch acc 0.1092
14:31:01.240   Training iter 600, batch loss 0.4517, batch acc 0.1118
14:31:01.242 Training @ 393 epoch...
14:31:01.746   Training iter 50, batch loss 0.4518, batch acc 0.1102
14:31:02.308   Training iter 100, batch loss 0.4517, batch acc 0.1084
14:31:02.881   Training iter 150, batch loss 0.4518, batch acc 0.1086
14:31:03.472   Training iter 200, batch loss 0.4517, batch acc 0.1178
14:31:04.018   Training iter 250, batch loss 0.4518, batch acc 0.1114
14:31:04.560   Training iter 300, batch loss 0.4517, batch acc 0.1118
14:31:05.130   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:31:05.709   Training iter 400, batch loss 0.4518, batch acc 0.1150
14:31:06.307   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:31:06.888   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:31:07.443   Training iter 550, batch loss 0.4516, batch acc 0.1212
14:31:07.987   Training iter 600, batch loss 0.4518, batch acc 0.1050
14:31:07.989 Training @ 394 epoch...
14:31:08.523   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:31:09.012   Training iter 100, batch loss 0.4518, batch acc 0.1100
14:31:09.512   Training iter 150, batch loss 0.4517, batch acc 0.1140
14:31:10.013   Training iter 200, batch loss 0.4517, batch acc 0.1112
14:31:10.532   Training iter 250, batch loss 0.4517, batch acc 0.1196
14:31:11.043   Training iter 300, batch loss 0.4517, batch acc 0.1188
14:31:11.530   Training iter 350, batch loss 0.4518, batch acc 0.1108
14:31:12.025   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:31:12.514   Training iter 450, batch loss 0.4518, batch acc 0.1134
14:31:13.006   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:31:13.498   Training iter 550, batch loss 0.4518, batch acc 0.1138
14:31:13.992   Training iter 600, batch loss 0.4518, batch acc 0.1080
14:31:13.994 Training @ 395 epoch...
14:31:14.502   Training iter 50, batch loss 0.4518, batch acc 0.1126
14:31:15.010   Training iter 100, batch loss 0.4518, batch acc 0.1110
14:31:15.505   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:31:16.007   Training iter 200, batch loss 0.4518, batch acc 0.1142
14:31:16.507   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:31:16.992   Training iter 300, batch loss 0.4517, batch acc 0.1154
14:31:17.452   Training iter 350, batch loss 0.4518, batch acc 0.1118
14:31:17.904   Training iter 400, batch loss 0.4517, batch acc 0.1112
14:31:18.373   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:31:18.838   Training iter 500, batch loss 0.4516, batch acc 0.1180
14:31:19.309   Training iter 550, batch loss 0.4517, batch acc 0.1176
14:31:19.774   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:31:19.776 Testing @ 395 epoch...
14:31:19.814     Testing, total mean loss 0.45174, total acc 0.11350
14:31:19.814 Training @ 396 epoch...
14:31:20.291   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:31:20.769   Training iter 100, batch loss 0.4518, batch acc 0.1170
14:31:21.299   Training iter 150, batch loss 0.4517, batch acc 0.1170
14:31:21.831   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:31:22.364   Training iter 250, batch loss 0.4518, batch acc 0.1124
14:31:22.905   Training iter 300, batch loss 0.4517, batch acc 0.1096
14:31:23.439   Training iter 350, batch loss 0.4519, batch acc 0.1038
14:31:23.970   Training iter 400, batch loss 0.4516, batch acc 0.1156
14:31:24.502   Training iter 450, batch loss 0.4517, batch acc 0.1122
14:31:25.044   Training iter 500, batch loss 0.4518, batch acc 0.1134
14:31:25.586   Training iter 550, batch loss 0.4517, batch acc 0.1226
14:31:26.131   Training iter 600, batch loss 0.4518, batch acc 0.1076
14:31:26.133 Training @ 397 epoch...
14:31:26.677   Training iter 50, batch loss 0.4516, batch acc 0.1230
14:31:27.205   Training iter 100, batch loss 0.4518, batch acc 0.1098
14:31:27.726   Training iter 150, batch loss 0.4518, batch acc 0.1064
14:31:28.251   Training iter 200, batch loss 0.4518, batch acc 0.1092
14:31:28.772   Training iter 250, batch loss 0.4517, batch acc 0.1114
14:31:29.293   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:31:29.814   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:31:30.338   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:31:30.849   Training iter 450, batch loss 0.4518, batch acc 0.1090
14:31:31.355   Training iter 500, batch loss 0.4518, batch acc 0.1096
14:31:31.868   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:31:32.373   Training iter 600, batch loss 0.4517, batch acc 0.1162
14:31:32.374 Training @ 398 epoch...
14:31:32.884   Training iter 50, batch loss 0.4517, batch acc 0.1110
14:31:33.408   Training iter 100, batch loss 0.4516, batch acc 0.1156
14:31:33.912   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:31:34.422   Training iter 200, batch loss 0.4517, batch acc 0.1096
14:31:34.945   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:31:35.458   Training iter 300, batch loss 0.4518, batch acc 0.1164
14:31:35.945   Training iter 350, batch loss 0.4518, batch acc 0.1112
14:31:36.445   Training iter 400, batch loss 0.4518, batch acc 0.1086
14:31:36.944   Training iter 450, batch loss 0.4517, batch acc 0.1146
14:31:37.474   Training iter 500, batch loss 0.4518, batch acc 0.1104
14:31:38.011   Training iter 550, batch loss 0.4517, batch acc 0.1190
14:31:38.594   Training iter 600, batch loss 0.4517, batch acc 0.1100
14:31:38.596 Training @ 399 epoch...
14:31:39.152   Training iter 50, batch loss 0.4517, batch acc 0.1194
14:31:39.707   Training iter 100, batch loss 0.4518, batch acc 0.1098
14:31:40.257   Training iter 150, batch loss 0.4518, batch acc 0.1110
14:31:40.789   Training iter 200, batch loss 0.4517, batch acc 0.1186
14:31:41.324   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:31:41.860   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:31:42.403   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:31:42.951   Training iter 400, batch loss 0.4518, batch acc 0.1134
14:31:43.496   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:31:44.031   Training iter 500, batch loss 0.4518, batch acc 0.1074
14:31:44.548   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:31:45.068   Training iter 600, batch loss 0.4518, batch acc 0.1094
14:31:45.070 Training @ 400 epoch...
14:31:45.596   Training iter 50, batch loss 0.4519, batch acc 0.1044
14:31:46.119   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:31:46.637   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:31:47.174   Training iter 200, batch loss 0.4516, batch acc 0.1200
14:31:47.716   Training iter 250, batch loss 0.4517, batch acc 0.1182
14:31:48.253   Training iter 300, batch loss 0.4517, batch acc 0.1114
14:31:48.786   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:31:49.323   Training iter 400, batch loss 0.4517, batch acc 0.1152
14:31:49.865   Training iter 450, batch loss 0.4517, batch acc 0.1092
14:31:50.413   Training iter 500, batch loss 0.4517, batch acc 0.1152
14:31:50.942   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:31:51.473   Training iter 600, batch loss 0.4518, batch acc 0.1096
14:31:51.475 Testing @ 400 epoch...
14:31:51.516     Testing, total mean loss 0.45174, total acc 0.11350
14:31:51.517 Plot @ 400 epoch...
14:31:51.517 Training @ 401 epoch...
14:31:52.044   Training iter 50, batch loss 0.4518, batch acc 0.1092
14:31:52.548   Training iter 100, batch loss 0.4518, batch acc 0.1136
14:31:53.039   Training iter 150, batch loss 0.4517, batch acc 0.1154
14:31:53.525   Training iter 200, batch loss 0.4517, batch acc 0.1162
14:31:54.007   Training iter 250, batch loss 0.4518, batch acc 0.1128
14:31:54.524   Training iter 300, batch loss 0.4518, batch acc 0.1126
14:31:55.048   Training iter 350, batch loss 0.4518, batch acc 0.1098
14:31:55.595   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:31:56.128   Training iter 450, batch loss 0.4517, batch acc 0.1120
14:31:56.682   Training iter 500, batch loss 0.4518, batch acc 0.1112
14:31:57.222   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:31:57.777   Training iter 600, batch loss 0.4519, batch acc 0.1080
14:31:57.780 Training @ 402 epoch...
14:31:58.418   Training iter 50, batch loss 0.4519, batch acc 0.1020
14:31:59.033   Training iter 100, batch loss 0.4517, batch acc 0.1212
14:31:59.616   Training iter 150, batch loss 0.4518, batch acc 0.1038
14:32:00.160   Training iter 200, batch loss 0.4518, batch acc 0.1160
14:32:00.703   Training iter 250, batch loss 0.4517, batch acc 0.1156
14:32:01.269   Training iter 300, batch loss 0.4517, batch acc 0.1138
14:32:01.880   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:32:02.452   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:32:03.017   Training iter 450, batch loss 0.4516, batch acc 0.1210
14:32:03.573   Training iter 500, batch loss 0.4517, batch acc 0.1116
14:32:04.073   Training iter 550, batch loss 0.4518, batch acc 0.1088
14:32:04.603   Training iter 600, batch loss 0.4517, batch acc 0.1092
14:32:04.604 Training @ 403 epoch...
14:32:05.134   Training iter 50, batch loss 0.4517, batch acc 0.1184
14:32:05.624   Training iter 100, batch loss 0.4516, batch acc 0.1192
14:32:06.119   Training iter 150, batch loss 0.4517, batch acc 0.1192
14:32:06.615   Training iter 200, batch loss 0.4518, batch acc 0.1116
14:32:07.104   Training iter 250, batch loss 0.4518, batch acc 0.1044
14:32:07.601   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:32:08.067   Training iter 350, batch loss 0.4518, batch acc 0.1078
14:32:08.534   Training iter 400, batch loss 0.4518, batch acc 0.1122
14:32:08.989   Training iter 450, batch loss 0.4518, batch acc 0.1114
14:32:09.483   Training iter 500, batch loss 0.4518, batch acc 0.1144
14:32:09.990   Training iter 550, batch loss 0.4518, batch acc 0.1068
14:32:10.501   Training iter 600, batch loss 0.4517, batch acc 0.1114
14:32:10.503 Training @ 404 epoch...
14:32:11.012   Training iter 50, batch loss 0.4517, batch acc 0.1138
14:32:11.515   Training iter 100, batch loss 0.4517, batch acc 0.1174
14:32:12.023   Training iter 150, batch loss 0.4518, batch acc 0.1056
14:32:12.531   Training iter 200, batch loss 0.4518, batch acc 0.1120
14:32:13.047   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:32:13.560   Training iter 300, batch loss 0.4518, batch acc 0.1100
14:32:14.074   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:32:14.596   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:32:15.090   Training iter 450, batch loss 0.4518, batch acc 0.1112
14:32:15.566   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:32:16.028   Training iter 550, batch loss 0.4518, batch acc 0.1060
14:32:16.500   Training iter 600, batch loss 0.4518, batch acc 0.1156
14:32:16.502 Training @ 405 epoch...
14:32:16.999   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:32:17.501   Training iter 100, batch loss 0.4517, batch acc 0.1204
14:32:18.006   Training iter 150, batch loss 0.4518, batch acc 0.1148
14:32:18.511   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:32:19.008   Training iter 250, batch loss 0.4518, batch acc 0.1092
14:32:19.502   Training iter 300, batch loss 0.4517, batch acc 0.1148
14:32:20.023   Training iter 350, batch loss 0.4517, batch acc 0.1152
14:32:20.538   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:32:21.025   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:32:21.513   Training iter 500, batch loss 0.4517, batch acc 0.1094
14:32:22.003   Training iter 550, batch loss 0.4518, batch acc 0.1176
14:32:22.497   Training iter 600, batch loss 0.4517, batch acc 0.1078
14:32:22.499 Testing @ 405 epoch...
14:32:22.537     Testing, total mean loss 0.45174, total acc 0.11350
14:32:22.537 Training @ 406 epoch...
14:32:23.040   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:32:23.545   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:32:24.036   Training iter 150, batch loss 0.4517, batch acc 0.1158
14:32:24.540   Training iter 200, batch loss 0.4518, batch acc 0.1062
14:32:25.058   Training iter 250, batch loss 0.4517, batch acc 0.1184
14:32:25.596   Training iter 300, batch loss 0.4518, batch acc 0.1086
14:32:26.132   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:32:26.662   Training iter 400, batch loss 0.4518, batch acc 0.1136
14:32:27.209   Training iter 450, batch loss 0.4517, batch acc 0.1104
14:32:27.749   Training iter 500, batch loss 0.4517, batch acc 0.1186
14:32:28.293   Training iter 550, batch loss 0.4518, batch acc 0.1126
14:32:28.816   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:32:28.818 Training @ 407 epoch...
14:32:29.337   Training iter 50, batch loss 0.4517, batch acc 0.1108
14:32:29.877   Training iter 100, batch loss 0.4518, batch acc 0.1126
14:32:30.431   Training iter 150, batch loss 0.4518, batch acc 0.1098
14:32:30.996   Training iter 200, batch loss 0.4517, batch acc 0.1164
14:32:31.519   Training iter 250, batch loss 0.4518, batch acc 0.1080
14:32:32.024   Training iter 300, batch loss 0.4518, batch acc 0.1144
14:32:32.535   Training iter 350, batch loss 0.4517, batch acc 0.1174
14:32:33.064   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:32:33.574   Training iter 450, batch loss 0.4518, batch acc 0.1078
14:32:34.091   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:32:34.612   Training iter 550, batch loss 0.4517, batch acc 0.1142
14:32:35.123   Training iter 600, batch loss 0.4518, batch acc 0.1128
14:32:35.125 Training @ 408 epoch...
14:32:35.648   Training iter 50, batch loss 0.4517, batch acc 0.1124
14:32:36.177   Training iter 100, batch loss 0.4518, batch acc 0.1142
14:32:36.713   Training iter 150, batch loss 0.4518, batch acc 0.1102
14:32:37.225   Training iter 200, batch loss 0.4517, batch acc 0.1166
14:32:37.759   Training iter 250, batch loss 0.4518, batch acc 0.1146
14:32:38.240   Training iter 300, batch loss 0.4518, batch acc 0.1122
14:32:38.744   Training iter 350, batch loss 0.4517, batch acc 0.1094
14:32:39.243   Training iter 400, batch loss 0.4516, batch acc 0.1208
14:32:39.751   Training iter 450, batch loss 0.4518, batch acc 0.1150
14:32:40.276   Training iter 500, batch loss 0.4519, batch acc 0.1030
14:32:40.792   Training iter 550, batch loss 0.4518, batch acc 0.1070
14:32:41.383   Training iter 600, batch loss 0.4517, batch acc 0.1130
14:32:41.385 Training @ 409 epoch...
14:32:41.914   Training iter 50, batch loss 0.4519, batch acc 0.1094
14:32:42.445   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:32:42.958   Training iter 150, batch loss 0.4517, batch acc 0.1106
14:32:43.468   Training iter 200, batch loss 0.4518, batch acc 0.1072
14:32:43.976   Training iter 250, batch loss 0.4517, batch acc 0.1162
14:32:44.484   Training iter 300, batch loss 0.4519, batch acc 0.1110
14:32:44.999   Training iter 350, batch loss 0.4517, batch acc 0.1172
14:32:45.508   Training iter 400, batch loss 0.4518, batch acc 0.1074
14:32:46.020   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:32:46.537   Training iter 500, batch loss 0.4517, batch acc 0.1188
14:32:47.100   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:32:47.614   Training iter 600, batch loss 0.4517, batch acc 0.1118
14:32:47.616 Training @ 410 epoch...
14:32:48.132   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:32:48.631   Training iter 100, batch loss 0.4517, batch acc 0.1202
14:32:49.116   Training iter 150, batch loss 0.4516, batch acc 0.1204
14:32:49.603   Training iter 200, batch loss 0.4518, batch acc 0.1066
14:32:50.060   Training iter 250, batch loss 0.4517, batch acc 0.1146
14:32:50.515   Training iter 300, batch loss 0.4518, batch acc 0.1110
14:32:50.960   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:32:51.417   Training iter 400, batch loss 0.4519, batch acc 0.1008
14:32:51.876   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:32:52.352   Training iter 500, batch loss 0.4518, batch acc 0.1154
14:32:52.820   Training iter 550, batch loss 0.4517, batch acc 0.1096
14:32:53.306   Training iter 600, batch loss 0.4517, batch acc 0.1130
14:32:53.308 Testing @ 410 epoch...
14:32:53.346     Testing, total mean loss 0.45174, total acc 0.11350
14:32:53.347 Training @ 411 epoch...
14:32:53.808   Training iter 50, batch loss 0.4518, batch acc 0.1066
14:32:54.270   Training iter 100, batch loss 0.4518, batch acc 0.1102
14:32:54.753   Training iter 150, batch loss 0.4518, batch acc 0.1068
14:32:55.255   Training iter 200, batch loss 0.4518, batch acc 0.1120
14:32:55.744   Training iter 250, batch loss 0.4519, batch acc 0.1040
14:32:56.219   Training iter 300, batch loss 0.4517, batch acc 0.1230
14:32:56.676   Training iter 350, batch loss 0.4516, batch acc 0.1200
14:32:57.141   Training iter 400, batch loss 0.4517, batch acc 0.1164
14:32:57.661   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:32:58.187   Training iter 500, batch loss 0.4518, batch acc 0.1066
14:32:58.716   Training iter 550, batch loss 0.4518, batch acc 0.1092
14:32:59.256   Training iter 600, batch loss 0.4517, batch acc 0.1172
14:32:59.258 Training @ 412 epoch...
14:32:59.801   Training iter 50, batch loss 0.4516, batch acc 0.1162
14:33:00.339   Training iter 100, batch loss 0.4518, batch acc 0.1106
14:33:00.871   Training iter 150, batch loss 0.4517, batch acc 0.1160
14:33:01.395   Training iter 200, batch loss 0.4517, batch acc 0.1200
14:33:01.949   Training iter 250, batch loss 0.4518, batch acc 0.1100
14:33:02.518   Training iter 300, batch loss 0.4519, batch acc 0.1044
14:33:03.073   Training iter 350, batch loss 0.4517, batch acc 0.1146
14:33:03.592   Training iter 400, batch loss 0.4518, batch acc 0.1162
14:33:04.103   Training iter 450, batch loss 0.4518, batch acc 0.1134
14:33:04.650   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:33:05.208   Training iter 550, batch loss 0.4518, batch acc 0.1098
14:33:05.758   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:33:05.760 Training @ 413 epoch...
14:33:06.311   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:33:06.874   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:33:07.460   Training iter 150, batch loss 0.4518, batch acc 0.1074
14:33:08.029   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:33:08.573   Training iter 250, batch loss 0.4518, batch acc 0.1074
14:33:09.115   Training iter 300, batch loss 0.4518, batch acc 0.1120
14:33:09.659   Training iter 350, batch loss 0.4518, batch acc 0.1114
14:33:10.218   Training iter 400, batch loss 0.4518, batch acc 0.1148
14:33:10.709   Training iter 450, batch loss 0.4517, batch acc 0.1168
14:33:11.188   Training iter 500, batch loss 0.4517, batch acc 0.1138
14:33:11.743   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:33:12.325   Training iter 600, batch loss 0.4517, batch acc 0.1162
14:33:12.328 Training @ 414 epoch...
14:33:12.870   Training iter 50, batch loss 0.4518, batch acc 0.1106
14:33:13.384   Training iter 100, batch loss 0.4518, batch acc 0.1080
14:33:13.912   Training iter 150, batch loss 0.4517, batch acc 0.1134
14:33:14.447   Training iter 200, batch loss 0.4517, batch acc 0.1134
14:33:14.997   Training iter 250, batch loss 0.4518, batch acc 0.1094
14:33:15.564   Training iter 300, batch loss 0.4517, batch acc 0.1158
14:33:16.139   Training iter 350, batch loss 0.4517, batch acc 0.1136
14:33:16.719   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:33:17.275   Training iter 450, batch loss 0.4518, batch acc 0.1116
14:33:17.774   Training iter 500, batch loss 0.4518, batch acc 0.1124
14:33:18.301   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:33:18.837   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:33:18.839 Training @ 415 epoch...
14:33:19.386   Training iter 50, batch loss 0.4517, batch acc 0.1130
14:33:19.906   Training iter 100, batch loss 0.4518, batch acc 0.1068
14:33:20.416   Training iter 150, batch loss 0.4517, batch acc 0.1138
14:33:20.917   Training iter 200, batch loss 0.4519, batch acc 0.1092
14:33:21.430   Training iter 250, batch loss 0.4517, batch acc 0.1112
14:33:21.937   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:33:22.454   Training iter 350, batch loss 0.4517, batch acc 0.1130
14:33:22.959   Training iter 400, batch loss 0.4517, batch acc 0.1110
14:33:23.475   Training iter 450, batch loss 0.4518, batch acc 0.1148
14:33:23.979   Training iter 500, batch loss 0.4518, batch acc 0.1136
14:33:24.489   Training iter 550, batch loss 0.4517, batch acc 0.1194
14:33:25.001   Training iter 600, batch loss 0.4518, batch acc 0.1118
14:33:25.003 Testing @ 415 epoch...
14:33:25.042     Testing, total mean loss 0.45174, total acc 0.11350
14:33:25.042 Training @ 416 epoch...
14:33:25.580   Training iter 50, batch loss 0.4518, batch acc 0.1096
14:33:26.112   Training iter 100, batch loss 0.4518, batch acc 0.1080
14:33:26.634   Training iter 150, batch loss 0.4519, batch acc 0.1018
14:33:27.214   Training iter 200, batch loss 0.4517, batch acc 0.1170
14:33:27.776   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:33:28.271   Training iter 300, batch loss 0.4518, batch acc 0.1126
14:33:28.748   Training iter 350, batch loss 0.4518, batch acc 0.1090
14:33:29.261   Training iter 400, batch loss 0.4517, batch acc 0.1206
14:33:29.791   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:33:30.344   Training iter 500, batch loss 0.4517, batch acc 0.1166
14:33:30.895   Training iter 550, batch loss 0.4517, batch acc 0.1148
14:33:31.438   Training iter 600, batch loss 0.4518, batch acc 0.1052
14:33:31.440 Training @ 417 epoch...
14:33:32.003   Training iter 50, batch loss 0.4518, batch acc 0.1158
14:33:32.563   Training iter 100, batch loss 0.4518, batch acc 0.1128
14:33:33.140   Training iter 150, batch loss 0.4518, batch acc 0.1068
14:33:33.712   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:33:34.288   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:33:34.857   Training iter 300, batch loss 0.4519, batch acc 0.1062
14:33:35.406   Training iter 350, batch loss 0.4518, batch acc 0.1088
14:33:35.923   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:33:36.429   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:33:36.931   Training iter 500, batch loss 0.4518, batch acc 0.1132
14:33:37.456   Training iter 550, batch loss 0.4517, batch acc 0.1136
14:33:37.973   Training iter 600, batch loss 0.4516, batch acc 0.1256
14:33:37.975 Training @ 418 epoch...
14:33:38.495   Training iter 50, batch loss 0.4518, batch acc 0.1162
14:33:39.001   Training iter 100, batch loss 0.4517, batch acc 0.1112
14:33:39.519   Training iter 150, batch loss 0.4518, batch acc 0.1064
14:33:40.043   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:33:40.571   Training iter 250, batch loss 0.4517, batch acc 0.1164
14:33:41.103   Training iter 300, batch loss 0.4518, batch acc 0.1082
14:33:41.642   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:33:42.230   Training iter 400, batch loss 0.4518, batch acc 0.1078
14:33:42.820   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:33:43.378   Training iter 500, batch loss 0.4517, batch acc 0.1124
14:33:43.902   Training iter 550, batch loss 0.4518, batch acc 0.1156
14:33:44.425   Training iter 600, batch loss 0.4516, batch acc 0.1184
14:33:44.426 Training @ 419 epoch...
14:33:44.972   Training iter 50, batch loss 0.4517, batch acc 0.1144
14:33:45.497   Training iter 100, batch loss 0.4518, batch acc 0.1090
14:33:46.049   Training iter 150, batch loss 0.4518, batch acc 0.1090
14:33:46.605   Training iter 200, batch loss 0.4516, batch acc 0.1206
14:33:47.162   Training iter 250, batch loss 0.4518, batch acc 0.1138
14:33:47.723   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:33:48.297   Training iter 350, batch loss 0.4517, batch acc 0.1094
14:33:48.855   Training iter 400, batch loss 0.4517, batch acc 0.1112
14:33:49.411   Training iter 450, batch loss 0.4517, batch acc 0.1170
14:33:49.956   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:33:50.491   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:33:51.025   Training iter 600, batch loss 0.4518, batch acc 0.1086
14:33:51.027 Training @ 420 epoch...
14:33:51.566   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:33:52.091   Training iter 100, batch loss 0.4517, batch acc 0.1094
14:33:52.605   Training iter 150, batch loss 0.4517, batch acc 0.1144
14:33:53.121   Training iter 200, batch loss 0.4518, batch acc 0.1124
14:33:53.634   Training iter 250, batch loss 0.4518, batch acc 0.1142
14:33:54.140   Training iter 300, batch loss 0.4518, batch acc 0.1108
14:33:54.650   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:33:55.173   Training iter 400, batch loss 0.4517, batch acc 0.1088
14:33:55.680   Training iter 450, batch loss 0.4517, batch acc 0.1190
14:33:56.192   Training iter 500, batch loss 0.4518, batch acc 0.1104
14:33:56.699   Training iter 550, batch loss 0.4517, batch acc 0.1160
14:33:57.191   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:33:57.193 Testing @ 420 epoch...
14:33:57.233     Testing, total mean loss 0.45174, total acc 0.11350
14:33:57.233 Training @ 421 epoch...
14:33:57.761   Training iter 50, batch loss 0.4517, batch acc 0.1124
14:33:58.344   Training iter 100, batch loss 0.4518, batch acc 0.1112
14:33:58.854   Training iter 150, batch loss 0.4516, batch acc 0.1174
14:33:59.371   Training iter 200, batch loss 0.4518, batch acc 0.1146
14:33:59.879   Training iter 250, batch loss 0.4518, batch acc 0.1104
14:34:00.419   Training iter 300, batch loss 0.4517, batch acc 0.1096
14:34:00.960   Training iter 350, batch loss 0.4517, batch acc 0.1098
14:34:01.525   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:34:02.207   Training iter 450, batch loss 0.4518, batch acc 0.1118
14:34:02.793   Training iter 500, batch loss 0.4516, batch acc 0.1200
14:34:03.338   Training iter 550, batch loss 0.4517, batch acc 0.1186
14:34:03.877   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:34:03.879 Training @ 422 epoch...
14:34:04.417   Training iter 50, batch loss 0.4517, batch acc 0.1136
14:34:04.960   Training iter 100, batch loss 0.4517, batch acc 0.1156
14:34:05.508   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:34:06.088   Training iter 200, batch loss 0.4517, batch acc 0.1172
14:34:06.657   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:34:07.206   Training iter 300, batch loss 0.4517, batch acc 0.1106
14:34:07.720   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:34:08.248   Training iter 400, batch loss 0.4519, batch acc 0.1070
14:34:08.749   Training iter 450, batch loss 0.4518, batch acc 0.1166
14:34:09.280   Training iter 500, batch loss 0.4518, batch acc 0.1046
14:34:09.817   Training iter 550, batch loss 0.4517, batch acc 0.1126
14:34:10.390   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:34:10.392 Training @ 423 epoch...
14:34:10.987   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:34:11.589   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:34:12.162   Training iter 150, batch loss 0.4517, batch acc 0.1178
14:34:12.678   Training iter 200, batch loss 0.4516, batch acc 0.1242
14:34:13.194   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:34:13.703   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:34:14.227   Training iter 350, batch loss 0.4518, batch acc 0.1110
14:34:14.748   Training iter 400, batch loss 0.4519, batch acc 0.0992
14:34:15.280   Training iter 450, batch loss 0.4518, batch acc 0.1040
14:34:15.798   Training iter 500, batch loss 0.4518, batch acc 0.1144
14:34:16.322   Training iter 550, batch loss 0.4517, batch acc 0.1144
14:34:16.839   Training iter 600, batch loss 0.4517, batch acc 0.1200
14:34:16.841 Training @ 424 epoch...
14:34:17.373   Training iter 50, batch loss 0.4518, batch acc 0.1052
14:34:17.896   Training iter 100, batch loss 0.4517, batch acc 0.1186
14:34:18.435   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:34:18.952   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:34:19.457   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:34:19.958   Training iter 300, batch loss 0.4517, batch acc 0.1152
14:34:20.471   Training iter 350, batch loss 0.4518, batch acc 0.1150
14:34:20.973   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:34:21.477   Training iter 450, batch loss 0.4519, batch acc 0.1054
14:34:21.988   Training iter 500, batch loss 0.4518, batch acc 0.1086
14:34:22.515   Training iter 550, batch loss 0.4518, batch acc 0.1076
14:34:23.017   Training iter 600, batch loss 0.4517, batch acc 0.1204
14:34:23.018 Training @ 425 epoch...
14:34:23.532   Training iter 50, batch loss 0.4518, batch acc 0.1094
14:34:24.025   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:34:24.523   Training iter 150, batch loss 0.4517, batch acc 0.1116
14:34:25.032   Training iter 200, batch loss 0.4518, batch acc 0.1076
14:34:25.537   Training iter 250, batch loss 0.4516, batch acc 0.1216
14:34:26.048   Training iter 300, batch loss 0.4518, batch acc 0.1114
14:34:26.546   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:34:27.058   Training iter 400, batch loss 0.4518, batch acc 0.1126
14:34:27.578   Training iter 450, batch loss 0.4518, batch acc 0.1104
14:34:28.095   Training iter 500, batch loss 0.4518, batch acc 0.1062
14:34:28.609   Training iter 550, batch loss 0.4516, batch acc 0.1202
14:34:29.125   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:34:29.126 Testing @ 425 epoch...
14:34:29.165     Testing, total mean loss 0.45174, total acc 0.11350
14:34:29.165 Training @ 426 epoch...
14:34:29.652   Training iter 50, batch loss 0.4519, batch acc 0.1084
14:34:30.134   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:34:30.646   Training iter 150, batch loss 0.4518, batch acc 0.1106
14:34:31.159   Training iter 200, batch loss 0.4517, batch acc 0.1180
14:34:31.678   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:34:32.188   Training iter 300, batch loss 0.4517, batch acc 0.1210
14:34:32.710   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:34:33.194   Training iter 400, batch loss 0.4518, batch acc 0.1124
14:34:33.680   Training iter 450, batch loss 0.4517, batch acc 0.1098
14:34:34.167   Training iter 500, batch loss 0.4517, batch acc 0.1104
14:34:34.698   Training iter 550, batch loss 0.4517, batch acc 0.1104
14:34:35.295   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:34:35.298 Training @ 427 epoch...
14:34:35.941   Training iter 50, batch loss 0.4518, batch acc 0.1068
14:34:36.534   Training iter 100, batch loss 0.4517, batch acc 0.1194
14:34:37.072   Training iter 150, batch loss 0.4518, batch acc 0.1104
14:34:37.589   Training iter 200, batch loss 0.4516, batch acc 0.1220
14:34:38.108   Training iter 250, batch loss 0.4518, batch acc 0.1082
14:34:38.661   Training iter 300, batch loss 0.4517, batch acc 0.1152
14:34:39.180   Training iter 350, batch loss 0.4518, batch acc 0.1054
14:34:39.689   Training iter 400, batch loss 0.4518, batch acc 0.1106
14:34:40.207   Training iter 450, batch loss 0.4518, batch acc 0.1062
14:34:40.719   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:34:41.231   Training iter 550, batch loss 0.4518, batch acc 0.1096
14:34:41.738   Training iter 600, batch loss 0.4517, batch acc 0.1204
14:34:41.740 Training @ 428 epoch...
14:34:42.255   Training iter 50, batch loss 0.4517, batch acc 0.1126
14:34:42.773   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:34:43.289   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:34:43.806   Training iter 200, batch loss 0.4518, batch acc 0.1110
14:34:44.328   Training iter 250, batch loss 0.4516, batch acc 0.1198
14:34:44.855   Training iter 300, batch loss 0.4517, batch acc 0.1138
14:34:45.382   Training iter 350, batch loss 0.4517, batch acc 0.1098
14:34:45.899   Training iter 400, batch loss 0.4519, batch acc 0.1100
14:34:46.419   Training iter 450, batch loss 0.4518, batch acc 0.1130
14:34:46.939   Training iter 500, batch loss 0.4518, batch acc 0.1070
14:34:47.452   Training iter 550, batch loss 0.4518, batch acc 0.1102
14:34:47.954   Training iter 600, batch loss 0.4517, batch acc 0.1136
14:34:47.956 Training @ 429 epoch...
14:34:48.479   Training iter 50, batch loss 0.4518, batch acc 0.1090
14:34:48.978   Training iter 100, batch loss 0.4518, batch acc 0.1084
14:34:49.488   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:34:50.009   Training iter 200, batch loss 0.4517, batch acc 0.1174
14:34:50.556   Training iter 250, batch loss 0.4517, batch acc 0.1138
14:34:51.091   Training iter 300, batch loss 0.4518, batch acc 0.1098
14:34:51.637   Training iter 350, batch loss 0.4517, batch acc 0.1168
14:34:52.186   Training iter 400, batch loss 0.4516, batch acc 0.1202
14:34:52.741   Training iter 450, batch loss 0.4518, batch acc 0.1136
14:34:53.291   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:34:53.833   Training iter 550, batch loss 0.4518, batch acc 0.1120
14:34:54.379   Training iter 600, batch loss 0.4519, batch acc 0.1034
14:34:54.381 Training @ 430 epoch...
14:34:54.954   Training iter 50, batch loss 0.4518, batch acc 0.1046
14:34:55.591   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:34:56.169   Training iter 150, batch loss 0.4518, batch acc 0.1086
14:34:56.719   Training iter 200, batch loss 0.4517, batch acc 0.1194
14:34:57.272   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:34:57.820   Training iter 300, batch loss 0.4517, batch acc 0.1124
14:34:58.374   Training iter 350, batch loss 0.4518, batch acc 0.1074
14:34:58.915   Training iter 400, batch loss 0.4518, batch acc 0.1148
14:34:59.457   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:34:59.984   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:35:00.519   Training iter 550, batch loss 0.4517, batch acc 0.1174
14:35:01.085   Training iter 600, batch loss 0.4517, batch acc 0.1100
14:35:01.087 Testing @ 430 epoch...
14:35:01.127     Testing, total mean loss 0.45174, total acc 0.11350
14:35:01.127 Training @ 431 epoch...
14:35:01.695   Training iter 50, batch loss 0.4519, batch acc 0.1070
14:35:02.274   Training iter 100, batch loss 0.4518, batch acc 0.1126
14:35:02.850   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:35:03.425   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:35:03.956   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:35:04.482   Training iter 300, batch loss 0.4518, batch acc 0.1136
14:35:05.001   Training iter 350, batch loss 0.4517, batch acc 0.1120
14:35:05.531   Training iter 400, batch loss 0.4517, batch acc 0.1118
14:35:06.075   Training iter 450, batch loss 0.4518, batch acc 0.1096
14:35:06.619   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:35:07.158   Training iter 550, batch loss 0.4518, batch acc 0.1062
14:35:07.693   Training iter 600, batch loss 0.4518, batch acc 0.1162
14:35:07.695 Training @ 432 epoch...
14:35:08.231   Training iter 50, batch loss 0.4517, batch acc 0.1170
14:35:08.757   Training iter 100, batch loss 0.4517, batch acc 0.1180
14:35:09.286   Training iter 150, batch loss 0.4518, batch acc 0.1066
14:35:09.811   Training iter 200, batch loss 0.4518, batch acc 0.1110
14:35:10.341   Training iter 250, batch loss 0.4518, batch acc 0.1130
14:35:10.861   Training iter 300, batch loss 0.4518, batch acc 0.1074
14:35:11.387   Training iter 350, batch loss 0.4516, batch acc 0.1186
14:35:11.908   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:35:12.436   Training iter 450, batch loss 0.4518, batch acc 0.1064
14:35:12.981   Training iter 500, batch loss 0.4517, batch acc 0.1112
14:35:13.518   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:35:14.050   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:35:14.052 Training @ 433 epoch...
14:35:14.586   Training iter 50, batch loss 0.4518, batch acc 0.1092
14:35:15.118   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:35:15.650   Training iter 150, batch loss 0.4517, batch acc 0.1164
14:35:16.192   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:35:16.716   Training iter 250, batch loss 0.4518, batch acc 0.1112
14:35:17.242   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:35:17.760   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:35:18.276   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:35:18.790   Training iter 450, batch loss 0.4517, batch acc 0.1134
14:35:19.294   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:35:19.799   Training iter 550, batch loss 0.4517, batch acc 0.1120
14:35:20.302   Training iter 600, batch loss 0.4519, batch acc 0.1072
14:35:20.304 Training @ 434 epoch...
14:35:20.820   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:35:21.331   Training iter 100, batch loss 0.4517, batch acc 0.1094
14:35:21.802   Training iter 150, batch loss 0.4518, batch acc 0.1072
14:35:22.267   Training iter 200, batch loss 0.4517, batch acc 0.1168
14:35:22.725   Training iter 250, batch loss 0.4517, batch acc 0.1168
14:35:23.225   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:35:23.740   Training iter 350, batch loss 0.4518, batch acc 0.1056
14:35:24.260   Training iter 400, batch loss 0.4517, batch acc 0.1178
14:35:24.778   Training iter 450, batch loss 0.4518, batch acc 0.1122
14:35:25.318   Training iter 500, batch loss 0.4518, batch acc 0.1088
14:35:25.847   Training iter 550, batch loss 0.4517, batch acc 0.1172
14:35:26.366   Training iter 600, batch loss 0.4518, batch acc 0.1064
14:35:26.368 Training @ 435 epoch...
14:35:26.899   Training iter 50, batch loss 0.4518, batch acc 0.1038
14:35:27.426   Training iter 100, batch loss 0.4518, batch acc 0.1188
14:35:27.946   Training iter 150, batch loss 0.4519, batch acc 0.1020
14:35:28.456   Training iter 200, batch loss 0.4518, batch acc 0.1066
14:35:28.971   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:35:29.505   Training iter 300, batch loss 0.4517, batch acc 0.1166
14:35:30.028   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:35:30.560   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:35:31.117   Training iter 450, batch loss 0.4517, batch acc 0.1126
14:35:31.655   Training iter 500, batch loss 0.4517, batch acc 0.1204
14:35:32.179   Training iter 550, batch loss 0.4517, batch acc 0.1126
14:35:32.718   Training iter 600, batch loss 0.4517, batch acc 0.1182
14:35:32.720 Testing @ 435 epoch...
14:35:32.761     Testing, total mean loss 0.45174, total acc 0.11350
14:35:32.761 Training @ 436 epoch...
14:35:33.300   Training iter 50, batch loss 0.4518, batch acc 0.1132
14:35:33.838   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:35:34.372   Training iter 150, batch loss 0.4519, batch acc 0.1140
14:35:34.915   Training iter 200, batch loss 0.4517, batch acc 0.1174
14:35:35.454   Training iter 250, batch loss 0.4517, batch acc 0.1138
14:35:35.978   Training iter 300, batch loss 0.4517, batch acc 0.1148
14:35:36.525   Training iter 350, batch loss 0.4519, batch acc 0.1022
14:35:37.057   Training iter 400, batch loss 0.4517, batch acc 0.1150
14:35:37.573   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:35:38.107   Training iter 500, batch loss 0.4517, batch acc 0.1168
14:35:38.721   Training iter 550, batch loss 0.4518, batch acc 0.1078
14:35:39.234   Training iter 600, batch loss 0.4518, batch acc 0.1074
14:35:39.235 Training @ 437 epoch...
14:35:39.771   Training iter 50, batch loss 0.4518, batch acc 0.1076
14:35:40.388   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:35:40.916   Training iter 150, batch loss 0.4517, batch acc 0.1134
14:35:41.461   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:35:42.013   Training iter 250, batch loss 0.4518, batch acc 0.1132
14:35:42.552   Training iter 300, batch loss 0.4518, batch acc 0.1146
14:35:43.126   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:35:43.693   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:35:44.262   Training iter 450, batch loss 0.4517, batch acc 0.1122
14:35:44.828   Training iter 500, batch loss 0.4517, batch acc 0.1150
14:35:45.359   Training iter 550, batch loss 0.4518, batch acc 0.1076
14:35:45.867   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:35:45.869 Training @ 438 epoch...
14:35:46.372   Training iter 50, batch loss 0.4517, batch acc 0.1132
14:35:46.888   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:35:47.419   Training iter 150, batch loss 0.4517, batch acc 0.1136
14:35:47.956   Training iter 200, batch loss 0.4517, batch acc 0.1194
14:35:48.471   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:35:48.981   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:35:49.466   Training iter 350, batch loss 0.4517, batch acc 0.1134
14:35:49.975   Training iter 400, batch loss 0.4518, batch acc 0.1100
14:35:50.485   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:35:50.972   Training iter 500, batch loss 0.4518, batch acc 0.1066
14:35:51.441   Training iter 550, batch loss 0.4518, batch acc 0.1110
14:35:51.910   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:35:51.912 Training @ 439 epoch...
14:35:52.392   Training iter 50, batch loss 0.4517, batch acc 0.1124
14:35:52.869   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:35:53.352   Training iter 150, batch loss 0.4518, batch acc 0.1104
14:35:53.822   Training iter 200, batch loss 0.4518, batch acc 0.1142
14:35:54.283   Training iter 250, batch loss 0.4518, batch acc 0.1076
14:35:54.739   Training iter 300, batch loss 0.4517, batch acc 0.1148
14:35:55.202   Training iter 350, batch loss 0.4517, batch acc 0.1086
14:35:55.664   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:35:56.141   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:35:56.602   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:35:57.079   Training iter 550, batch loss 0.4517, batch acc 0.1168
14:35:57.556   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:35:57.558 Training @ 440 epoch...
14:35:58.044   Training iter 50, batch loss 0.4519, batch acc 0.1006
14:35:58.527   Training iter 100, batch loss 0.4517, batch acc 0.1148
14:35:59.008   Training iter 150, batch loss 0.4517, batch acc 0.1118
14:35:59.560   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:36:00.109   Training iter 250, batch loss 0.4518, batch acc 0.1090
14:36:00.674   Training iter 300, batch loss 0.4517, batch acc 0.1166
14:36:01.154   Training iter 350, batch loss 0.4517, batch acc 0.1174
14:36:01.656   Training iter 400, batch loss 0.4517, batch acc 0.1190
14:36:02.176   Training iter 450, batch loss 0.4517, batch acc 0.1156
14:36:02.717   Training iter 500, batch loss 0.4518, batch acc 0.1076
14:36:03.263   Training iter 550, batch loss 0.4518, batch acc 0.1084
14:36:03.771   Training iter 600, batch loss 0.4517, batch acc 0.1190
14:36:03.773 Testing @ 440 epoch...
14:36:03.812     Testing, total mean loss 0.45174, total acc 0.11350
14:36:03.812 Training @ 441 epoch...
14:36:04.305   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:36:04.785   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:36:05.265   Training iter 150, batch loss 0.4518, batch acc 0.1100
14:36:05.744   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:36:06.229   Training iter 250, batch loss 0.4517, batch acc 0.1086
14:36:06.719   Training iter 300, batch loss 0.4517, batch acc 0.1166
14:36:07.235   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:36:07.743   Training iter 400, batch loss 0.4518, batch acc 0.1144
14:36:08.243   Training iter 450, batch loss 0.4518, batch acc 0.1108
14:36:08.739   Training iter 500, batch loss 0.4518, batch acc 0.1122
14:36:09.223   Training iter 550, batch loss 0.4517, batch acc 0.1164
14:36:09.708   Training iter 600, batch loss 0.4517, batch acc 0.1114
14:36:09.710 Training @ 442 epoch...
14:36:10.205   Training iter 50, batch loss 0.4517, batch acc 0.1162
14:36:10.692   Training iter 100, batch loss 0.4518, batch acc 0.1058
14:36:11.173   Training iter 150, batch loss 0.4518, batch acc 0.1128
14:36:11.658   Training iter 200, batch loss 0.4517, batch acc 0.1180
14:36:12.089   Training iter 250, batch loss 0.4517, batch acc 0.1140
14:36:12.544   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:36:13.002   Training iter 350, batch loss 0.4518, batch acc 0.1144
14:36:13.455   Training iter 400, batch loss 0.4519, batch acc 0.1080
14:36:13.902   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:36:14.361   Training iter 500, batch loss 0.4517, batch acc 0.1098
14:36:14.823   Training iter 550, batch loss 0.4518, batch acc 0.1136
14:36:15.271   Training iter 600, batch loss 0.4517, batch acc 0.1118
14:36:15.273 Training @ 443 epoch...
14:36:15.753   Training iter 50, batch loss 0.4517, batch acc 0.1138
14:36:16.242   Training iter 100, batch loss 0.4518, batch acc 0.1096
14:36:16.725   Training iter 150, batch loss 0.4519, batch acc 0.1102
14:36:17.210   Training iter 200, batch loss 0.4517, batch acc 0.1104
14:36:17.691   Training iter 250, batch loss 0.4517, batch acc 0.1152
14:36:18.190   Training iter 300, batch loss 0.4517, batch acc 0.1154
14:36:18.698   Training iter 350, batch loss 0.4517, batch acc 0.1078
14:36:19.210   Training iter 400, batch loss 0.4518, batch acc 0.1068
14:36:19.729   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:36:20.242   Training iter 500, batch loss 0.4517, batch acc 0.1160
14:36:20.761   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:36:21.272   Training iter 600, batch loss 0.4518, batch acc 0.1114
14:36:21.274 Training @ 444 epoch...
14:36:21.791   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:36:22.316   Training iter 100, batch loss 0.4517, batch acc 0.1120
14:36:22.837   Training iter 150, batch loss 0.4518, batch acc 0.1080
14:36:23.351   Training iter 200, batch loss 0.4517, batch acc 0.1158
14:36:23.869   Training iter 250, batch loss 0.4519, batch acc 0.1072
14:36:24.371   Training iter 300, batch loss 0.4518, batch acc 0.1086
14:36:24.886   Training iter 350, batch loss 0.4516, batch acc 0.1156
14:36:25.430   Training iter 400, batch loss 0.4518, batch acc 0.1118
14:36:25.957   Training iter 450, batch loss 0.4517, batch acc 0.1204
14:36:26.483   Training iter 500, batch loss 0.4518, batch acc 0.1058
14:36:27.001   Training iter 550, batch loss 0.4518, batch acc 0.1100
14:36:27.534   Training iter 600, batch loss 0.4516, batch acc 0.1210
14:36:27.536 Training @ 445 epoch...
14:36:28.069   Training iter 50, batch loss 0.4518, batch acc 0.1144
14:36:28.600   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:36:29.133   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:36:29.654   Training iter 200, batch loss 0.4518, batch acc 0.1170
14:36:30.192   Training iter 250, batch loss 0.4516, batch acc 0.1156
14:36:30.736   Training iter 300, batch loss 0.4519, batch acc 0.1024
14:36:31.281   Training iter 350, batch loss 0.4518, batch acc 0.1128
14:36:31.786   Training iter 400, batch loss 0.4517, batch acc 0.1162
14:36:32.305   Training iter 450, batch loss 0.4518, batch acc 0.1042
14:36:32.818   Training iter 500, batch loss 0.4518, batch acc 0.1142
14:36:33.332   Training iter 550, batch loss 0.4517, batch acc 0.1124
14:36:33.842   Training iter 600, batch loss 0.4517, batch acc 0.1142
14:36:33.844 Testing @ 445 epoch...
14:36:33.883     Testing, total mean loss 0.45174, total acc 0.11350
14:36:33.883 Training @ 446 epoch...
14:36:34.388   Training iter 50, batch loss 0.4518, batch acc 0.1120
14:36:34.902   Training iter 100, batch loss 0.4519, batch acc 0.1056
14:36:35.418   Training iter 150, batch loss 0.4518, batch acc 0.1092
14:36:35.931   Training iter 200, batch loss 0.4517, batch acc 0.1162
14:36:36.449   Training iter 250, batch loss 0.4518, batch acc 0.1092
14:36:36.964   Training iter 300, batch loss 0.4517, batch acc 0.1174
14:36:37.502   Training iter 350, batch loss 0.4517, batch acc 0.1162
14:36:38.038   Training iter 400, batch loss 0.4518, batch acc 0.1068
14:36:38.562   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:36:39.087   Training iter 500, batch loss 0.4517, batch acc 0.1176
14:36:39.607   Training iter 550, batch loss 0.4517, batch acc 0.1186
14:36:40.148   Training iter 600, batch loss 0.4518, batch acc 0.1096
14:36:40.150 Training @ 447 epoch...
14:36:40.738   Training iter 50, batch loss 0.4517, batch acc 0.1178
14:36:41.325   Training iter 100, batch loss 0.4518, batch acc 0.1110
14:36:41.932   Training iter 150, batch loss 0.4518, batch acc 0.1074
14:36:42.508   Training iter 200, batch loss 0.4517, batch acc 0.1146
14:36:43.069   Training iter 250, batch loss 0.4519, batch acc 0.1082
14:36:43.604   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:36:44.127   Training iter 350, batch loss 0.4517, batch acc 0.1192
14:36:44.651   Training iter 400, batch loss 0.4518, batch acc 0.1140
14:36:45.185   Training iter 450, batch loss 0.4517, batch acc 0.1102
14:36:45.715   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:36:46.257   Training iter 550, batch loss 0.4518, batch acc 0.1078
14:36:46.782   Training iter 600, batch loss 0.4517, batch acc 0.1194
14:36:46.784 Training @ 448 epoch...
14:36:47.314   Training iter 50, batch loss 0.4517, batch acc 0.1160
14:36:47.811   Training iter 100, batch loss 0.4518, batch acc 0.1138
14:36:48.321   Training iter 150, batch loss 0.4517, batch acc 0.1118
14:36:48.836   Training iter 200, batch loss 0.4518, batch acc 0.1066
14:36:49.333   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:36:49.807   Training iter 300, batch loss 0.4517, batch acc 0.1138
14:36:50.275   Training iter 350, batch loss 0.4518, batch acc 0.1064
14:36:50.748   Training iter 400, batch loss 0.4518, batch acc 0.1140
14:36:51.259   Training iter 450, batch loss 0.4518, batch acc 0.1082
14:36:51.773   Training iter 500, batch loss 0.4517, batch acc 0.1128
14:36:52.291   Training iter 550, batch loss 0.4517, batch acc 0.1172
14:36:52.821   Training iter 600, batch loss 0.4517, batch acc 0.1180
14:36:52.822 Training @ 449 epoch...
14:36:53.359   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:36:53.874   Training iter 100, batch loss 0.4516, batch acc 0.1158
14:36:54.388   Training iter 150, batch loss 0.4518, batch acc 0.1142
14:36:54.918   Training iter 200, batch loss 0.4517, batch acc 0.1152
14:36:55.453   Training iter 250, batch loss 0.4518, batch acc 0.1130
14:36:55.986   Training iter 300, batch loss 0.4518, batch acc 0.1106
14:36:56.511   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:36:57.026   Training iter 400, batch loss 0.4517, batch acc 0.1140
14:36:57.546   Training iter 450, batch loss 0.4517, batch acc 0.1142
14:36:58.070   Training iter 500, batch loss 0.4517, batch acc 0.1084
14:36:58.607   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:36:59.201   Training iter 600, batch loss 0.4518, batch acc 0.1116
14:36:59.203 Training @ 450 epoch...
14:36:59.774   Training iter 50, batch loss 0.4519, batch acc 0.1066
14:37:00.305   Training iter 100, batch loss 0.4518, batch acc 0.1134
14:37:00.829   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:37:01.350   Training iter 200, batch loss 0.4518, batch acc 0.1124
14:37:01.868   Training iter 250, batch loss 0.4516, batch acc 0.1278
14:37:02.419   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:37:02.951   Training iter 350, batch loss 0.4518, batch acc 0.1092
14:37:03.452   Training iter 400, batch loss 0.4518, batch acc 0.1094
14:37:03.957   Training iter 450, batch loss 0.4517, batch acc 0.1132
14:37:04.466   Training iter 500, batch loss 0.4518, batch acc 0.1106
14:37:04.992   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:37:05.499   Training iter 600, batch loss 0.4517, batch acc 0.1080
14:37:05.501 Testing @ 450 epoch...
14:37:05.539     Testing, total mean loss 0.45174, total acc 0.11350
14:37:05.539 Training @ 451 epoch...
14:37:06.013   Training iter 50, batch loss 0.4516, batch acc 0.1194
14:37:06.512   Training iter 100, batch loss 0.4518, batch acc 0.1098
14:37:07.058   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:37:07.620   Training iter 200, batch loss 0.4518, batch acc 0.1082
14:37:08.147   Training iter 250, batch loss 0.4517, batch acc 0.1136
14:37:08.685   Training iter 300, batch loss 0.4518, batch acc 0.1092
14:37:09.220   Training iter 350, batch loss 0.4517, batch acc 0.1122
14:37:09.748   Training iter 400, batch loss 0.4518, batch acc 0.1142
14:37:10.287   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:37:10.829   Training iter 500, batch loss 0.4518, batch acc 0.1106
14:37:11.372   Training iter 550, batch loss 0.4517, batch acc 0.1146
14:37:11.903   Training iter 600, batch loss 0.4517, batch acc 0.1154
14:37:11.904 Training @ 452 epoch...
14:37:12.437   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:37:12.964   Training iter 100, batch loss 0.4517, batch acc 0.1162
14:37:13.488   Training iter 150, batch loss 0.4518, batch acc 0.1078
14:37:13.998   Training iter 200, batch loss 0.4518, batch acc 0.1126
14:37:14.542   Training iter 250, batch loss 0.4518, batch acc 0.1036
14:37:15.065   Training iter 300, batch loss 0.4517, batch acc 0.1142
14:37:15.590   Training iter 350, batch loss 0.4517, batch acc 0.1164
14:37:16.108   Training iter 400, batch loss 0.4519, batch acc 0.1092
14:37:16.623   Training iter 450, batch loss 0.4518, batch acc 0.1138
14:37:17.124   Training iter 500, batch loss 0.4517, batch acc 0.1186
14:37:17.625   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:37:18.149   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:37:18.151 Training @ 453 epoch...
14:37:18.682   Training iter 50, batch loss 0.4517, batch acc 0.1138
14:37:19.189   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:37:19.692   Training iter 150, batch loss 0.4518, batch acc 0.1102
14:37:20.215   Training iter 200, batch loss 0.4518, batch acc 0.1132
14:37:20.734   Training iter 250, batch loss 0.4517, batch acc 0.1190
14:37:21.244   Training iter 300, batch loss 0.4517, batch acc 0.1150
14:37:21.741   Training iter 350, batch loss 0.4518, batch acc 0.1086
14:37:22.247   Training iter 400, batch loss 0.4516, batch acc 0.1174
14:37:22.783   Training iter 450, batch loss 0.4518, batch acc 0.1134
14:37:23.301   Training iter 500, batch loss 0.4518, batch acc 0.1084
14:37:23.820   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:37:24.333   Training iter 600, batch loss 0.4518, batch acc 0.1066
14:37:24.335 Training @ 454 epoch...
14:37:24.861   Training iter 50, batch loss 0.4517, batch acc 0.1120
14:37:25.403   Training iter 100, batch loss 0.4516, batch acc 0.1182
14:37:25.930   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:37:26.454   Training iter 200, batch loss 0.4517, batch acc 0.1162
14:37:26.964   Training iter 250, batch loss 0.4517, batch acc 0.1122
14:37:27.482   Training iter 300, batch loss 0.4518, batch acc 0.1080
14:37:28.006   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:37:28.538   Training iter 400, batch loss 0.4517, batch acc 0.1108
14:37:29.075   Training iter 450, batch loss 0.4518, batch acc 0.1024
14:37:29.627   Training iter 500, batch loss 0.4518, batch acc 0.1152
14:37:30.178   Training iter 550, batch loss 0.4518, batch acc 0.1142
14:37:30.739   Training iter 600, batch loss 0.4518, batch acc 0.1138
14:37:30.741 Training @ 455 epoch...
14:37:31.296   Training iter 50, batch loss 0.4518, batch acc 0.1028
14:37:31.831   Training iter 100, batch loss 0.4518, batch acc 0.1124
14:37:32.372   Training iter 150, batch loss 0.4518, batch acc 0.1142
14:37:32.949   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:37:33.535   Training iter 250, batch loss 0.4517, batch acc 0.1170
14:37:34.104   Training iter 300, batch loss 0.4518, batch acc 0.1074
14:37:34.675   Training iter 350, batch loss 0.4517, batch acc 0.1160
14:37:35.271   Training iter 400, batch loss 0.4517, batch acc 0.1194
14:37:35.828   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:37:36.376   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:37:36.908   Training iter 550, batch loss 0.4518, batch acc 0.1010
14:37:37.417   Training iter 600, batch loss 0.4518, batch acc 0.1148
14:37:37.418 Testing @ 455 epoch...
14:37:37.457     Testing, total mean loss 0.45174, total acc 0.11350
14:37:37.457 Training @ 456 epoch...
14:37:37.962   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:37:38.459   Training iter 100, batch loss 0.4518, batch acc 0.1116
14:37:38.957   Training iter 150, batch loss 0.4517, batch acc 0.1138
14:37:39.456   Training iter 200, batch loss 0.4519, batch acc 0.1082
14:37:39.945   Training iter 250, batch loss 0.4518, batch acc 0.1070
14:37:40.433   Training iter 300, batch loss 0.4518, batch acc 0.1080
14:37:40.922   Training iter 350, batch loss 0.4517, batch acc 0.1126
14:37:41.411   Training iter 400, batch loss 0.4516, batch acc 0.1138
14:37:41.909   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:37:42.399   Training iter 500, batch loss 0.4517, batch acc 0.1216
14:37:42.891   Training iter 550, batch loss 0.4517, batch acc 0.1166
14:37:43.385   Training iter 600, batch loss 0.4517, batch acc 0.1134
14:37:43.387 Training @ 457 epoch...
14:37:43.879   Training iter 50, batch loss 0.4518, batch acc 0.1128
14:37:44.361   Training iter 100, batch loss 0.4518, batch acc 0.1104
14:37:44.860   Training iter 150, batch loss 0.4518, batch acc 0.1110
14:37:45.360   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:37:45.876   Training iter 250, batch loss 0.4518, batch acc 0.1104
14:37:46.413   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:37:46.943   Training iter 350, batch loss 0.4516, batch acc 0.1172
14:37:47.484   Training iter 400, batch loss 0.4517, batch acc 0.1184
14:37:48.033   Training iter 450, batch loss 0.4518, batch acc 0.1120
14:37:48.573   Training iter 500, batch loss 0.4517, batch acc 0.1182
14:37:49.092   Training iter 550, batch loss 0.4519, batch acc 0.1040
14:37:49.605   Training iter 600, batch loss 0.4517, batch acc 0.1152
14:37:49.606 Training @ 458 epoch...
14:37:50.128   Training iter 50, batch loss 0.4519, batch acc 0.1058
14:37:50.652   Training iter 100, batch loss 0.4518, batch acc 0.1080
14:37:51.168   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:37:51.676   Training iter 200, batch loss 0.4518, batch acc 0.1098
14:37:52.184   Training iter 250, batch loss 0.4516, batch acc 0.1230
14:37:52.660   Training iter 300, batch loss 0.4519, batch acc 0.1020
14:37:53.158   Training iter 350, batch loss 0.4518, batch acc 0.1104
14:37:53.666   Training iter 400, batch loss 0.4517, batch acc 0.1132
14:37:54.159   Training iter 450, batch loss 0.4517, batch acc 0.1196
14:37:54.657   Training iter 500, batch loss 0.4516, batch acc 0.1192
14:37:55.162   Training iter 550, batch loss 0.4517, batch acc 0.1146
14:37:55.666   Training iter 600, batch loss 0.4518, batch acc 0.1100
14:37:55.668 Training @ 459 epoch...
14:37:56.172   Training iter 50, batch loss 0.4516, batch acc 0.1240
14:37:56.671   Training iter 100, batch loss 0.4518, batch acc 0.1114
14:37:57.169   Training iter 150, batch loss 0.4517, batch acc 0.1162
14:37:57.675   Training iter 200, batch loss 0.4518, batch acc 0.1128
14:37:58.191   Training iter 250, batch loss 0.4518, batch acc 0.1064
14:37:58.716   Training iter 300, batch loss 0.4519, batch acc 0.1008
14:37:59.213   Training iter 350, batch loss 0.4518, batch acc 0.1106
14:37:59.724   Training iter 400, batch loss 0.4517, batch acc 0.1178
14:38:00.275   Training iter 450, batch loss 0.4517, batch acc 0.1116
14:38:00.793   Training iter 500, batch loss 0.4517, batch acc 0.1146
14:38:01.317   Training iter 550, batch loss 0.4517, batch acc 0.1158
14:38:01.879   Training iter 600, batch loss 0.4518, batch acc 0.1064
14:38:01.880 Training @ 460 epoch...
14:38:02.465   Training iter 50, batch loss 0.4518, batch acc 0.1142
14:38:03.073   Training iter 100, batch loss 0.4517, batch acc 0.1154
14:38:03.650   Training iter 150, batch loss 0.4517, batch acc 0.1082
14:38:04.192   Training iter 200, batch loss 0.4518, batch acc 0.1160
14:38:04.739   Training iter 250, batch loss 0.4517, batch acc 0.1178
14:38:05.275   Training iter 300, batch loss 0.4518, batch acc 0.1072
14:38:05.808   Training iter 350, batch loss 0.4518, batch acc 0.1076
14:38:06.349   Training iter 400, batch loss 0.4518, batch acc 0.1102
14:38:06.900   Training iter 450, batch loss 0.4517, batch acc 0.1136
14:38:07.430   Training iter 500, batch loss 0.4518, batch acc 0.1136
14:38:07.949   Training iter 550, batch loss 0.4518, batch acc 0.1082
14:38:08.464   Training iter 600, batch loss 0.4517, batch acc 0.1164
14:38:08.466 Testing @ 460 epoch...
14:38:08.504     Testing, total mean loss 0.45174, total acc 0.11350
14:38:08.504 Training @ 461 epoch...
14:38:09.008   Training iter 50, batch loss 0.4518, batch acc 0.1070
14:38:09.513   Training iter 100, batch loss 0.4518, batch acc 0.1082
14:38:10.025   Training iter 150, batch loss 0.4517, batch acc 0.1170
14:38:10.543   Training iter 200, batch loss 0.4518, batch acc 0.1140
14:38:11.050   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:38:11.543   Training iter 300, batch loss 0.4516, batch acc 0.1204
14:38:12.051   Training iter 350, batch loss 0.4518, batch acc 0.1098
14:38:12.561   Training iter 400, batch loss 0.4517, batch acc 0.1168
14:38:13.082   Training iter 450, batch loss 0.4517, batch acc 0.1160
14:38:13.606   Training iter 500, batch loss 0.4518, batch acc 0.1110
14:38:14.126   Training iter 550, batch loss 0.4518, batch acc 0.1046
14:38:14.700   Training iter 600, batch loss 0.4518, batch acc 0.1140
14:38:14.702 Training @ 462 epoch...
14:38:15.347   Training iter 50, batch loss 0.4519, batch acc 0.1048
14:38:15.980   Training iter 100, batch loss 0.4517, batch acc 0.1160
14:38:16.596   Training iter 150, batch loss 0.4516, batch acc 0.1202
14:38:17.131   Training iter 200, batch loss 0.4517, batch acc 0.1124
14:38:17.663   Training iter 250, batch loss 0.4517, batch acc 0.1178
14:38:18.196   Training iter 300, batch loss 0.4518, batch acc 0.1124
14:38:18.725   Training iter 350, batch loss 0.4518, batch acc 0.1088
14:38:19.209   Training iter 400, batch loss 0.4517, batch acc 0.1134
14:38:19.730   Training iter 450, batch loss 0.4518, batch acc 0.1034
14:38:20.254   Training iter 500, batch loss 0.4517, batch acc 0.1192
14:38:20.767   Training iter 550, batch loss 0.4519, batch acc 0.1060
14:38:21.272   Training iter 600, batch loss 0.4517, batch acc 0.1140
14:38:21.273 Training @ 463 epoch...
14:38:21.780   Training iter 50, batch loss 0.4518, batch acc 0.1136
14:38:22.302   Training iter 100, batch loss 0.4517, batch acc 0.1188
14:38:22.817   Training iter 150, batch loss 0.4516, batch acc 0.1168
14:38:23.339   Training iter 200, batch loss 0.4517, batch acc 0.1096
14:38:23.855   Training iter 250, batch loss 0.4519, batch acc 0.1042
14:38:24.363   Training iter 300, batch loss 0.4518, batch acc 0.1120
14:38:24.881   Training iter 350, batch loss 0.4517, batch acc 0.1176
14:38:25.405   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:38:25.924   Training iter 450, batch loss 0.4518, batch acc 0.1100
14:38:26.444   Training iter 500, batch loss 0.4517, batch acc 0.1120
14:38:26.945   Training iter 550, batch loss 0.4518, batch acc 0.1130
14:38:27.465   Training iter 600, batch loss 0.4518, batch acc 0.1094
14:38:27.466 Training @ 464 epoch...
14:38:28.168   Training iter 50, batch loss 0.4518, batch acc 0.1060
14:38:28.857   Training iter 100, batch loss 0.4518, batch acc 0.1132
14:38:29.517   Training iter 150, batch loss 0.4518, batch acc 0.1062
14:38:30.018   Training iter 200, batch loss 0.4517, batch acc 0.1094
14:38:30.556   Training iter 250, batch loss 0.4517, batch acc 0.1120
14:38:31.139   Training iter 300, batch loss 0.4517, batch acc 0.1162
14:38:31.670   Training iter 350, batch loss 0.4517, batch acc 0.1148
14:38:32.208   Training iter 400, batch loss 0.4519, batch acc 0.1078
14:38:32.719   Training iter 450, batch loss 0.4517, batch acc 0.1192
14:38:33.218   Training iter 500, batch loss 0.4518, batch acc 0.1152
14:38:33.705   Training iter 550, batch loss 0.4517, batch acc 0.1132
14:38:34.209   Training iter 600, batch loss 0.4518, batch acc 0.1152
14:38:34.210 Training @ 465 epoch...
14:38:34.719   Training iter 50, batch loss 0.4517, batch acc 0.1100
14:38:35.221   Training iter 100, batch loss 0.4517, batch acc 0.1158
14:38:35.725   Training iter 150, batch loss 0.4517, batch acc 0.1136
14:38:36.235   Training iter 200, batch loss 0.4518, batch acc 0.1072
14:38:36.744   Training iter 250, batch loss 0.4517, batch acc 0.1166
14:38:37.251   Training iter 300, batch loss 0.4518, batch acc 0.1066
14:38:37.756   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:38:38.273   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:38:38.785   Training iter 450, batch loss 0.4517, batch acc 0.1190
14:38:39.287   Training iter 500, batch loss 0.4517, batch acc 0.1158
14:38:39.798   Training iter 550, batch loss 0.4519, batch acc 0.1074
14:38:40.318   Training iter 600, batch loss 0.4518, batch acc 0.1120
14:38:40.320 Testing @ 465 epoch...
14:38:40.359     Testing, total mean loss 0.45174, total acc 0.11350
14:38:40.359 Training @ 466 epoch...
14:38:40.876   Training iter 50, batch loss 0.4518, batch acc 0.1088
14:38:41.390   Training iter 100, batch loss 0.4517, batch acc 0.1172
14:38:41.897   Training iter 150, batch loss 0.4518, batch acc 0.1080
14:38:42.428   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:38:42.959   Training iter 250, batch loss 0.4518, batch acc 0.1140
14:38:43.475   Training iter 300, batch loss 0.4518, batch acc 0.1088
14:38:43.972   Training iter 350, batch loss 0.4517, batch acc 0.1098
14:38:44.479   Training iter 400, batch loss 0.4517, batch acc 0.1198
14:38:44.984   Training iter 450, batch loss 0.4518, batch acc 0.1062
14:38:45.496   Training iter 500, batch loss 0.4517, batch acc 0.1118
14:38:45.989   Training iter 550, batch loss 0.4517, batch acc 0.1162
14:38:46.490   Training iter 600, batch loss 0.4517, batch acc 0.1124
14:38:46.492 Training @ 467 epoch...
14:38:46.988   Training iter 50, batch loss 0.4518, batch acc 0.1120
14:38:47.477   Training iter 100, batch loss 0.4517, batch acc 0.1122
14:38:47.978   Training iter 150, batch loss 0.4518, batch acc 0.1126
14:38:48.482   Training iter 200, batch loss 0.4517, batch acc 0.1118
14:38:48.971   Training iter 250, batch loss 0.4518, batch acc 0.1116
14:38:49.466   Training iter 300, batch loss 0.4517, batch acc 0.1156
14:38:49.954   Training iter 350, batch loss 0.4518, batch acc 0.1070
14:38:50.464   Training iter 400, batch loss 0.4517, batch acc 0.1176
14:38:50.955   Training iter 450, batch loss 0.4517, batch acc 0.1138
14:38:51.452   Training iter 500, batch loss 0.4516, batch acc 0.1146
14:38:51.943   Training iter 550, batch loss 0.4518, batch acc 0.1052
14:38:52.442   Training iter 600, batch loss 0.4518, batch acc 0.1144
14:38:52.444 Training @ 468 epoch...
14:38:52.964   Training iter 50, batch loss 0.4517, batch acc 0.1186
14:38:53.472   Training iter 100, batch loss 0.4517, batch acc 0.1086
14:38:53.992   Training iter 150, batch loss 0.4519, batch acc 0.1064
14:38:54.513   Training iter 200, batch loss 0.4518, batch acc 0.1108
14:38:55.040   Training iter 250, batch loss 0.4517, batch acc 0.1188
14:38:55.568   Training iter 300, batch loss 0.4517, batch acc 0.1166
14:38:56.088   Training iter 350, batch loss 0.4517, batch acc 0.1100
14:38:56.600   Training iter 400, batch loss 0.4517, batch acc 0.1156
14:38:57.118   Training iter 450, batch loss 0.4518, batch acc 0.1056
14:38:57.642   Training iter 500, batch loss 0.4517, batch acc 0.1128
14:38:58.156   Training iter 550, batch loss 0.4518, batch acc 0.1138
14:38:58.682   Training iter 600, batch loss 0.4519, batch acc 0.1108
14:38:58.684 Training @ 469 epoch...
14:38:59.203   Training iter 50, batch loss 0.4517, batch acc 0.1200
14:38:59.736   Training iter 100, batch loss 0.4518, batch acc 0.1114
14:39:00.269   Training iter 150, batch loss 0.4517, batch acc 0.1172
14:39:00.800   Training iter 200, batch loss 0.4517, batch acc 0.1156
14:39:01.326   Training iter 250, batch loss 0.4517, batch acc 0.1146
14:39:01.863   Training iter 300, batch loss 0.4518, batch acc 0.1096
14:39:02.408   Training iter 350, batch loss 0.4517, batch acc 0.1162
14:39:02.955   Training iter 400, batch loss 0.4519, batch acc 0.1010
14:39:03.506   Training iter 450, batch loss 0.4518, batch acc 0.1092
14:39:04.017   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:39:04.518   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:39:05.056   Training iter 600, batch loss 0.4517, batch acc 0.1102
14:39:05.058 Training @ 470 epoch...
14:39:05.599   Training iter 50, batch loss 0.4517, batch acc 0.1164
14:39:06.143   Training iter 100, batch loss 0.4517, batch acc 0.1180
14:39:06.676   Training iter 150, batch loss 0.4517, batch acc 0.1152
14:39:07.226   Training iter 200, batch loss 0.4518, batch acc 0.1124
14:39:07.769   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:39:08.302   Training iter 300, batch loss 0.4517, batch acc 0.1132
14:39:08.841   Training iter 350, batch loss 0.4518, batch acc 0.1126
14:39:09.364   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:39:09.882   Training iter 450, batch loss 0.4517, batch acc 0.1158
14:39:10.453   Training iter 500, batch loss 0.4518, batch acc 0.1100
14:39:10.969   Training iter 550, batch loss 0.4518, batch acc 0.1082
14:39:11.488   Training iter 600, batch loss 0.4518, batch acc 0.1056
14:39:11.490 Testing @ 470 epoch...
14:39:11.530     Testing, total mean loss 0.45174, total acc 0.11350
14:39:11.530 Training @ 471 epoch...
14:39:12.063   Training iter 50, batch loss 0.4517, batch acc 0.1106
14:39:12.602   Training iter 100, batch loss 0.4518, batch acc 0.1158
14:39:13.104   Training iter 150, batch loss 0.4518, batch acc 0.1074
14:39:13.598   Training iter 200, batch loss 0.4517, batch acc 0.1152
14:39:14.082   Training iter 250, batch loss 0.4518, batch acc 0.1124
14:39:14.573   Training iter 300, batch loss 0.4517, batch acc 0.1112
14:39:15.056   Training iter 350, batch loss 0.4518, batch acc 0.1078
14:39:15.542   Training iter 400, batch loss 0.4518, batch acc 0.1090
14:39:16.030   Training iter 450, batch loss 0.4518, batch acc 0.1086
14:39:16.508   Training iter 500, batch loss 0.4518, batch acc 0.1114
14:39:16.984   Training iter 550, batch loss 0.4517, batch acc 0.1224
14:39:17.459   Training iter 600, batch loss 0.4517, batch acc 0.1166
14:39:17.461 Training @ 472 epoch...
14:39:17.960   Training iter 50, batch loss 0.4518, batch acc 0.1128
14:39:18.468   Training iter 100, batch loss 0.4518, batch acc 0.1000
14:39:18.983   Training iter 150, batch loss 0.4517, batch acc 0.1144
14:39:19.501   Training iter 200, batch loss 0.4517, batch acc 0.1140
14:39:20.020   Training iter 250, batch loss 0.4517, batch acc 0.1210
14:39:20.548   Training iter 300, batch loss 0.4517, batch acc 0.1240
14:39:21.054   Training iter 350, batch loss 0.4518, batch acc 0.1078
14:39:21.553   Training iter 400, batch loss 0.4518, batch acc 0.1066
14:39:22.068   Training iter 450, batch loss 0.4518, batch acc 0.1146
14:39:22.583   Training iter 500, batch loss 0.4517, batch acc 0.1136
14:39:23.121   Training iter 550, batch loss 0.4518, batch acc 0.1112
14:39:23.633   Training iter 600, batch loss 0.4518, batch acc 0.1084
14:39:23.634 Training @ 473 epoch...
14:39:24.148   Training iter 50, batch loss 0.4517, batch acc 0.1136
14:39:24.660   Training iter 100, batch loss 0.4518, batch acc 0.1140
14:39:25.200   Training iter 150, batch loss 0.4516, batch acc 0.1194
14:39:25.906   Training iter 200, batch loss 0.4518, batch acc 0.1052
14:39:26.652   Training iter 250, batch loss 0.4518, batch acc 0.1084
14:39:27.327   Training iter 300, batch loss 0.4517, batch acc 0.1164
14:39:27.882   Training iter 350, batch loss 0.4518, batch acc 0.1062
14:39:28.468   Training iter 400, batch loss 0.4519, batch acc 0.1074
14:39:29.065   Training iter 450, batch loss 0.4517, batch acc 0.1214
14:39:29.648   Training iter 500, batch loss 0.4517, batch acc 0.1126
14:39:30.212   Training iter 550, batch loss 0.4518, batch acc 0.1078
14:39:30.722   Training iter 600, batch loss 0.4517, batch acc 0.1160
14:39:30.724 Training @ 474 epoch...
14:39:31.240   Training iter 50, batch loss 0.4518, batch acc 0.1124
14:39:31.720   Training iter 100, batch loss 0.4517, batch acc 0.1144
14:39:32.220   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:39:32.700   Training iter 200, batch loss 0.4517, batch acc 0.1146
14:39:33.293   Training iter 250, batch loss 0.4517, batch acc 0.1148
14:39:33.894   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:39:34.396   Training iter 350, batch loss 0.4518, batch acc 0.1080
14:39:34.902   Training iter 400, batch loss 0.4518, batch acc 0.1120
14:39:35.422   Training iter 450, batch loss 0.4517, batch acc 0.1122
14:39:35.939   Training iter 500, batch loss 0.4518, batch acc 0.1088
14:39:36.479   Training iter 550, batch loss 0.4517, batch acc 0.1134
14:39:36.998   Training iter 600, batch loss 0.4517, batch acc 0.1146
14:39:37.001 Training @ 475 epoch...
14:39:37.518   Training iter 50, batch loss 0.4517, batch acc 0.1140
14:39:38.038   Training iter 100, batch loss 0.4517, batch acc 0.1110
14:39:38.554   Training iter 150, batch loss 0.4518, batch acc 0.1094
14:39:39.045   Training iter 200, batch loss 0.4517, batch acc 0.1186
14:39:39.545   Training iter 250, batch loss 0.4518, batch acc 0.1044
14:39:40.063   Training iter 300, batch loss 0.4517, batch acc 0.1126
14:39:40.597   Training iter 350, batch loss 0.4518, batch acc 0.1120
14:39:41.135   Training iter 400, batch loss 0.4518, batch acc 0.1096
14:39:41.698   Training iter 450, batch loss 0.4516, batch acc 0.1228
14:39:42.225   Training iter 500, batch loss 0.4518, batch acc 0.1120
14:39:42.726   Training iter 550, batch loss 0.4517, batch acc 0.1128
14:39:43.239   Training iter 600, batch loss 0.4518, batch acc 0.1092
14:39:43.241 Testing @ 475 epoch...
14:39:43.280     Testing, total mean loss 0.45174, total acc 0.11350
14:39:43.280 Training @ 476 epoch...
14:39:43.803   Training iter 50, batch loss 0.4518, batch acc 0.1096
14:39:44.301   Training iter 100, batch loss 0.4518, batch acc 0.1122
14:39:44.801   Training iter 150, batch loss 0.4517, batch acc 0.1148
14:39:45.311   Training iter 200, batch loss 0.4518, batch acc 0.1066
14:39:45.813   Training iter 250, batch loss 0.4517, batch acc 0.1162
14:39:46.329   Training iter 300, batch loss 0.4517, batch acc 0.1110
14:39:46.824   Training iter 350, batch loss 0.4518, batch acc 0.1086
14:39:47.325   Training iter 400, batch loss 0.4518, batch acc 0.1104
14:39:47.841   Training iter 450, batch loss 0.4518, batch acc 0.1112
14:39:48.363   Training iter 500, batch loss 0.4516, batch acc 0.1230
14:39:48.857   Training iter 550, batch loss 0.4517, batch acc 0.1188
14:39:49.351   Training iter 600, batch loss 0.4518, batch acc 0.1060
14:39:49.353 Training @ 477 epoch...
14:39:49.865   Training iter 50, batch loss 0.4518, batch acc 0.1070
14:39:50.383   Training iter 100, batch loss 0.4516, batch acc 0.1188
14:39:50.887   Training iter 150, batch loss 0.4517, batch acc 0.1130
14:39:51.404   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:39:51.920   Training iter 250, batch loss 0.4517, batch acc 0.1142
14:39:52.429   Training iter 300, batch loss 0.4518, batch acc 0.1144
14:39:52.922   Training iter 350, batch loss 0.4517, batch acc 0.1140
14:39:53.449   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:39:53.916   Training iter 450, batch loss 0.4517, batch acc 0.1164
14:39:54.373   Training iter 500, batch loss 0.4518, batch acc 0.1134
14:39:54.832   Training iter 550, batch loss 0.4518, batch acc 0.1086
14:39:55.300   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:39:55.302 Training @ 478 epoch...
14:39:55.761   Training iter 50, batch loss 0.4517, batch acc 0.1128
14:39:56.223   Training iter 100, batch loss 0.4517, batch acc 0.1128
14:39:56.685   Training iter 150, batch loss 0.4518, batch acc 0.1124
14:39:57.162   Training iter 200, batch loss 0.4518, batch acc 0.1102
14:39:57.632   Training iter 250, batch loss 0.4517, batch acc 0.1128
14:39:58.126   Training iter 300, batch loss 0.4517, batch acc 0.1114
14:39:58.606   Training iter 350, batch loss 0.4517, batch acc 0.1182
14:39:59.066   Training iter 400, batch loss 0.4518, batch acc 0.1116
14:39:59.521   Training iter 450, batch loss 0.4518, batch acc 0.1106
14:39:59.982   Training iter 500, batch loss 0.4517, batch acc 0.1150
14:40:00.472   Training iter 550, batch loss 0.4518, batch acc 0.1026
14:40:00.944   Training iter 600, batch loss 0.4517, batch acc 0.1180
14:40:00.945 Training @ 479 epoch...
14:40:01.461   Training iter 50, batch loss 0.4518, batch acc 0.1082
14:40:02.011   Training iter 100, batch loss 0.4518, batch acc 0.1072
14:40:02.536   Training iter 150, batch loss 0.4516, batch acc 0.1242
14:40:03.102   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:40:03.668   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:40:04.234   Training iter 300, batch loss 0.4518, batch acc 0.1122
14:40:04.785   Training iter 350, batch loss 0.4518, batch acc 0.1112
14:40:05.349   Training iter 400, batch loss 0.4518, batch acc 0.1064
14:40:05.882   Training iter 450, batch loss 0.4517, batch acc 0.1168
14:40:06.426   Training iter 500, batch loss 0.4518, batch acc 0.1044
14:40:06.967   Training iter 550, batch loss 0.4517, batch acc 0.1184
14:40:07.485   Training iter 600, batch loss 0.4517, batch acc 0.1166
14:40:07.486 Training @ 480 epoch...
14:40:08.015   Training iter 50, batch loss 0.4518, batch acc 0.1100
14:40:08.566   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:40:09.105   Training iter 150, batch loss 0.4518, batch acc 0.1096
14:40:09.635   Training iter 200, batch loss 0.4517, batch acc 0.1178
14:40:10.168   Training iter 250, batch loss 0.4518, batch acc 0.1096
14:40:10.689   Training iter 300, batch loss 0.4518, batch acc 0.1092
14:40:11.194   Training iter 350, batch loss 0.4518, batch acc 0.1150
14:40:11.691   Training iter 400, batch loss 0.4518, batch acc 0.1094
14:40:12.202   Training iter 450, batch loss 0.4517, batch acc 0.1180
14:40:12.714   Training iter 500, batch loss 0.4517, batch acc 0.1096
14:40:13.240   Training iter 550, batch loss 0.4518, batch acc 0.1134
14:40:13.730   Training iter 600, batch loss 0.4517, batch acc 0.1150
14:40:13.732 Testing @ 480 epoch...
14:40:13.771     Testing, total mean loss 0.45174, total acc 0.11350
14:40:13.771 Training @ 481 epoch...
14:40:14.249   Training iter 50, batch loss 0.4516, batch acc 0.1206
14:40:14.737   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:40:15.208   Training iter 150, batch loss 0.4517, batch acc 0.1122
14:40:15.673   Training iter 200, batch loss 0.4519, batch acc 0.1094
14:40:16.136   Training iter 250, batch loss 0.4517, batch acc 0.1118
14:40:16.637   Training iter 300, batch loss 0.4517, batch acc 0.1160
14:40:17.152   Training iter 350, batch loss 0.4518, batch acc 0.1142
14:40:17.668   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:40:18.186   Training iter 450, batch loss 0.4518, batch acc 0.1124
14:40:18.686   Training iter 500, batch loss 0.4518, batch acc 0.1080
14:40:19.193   Training iter 550, batch loss 0.4518, batch acc 0.1082
14:40:19.695   Training iter 600, batch loss 0.4518, batch acc 0.1158
14:40:19.696 Training @ 482 epoch...
14:40:20.228   Training iter 50, batch loss 0.4518, batch acc 0.1096
14:40:20.763   Training iter 100, batch loss 0.4517, batch acc 0.1176
14:40:21.267   Training iter 150, batch loss 0.4518, batch acc 0.1124
14:40:21.760   Training iter 200, batch loss 0.4518, batch acc 0.1086
14:40:22.255   Training iter 250, batch loss 0.4518, batch acc 0.1098
14:40:22.772   Training iter 300, batch loss 0.4518, batch acc 0.1064
14:40:23.333   Training iter 350, batch loss 0.4516, batch acc 0.1216
14:40:23.864   Training iter 400, batch loss 0.4517, batch acc 0.1170
14:40:24.398   Training iter 450, batch loss 0.4518, batch acc 0.1110
14:40:24.953   Training iter 500, batch loss 0.4517, batch acc 0.1172
14:40:25.525   Training iter 550, batch loss 0.4517, batch acc 0.1142
14:40:26.072   Training iter 600, batch loss 0.4518, batch acc 0.1030
14:40:26.074 Training @ 483 epoch...
14:40:26.639   Training iter 50, batch loss 0.4518, batch acc 0.1120
14:40:27.182   Training iter 100, batch loss 0.4518, batch acc 0.1098
14:40:27.711   Training iter 150, batch loss 0.4518, batch acc 0.1090
14:40:28.247   Training iter 200, batch loss 0.4517, batch acc 0.1154
14:40:28.769   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:40:29.298   Training iter 300, batch loss 0.4518, batch acc 0.1144
14:40:29.826   Training iter 350, batch loss 0.4517, batch acc 0.1168
14:40:30.340   Training iter 400, batch loss 0.4516, batch acc 0.1172
14:40:30.868   Training iter 450, batch loss 0.4517, batch acc 0.1174
14:40:31.416   Training iter 500, batch loss 0.4518, batch acc 0.1074
14:40:31.920   Training iter 550, batch loss 0.4518, batch acc 0.1090
14:40:32.444   Training iter 600, batch loss 0.4518, batch acc 0.1082
14:40:32.447 Training @ 484 epoch...
14:40:32.939   Training iter 50, batch loss 0.4517, batch acc 0.1188
14:40:33.423   Training iter 100, batch loss 0.4517, batch acc 0.1136
14:40:33.882   Training iter 150, batch loss 0.4518, batch acc 0.1056
14:40:34.356   Training iter 200, batch loss 0.4518, batch acc 0.1096
14:40:34.847   Training iter 250, batch loss 0.4517, batch acc 0.1172
14:40:35.352   Training iter 300, batch loss 0.4517, batch acc 0.1190
14:40:35.867   Training iter 350, batch loss 0.4519, batch acc 0.1036
14:40:36.358   Training iter 400, batch loss 0.4519, batch acc 0.1062
14:40:36.849   Training iter 450, batch loss 0.4517, batch acc 0.1128
14:40:37.344   Training iter 500, batch loss 0.4517, batch acc 0.1132
14:40:37.839   Training iter 550, batch loss 0.4518, batch acc 0.1144
14:40:38.339   Training iter 600, batch loss 0.4517, batch acc 0.1144
14:40:38.340 Training @ 485 epoch...
14:40:38.848   Training iter 50, batch loss 0.4518, batch acc 0.1080
14:40:39.365   Training iter 100, batch loss 0.4517, batch acc 0.1108
14:40:39.842   Training iter 150, batch loss 0.4518, batch acc 0.1110
14:40:40.321   Training iter 200, batch loss 0.4517, batch acc 0.1172
14:40:40.788   Training iter 250, batch loss 0.4518, batch acc 0.1090
14:40:41.257   Training iter 300, batch loss 0.4518, batch acc 0.1070
14:40:41.728   Training iter 350, batch loss 0.4518, batch acc 0.1156
14:40:42.208   Training iter 400, batch loss 0.4517, batch acc 0.1146
14:40:42.710   Training iter 450, batch loss 0.4517, batch acc 0.1106
14:40:43.220   Training iter 500, batch loss 0.4517, batch acc 0.1142
14:40:43.724   Training iter 550, batch loss 0.4517, batch acc 0.1200
14:40:44.219   Training iter 600, batch loss 0.4518, batch acc 0.1104
14:40:44.221 Testing @ 485 epoch...
14:40:44.261     Testing, total mean loss 0.45174, total acc 0.11350
14:40:44.261 Training @ 486 epoch...
14:40:44.782   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:40:45.290   Training iter 100, batch loss 0.4517, batch acc 0.1140
14:40:45.782   Training iter 150, batch loss 0.4517, batch acc 0.1160
14:40:46.270   Training iter 200, batch loss 0.4517, batch acc 0.1128
14:40:46.757   Training iter 250, batch loss 0.4519, batch acc 0.1006
14:40:47.242   Training iter 300, batch loss 0.4517, batch acc 0.1162
14:40:47.722   Training iter 350, batch loss 0.4517, batch acc 0.1158
14:40:48.220   Training iter 400, batch loss 0.4518, batch acc 0.1098
14:40:48.716   Training iter 450, batch loss 0.4517, batch acc 0.1114
14:40:49.197   Training iter 500, batch loss 0.4518, batch acc 0.1050
14:40:49.690   Training iter 550, batch loss 0.4516, batch acc 0.1174
14:40:50.177   Training iter 600, batch loss 0.4518, batch acc 0.1146
14:40:50.178 Training @ 487 epoch...
14:40:50.683   Training iter 50, batch loss 0.4517, batch acc 0.1152
14:40:51.178   Training iter 100, batch loss 0.4518, batch acc 0.1078
14:40:51.665   Training iter 150, batch loss 0.4518, batch acc 0.1116
14:40:52.168   Training iter 200, batch loss 0.4517, batch acc 0.1168
14:40:52.683   Training iter 250, batch loss 0.4518, batch acc 0.1120
14:40:53.193   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:40:53.697   Training iter 350, batch loss 0.4518, batch acc 0.1060
14:40:54.168   Training iter 400, batch loss 0.4517, batch acc 0.1148
14:40:54.645   Training iter 450, batch loss 0.4519, batch acc 0.1080
14:40:55.133   Training iter 500, batch loss 0.4517, batch acc 0.1162
14:40:55.624   Training iter 550, batch loss 0.4517, batch acc 0.1154
14:40:56.125   Training iter 600, batch loss 0.4517, batch acc 0.1130
14:40:56.127 Training @ 488 epoch...
14:40:56.654   Training iter 50, batch loss 0.4518, batch acc 0.1126
14:40:57.174   Training iter 100, batch loss 0.4518, batch acc 0.1082
14:40:57.705   Training iter 150, batch loss 0.4518, batch acc 0.1112
14:40:58.226   Training iter 200, batch loss 0.4517, batch acc 0.1132
14:40:58.736   Training iter 250, batch loss 0.4518, batch acc 0.1106
14:40:59.248   Training iter 300, batch loss 0.4517, batch acc 0.1156
14:40:59.753   Training iter 350, batch loss 0.4517, batch acc 0.1162
14:41:00.273   Training iter 400, batch loss 0.4518, batch acc 0.1114
14:41:00.790   Training iter 450, batch loss 0.4518, batch acc 0.1054
14:41:01.325   Training iter 500, batch loss 0.4517, batch acc 0.1106
14:41:01.878   Training iter 550, batch loss 0.4517, batch acc 0.1162
14:41:02.437   Training iter 600, batch loss 0.4517, batch acc 0.1172
14:41:02.439 Training @ 489 epoch...
14:41:02.976   Training iter 50, batch loss 0.4517, batch acc 0.1166
14:41:03.521   Training iter 100, batch loss 0.4517, batch acc 0.1150
14:41:04.063   Training iter 150, batch loss 0.4516, batch acc 0.1202
14:41:04.615   Training iter 200, batch loss 0.4519, batch acc 0.1056
14:41:05.137   Training iter 250, batch loss 0.4518, batch acc 0.1084
14:41:05.673   Training iter 300, batch loss 0.4517, batch acc 0.1156
14:41:06.221   Training iter 350, batch loss 0.4518, batch acc 0.1096
14:41:06.750   Training iter 400, batch loss 0.4518, batch acc 0.1058
14:41:07.278   Training iter 450, batch loss 0.4518, batch acc 0.1148
14:41:07.770   Training iter 500, batch loss 0.4518, batch acc 0.1102
14:41:08.283   Training iter 550, batch loss 0.4517, batch acc 0.1112
14:41:08.789   Training iter 600, batch loss 0.4517, batch acc 0.1154
14:41:08.791 Training @ 490 epoch...
14:41:09.302   Training iter 50, batch loss 0.4517, batch acc 0.1068
14:41:09.824   Training iter 100, batch loss 0.4519, batch acc 0.1088
14:41:10.360   Training iter 150, batch loss 0.4517, batch acc 0.1206
14:41:10.881   Training iter 200, batch loss 0.4517, batch acc 0.1148
14:41:11.407   Training iter 250, batch loss 0.4518, batch acc 0.1138
14:41:11.957   Training iter 300, batch loss 0.4519, batch acc 0.1016
14:41:12.508   Training iter 350, batch loss 0.4517, batch acc 0.1138
14:41:13.072   Training iter 400, batch loss 0.4518, batch acc 0.1058
14:41:13.643   Training iter 450, batch loss 0.4518, batch acc 0.1088
14:41:14.227   Training iter 500, batch loss 0.4517, batch acc 0.1198
14:41:14.810   Training iter 550, batch loss 0.4516, batch acc 0.1226
14:41:15.382   Training iter 600, batch loss 0.4517, batch acc 0.1112
14:41:15.383 Testing @ 490 epoch...
14:41:15.422     Testing, total mean loss 0.45174, total acc 0.11350
14:41:15.422 Training @ 491 epoch...
14:41:15.981   Training iter 50, batch loss 0.4517, batch acc 0.1148
14:41:16.533   Training iter 100, batch loss 0.4518, batch acc 0.1118
14:41:17.082   Training iter 150, batch loss 0.4518, batch acc 0.1098
14:41:17.633   Training iter 200, batch loss 0.4518, batch acc 0.1096
14:41:18.131   Training iter 250, batch loss 0.4518, batch acc 0.1110
14:41:18.634   Training iter 300, batch loss 0.4518, batch acc 0.1112
14:41:19.143   Training iter 350, batch loss 0.4517, batch acc 0.1130
14:41:19.641   Training iter 400, batch loss 0.4517, batch acc 0.1136
14:41:20.142   Training iter 450, batch loss 0.4517, batch acc 0.1174
14:41:20.632   Training iter 500, batch loss 0.4517, batch acc 0.1122
14:41:21.123   Training iter 550, batch loss 0.4517, batch acc 0.1138
14:41:21.620   Training iter 600, batch loss 0.4518, batch acc 0.1102
14:41:21.621 Training @ 492 epoch...
14:41:22.115   Training iter 50, batch loss 0.4517, batch acc 0.1176
14:41:22.609   Training iter 100, batch loss 0.4517, batch acc 0.1136
14:41:23.117   Training iter 150, batch loss 0.4517, batch acc 0.1112
14:41:23.630   Training iter 200, batch loss 0.4517, batch acc 0.1160
14:41:24.113   Training iter 250, batch loss 0.4518, batch acc 0.1088
14:41:24.569   Training iter 300, batch loss 0.4517, batch acc 0.1136
14:41:25.060   Training iter 350, batch loss 0.4518, batch acc 0.1082
14:41:25.563   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:41:26.078   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:41:26.591   Training iter 500, batch loss 0.4518, batch acc 0.1128
14:41:27.095   Training iter 550, batch loss 0.4518, batch acc 0.1128
14:41:27.602   Training iter 600, batch loss 0.4518, batch acc 0.1072
14:41:27.603 Training @ 493 epoch...
14:41:28.141   Training iter 50, batch loss 0.4518, batch acc 0.1146
14:41:28.680   Training iter 100, batch loss 0.4517, batch acc 0.1118
14:41:29.218   Training iter 150, batch loss 0.4517, batch acc 0.1182
14:41:29.756   Training iter 200, batch loss 0.4518, batch acc 0.1138
14:41:30.299   Training iter 250, batch loss 0.4517, batch acc 0.1126
14:41:30.841   Training iter 300, batch loss 0.4516, batch acc 0.1180
14:41:31.375   Training iter 350, batch loss 0.4517, batch acc 0.1124
14:41:31.915   Training iter 400, batch loss 0.4519, batch acc 0.1028
14:41:32.451   Training iter 450, batch loss 0.4518, batch acc 0.1068
14:41:33.005   Training iter 500, batch loss 0.4518, batch acc 0.1092
14:41:33.533   Training iter 550, batch loss 0.4517, batch acc 0.1192
14:41:34.052   Training iter 600, batch loss 0.4518, batch acc 0.1090
14:41:34.054 Training @ 494 epoch...
14:41:34.557   Training iter 50, batch loss 0.4517, batch acc 0.1132
14:41:35.039   Training iter 100, batch loss 0.4518, batch acc 0.1088
14:41:35.520   Training iter 150, batch loss 0.4517, batch acc 0.1120
14:41:36.022   Training iter 200, batch loss 0.4518, batch acc 0.1112
14:41:36.515   Training iter 250, batch loss 0.4518, batch acc 0.1102
14:41:37.025   Training iter 300, batch loss 0.4517, batch acc 0.1182
14:41:37.541   Training iter 350, batch loss 0.4517, batch acc 0.1178
14:41:38.037   Training iter 400, batch loss 0.4518, batch acc 0.1080
14:41:38.535   Training iter 450, batch loss 0.4518, batch acc 0.1128
14:41:39.020   Training iter 500, batch loss 0.4518, batch acc 0.1136
14:41:39.512   Training iter 550, batch loss 0.4517, batch acc 0.1120
14:41:40.010   Training iter 600, batch loss 0.4517, batch acc 0.1106
14:41:40.012 Training @ 495 epoch...
14:41:40.532   Training iter 50, batch loss 0.4517, batch acc 0.1134
14:41:41.027   Training iter 100, batch loss 0.4518, batch acc 0.1052
14:41:41.517   Training iter 150, batch loss 0.4517, batch acc 0.1190
14:41:42.012   Training iter 200, batch loss 0.4517, batch acc 0.1110
14:41:42.534   Training iter 250, batch loss 0.4518, batch acc 0.1100
14:41:43.044   Training iter 300, batch loss 0.4518, batch acc 0.1116
14:41:43.569   Training iter 350, batch loss 0.4518, batch acc 0.1174
14:41:44.098   Training iter 400, batch loss 0.4519, batch acc 0.1032
14:41:44.647   Training iter 450, batch loss 0.4517, batch acc 0.1148
14:41:45.198   Training iter 500, batch loss 0.4517, batch acc 0.1140
14:41:45.744   Training iter 550, batch loss 0.4517, batch acc 0.1170
14:41:46.297   Training iter 600, batch loss 0.4517, batch acc 0.1118
14:41:46.299 Testing @ 495 epoch...
14:41:46.338     Testing, total mean loss 0.45174, total acc 0.11350
14:41:46.338 Training @ 496 epoch...
14:41:46.887   Training iter 50, batch loss 0.4518, batch acc 0.1108
14:41:47.429   Training iter 100, batch loss 0.4518, batch acc 0.1120
14:41:47.977   Training iter 150, batch loss 0.4518, batch acc 0.1108
14:41:48.538   Training iter 200, batch loss 0.4518, batch acc 0.1100
14:41:49.085   Training iter 250, batch loss 0.4518, batch acc 0.1078
14:41:49.632   Training iter 300, batch loss 0.4518, batch acc 0.1146
14:41:50.173   Training iter 350, batch loss 0.4518, batch acc 0.1124
14:41:50.711   Training iter 400, batch loss 0.4518, batch acc 0.1092
14:41:51.244   Training iter 450, batch loss 0.4517, batch acc 0.1192
14:41:51.731   Training iter 500, batch loss 0.4517, batch acc 0.1144
14:41:52.220   Training iter 550, batch loss 0.4517, batch acc 0.1094
14:41:52.710   Training iter 600, batch loss 0.4517, batch acc 0.1178
14:41:52.712 Training @ 497 epoch...
14:41:53.230   Training iter 50, batch loss 0.4518, batch acc 0.1122
14:41:53.727   Training iter 100, batch loss 0.4518, batch acc 0.1112
14:41:54.227   Training iter 150, batch loss 0.4518, batch acc 0.1120
14:41:54.724   Training iter 200, batch loss 0.4518, batch acc 0.1106
14:41:55.241   Training iter 250, batch loss 0.4517, batch acc 0.1186
14:41:55.747   Training iter 300, batch loss 0.4518, batch acc 0.1102
14:41:56.261   Training iter 350, batch loss 0.4517, batch acc 0.1166
14:41:56.768   Training iter 400, batch loss 0.4517, batch acc 0.1166
14:41:57.277   Training iter 450, batch loss 0.4517, batch acc 0.1128
14:41:57.790   Training iter 500, batch loss 0.4518, batch acc 0.1006
14:41:58.358   Training iter 550, batch loss 0.4517, batch acc 0.1192
14:41:58.933   Training iter 600, batch loss 0.4518, batch acc 0.1078
14:41:58.935 Training @ 498 epoch...
14:41:59.430   Training iter 50, batch loss 0.4517, batch acc 0.1188
14:41:59.914   Training iter 100, batch loss 0.4519, batch acc 0.1044
14:42:00.428   Training iter 150, batch loss 0.4517, batch acc 0.1132
14:42:00.956   Training iter 200, batch loss 0.4518, batch acc 0.1076
14:42:01.498   Training iter 250, batch loss 0.4518, batch acc 0.1118
14:42:02.051   Training iter 300, batch loss 0.4516, batch acc 0.1192
14:42:02.590   Training iter 350, batch loss 0.4517, batch acc 0.1154
14:42:03.134   Training iter 400, batch loss 0.4517, batch acc 0.1138
14:42:03.708   Training iter 450, batch loss 0.4517, batch acc 0.1162
14:42:04.278   Training iter 500, batch loss 0.4519, batch acc 0.1068
14:42:04.842   Training iter 550, batch loss 0.4518, batch acc 0.1104
14:42:05.387   Training iter 600, batch loss 0.4518, batch acc 0.1108
14:42:05.388 Training @ 499 epoch...
14:42:05.917   Training iter 50, batch loss 0.4518, batch acc 0.1118
14:42:06.440   Training iter 100, batch loss 0.4518, batch acc 0.1038
14:42:06.962   Training iter 150, batch loss 0.4517, batch acc 0.1128
14:42:07.467   Training iter 200, batch loss 0.4518, batch acc 0.1136
14:42:07.958   Training iter 250, batch loss 0.4518, batch acc 0.1108
14:42:08.461   Training iter 300, batch loss 0.4517, batch acc 0.1136
14:42:08.943   Training iter 350, batch loss 0.4518, batch acc 0.1136
14:42:09.437   Training iter 400, batch loss 0.4518, batch acc 0.1050
14:42:09.933   Training iter 450, batch loss 0.4516, batch acc 0.1180
14:42:10.429   Training iter 500, batch loss 0.4518, batch acc 0.1150
14:42:10.923   Training iter 550, batch loss 0.4517, batch acc 0.1176
14:42:11.389   Training iter 600, batch loss 0.4517, batch acc 0.1128
======================================================
14:42:11.391 Testing @ final epoch...
14:42:11.430     Testing, total mean loss 0.45174, total acc 0.11350
training time: 3140 seconds
